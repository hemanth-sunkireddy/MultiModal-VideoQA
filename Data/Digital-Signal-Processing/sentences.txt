Welcome back to real time digital signal processing course.
So today we will discuss about discrete cosine transform.
So, how we can implement using both MATLAB and then the DSP processor what we will be looking at it.
So, before giving the demo, so we will have little on the theory part of it.
So, as a recap in the last class we did little bit on speech coding and then its applications.
One of the application was LPC coding what we did both in MATLAB and then.
So, the other applications you can look in and then see that how you can use the speech coding in different applications.
So, today we will see little on image compression basically.
So, mostly we will be concentrating on the JPEG part of it.
So, why do we need compression?
Most of you will be taking lot of images using your mobile phones, cameras and so many other devices basically.
So, then how you are going to represent it most of the time will be telling that our memory is full.
So, we have to move our all images to some storage place what we have to take it can be a cloud or somewhere hard disk and then how you are going to retrieve and other problems challenges what you will be facing it.
So, to say that how the number of bits is going to increase we will see for a bit.
black and white image ok.
So, we say that it has a resolution of or the size of it is 1000 by 1000 is the image what you have taken a thing and each pixel we represent it with 8 bits.
We know that black and white is 0 to 255 is enough for us to represent it.
So, we say that 8 bits are sufficient to represent the intensity of these pixels.
So, now we will see that.
total number of bits what is required is we know that if we multiply 1000 into 1000 into 8 bits.
So, it comes to about as you can see that 80 lakhs bits per image what we needed.
And we say when we are talking about the video this is only the still image what you are talking about and then if we are considering a video for a black and white you know that it is 30 frames per second what we assume the video rate which is at which it is coming.
So, this type what happens we will be seeing that if it is taken for just 3 seconds ok.
So, what will be the value of it.
So, it is 3 into 0.
30 frames per second, 30 frames what I have to store it into whatever we have this value what we will be taking it 80000.
So, you will be seeing that how many bits is required to store our image in any of the storage units.
Then the further still images JPEG compression the compression is one of the popular one.
So, that is joint program extend group actually what it is.
So, here what are the steps involved in it.
So, we know that we need discrete cosine transform usually it is being used for compression.
Then the bits whatever received is going to be quantized and then it is going to be zig zag scanned and then the whatever you use the run length.
the encoding and then DPCM whatever differential pulse code modulation what you can use it.
Then later on use the entropy coding these are the coding techniques what you can use it and then you will be transmitting it.
So, what are the modes available for the JPEG?
It can be sequential what you can have mode or you want to have a lossless compression you can incorporate it or it can be a progressive mode what you can select it or it can be even the hierarchical mode what you can select.
Those these are the options in the modes what you have it for the JPEG.
So, the website what you can visit for more information is given here for you ok.
So, now why we have to select JPEG.
So, the compression ratio of lossless method is that is example is we can use the Huffman coding or arithmetic coding or LZW coding.
So, these are the once what it is used for coding.
So, it is not high enough for image and video compression.
So, although we use these things still the size of the image what we have to store is very high.
So, what happens in the JPEG it uses a transform coding basically.
So, largely based on the following observations.
So, you will be seeing that why do we need the transform.
So, we have looked at Fourier transform in our.
course already.
So, how fast you can make discrete Fourier transform to run using fast Fourier transform.
So, why do we have to represent an signal in the transform domain also what we have looked in.
Now, we will see why we need the transform for our images.
What it says is a large majority of useful image contents change relatively slowly across images.
So, it is unusual for intensity values to alter up.
and down several times in a small area.
So, that is usually we assume the small areas 8 by 8 image block.
So, even you would be seeing when you want to create your video from a small image what you do is I think the famous one you will be seeing that bird in a cage ok.
So, they are two different and if you rotate them varies.
high rotation if you are giving the thing or high speed you rotate it you will be observing the bird in the cage basically that is what the illusion what you will be getting it.
So, it is enough for us to look in the small image block and see the intensity values and whether we can remove some of the things.
So that we need not have to keep those values which are below some threshold what we will be putting it.
So, the translation of this fact into your spatial frequency domain implies generally that is lower spatial frequency components contain more information than the high frequency components.
So, we say that which often correspond to less useful details and then we call them as noises.
So, just like our speech the contents of it is in the lower frequency part of it.
Here also in the images we say at the lower frequency we have more.
coverage of the thing and then at a high frequencies the not much information and then it may be noises.
So, the that is what it says that experiment suggests that humans are more immune to loss of highest spatial frequency components than loss of lower frequency components.
So, if we lose the higher frequency components because of our visual what we call it as seeing capability.
So, it gets the low frequency components much registered than the one in the higher frequency region.
So, how we are going to incorporate this JPEG coding?
So, these are the steps involved.
First we do the discrete cosine transform of each 8 by 8 pixel array.
So, if you know f of x comma y is an image.
So, in the DCT what we will take it.
So, the image what you will be getting it is f.
So, you will be seeing that here it is represented in YCbCr basically.
So, this is the luminance and these are the chromium what you will have it in the image data.
So, you will be if you are considering the colour image.
So, instead of RGB so, we can represent it in this YCbCr format.
So, you will be seeing.
even in storage you have a JPEG image, BMP image, TIFF image.
So, you can compare which one consumes less storage for your storages.
So, we will consider 8 by 8 of the thing as you can see each one is divided into blocks of 8 by 8.
So, we will be using that and then we will do the DCT of it.
Then what we have is F, U, Y is the.
output what we have it and do the quantization.
So, we will call that quantized as FQ of u, v and that output what you will be feeding it for the sending through the channel what you can send it and then this is the receiving channel side of it what you will be looking at it.
So, you will be doing the you can have the either the run link.
coding you can do and then you will be using the differential PCM coding to generate our entropy coding part of it and then it can be stored as data if you want to store it with header and then tables what you will be getting it from your quantization tables of what type of quantization if you have used it for this image.
So, this is how the data is going to be stored and then you will be having the coding.
tables also whether you have used the zigzag scan and then what type of coding tables you will be putting it and then you will be using in storing the images and which you can retrieve it back.
So, what it says is quantization using a table or using a constant what you can do it and then the scanning is going to be zigzag scan to exploit redundancy we will see in a while with an example.
Then you will be using the differential pulse code modulation DPCPN and the DC component.
And, run length coding what you can incorporate on the AC components.
So, then you will be doing the entropy coding that is usually Hoffman code what popularly in the JPEG what you can have it of the final output.
So, what happens?
The first step what we have is the discrete cosine transform.
So, this converts the information contained in our block of 8 by 8 of pixels from.
spatial domain to the frequency domain.
So, in the case of FFT from time domain to frequency domain we transform.
Here it is from the spatial domain will be going into the frequency domain.
So, a simple analogy what it uses is that is uncertain list of 12 numbers between only 0 and 3 value what you are considering.
So, this is the thing what you have it 2312201101 0 and 0.
So, how we are going to do the transformation of this list involving two steps ok. First is sort the list that is we know that what is the this thing either it is upwards sorting you can do or downwards sorting what you can do the thing then sort it.
The second step is what you are going to use is 10100 that is consider with transformation of the list involving this thing 2 steps and then sorry count the frequency of occurrence of each of the numbers.
So, we because we have only 0 to 3 means it is only 4 numbers what we can represent here.
So, how many times these got repeated.
So, you will be seeing that 2 has got repeated 4 times and then you will be seeing that 3 is repeated 4 times this is the repetition rate what you will be putting it and through this transformation.
So, we lost the what we say is spatial information, but captured the frequency information part of it.
So, what is the frequency of numbers occurrence what we have collected.
So, there are other transformations which retain the spatial information like example Fourier transform, DCT etcetera.
So, therefore, allowing us to move back and forth between spatial and then frequency domains.
So, as an So, running the MATLAB that is we consider the discrete cosine transform.
So, this is the original signal what it has been considered and when you take the DCT, this is the DCT values what you will be getting it.
So, as you can see only in the small frequency that is lower frequency you have some values both positive and negative and after that you will be seeing that it is almost 0.
Then what I can do is this can be represented as 0 and then if I reconstruct that is I take the 1D inverse transform then I will be getting back my signal.
to show that how it is going to be the difference between the original and then are this thing reconstructed is shown here.
So, that is blue shows the original one and then the orange one is showing the reconstructed one.
So, you will be seeing that with little difference almost it is following the original one.
So, you will be seeing as an this thing in the case of image how it is going to look like this is original lena image when I take a DCT of this.
that is 2D DCT basically this is how the coefficients what will look like.
And then what we do is we put a threshold and then we eliminate the coefficients and make them zeros then we reconstruct the lossy information then what we after reconstruction we take a inverse DCT.
So, this is the reconstruction part of it.
So, you will be seeing that.
Our human eye perception what you can see is visually what you see is not much difference between the two.
Sorry, I did not take the difference between the original image and then the reconstructed image and then we can plot that also.
So, then we will get the complete information how much information is lot, but still our perception of eye has unable to make out.
So, only if you closely observe what you will be looking with the difference.
So, that is it had a 64000 pixels.
So, from 3200 to 64000 it was made zeros and then only use only 0 to 3200 images to reconstruct.
by using IDCT.
So, we will see in the lab these examples how we will be doing it.
So, now one more comparison we said that even the discrete Fourier transform is going to work in the frequency domain for our images and discrete cosine transform.
So, we will see that with an example you have 8 this thing n is 1D comparison what we are doing it.
So, you have 8 samples with different values what you will be seeing it.
So, it will be in terms of as you can see that.
8, 16, 24 that is what the values what you have at different play distinct samples that is what we say n is 0 to 7 what it is been chosen and these values are passed through FFT and then DCT.
So, this is what the table shows 8 values.
So, you will be getting after doing FFT 36, 10, 10, 6, 6 and then all these are 4s.
When you pass it through the DCT basically, so you will be seeing that this one the first value what we call it as DC coefficient and rest of them we call it as AC coefficients.
So, you will be seeing that maximum value is present in our DC coefficient and then you will be seeing some almost it is we see after the first coefficient rest of them are almost negligible.
So, for reconstruction we will do that 50 percent of the values we strike it off and make them 0s ok.
So, same thing what we will do with.
respect our FFT also.
So, we are striking of these 4 values and then we will take the inverse DCT here and then inverse FFT here.
So, that is IDCT and IFFT what we will be doing it and these are the values what we have got it.
Whereas, in the case of DCT you will be seeing that few of them are exactly represented 824 and then 32, 40, 48 almost same values.
And, then the other one instead of 16 what we have is 15 and then instead of 56 it is 57 instead of 64 it is 63 ok.
But the you can see the graph when we plot it almost it resembles the original plot with little what we call it as loss of information.
When we reconstruct our this thing from FFT that is IFFT we do the thing.
So, you will be seeing lot of difference with.
some places values of it.
So, you will be seeing that here it is gone bad and then here it is little smooth again at the higher end it has gone instead of 64 it is 48.
This is somewhat nearby in these values and then after that it goes down.
So, you will be seeing the advantage of using DCT for compression because we can eliminate these 0s.
That is what it says is we truncate and use inverse transform to compute our F dash.
n in both the cases.
So, coming to 2D DCT.
So, how we are going to incorporate this that is 2 dimensional how do you perform 2D DCT usually what we prefer is 1D transform.
So, how it is going to result in 2D is demonstrated here f of i comma j is your 2D image pixel values what it has been represented here it has been taken as 8 by 8 in this case.
So, first we will do 1D DCT.
that is row wise what you will be doing it.
So, it is shown as row wise DCT what we will do.
And then in the next stage for this input we can do only column wise DCT what we will be taking it.
Since we call it as this is a separable transform DCT.
So, we can use row decomposition and then column decomposition together to get our final output f of u comma v. So, we say that f of 0 0 is called DC component and rest of f of i comma j are going to be called as AC components.
So, how just it is an intuitive example in this picture what you will be seeing it.
So, to show the 2D transform ok.
So, the first one you will be representing all of them are once in thus f of i comma j and then this has a 8 by 8 matrix what you will be seeing it.
So, first we will do the 1D row wise ok.
So, you will be seeing that you will be So, what the function what we are doing is that is f m of w that is mimicking our d c t. So, which will be omega will this is going to vary n will be varying from omega to 8 f of n that is summation what we are doing it.
As you can see first I will be doing it row wise when we add it up this is 8 then omega becomes 0 to either it is 1 then 1 to 8 or it has to be 0 to 7 as you know 8 values what we have to take.
So, omega becomes 2 then we will be doing this summation.
So, which gives you 7.
So, on what you will be doing it and this is how our row wise transformation what it is shown.
Just it is the addition what we have done this is not the one what we will be using it for DCT as it is mentioned here ok.
It is a hypothetical transform and then we will see what is our DCT equation later.
After doing this then we will do column wise ok.
So, how we are going to do column wise?
So, you will be seeing that 8 into 8 64 and 8 into 7 becomes 56 and then you can go on doing that way.
Last one is 8 into 1 ok.
So, which is going to be 1 into 8.
So, you will be getting it 8 here.
The same with the next one.
So, it will be starting if I look from right to left.
So, it will be going from 7 to.
56 same what you have to apply this equation ok.
So, when you add it up column wise you will be doing it.
So, you know that 8 into 8 and here 7 into 8 and 6 into 8.
So, that is how these values have been filled and later on also what you will be doing from here to here what you will be doing ok column wise.
So, this is a intuitive thing to show that how the DCT is going to work in the regular sense the equation is going to be different.
So, this is how you will be getting f m u comma v. Coming with the quantization the next step is in our JPEG compression basically it is quantization.
Why do we need the quantization?
That is to reduce the number of bits per sample.
So, I need not have to as we know that f 7 has to be represented we need 3 bits 1 1 1.
If I have to represent 0 I.
it is enough to show that 1 bit is sufficient for me to represent 0th bit.
So, that is how we can do the reduction that is what it is shown here as an example 101101 which is the value is 45, we need 6 bits to represent and we will truncate it to 4 bits then it becomes 1011 that is what we will be selecting it.
So, I need this also further.
we can represent it as 1 1.
So, compare that is 11 into 4 is 44 against 45.
So, instead of 45 we will represent it as 11 and then because we have represented it 4 bits.
So, I can multiply and then I will be almost nearer 45 ok.
Same way truncate to 3 bits that is 101 what you will be doing it.
So, then what happens the result value what I will get is 5.
So, then what happens it is 8 into 5 what I have to multiply which is 40 again as 45 whether this loss I can take into account that is what will be looking at it.
So, how much quantization it can tolerate.
So, that the more bits we truncate the more precision we lose basically.
So, it depends on how much precision you want to have it.
So, the quantization it is the error is the main source of our lossy compression.
So, I can do uniform quantization that is Q of u comma v is a constant value I can take it and then do the quantization or I can do different ways of quantizations.
So, that is the other one is non uniform quantization.
So, you will be using the quantization tables that is the reason why you have tables in JPEG compression.
So, that is what we say I is most sensitive to low frequencies upper left corner in frequency matrix what it says and then less sensitive to high frequency that is lower right corner.
So, the custom quantization tables can be put in an image as scan header and say what kind of quantization was incorporated.
So, the JPEG standard defines two default quantization tables, one each for luminance and chrominance fine.
So, as an example how the code length we can decrease that is encoding average code length is shown with this way.
A 1 has this thing 18 symbols what will be representing it 18 and then the probability of its occurrence is 0.6 times and binary code to represent 18 is given here and then if we represent with the Huffman coding we represent it as 0 then the length of Huffman code is 1 bit in this case.
So, the same way for A 2 is equal to 25 what it is shown here.
which is occurrence is 0.3.
So, these are the Huffman code length what it is represent 1, 2, 3, 4 and then 5.
Now, if we see how many bits per bits are required to represent our intensity level is shown here.
So, because the occurrence is 0.6 and then I need 1 bit here and then the other ones you multiply this is 0.3 the probability into number of bits.
So, you will be seeing that approximately we need 1.56 bits per intensity level.
So, you will be seeing that does the number of bits required represent our.
pixel intensities drastically is going to be reduced from 8 earlier we had 8 bits which has come down to 1.56 bits per intensity level with our coding.
So, after coding we have to do the scanning.
So, why to do the scanning?
Because in this 8 by 8 different values what we have represented and then we have done the quantization.
So, low frequency coefficients in top of vector basically what we will call it and high frequency coefficients at the bottom what we will look at it.
So, this maps 8 by 8 matrix into 1 into 64 vector.
So, you will be seeing that this is how we will be representing it as 1 into 64.
As you have seen earlier also higher values were for the DC coefficient that is on top and then after that it decreases.
So, this is how will be.
putting it in our zigzag scan what we will do it and then put the values of the bits here.
So, the next one what we say that we will do differential pulse code modulation on the DC components.
So, the DC component value of in each 8 by 8 block is large as we know in the thing.
So, continuously what we can represent it.
So, the first one will be the maximum value what will be having it.
And then use the this thing DPC to represent this that is 1 into 64.
So, this is how.
you will be converting it into lesser this thing value in the initial because the otherwise we need more number of bits to represent this value ok.
So, the next is we can have a run length encoder on AC component that is the 1 into 64 vectors have a lot of 0s in them.
So, more so towards the end of the vector.
So, higher up entries in the vector capture higher frequency that is DCT components which to be capture less of the content.
So, could have been as result of using a quantization table ok. Encode a series of 0s as skip comma value.
So, the this is the pair what you will be sending it ok, where skip is the number of 0s and value is the next non-zero component what you will send.
So, that is sent 0 comma 0s end of block that is sentinel value basically what you will be.
So, you will be seeing that how this is represented and then the run length coding if they are repeating it so many 0s.
So, you will be putting the value skip and then value in this way ok.
So, the next one is what we have to do is entropy coding that is basically for the DC components if you use the thing you will be having size and value what you will be providing it.
So, the code for a value is derived from the following table this is the size what we have it size and value table these are the values and then how you will be generating the code is shown in this.
So, this is how the entropy coding for DC components happens.
So, you will be seeing that as an example if a DC component is 40 and the previous DC component is 48, then what we will do because we are doing the differential pulse code modulation the difference is minus 8.
So, therefore, it is coded as this value.
So, that is 011 the value for representing minus 8.
So, that is these are the values what will be representing it this is the code length.
So, 101 is the size from the same table what you will be taking it and then it reads as 4.
So, you will be seeing that 101 is 5 it reads it as 4 what you will be representing it ok.
The corresponding code from the table at left is 101 here what you are showing it ok. Ok.
So, the code length is 3 bits for 101 this thing size is 4 what you have taken the thing that is length of it is you have chosen as for 8, 4 bits are required and this is how you will be Huffman table for DC component size field what it is shown fine.
Next is what you can have is a entropy coding for your AC components.
So, the range between minus 1023 and etcetera to negative to positive value 1023.
So, you will be coding it as S1 comma S2 pairs basically and then S1 is run length slash size you will have it.
So, how do you are going to take the run length?
The length of the consecutive 0 values that is 0 to 15 what you will take it.
So, you will be seeing that here lot of them have 0s how you will take the run length.
length and then code it basically.
So, the last value will be 0 comma 0 is the end of block for the 8 by 8 block.
So, this one Huffman coded.
So, you have to see this AC code table for what is the run size and what is the code length and then what is the code which is going to be represented and then this will be the run size for these values.
Otherwise, if you are transmitting this length of bits.
So, you know that how many bits are required to transmit.
So, you will be this thing sending it as this way so that you will be reducing your code length.
So, in this case S2 what you will be having S1 comma S2.
So, S2 will be the value.
So, this is the run length or size what you will be sending it and then the value what you will exactly put in here.
Value of the AC component size and then value table this is size.
And, then you have the code length and then code here.
So, the value will be from here ok.
So, this is how you would be doing the entropy coding example what it is shown in this.
So, it is in the as you see only these few coefficients what you have the values rest of them are 0s.
So, you will be seeing that zigzag order it is 12, 10, 1, minus 7, 2 and then 0s ok.
So, minus 4.
after that you are sending it as 56 0s ok.
So, it is 12 read as 0 0s.
So, you will be representing as 0 slash 4 that is 12 is 1011 1100.
So, you will be reading it as these 4 bits basically that is 12 what you will be sending it 1011 the code for what is your thing is 0 slash 4 from AC code table and 1100 the code for 12 from the size and then value table.
So, that is what you will be sending it.
So, minus 7 is sent as this and then next one what you have is two 0s in between minus 7 and then minus 4.
So, you will be sending it in this fashion and the 10 bit code for 2 comma 3 what it is represented and the last one is minus 4 what you will be representing it size and value table.
So, you will be having what is it last one 56 0s have been represented.
So, which is 0 comma 0.
1 0 1 0 rest of the components are 0s.
Therefore, we simply put the end of block to signify the to show that this is the end of the block ok.
So, this is what how the coding has been implemented in JPEG.
So, the rest of the components what we will see it in the next class DCT we will continue and then we will see how quantization is going to be done ok.
Thank you.
Happy learning and then have a nice day.
Welcome back to real time digital signal processing course.
So we are discussing about discrete cosine transform in image processing.
So we will continue in today's class also.
So, in the last class we discussed about discrete cosine transform where it is being used we know that it is in JPEG compression.
So, today we will continue with some of the properties what we are discussing about JPEG.
So, here we will see the JPEG modes.
So, that is the first one is we can have sequential mode that is each image is encoded in a single left to right.
top to bottom scan.
So, this technique we have been discussing so far in is an example of such a mode also referred to as the baseline sequential mode.
And it supports only 8 bit images as opposed to 12 bit images as we have discussed it earlier.
Coming to the second mode, so we will see that it is lossless mode that is truly lossless what we call it.
What do you mean by that?
So, we will be doing the predictive coding mechanism opposed to the baseline mechanism which is based on DCT and quantization that is source of the loss.
So, here the simple block diagram of the technique is what it is shown in this.
So, what we have is this is the image what we have it.
So, we will find the predictive difference.
So, which is shown in this diagram.
Then we will do the.
Huffman encoder, then we will be calling this as the last list coding.
So, as you can see in this figure, there are 7 predictive coding techniques which is going to be used.
Here, it is going to be unknown parameter in the P1 and the surrounding images pixels what we call it which are 0 0 and 1.
In this case, in the P2 mode, it is going to be 1 0 0.
and so on what we will be using it.
As you will be seeing in the p 5 we have 1 minus half and then half same way with p 7 we have half 0 and then half.
So, we will see predictive coding how it is going to be used.
Only we are going to consider the difference in this case.
So, that is for each pixel a predictor that is what we shown one of the 7 which is listed in the table here is possible.
So, that is used best predicts the value contained in the pixel as a combination of up to 3 neighbouring pixels as you are seeing it this is the pixel.
So, it can be a, c, b, r these 3.
So, the predictor with respect to that if it is in the p 1 only a what you will be selecting it p 2 b and p 3 c and then the other combinations what you can see the thing up to p 4 to p 7 with respect to a b and then c.
What we say is the difference between the predicted value and the actual value that is x containing the pixel is used as the predictive difference to represent the pixel.
Instead of directly sending the value of that pixel, so we will be computing predict the difference and then what it belongs to, so that number of bits are going to be less to represent them.
The predictor along with the predictive difference are encoded as the pixels content.
So, the series of pixel values are encoded using as in the previous slide it depicted using the Huffman coding.
So, one has to take care of it that is what is this nodes.
The very first pixel in location 0 comma 0 will always use itself and pixels at the first row always use p 1 that is pixel in row they will use p 1 and pixel at the first column always.
In this use P2 technique ok and then the best that that is what of the 7 predictions is always chosen for any of the pixel in this portion.
So, here it is selected as 5 by 5 pixel what it is shown, but usually we will take 8 by 8 pixel as the sample.
So, then how we are going to continue with the progressive mode.
So, from the.
previous one predictive.
So, we will see progressive how it is going to go.
So, it allows a coarse conversion of an image to be transmitted at a low rate which is then progressively improved over subsequent transmissions.
So, as you will be seeing spectral selection, send DC component and first few AC coefficients first and then gradually some more AC coefficients what you will be selecting it.
So, what is it?
So, you will be seeing that in the 8 by 8.
So, these are your red depicts your DC coefficients.
So, first scan you will be sending all the dc coefficients.
In the second scan what you will be seeing it.
So, you will send some few ac coefficients like that you can send some more ac coefficients which are dominant as you can see the thing the last one is yellow that is nth scan you will be sending these coefficients.
This is how in the progressive mode you will be sending the coefficients.
So, as you can see that in the progressive mode successive approximation all the DCT components are sent few bits at a time.
For example, send n 1 what it says is 4.
So, you are seeing that these are the 4 pixels which are sent ok.
Bit starting with MSB of all pixels in the first scan.
The next n to say in this case only one bit.
what it will be sent here that is the complete length of it.
So, you will be seeing that this 4 bits that whatever the length of it is going to be our first scan and then the second scan what you are seeing it here and then bits of all pixels in the second scan and then so on what you will be doing it.
So, you are seeing that till the end that is LSB bit.
So, that is 1 pixel what for the rest of the thing what you will be sending it.
Last one is that is in this case it becomes fifth scan which you will be transmitting yellow.
And then this is what you have ordered the pixels in the zigzag wise basically on this axis.
So, the other mode is the hierarchical mode what you have to incorporate.
So, this is used primarily to support multiple resolutions of the same image which can be chosen from depending on the targets capabilities.
So, the figure shows here description of how we are three level hierarchical encoder or decoder is going to work.
So, what is it?
So, you have I as the image input here.
So, you have a 4 by 4.
you call it as I 4, then do the encoding of it and then you will call it as L 4 basically and then you will be at the decoder end that is you will be doing the decode and do the conversion to 4 by 4 and then output will be I dash 4 what you will be getting it.
So, the same thing encoded at the encoding side also you can decode and then convert it into 2 by 2.
So, you will be seeing that the next 2 by 2 whatever image thing what you have taken you call it as I 2, then find the difference between these two.
And then you will be encoding this value and then calling it as L 2 and you will be transmitting it.
So, the same thing the next level is you are passing this encoder to decode.
And, then you will be doing the addition of the thing from whatever 2 by 2 what you have it and then you will call it as the 2 by 2 and this will be passed on to the third level.
So, which will be subtracted with respect to the original i and then do this encode and call it as L alone.
And again at the decoding place you are doing the.
decode of these 3 level whatever encoded message.
So, we got I 4 dash.
Now, the same thing what you will be taking it and then doing it as 2 by 2, then you will be adding with whatever you are getting from L 2 and that you call it as I 2 dash.
The same thing will proceed to the next stage that is 2 by 2 and then whatever it decoded at this.
last stage is going to be added and then you will be calling it as I dash ok so where this JPEG common applications lie so one of the application is the JPEG format what we have it and in MPEG one that is this is the joint distinct group what you have it this is MPEG is a moving average what you have one and then two And, then MP3 is the audio player and even in the advanced audio coding and then in WMA most of them use are DCT method for compression.
So, that is what is common in all these applications what you have the DCT coming into the thing.
So, now, we will see a little bit on wide dimensional DCT.
How does it look like?
So, we say n be a positive integer, the one dimensional DCT of order n is defined by an n by n matrix C will be using A and C interchangeably.
So, wherever C matrix in some of the applications we may call it as A matrix.
So, whose entries are given by that is C i comma j is given by.
A i into cos i of 2 j plus 1 into pi divided by 2 n. What is the advantage of orthogonality we will see the thing?
If c is orthogonal then we say that c transpose c is going to be identity matrix i.
That implies that when you take a inverse of c which is equivalent to c transpose itself.
So, this makes us solving the matrix.
equation easy that is shown here that is y is c into x into c transpose for x then what happens to c transpose y when I take c transpose of y and then c transpose on the right hand side also.
Then it becomes c transpose c into x into c transpose here which is nothing, but x into c transpose if you multiply with c c transpose y into c is nothing, but X into C transpose C which becomes X.
So, now, you will be seeing that how Y and X can be computed interchangeably basically that if our matrix is orthogonal.
So, X will be what is it C transpose Y into C whereas, original Y is nothing, but C X into C transpose.
So, it does helps in computation that is both synthesis and analysis equation.
becomes easy for us to do the computation.
Now, we will see for the discrete cosine transform that is we have taken here n length basically.
So, one basic characteristic is it is real orthogonal matrix.
So, what is it which is given by c is equal to root 2 by n into the all the first columns are 1 by root 2.
So, the next one is cos pi by 2n.
n and then cos 3 pi by 2 n and so on.
So, the last one entry will be cos 2 n minus 1 into pi divided by 2 n. And in the last row what we have cos n minus 1 into pi by 2 pi and so on.
And the last entry will be n by n entry is cos n minus 1 into 2 n minus 1 into pi divided by 2 n. Now, we will see either C inverse or C transpose how does it look like.
that is root 2 by n and we know that row becomes column in this case and you will be seeing cos 2 pi by n and then this row is becoming this column and you will be seeing this last column entries cos of n minus 1 into pi by 2 n and so on and then this is the last n by nth entry is the same as the original.
So, how we are going to do the classification of our DCT algorithm?
So, either we can do direct 2D method fine.
This 2D transforms what we call it as both DCT and IDCT to be applied directly on the n by n input data items or we can go with row column method.
That is the 2D transform can be carried out with two passes of 1D transforms.
So, we will be applying the separability property of 2D DCT and IDCT allows us to transform apply in this 1D fashion that is one dimension row then on the other column.
So, this requires what we say 2N instances of endpoint 1D DCT.
So, to implement an N by N 2D DCT that is one of the advantage of using it and then what we call it is this computation is.
So, what do I mean by in place is?
So, whatever the original your matrix what it has it.
So, same thing can be replaced with the new data.
So, that I need not have more storage for this computation and it is much faster also we will see in a while.
So, now how we are going to do the row column decomposition.
So, we said that separable row column decomposition what will be using it.
So, in the matrix form what it is given as z is equal to x into a transpose what we have it and then a k of n is nothing, but root 2 by n into c of k, n is the order what will be taking it and then these are the cos 2 pi into 2 n plus 1 into k divided by 4 n. So, these are the coefficients what we have it.
k and n will be varying between 0 to n minus 1.
And we know the first coefficient c of 0 is root 1 by 2 and then the other coefficients k is equal to 1 to n minus 1 that is what it says for k is not equal to 0, c of k coefficient is going to be 1.
As you can see in the previous this thing, you will be seeing that this is root 2 by.
n what we have taken the thing.
So, this is 1 by root 2.
So, you will be seeing that the first c 0 is 1 by root 2 basically.
So, which we can take it as 1 by root 2 and then rest of them we can assume it as 1.
Then what happens to our equation?
So, x is the input or 1 d dct unit.
So, what we are going to compute here y is equal to.
The first stage of the thing A into x, then we will be doing the transpose the memory of Y.
So, Y we have to do the transpose.
So, you will be seeing that this is my transpose of Y here it is C what it has been done here A into x what will be transposing.
Then I will do the 1D DCT same unit I can apply 1D DCT unit.
then I will be getting y into A transpose.
So, that is my z what it is shown here.
So, this is how we do the row column decomposition and then computation.
Now, why we have to use this?
So, carry out the computation as a full matrix vector multiplications.
We know that 1D transform requires n into n multiplications which is nothing, but 1D order of n squared multiplications and then n into n minus 1 additions what we needed.
So, this also order of n squared whereas, our 2D transform requires as we know that all is length n which is going to be order of n to the power of 4 and then multiplications and this one order of n to the power of 4 that is n into n into.
n minus 1 additions what we needed if we are using direct 2D transform.
So, although requiring most number of operations this method is very regular and most suitable for vector processors are deeply pipelined architecture what we have discussed for high processor execute our processor engine basically utilization.
So, what is it?
So, we can have 1D fast algorithms, we can just like our FFT we can configure our DCT also for the fast algorithm, which brings down to order of n log n instead of order of n squared what we can have computation.
Whereas, a 2D fast algorithm we can incorporate it in order of n into n log n a ways that is order of n squared log n.
what we will be getting directly if we are doing the 2D algorithm.
So, one of the applications I will be showing that how this can be incorporated later.
So, now, we will see why we need the compression we have been discussed in the last class also.
So, there are different ways of doing the compression.
So, we know that is a method that reduces amount of a memory takes to store in image.
So, we discussed in the last class so with 3 milliseconds.
data, how much video we have to store it.
So, how we can reduce it.
So, that DCT matrix is based on our visual system for the purpose of image compression.
And this means we can delete the least significant values without our eyes noticing the difference.
There are different ways of doing the compression.
So, the first one we have discussed we will just go for one more.
time to see the thing.
So, what is it?
We have found this matrix that is y is c transpose whole transpose what we wanted.
And we say in this case this is the most important part in our image what it is required and these are semi important and these are the least important values what we are interested in.
So, using the DCT the entries in y will be organized based on the human visual system.
The most important values to arise will be placed in the upper left corner of the matrix.
And the least important values will be mostly in the lower right corner of the matrix as you are seeing it here.
So, the next one to show that what are the DCT coefficients how it is ordered ok.
So, you will be seeing that the first corner you will have the DC in terms of frequencies as DC component is here and rest of the frequencies that is low frequencies which are present in the.
this domain same as our previous one we have the medium frequencies and these are the high frequencies.
Most of us know that high frequencies is a noise so, that we can eliminate that.
And then when we are looking at some of the edges what we are going to want to put it in the frequency domain that is in the DCT coefficients.
So, we will have the DCT and the vertical edges are represented.
in the horizontal coefficients.
Whereas, the horizontal edges values are represented as are column wise in this and all these are high frequencies what we will be representing it.
So, coming to the image compression.
So, you will be seeing that it is 8 by 8 pixels.
So, this is the grayscale what we have taken the thing that is some of them are white, some of them are black and then some of them are gray.
So, this is how the pixels can be taken or one of the best way of doing it is take a checker board which has both white and black components only and then see how the compression is going to look like.
And then we have taken an image here all of you know that this is an input image lena.
So, which is there in the matlab you can choose this or from anywhere you can download different images and then you can represent.
So, we will see the compression how it is going to have it.
The first one is we can do a greyscale example what it is taken.
So, the value what will be representing is 0 to 255.
So, 0 represents black and 255 represent white and in between values will be different levels of grey what will have it.
So, as an x what you will be seeing is these are the values what you will have it in the matrix.
So, you will be seeing some of them are 214, 208, 198 and other things the first one is 63.
So, now, we will have we will do the.
So, 2D DCT of matrix what we are going to do it.
So, numbers are coefficients of a polynomial what we will take it and this is after doing the 2D DCT for this x value we will be getting y.
So, these are the values what it is represented.
So, we can see that this is dc minus 304 which is what we call it as 255 white and then you will be seeing that they will be having different values approximately this is minus 327 and 260 what you will be seeing somewhere here ok.
So, some of them are that is represented as black and then you will be seeing rest of the thing and then you are seeing that some of them have very less values.
So, what is it?
I can put a threshold.
So, that is above that I will be making them 0s or below them I will be making 0s and above threshold I will be making them whatever they have it.
So, what is the threshold you can put the thing here?
As you can see that the values less than arbitrarily you here it is chosen ok. As you can see here I have a 12 here 30 ok.
So, some of them are getting eliminated.
One way of doing the thing is I can put a threshold saying that above any value 10 or below that what I am going to make them 0s.
I can do that way or.
one corner of it what I can do it because these are going to be 0s.
So, what you have selected is from here you have made them 0s basically all of the lower side of the matrix ok.
So, this is one way of selecting rest of the what we say we are going to keep the coefficient as it is that is cut the least significant components that is what it is done that is we save a little over half the original memory by doing it.
So, this is one way of doing our compression.
So, in the next class we will see other ways that is we will use the quantization matrix.
So, to say that we will be dividing by that quantization matrix and then we will discuss that how it is done and then we will take the demo of the DCT also.
So, thank you and then happy listening.
We will meet in the next class.
So, welcome back to real time digital signal processing course.
Today we will discuss about some of the real time constraints what we are going to have it and then how to.
solve and then look for the built in DSP processor or how to design our own DSP processor in FPGA.
So, we will do the recap first.
In the previous class, we discussed about DSP architecture in detail.
So, hope you are comfortable with the architecture whatever we have used.
In this class as I mentioned, we will be seeing some of the real time constraints.
how to design the DSP for such applications.
What are the real-time constraints?
The major limitation of DSP systems for real-time applications is the bandwidth of the system.
So, the processing speed determines the maximum rate at which the analog signal can be sampled.
As an example with sample by sample processing.
So, if we use the interrupt driven service, one output sample is generated before the news input sample is presented to the system.
Then either we have to forego what we say is lose that sample if we are unable to compute our algorithm within that time or use buffer to store it that is if we do not want to lose any of the sample.
So, we have to have a buffer to store that.
whatever sample which is coming much faster than our computation time.
So, what it says therefore, the time delay between input and output for our sample by sample processing must be less than one sampling interval.
So, we have discussed that 80 seconds is my sampling time what I have it in seconds.
So, our processing time tp plus our overhead I o overhead together should be less than our sampling.
So, as it is defined TO is our overhead I O operations which takes that is the data which comes from input and then till the output is going to the system or wherever you are storing that we call it as TO will be the overhead.
And then TP will be our signal processing time the algorithm which you are going to incorporate in your computation basically.
So, the other constraint what we are going to see.
So, one we say that it is hard real time constraint, which is going to limit our highest frequency of signal that can be processed by our DSP systems using sample by sample processing approach.
That means, to say that I am unable to hard real time system constraint is one such that where I cannot afford to lose even a single clock cycle.
I have to process and then my result should be ready before the next sample comes.
In that case what happens to our bandwidth?
We say f m is the maximum frequency I can allow in my input sample.
So, that should be less than or equal to half the sampling rate which is driven by our sampling theorem constraint which should be less than or equal to 1 by 2 into our T p plus T o that is my processing time as well as my overhead for I O operations.
So, it says that the no long the longer the processing time.
T p that is my processing time is much greater then what happens lower will be the signal bandwidth that can be handled by the system as we can see from this equation.
So, coming to how to do the system design that is our digital signal processor system design how we are going to take it.
So, the first one is we will be seeing that DSP system is going to be characterized by the embedded algorithm.
which specifies the arithmetic operations to be performed.
So, the next step is the algorithm for a given application is initially described using difference equations and or signal flow block diagram with symbolic names for the inputs and outputs.
The next stage of the development process is to provide more details on the sequence of operations that must be performed in order to derive the output.
two methods which characterize the sequence of operations in a program.
One is using the flowcharts or structured descriptions one can give it.
So, in this case you will be giving the structured description it derived from your application for whichever application you are designing your processor you will be specifying that and then you have to consider all the system specifications in this case.
Then, you will be going for the algorithm development and then initially we will be doing the simulation.
So, that all our algorithm is working correctly, then we will be seeing that which DSP processor I have to select or which DSP processor I have to design if I am using the FPGA.
Then we will be coming for the software architecture, how to steer this hardware or I can generate my hardware schematic.
And, then I can generate the hardware prototype here.
Then in the software side we will be seeing that I have to do the coding and then debugging.
So, that the complete system is working as nowadays we will be seeing that hardware and then software code design is the popular one in the present scenario.
So, both of them will be going hand in hand if it is possible.
Otherwise, we have to do them separately and then merge here.
in the integration system here.
So, we have to integrate both software and hardware and then the do the debugging see that my software and then hardware are going correctly according to my application.
Then we will be doing the system testing and then we will be releasing my hardware.
So, even the system testing involves lot of test to be conducted it depends on how you will be for all cases you may do the testing and some of them may be left out because exhaustive testing is going to take a lot of time.
So, mostly some of the testing will be critical ones will be done and then we will be releasing our product or for whichever application we are doing our hardware which is going to be released.
Coming to the software side ok.
So, how general purpose processor is advantageous we will see it here.
One is we know that we use the high level languages.
such as we can use the MATLAB or C plus C or C plus plus or other DSP software packages on computers can significantly save algorithm development time.
So, even nowadays the python is the one of the popular one, one can use it and then test your prototype basically.
In addition the prototype C programs used for algorithm.
evaluation can be ported to different DSP hardware platforms.
So, one of the advantage of using the higher level language is it is independent of the platforms and with little bit of fine tuning.
So, we can port from one DSP hardware platform to the other DSP hardware platforms.
And then the other one is it is easier to debug and modify high level language programs to computers using integrated software development tools.
As an example you are seeing the DSP algorithm which is there I can specify either in MATLAB or using C plus C or C plus plus.
And, then the this is the DSP software what will be using it and data inputs for this software which will be coming from the external ADC or any other computers what you can take it as an input and you will be storing it in the data file.
And then you perform your software operations and see if you are meeting all your requirements for that particular algorithm.
So, if.
If everything is done, so you can specify some of the signal generators back, you can store it in the data file and then it can be reused.
So, if the complete algorithm is satisfactorily working, then what you will be doing is you will be generating the data files, you can send it for either for analysis or if you want to have the analog output, you will be converting this digital data into analog and sending it.
out to other hardware or you can save them as digital data in other computers also for later use if you want to have it.
Continuing with development of software basically on the general purpose computer what happens to our I O operations.
So, it will be based on disk files, so it is easy to implement and behaviors of the system are easy to analyze all these operations.
And, we know that we have a floating point data formats and arithmetic can be used for computer simulations thus ease of development.
So, as we can see even the fixed point file system is available in MATLAB.
So, if I want to test my floating point data if it is working and then I want to convert it into fixed point and then see that my code is running perfectly.
almost equivalent to my floating point operations, I can check it and then use them in my hardware development.
So, we will see that we call that as the bit true simulations of the developed algorithms which can be performed using MATLAB or CRC++ for fixed point DSP implementation.
So, our algorithms will be running depending on what software I will be using it on the general purpose computer.
So, the next one is how we are going to decide on the selection of DSP hardware.
So, we know that the hardware cost and product manufacture integration are important factors for our high volume applications.
So, one is concentrating on high volume.
So, we have to see the cost and then the manufacture integration how it is going to happen.
So, we know that for portable.
that is battery powered products, power consumption is more critical.
All of us use our mobiles, they have DSP processor built in them, all of us are power hungry as you know about it.
I want to save my power and I should not be charging my mobile and then I want all the features in them to be working for full day.
So, that I need not have to use the power banks in these cases.
So, this becomes the critical component of our portable devices.
And then for low to medium volume applications, there will be trade off among development time cost of development tools and the cost of the hardware itself.
So, in this case I do not want to have high volume products to be coming out, but mine is going to be low and medium, but at the same time I have to look at it my cost should not be going up.
At the same time I should provide whatever features that are required at the low cost.
So, the likelihood of having higher performance process with upwards compatible software is also an important factor.
So, one has to look at it that the they have to be programmable using higher level software basically that is like.
Either I can interface with MATLAB or I can use CRC plus plus programming so that one is at ease in programming.
So, for the high performance a low volume application such as communication infrastructures and wireless based stations the performance ease of development and multiprocessor configurations are the paramount in this case.
So, in the communication field you will be seeing that.
All of us will be hungry with our network.
So, I want immediate connectivity as we connect to other person or any other devices or whatever may be the thing.
I do not want to lose my time in that.
So, that way we say that this becomes the performance becomes the paramount in that.
And even the development of that and how we will be using the multiprocessor in those cases.
I have to increase my hardware and then the cost.
may little go up, but try to see that we try to keep the cost also at a low whatever possible.
Continuing with the hardware selection.
So, some of the ways one processor execution speed is compared is as follows.
So, usually we say it is MIPS that is million of instructions per second, how much the processor is doing it or we say MOPS it is millions of per second.
Otherwise it is going to be millions of floating point operations per second we call it as mega flops basically or the clock rate should be in the megahertz range what we have we wanted or in terms of my multiply and accumulate I should be able to do millions of them that is mm max what we will define.
So, these are the earlier comparisons one used to make it.
But, nowadays any of the DSP processor if you go to Buckley site actually you will be seeing how the processor are going to be tested.
It is based on the application previous to application it was on the algorithms whether you want to run the filter algorithm or discrete Fourier transform what you want to run it or any other adaptive filter applications wise basically that is algorithm wise the testing used to be done.
So, each one will not have the same hardware built in, but how well they react to these algorithms was getting tested.
So, but later on they found that even the algorithm level is not sufficient, it is in the application level one is going to test that how fast these applications in can run in their hardware.
So, you will you can go to the Berkeley website and then see that how the processors are.
tested for their operations.
In addition to these low level actually we need other matrix to be considered that is we call it as milli watts.
So, you will be seeing that power consumption always have to be in milli watt for measuring what are the things power consumption that is a mips per milli watt what we will call it instead of instructions per second I want to consume.
based on my power or MIPS per dollar also.
So, you will be seeing the cost is also coming into picture.
So, these numbers provide a simple indication of performance, power and price for the given applications.
So, depending on it you will be deciding on your hardware.
So, how we will do the selection of the DSP hardware we will continue with the thing.
So, we have number of DSP applications.
along with the relative importance for performance, price and then power consumption as we have already said.
So, which is given in the this table.
So, for handheld devices that the primary concern is power efficiency.
However, the main criterion for the communication infrastructure is performance.
So, these are the one low end to the high end what you will be traversing here.
So, the first application we will be considering was the audio receiver.
So, the performance what we want is 1 and price should be medium and power consumption should be low.
So, you will be seeing the rating is 1 to 3, 1 being the most important one and the 3 is the lowest one.
So, we want to have a low power consumption in this.
So, we know that hearing aid have DSP processor.
So, what is the constraint in this?
The performance is what we are claiming is medium and then my price has to be very low and power consumption can be little more what we say.
But still most of the cases that is power consumption has to be very low in this case because one person will be wearing it.
So, if it is a middle class or low class family who is using the hearing aid.
So, you can see that the.
that they have to replace in a day or in a week or in a month what you will be calculating it.
So, the next one now I think mp3 players are getting outdated, but they are more important earlier days for all our music and other things now because of the mobile all the players are available for us in the mobile system itself.
So, in this case what we say is the performances.
not such criteria and then price has to be as minimum as possible it is very important then then power consumption is in between because it is not being used continuously.
So, we can take it that it can have a power consumption of medium rate.
Coming with the portable video recorder one uses the thing.
So, which has to have the middle performance what we.
call it and then the price has to be minimum and then our power consumption has to be little more or whatever.
So, desktop computer we know that performance is the critical part of it and then price is a middle what we compare and then power consumption because it is connected to the mains basically.
So, not much botheration in this case.
So, you will be seeing like that notebook or cell phone handset.
And, then last one is cellular base station which is power hungry for your computation.
So, we say the performance rating is 1 and then price is 2 and then your power consumption is going to be 3.
So, that is how we have the list says that how the DSP applications with relative importance rating in this table.
Coming to the processor selection, so when processing speed is a premium.
The only valid comparison between processor is on an execution time must be compared.
How fast because I need the algorithm my or application running at most speed.
So, then I have to see that how execution of my algorithm is going to have it done being done in my processor.
Other important factors are memory usage and on chip peripheral devices.
such as on chip converters and I O interfaces.
So, some of the cases as we say that memory usage is very much you will be seeing that our portable device like I will be giving example of our mobile always what we want is the memory usage we want to have there is no end for asking for more memory every time.
So, whatever memory you want to add on with.
other devices or try to save it in some place or in your cloud or whatever you will be doing the thing if it is overflowing.
And then whether can I have on chip peripheral devices.
So, in the mobile itself what are the things I needed I have to answer my call, I want to see my movie, I want to listen to my music.
And then what else lot of applications what I needed.
So, you will be seeing lot of WhatsApp messages what so many.
peripherals which are connected to this device what you can have it.
And then I need on chip converters also because you will be seeing that we have different network providers how will I be switching from one vendor to the other one.
If I have a BSNL SIM or no what I will call it as Airtel SIM.
So, both are incorporated in the same mobile I should be able to.
or I must be able to have converters for me to change from one vendor to the other one.
So, these are the important ones.
Next one in addition to this we need full set of development tools and support listed as follows are important for digital signal processor.
Why do we need the tools?
Because we are in the development stage.
So, we have to see that our algorithm is going to run.
And, then our application is met and then all the testing is done.
So, these are the capabilities that development tools should have.
The first one we will say is the software development tools such as C compilers, assemblers, linkers, debuggers and simulators.
This is C compilers we know that it is the higher the software what I needed.
So, that I can have the.
I need not have to worry about the hardware which on which I am going to run.
The next one is assemblers because all DSP processors we say that assembler is equivalent almost our machine coding.
So, they usually we do C 2 assembly conversion or one can do the programming written in assembly language itself.
So, disadvantage of assembly languages it is particular to one of the hardware and this is not portable.
person who is writing the code or software should be knowing the in and out of the hardware or the architecture.
So, that he is going to use them in a better way.
The other one is linkers because I will be using some of the libraries which are present because or if I develop my own library I must be able to save them or combine them.
So, that I will be working on it.
So, it will be linking all the files and then next is debuggers.
So, this is one of the important thing because if I have done a mystic or if it is not running based on my intuition then how I am going to do the debugging and see where it is getting stuck or it is taking more time.
So, that that part of the code whether I can optimize on it and why do we need the simulators because I would not be able to go and buy all the DSP process for my applications.
So, I have to see that whether it is going to run on this platform.
So, if I have a simulator I can simulate and then check if it is doing the performance in this particular DSP processor, then I can go and then buy and then install the thing or this chip is suitable for me that is what I can say.
If it is not possible then I have to try other vendors or I have to design my own algorithm once I have tested it that it is working.
Then I can go for my own design in FPGA or VLSI.
The commercially available DSP boards for software development and testing before the target DSP hardware is available that is one of the criteria what we are looking at.
The other one is hardware testing tools such as in circuit emulators and logic analyzer should be able to pinpoint where the error is coming from.
The other one is development assistance such as application notes and DSP function libraries and application libraries, data books, low cost prototyping and so on are the criteria for the processor selection.
Coming to the software development, we have there are four common measures for of a good DSP software.
What are they?
The first one is what we call it as real reliability.
The reliable program is one that seldom or we say never fails.
So, that is what one of the thing.
So, you will be seeing that Google never goes down or whatever may be the thing or you can say that it has gone down in once in 20 years or what you call it.
I think you will be seeing even the banking system, you will be seeing that whenever they are doing the updation or something like that it goes down for one or two hours that is you will be getting the message, but we do not want this basically happen or seldom what we call it.
The next one is the maintainability.
Since most programs will occasionally fail, we know that although it has been considered you can think of 2000 case nobody had considered that our computers will sustain so many years.
So, all of them Y2K problem so, you know that how everybody has to.
go and then redo their checking and then redesigning all their software and other things to take care of beyond 2000 and beyond.
A maintainable program is one that is easy to correct.
So, that is what the thing what one needs it.
So, that I can modify it.
So, that I can maintain whenever I want to change some of the things which I found out that it has got.
error in it.
The other one is extensibility, what when do we say that program is extensible that is from one platform to the other platform I can extend it.
So, whenever the requirement changes also I can easily modify that.
So, that the extension of the program is easy in that case.
The other one is efficiency that is a good DSP program often contains many small functions with only one purpose which can be easily reduced by other programs for different purposes that is what we call it as efficiency.
Coming further with the software development we know that hardware and software design can be conducted at the same time for a given DSP application that is what I discussed when we are doing the DSP system design.
So, we said since there are many independent factors between hardware and software which restricts them actually what we call it as may not be a true system engineer should be capable of understanding issues with both hardware and then software.
So, most of the people you will be seeing that IT software industry most of us or something we say that we are capable of solving the software, but not in the hardware.
So, one person as you can see that he can understand both the hardware and software he can do a real justice to the.
hardware which has come out.
So, which is going to be rare.
So, that is why we will be having a little bit of difference between the two.
So, as we know VLSI has come a long way.
So, our hardware has the cost of it has gone down dramatically as you will be seeing it whatever buying of your laptop or system or your mobile or any product for that matter.
So, you will be seeing that your cost is going down.
But major cost of our DSP solutions it resides in the software development.
So, as I can point out we used to have software cost was much higher than in 1000 dollars earlier for our emulators that is JTAG interfaces compared our own system which was in 400 dollars or something like that.
The software lifecycle involves completion of the software project.
So, namely that is project definition, detailed specifications one has to have it, how you are going to do coding and then you will be having the coding also you can do modularly.
So, that testing becomes easy.
The next is system integration all of them have to be your hardware and then software has to be integrated and finally, how you are going to test it and later on you will be seeing that your product software.
maintenance is one of the important criteria in your software development.
So, continuing with this maintenance is a significant part of the cost for DSP systems.
How we are going to do that?
What are the things that are there in maintenance basically?
One is enhancing the software functions, fixing errors identified as the software is used.
As you will be seeing even in your mobile you will be getting.
updates for your software.
So, from one stage to the other one within one year you may be having multiple software updation which is going to come.
So, you should be able to have more functions incorporated and then if there are bugs in the earlier cases how you have rectified and then identification and then how you will be updating them in your next software.
And then modifying the software to work with new hardware and then software.
So, you will be seeing that iPhone has its own operating system whereas, Android has its own operating system, but the devices may be from different wonders vendors basically.
So, how the Androids the platforms will be having the same software which is running on different platform.
So, it is important to use meaningful variable names in source code and do document programs, thoroughly with the.
titles and comment statements because this greatly simplifies the task of software maintenance.
It is not just writing and then leaving it like or solving our own problem or a math problem, we have to document how it has been done.
So, it will be easy for someone else to take our and then continue from that so, that it need not have to be repeated.
So, the specifications for the software include the basic algorithm and task description.
and how much of memory I need it and constraints on the program size execution and time and then so on what you can keep on including it these are the major ones rest of it will be coming as and when you will be developing it.
So, the next one in the software development is we have to thoroughly review specifications to catch the mistakes even before the code has been written and prevent potential code changes at system integration stage this becomes a little cumbersome.
So, it is better to.
see that all the errors are fixed much earlier.
And as always I mentioned to students nowadays people would not write their flow diagram.
They directly go and then implement their algorithm in the software or whatever and then it becomes little tough to see that where the error has occurred.
If a flow diagram is prepared ok, it will help in design tool to adapt.
at any stage.
So, which flow has gone bad whether I am flowing in the right direction or wrong direction I will be knowing about it.
And writing and testing DSP code is highly interactive process one has to discuss and then do the thing.
So, with the use of integrated software development tools we call it as IDE tool that include simulators or evaluation boards code may be tested regularly as it is written.
So, we will be seeing thus.
how we will be using the software exclusively in our DSK boards, how we will be testing how the input is coming, how the output is going, how our algorithm is running, we will be looking into that.
And writing code in modules as I have already mentioned or sections can help this process because debugging becomes easier, which part of the section or module is not working.
So, we can fix go back and then fix that and input and output those modules are coming correctly or not.
So, coming to the comparison we know that already we said we have different programming parts of it.
So, one of the DSP processor popular one in the earlier 80s and 90s was assembly programming.
So, it is as I have already mentioned it is equivalent to machine code actually used by the processor.
And this gives engineers full control of processor functions and resources thus.
resulting in the most efficient program for mapping the algorithm by hand.
This is the disadvantage what I have to say very time consuming because you should understand how one assembly programming runs and laborious task it is going to be especially for today's highly parallel processor architectures and then complicated DSP algorithms it becomes a hindrance.
So, it is better to go will come to the mixed C and X assembly in a while.
ok. What is the advantage of C programming?
We know that it is software development upgrading and then maintenance is easy and machine code is generated by the C compiler in this case.
Often what happens in this case it is inefficient in both processing speed as well as memory usage which will be much more we will see this in a lab in the lab I will demonstrate how you can compare between just one addition what is going to happen.
Whereas, I can use both C and then assembly and then where I am going to use we will see the thing.
Overall program is written using C actually, but the runtime critical inner loops and modules are replaced by your assembly code.
So, routine may be called as a function or intrinsics we call it or inline coded into the C program.
So, you will be having the library of hand optimized functions may be built up and then brought into your code when required.
So, coming to other distinct development tools, we know that either signal analysis or filtering what we will be doing in the DSP operations.
So, we know that signal analysis deals with measurement of signal properties and MATLAB is powerful tool basically all of us know for the analysis, visualization.
So, which are the critical components in understanding and developing DSP systems.
Even in my regular.
course I told my students to check using MATLAB and later on port it on to the DSP processor.
So, that you can compare with whether you are getting the same results.
Any design we do FPGA or any of the coding we do the thing we first test it in the MATLAB.
So, that our algorithm is running correctly then we will go to our hardware implementation and see that we are almost nearer to whatever MATLAB gives.
So, we say C is an efficient tool for performing signal processing and is portable for different platforms DSP platform what we have said.
Then what happens my input is going to be a C program which is a source code I will be giving it.
So, I have to do use the compiler here and then generate the object code which we call it as machine code or assembly code basically.
And we will be linking with the libraries and then we will loading the code on to the hardware.
Then the data whichever has to be input it is taken from the.
input and then we will be doing the execution here.
So, I will be getting the program output here.
Coming to the comparison of MATLAB versus C C++ we will see.
So, we know that it is an MATLAB is an interactive technical computing environment for scientific and engineering numerical analysis computation and visualization.
So, its strength lies in the fact that complex numerical problems can be solved easily in a fraction of the.
time which is required by our CRC++.
And then program written in these are usually portable.
So, they can be recompiled and run on many different computer platforms.
And it is a high level language, it can also be used for our low level device drivers you know that all your kernel and other things are written using C and C++.
Nowadays you will be seeing with python also.
The other advantage of MATLAB is by using its relatively simple programming.
capability, it can be easily extended to your create a new functions and is further enhanced by our numerous tool boxes.
This is you will be seeing every year there will be new tool boxes introduced or updated basically in the tool box itself.
So, that you have whatever is required at your tip of fingers that is what I will call it.
So, I have the GUI.
tools to support whatever design you are doing it and then for the signal processing toolbox we have the SP toolbox or FDA toolbox for the filter design analysis toolbox.
So, we will be using the FDA toolbox, but nowadays they are naming it in 2020 and above as a filter design toolbox basically.
So, still this is supported.
So, we will use them.
The other one we say that CC++.
is a high level language and usually used for many DSP software development engineers not only because it has powerful commands and data structures, but also because it can easily be ported as we have been telling from the one we have started considering the C. It includes even C or we know that C or C++ debugger which is useful in identifying errors in source programs.
So, it can display values stored in variables at different points in the program and step through the program line by line.
So, which will be taking it up in the lab and see.
So, this ends the constraints when we are designing the DSP processor for real time applications.
So, in the next class we will see that our module second will continue that how the algorithm or filters are going to be built around.
So, we will be considering both finite impulse response.
and infinite impulse response.
So, we have some input how I want to extract these components using different kinds of filters it can be a low pass filter, high pass, band pass or band stop or notch filter to eliminate one of the frequency and how you will be getting the output and their responses is shown.
So, more in detail we will cover it in the next class.
So, happy learning.
And, then thank you for listening to this lecture.
Welcome back to real time digital signal processing course.
Today we will be discussing about module 2 unit 7.
So, as a recap we saw in the module 1 which goes from unit 1 to 6 introduction design concepts and real time constraints what we have considered.
In this class in the module 2 first we will discuss about digital filters and later with FIR filters.
So, why do we need digital filters?
So, where we are going to use it in signal processing.
For separation of signals is one of the application we say as you can see in the example here your original signals has multiple frequencies components present in it and you can see that how they have been added and each one how we can separate it from the signal using different techniques.
So, we will be seeing in a while here it is low pass filter this gives the high pass filter and this is band.
pass and this we call it as notch filter or band stop filter if only one frequency has to be removed then we call it as notch filter.
The one application is restoration.
So, from these signals I want to reconstruct my signal then as you have seen the thing we will be adding all of them and I will be getting back the original signal.
So, if I want to restore back I will be using that.
Then coming to analog that is electronic filters can be used for these same task.
However, digital filters can achieve far superior results.
So, we will see in a short while how it is going to be done with digital filters.
And the application of digital filters is given here, one is in the signal processing what we are considering it, it can be in the communication systems or in control or in electrical systems or in biomedical systems, everywhere we need the filters.
What are the advantages of digital filters?
So, we know that many input signals can be filtered by one digital filter without replacing the hardware.
And then they have the characteristic like linear phase response, we will see it in a while and the performance does not vary with environmental parameters.
So, if you are in a cold place or is in a hot place as we know in the analog filters their components have to be highly meant for those conditions, if it is not the environment is going to play an havoc.
Hence, digital filters will not have this degradation for environments and that is what what it says and it is unlike analog filters these can be portable.
So, from place to place and from one application to the other application.
The other disadvantage of digital filter is basically the bandwidth of the digital filter is much lower than that of analog filter.
And, we are going to have quantization noise in this filters.
The accuracy of digital filter depends on the word length used to encode them in binary form.
So, we have seen the number system.
So, we have used fixed point and then floating point.
So, their pros and cons.
So, this will be constituting whatever we say that accuracy is going to be affected.
And it requires more design and development time.
compared to analog filters.
So, one has to see what should be the order of the filter, whatever you are designing and then you have to pass through input and then if it is available and then see and it is going to take more time.
The difference between analog digital filters is this.
The main difference we will consider here two methods is that digital circuit has to sample the analog signal first and convert it into a set of binary numbers.
And, in contrast analog filters need not have to do this conversion, they can be used directly wherever it is required.
So, coming to some of the recent in the social media what kind of filters is being used is shown here.
So, most of you may be using this augmented reality filters are computer generated effects all of you know about it.
So, they are layered over the real life images in your camera displays and in Instagram stories.
So, you will have most of this augmented the reality filters, they alter the image of your front or back camera displays.
You can think of Instagram's face filters, how they will be working and then you can imagine what is the.
role of filters in social media.
Coming to noise filter digital noise filters why we need it.
In basically in smart TV it is going to reduce the analog noise that is created during your signal transmission.
Helps in eliminate excess noise in a picture and reduce your flickers caused by them.
And how we can eliminate noise on an.
So, you will be knowing that frequency modulated receivers most of the time what we will be using it, how we can eliminate the noise in that.
Usually keep any cell phones or two way radios at least 20 feet from an FM receiver.
And then in cell phones even when not in use all of us know that send out pings that are picked up by your FM receivers.
You can choose a station and adjust the dial to the setting if you are using an analog radio.
Add a large external antler to the receiver that is how you will be eliminating your FM receiver noise.
So, in other way what we will see noise is in your microphone basically whatever microphone you are using for your applications they will have some what we call it as static noise.
So, how you can eliminate the static noise?
You can unplug and re-plug in your mic that way it will try to adapt to the noise which is present there and then it can eliminate it.
So, other way of doing it is try unplugging your headset or standalone microphone from the computer or device to which it is connected and then re-plugging it back.
So, if possible try using a different USB port, if it is USB connected you can try on a different USB so that.
your static noise is gone.
So, if there is a hissing noise in the audio all of you know the thing then use low pass filtering to avoid this hissing noise.
And then how we are going to stop my mic from picking up background noise.
Here it was the static noise here background noise because you will be at different places how you can do that.
So, what it says is click the recording tab in the sound window and select your microphone device and click properties.
Click the levels tab.
So, in that what you will be doing is background noise try lowering your microphone boost option.
Perhaps if you have kept it to 20 dB try to reduce it to plus 10 dB.
So, the other one is we know that most of the ECG signals carry line frequency in them.
How to avoid the line frequency?
In that case we use the notch filter.
to eliminate this line frequency.
So, usually in abroad it is 60 hertz or USA and in India we call it as 50 whatever our line frequency is 50 hertz signal.
So, we will see today FIR filter.
So, first we will see why we have to go for FIR filters their advantages and disadvantages.
So, the advantages as it is listed here.
So, we say it is stable.
simple and design complexity gets really linear in this case and then it has a linear phase response we will see in a while and it is easy to optimize on the order of the filter what we want to have it and this is a non causal system.
Hopefully you would have done your causal and non causal systems earlier in your signals and system.
So, how to make non causal system into causal all of you must be knowing it.
And it has a transient which is going to be finite duration.
So, what we call it is for finite input the output is going to be finite.
So, that is why there would not be any transient which is going to be finite in this case.
And we know that quantization noise is not much as a problem.
So, this is one of the advantage of our FIR filter.
What are the disadvantages?
So, we know that the order of the filter we usually call FIR filter is equivalent to an open loop systems.
It requires large storage basically.
So, it needs storage requirements what we say and then cannot simulate prototype analog filter.
So, a IR filter infinite impulse response filter will be taking it in further classes.
So, we know that.
We most of the design is done in the analog domain and then we convert it into digital domain.
Because, the earlier world more than 100 years analog filter have survived and then they are very well working with the system, but whereas, this FIA filter we would not be able to simulate using our analog filters.
So, for implementation complex computational we say is techniques are required.
And, then it is expensive to take a large order we have to pay in for the memory as well as the speed of it.
And then it is hard to implement than IR filter.
We will see how we will design it in the lab class.
And it is expensive as it is large order it is cost is going to be more.
Here more memory and time consuming process because we are talking about real time.
So, if the order of the filter is very high.
And, then we are unable to complete within the next sample comes if it is interrupt driven then we will be losing the sample that is why they are very time consuming in the case of FIR filters.
So, we will see there how they can be used they are represented in this figure.
So, we will consider FIR filter of length m order what we call it.
So, then what we say is order of n is equal to m minus 1.
So, you have to watch out it is that is order minus number of delays what will be considering as the length of the filter basically.
So, we are given the equation y of n is given by k is equal to 0 to m minus 1.
So, bk into x of n minus k, x is our input bk is our coefficients.
So, same thing we said that it is equivalent to convolution if it flashes to you h of k is the impulse response what we take it and x of n minus k is your.
So, we can represent it in this way, but since we use the filter coefficients usually we represent it as b k. And how in the flow diagram we are going to represent x of n is the input.
So, these are the square brackets are the unit delay basically and then x of n is multiplied by the b naught coefficient and this is the result what is available for our adder.
Same way here the after the delay which is going to come.
So, output is going to be x of n minus 1.
into if I am considered it as b1 then this is going to get added with the previous one.
So on because we are going to have m-1 delays basically.
So the last one is going to be bm into x of n-m will be the thing whatever the order of filter m which is going to be multiplied with your bm coefficients and added together you will be getting y of n as the output.
So, continuing with the thing so, if we represent our input as a impulse response if I want to take it then x of n is going to be delta n basically.
Then we will be getting the what will be the impulse response of the filter we will be getting it.
So, as h of n is equal to what we call it h of n is the impulse response which is equal to y of n which is given by k is equal to 0 to m minus 1.
So, you are replacing x of n minus k with the impulse response delta n minus k into b k. So, the output is going to be b n what you will be getting n will be varying to 0 to m minus 1.
So, the impulse response is a finite length m as required and then note that FIR filters have only 0s as you can see from the thing they do not have any poles that is the reason why we call this.
filter as a stable filter.
So, or this name is all zero filters also.
F air filters also known as feed forward or non recursive or traversal filters what we call it.
That is as you can see in the previous case the output will be only going in the forward direction that is why it is a feed forward filter also.
Coming with the design aspect of it, some of the parameters what we have to look in.
The characteristics as specified in the frequency domain in terms of desired magnitude and phase response of the filter.
We call it as H of omega in the frequency domain.
So, the filter design involves determining the coefficients of a or causal FIR or IR that closely approximate the desired frequency response specifications.
So, what are the design specification is given with this diagram.
So, what y axis represent is the magnitude of h of omega and then x axis will be represented with omega which varies between in this case 0 to pi what has been considered most of the time it will be minus pi to pi or 0 to pi.
2 pi, but we will be interested in only 0 to pi frequency components present in the thing as our sampling frequency is twice that of the highest frequency.
So, highest frequency is represented with 2 pi, hence we can consider the frequencies that are present only up to pi.
And then we say omega is the pass band frequency that is from 0 to if here it is the example taken as a low pass filter.
So, I want to allow all the frequencies which are.
in the pass band that is WP where I want to stop the collecting my frequency components.
Then what I have is I am going to say stop band, WS is going to say where I have to stop my collection of components.
So, that is WS between the difference between our WS and WP we call it as transition band.
For most of the cases we want.
direct dropping down which is not going to happen we will see in a while.
It is going to be a smooth transition what it should happen.
So, which will be constituting for our transition band.
And then we say that is W s is my pass band edge frequency and W s will be stop band edge frequency.
And what are this variation I am going to have it.
Most of the cases I want the magnitude to be 1 basically.
But, we know the constraints as and when more constraints are put our design is going to become very critical then we will be having order of the filter very high.
So, as we little bit relax on some of the components.
So, we can have the order low.
So, we say that delta r is the my ripple what I can allow actually in the pass band region between minus 1 minus delta r to 1 plus delta r.
So, then pass band will have little bit of ripples in the pass band and then I can little bit deviate from that.
And how I am going to represent the stop band?
Although most of the cases I want the flat response which may not be able to achieve it.
So, I have to specify what is the dB that is stop band attenuation what we call it as delta s how much I have to come down so that I will not have the frequencies beyond.
So, coming to comparison between FIR versus IAR.
So, we will take up IR filter more detailed one next few classes.
What is the comparison?
They we say that FIR filters are normally used when there is a requirement of a linear phase.
So, we will take it up little more in detail in a while and FIR filter with following symmetry what we call it as linear phase.
What is that symmetry?
My impulse response has to be.
H of n equal to plus or minus H of m minus 1 minus n for n is equal to 0 to m minus 1 order of the filter.
Whereas in IR filters they are normally used when linear phase is not required and cost effectiveness is going to be needed.
We say that they have compared to FIR filters they have lower side lobes and then stop band band than that of FIR filter.
And, for the same type of design we will see it later also how it is going to we will be meeting with IR filter with a less number of coefficients.
In some phase distortion is tolerable then better to use IR filter implementation with fewer parameters requiring less memory and then lower complexity.
Coming to how we are going to design FIR filters.
So, we say that we cannot derive it from analog filters.
So, we have to design in a different way.
So, why we have to bother?
Because we know the advantages of them which we have already discussed and then how they going to achieve linear phase stability and then how they will have the magnitude response which is what we can accommodate.
and then it is easy and then convenient to implement.
So, coming to the linear phase.
So, what is that?
The ability to have an exactly linear phase response is the one of the most important of FAR filters.
What is that?
h of omega it should be equal to magnitude of h of omega into e power j phi omega where phi of omega is nothing, but minus omega n naught.
So, when general FAR filter does not have a linear phase response, but this property is satisfied.
When your h of n is equal to plus or minus if I have taken h of m minus 1 minus n, n is varying between 0 to m minus 1 definitely we will have a linear phase filter.
So, different types of impulse response whether it is odd or even and then as you are seeing it there are 4 types how it can be designed.
So, you can go through them and then whichever is convenient you can select one of them to design your linear phase.
So, why do we say it is linear phase?
The phase is straight line in the pass band of the system as you are seeing it this minus pi to pi I say that that is my pass band it should be linear or we call it as all pass system basically.
In this case group delay is given by the negative of the slope of the line.
So, we will see it in a while.
hold on for little while.
So, coming to the other thing we said all pass system because we may have discontinuity in the filters or band pass filter at different frequencies what I want to design it.
Then what is the thing is going to happen?
We say phase wrapping may occur that is what you are seeing it.
So, but the phase is still considered to be linear.
Why?
This is the pass band region of one this thing.
the other region of the thing is from here to here still we have a what we call it as a line is linear in this case and then here this side also.
Coming to the other part of it that is if we are considering the high pass system we call it as high pass filter that is the low frequencies are going to be eliminated only the higher frequencies are going to be considered in that case.
the phase response looks like which is having a discontinuity that is from here to here I will be having that is my pi to magnitude 1 in this case to pi and then from here it is minus 1 to minus pi magnitude if I am considering the magnitude as minus 1 to 1.
So, then here it is going to be linear and then this side also it is going to be linear both on the negative side as well as the positive side of it.
So, the other one as you can see the thing when we say it is going to be linear phase.
So, this is my pass band region if it is going to be linear I say it is linear phase and I am not bothered about beyond my interest of region they are not linear they become non-linear in phase.
So, some of the terms we will see it which is going to help us for our linear derivation.
So, discrete time Fourier transform some of the theorems and properties which more we will be taking it up when I consider DFT and then FFT.
So, the property we consider is the notation what we are going to have it.
In time domain we say x of n, x1 and x2 and frequency domain all of us know it is capital x of omega, x1 of omega and x2 of omega.
So, when we say it is linearity.
when it meets the superposition theorem.
So, which is both commutative as well as can you guess the other one.
So, a 1 into x of x 1 of n plus a 2 into x 2 of n when I do the thing.
So, I should be able to get even in the frequency domain a 1 into x 1 of omega plus a 2 into x 2 of omega.
So, when we do the time shifting that is if I provide a shift of k n minus k then.
here the resultant is going to be e power minus j omega k into x of omega.
In the case of time reversal x of minus n will be giving me in the frequency domain is capital X of minus omega.
So, when we do the convolution of 2 signals x 1 and then x 2 I know it is convolution in the time domain whereas, in the frequency domain it is multiplication.
So, when we want to do the basically it can be autocorrelation as we will be seeing it later or x1 to x2.
So, if we consider the thing this is in the time domain it is convolution whereas, in the frequency domain it becomes a multiplication with respect to complex conjugate of the other sequence.
So, if we consider x2 of n as real it becomes a multiplication of x1 of omega into.
conjugate of x 2 of omega.
So, whereas, in the some of the Wiener filter we will be considering in the adaptive filter LMS algorithm.
So, that time you are autocorrelation with respect to the same signal what you are seeing it that convolution of this that is the time reverse signal what you are having it which becomes the square of the X of omega magnitude of it what you are seeing in the filter domain.
So, there are other more properties and then both in time domain and frequency domain.
So, you would have studied in your signal processing or signals and system classes you can look into them.
So, now we are telling that linear phase.
So, what we have said is something group delay which we have to consider.
So, Y of n is my.
output and then x of n is going to be delayed by n naught.
So, we call that as group delay then what happens to the frequency domain signal which is y of omega is the output which is going to be x of omega you are seeing e power minus j omega n naught it is going to be.
So, then what happens to the our magnitude and then phase responses basically.
So, h of omega will be y of omega by x of omega which is going to be given as e power minus j omega n naught and the phase of it we call it as phi of omega which is going to be minus omega n naught and because we know that n naught is the group delay which is minus omega into group delay.
So, in general even for non-linear phase systems we consider group delay as the differentiation with respect to our phase.
So, that is minus d by d omega of phi of omega negative part of it what will be taking up.
So, continuing with the group delay.
So, we know that linear phase filters maintain the relative positioning of the sinusoid in the filter pass band as you will be seeing it that is structure of the signal while removing unwanted frequency components.
So, if we see that.
So, some of the this is an input and as you can see this is a low pass filter which is represented both in the negative domain as well as in the positive domain.
So, the phase is going to be linear in this.
So, output after passing it through also you will be having little bit delay at the output, but they will maintain the same phase of the thing.
So, why do we need a linear phase?
So, as you know that in what happens to loss of phase information that is one of the thing whatever literature gives it most of us how do we identify the phases of people basically.
So, we say that the phase for one person to the other person is different.
So, if their linear that is a pass band frequency arranged linear phase or close to linear phase is required otherwise I may be reconstructing a different one as you will be seeing it some of the frequency domain component how it looks like and then what is the phase of it what you are looking at it and if they are distorted then you may not see the same phase you may be looking at different phase ok.
So, lean FIF filters as we said how we can the develop them that is we follow the symmetry property.
So, in this case we will be following only the simple one we will assume that h of n is equal to plus r minus h of m minus 1 minus n for n varying between 0 to m minus 1 what we will consider.
That means, what is the thing?
So, I am considering the positive side of this for these values as well as h of n for the negative of it what I am considering it.
So, we will see that what happens if I give delta n minus delta of n minus 1 as my impulse response to my system.
So, whether it is going to represent a linear phase or not we will see the thing.
So, for that we have to see the phase response as well as the group delay.
So, note in this case because m is equal to second order we have chosen the thing.
So, it will be going h of 1.
n will be equal to minus h of 1 minus n which is equal to h of minus h of m minus 1 minus n. So, these are the 2 things what will be substituting first n is equal to 0 comma 1 because m is equal to 2.
When n is equal to 0 h of 0 will be minus h of 1 minus 0 which is nothing but h of 1 and when n is equal to 1 h of 1 will be is equal to minus of h of 1 minus 1 which becomes minus.
1 basically which is h of 0, h of 0 is 1 so it becomes minus 1.
So, this is how you will be representing with respect to n is equal to 0 it is impulse response is 1 and then when is equal to 1 its impulse response is minus 1.
So, we will see an example how we are going to show that this has a linear phase.
So, what is that equivalent to convolution of your x of n into h of n by expanding the our function which is nothing but x of n into delta n plus delta of n minus 1.
In this case we have assumed minus delta of n minus 1.
So, this will be negative x of n into delta of n minus x of n into delta of n minus 1.
So, which is nothing but x of n minus x of n minus 1 this we call it as first difference system.
So, first difference system what we can go into the discrete sign time derivative.
So, we define this is a high pass filter we will seen it in a while how it can be a high pass filter.
So, we will be expanding this we have h of omega is nothing, but n is equal to minus infinity to infinity this is our DTFT equation h of n into e power minus j omega n. So, I am substituting h of 0 as 1.
And, we have e power minus j omega naught plus minus 1 into e power minus j omega 1 which is nothing but 1 minus e power minus j omega.
So, when I expand in terms of my exponential.
So, you will be seeing that simplifying it becomes e power minus j omega by 2 into 2 j into sin omega by 2.
So, this is what if I move 2 j into the first place and then put e power minus j omega by sin omega by 2.
So, for various value of omega between minus and pi if you plot the thing.
So, you will be seeing the curve like this.
So, that means, to say low frequencies whatever they are there that has going to be avoid going to be eliminated only higher frequencies almost when it becomes 1 you will be allowing those frequencies to be present in the system.
So, how we are going to consider the group delay we have to see phi of omega what we have got it as.
angle of 2, 2 j into e power minus j omega by 2 into sin omega by 2.
So, by putting them that is angle of 2 we know that it is 0, angle of j is equal to pi by 2 and angle of e power minus j omega by 2 will be minus omega by 2 and for sin omega by 2 it will be in this range.
It is going to be 0, 0 less than omega less than pi and it will be pi for minus pi to 0.
So, when we put it in terms of omega which will be pi by 2 minus omega by 2 and 3 pi by 2 minus omega by 2 minus 2 pi in this range.
So, when you put this simplified one you will be getting it as minus omega by 2 into the other one it is in the range 0 to pi minus pi to 0 will be minus pi minus omega by 2.
So, now, we will see that.
How is it going to be represented?
So, we have phi of omega.
So, we will be put omega 0 to pi.
Then you will be seeing this is shown as pi by 2 to pi here the magnitude is going to be half here which is going to go between that 2 that is pi here.
So, whereas, in the case of negative region.
So, you will be seeing that minus pi to minus pi by 2 because we are representing even my y axis is and phase of the thing.
So, which is going to be minus pi by 2 to pi by 2 fine.
So, how we are going to say that group delay is going to be constant in this case.
So, I am going to take the derivative negative derivative of my phase.
So, which is nothing, but half minus pi into delta omega.
So, which is going to give me.
half and then minus pi into delta omega which omega equal to 0 and wherever omega is not equal to 0 it is going to be half.
So, we consider in the pass band region because I am not bothered about when omega equal to 0.
So, we know that in the pass band region it is becoming constant.
So, we say that that delay is constant or we call it as a linear phase basically that is the reason why you will be seeing that it is pi by 2 to minus pi by 2 what you will be seeing a.
linear slope of the line here.
So, coming further with the example.
So, what we have is this is an assignment for you to work it out.
We showed that the FIR filter for a high pass filter is linear phase.
Now, it is your time to show that the low pass filter that is you have been given delta n plus delta of n minus 1 is my impulse response that this also is a linear phase.
So, you can consider here also you have m is equal to 2 and these are the values what you have it when n is equal to 0 it is going to be 1 and then when n is equal to 1 it is a plus h of 0 which is also 1.
So, you will be seeing that both of them are 1 you are supposed to show whether it is linear phase filter.
So, as you can see that when you are giving your delta n representation input.
Y of n is nothing, but because we have a impulse response delta n and delta n minus 1 equal to 1.
So, the output Y of n will be equal to x of n plus x of n minus 1, it is the scaled averaging system what we call it.
So, the averager is also represented as discrete time smoother and we call it as low pass filter.
So, some of the techniques to design our FIR filter which we will be taking it up more in our lab.
class just to give a flavor of it.
So, I can design a hamming using the window technique.
There are different ways of doing it.
So, most of the time we will be using MATLAB FDA toolbox with the older versions and latest version use the filter design toolbox.
So, here it is the hamming window what you are seeing m is equal to 16 what we have considered in this case plotting this figures from the MATLAB.
So, you will be seeing that this is a smooth.
as you will be seeing between 0 and the other thing.
So, whereas, the hamming window so, you will be seeing there is a little drift in the thing and then that is how what it will be represented.
Use a Blackman window as you will be seeing that it will be having the pass band is an arrow band whereas, it is going to drop down the number the dB whatever a frequency response what you can see that is if we have put this as a reference line.
So, which will be.
below this line that is minus 20 dB point.
Whereas, in the case of these are the side lobes what we call it whether I want a narrow this thing pass band lobe or more ripples in the side lobe what we have to take it into considerations.
So, for the hamming window you will be seeing that it goes little more than minus 20 dB whereas, in the hamming window also, but it is going to come down as you will be seeing when you are using the hamming window.
Most of the filter equations will be using the hamming window to design FIR filters.
So, that is it should this table shows that.
how they are represented?
The main lobe is going to be 4 pi by m which is equivalent to minus 13 dB what they will have it and if I consider the peak 20 log 10 delta side lobe.
So, it will be coming down to you will be seeing that minus 21 dB whereas, in the Hanning window it comes to minus 44 dB.
When I want to go with the increasing the order of the filter basically if I want to achieve it m has to be increased.
and then I can go up to minus 53 dB maximum in the hamming window and if you consider the Blackman window I can go up to 74 dB from 58 dB.
So, some of the design if you want to have a peak side lobe as that minus 13 and other things you can select any one of these windows and if you want a variable you would have heard of KSZ window which you can select it which one of the.
parameter what beta parameter what you can vary alpha and beta parameter there and select your own window.
So, this gives you a flavor of FIR filter.
So, in the next class we will be taking up pipelining and parallelism for low power how we can design this FIR filters.
Thank you for your listening and then happy learning in this course.
Thank you.
Welcome back to real time digital signal processing lab today.
So, we will be seeing some of the implementations whatever we have done using the MATLAB in the last class.
So, we saw some sign generation using the DDS in code composer studio.
Today we will see how we can use resonator for generating the sine wave and then we will see from lookup table how the real time signal is going to come out today.
So, you can see that.
Now, some of the things one has to remember is you can open the project and then some of the files has to be connected for this code basically.
In this case you will be seeing the CMD file which is going to define what are the memory which are going to be used in this.
So, the default what it takes and then you will be seeing.
that the what is the buffer length and then what is the audio which is going to be used.
So, in this case I am using LCDK 6748 board today for real time demo.
So, we have a sine waves that is it which is going to have 48 kilohertz what it is going to run.
So, we will be using the interrupt driven.
So, you will be knowing different methods of accessing the CPU, one is using the polling, the other one can be interrupt driven which we discussed in our theory class also, the other one is DMA based.
So, their CPU intervention is not going to be there directly from the memory you will be reading into your memory to work on it.
So, some of the cases you may have to have a frame length of whatever the length if you have given.
So, you can directly read from the memory and then put it into the local memory.
So, in this case what we have is.
So, the buffer length in this case is taken it as 128 samples and then the loop length is 48.
So, how we are going to generate the sine wave?
Basically we use MATLAB to generate the sine wave and then take this 48 samples here.
And, then use them as you can see it is in the fixed point that is signed Q15 format what we are using it here.
So, use this in your code, then all of it as you are seeing that it is in 16 length of the buffer as well as the computation.
So, here we are going to do interrupt driven.
In this case.
Interrupt 4 is going to be used and then you will be getting it is the stereo data what we are going to get it.
So, we will be as I have mentioned in the first lab session.
So, we can have mono input or stereo.
So, whenever speech is there either we can take it from the mono that is mic we can connect it or we can connect the audio input from our laptop.
Today we are connecting the audio input to the board.
So, we will be taking first left sample and then you will be doing the processing here.
So, what you have is take from the input buffer left sample pointer and then you are putting into the buffer length basically what you are comparing that is you are incrementing it and then you will be putting back left sample the value from the sign table whatever the pointer is pointing to.
And, then sine pointer is also going to be incremented here, then we will be seeing that both for the left and right channel the same left sample is going to be output.
So, then we are going to out the sample codec data out.
So, in this case as I have already mentioned we will be using AAC 3106.
So, now, what is the frequency at which it is going to operate that is what it shown it is L138.
initialize interrupt driven basically.
It has the sampling frequency of 48 kilohertz and then ADC gain what you have given is 0 dB and then DAC attenuation is also 0 dB what you have taken the thing and then you will be putting LCDK line input.
From here input what you are going to take it and then you will be outputting on the outside of your this thing.
processor basically both the codec input has in and then out one of the input is from the I will put it as our computer to input of the board and then output of the board is connected to the speaker here.
I think next time we will show the scenario where the board and other things are there.
So, we will see that how to run this code.
Some of the important thing what we have to do is when I am So, experimenting with this or generating the file one has to keep that in this case my as you are can see that it is LCDKC6748 what I am using it and then here using debug connector.
So, XDC110 USB debug connector what we are connecting it to the board and then the compiler version what it is being used is the 7.4.4 version.
And, we are generating the executable and then here output format has to be legacy cough file what will be generating.
It has a two options.
So, that is ELF format, but in our case it is legacy cough file what it we need it and device endian is little endian.
So, when I talk about little endian and big endian, in the little endian lower memory is going to be store first and then later on the higher part.
of your 32 bit data which is going to be stored later higher part later.
Whereas, in the big endian some applications need that higher memory has to be first and then lower memory bytes have to be later.
So, in that case we will be using the big endian for our cases all these TI board support little endian.
And then we will be command file what we needed is linkerdsp.cmd these can be downloaded from the TI.
site or we will be providing you whatever necessity to run your codes in the web page basically and we need is RTS 6740 dot library this is the common here 674 series any one of them can be using the library part of it.
The next one is what we see here is the compiler.
So, in this case we have to include certain files.
So, these are the support files one has to include where you have downloaded in my case it is in D colon DSP lab 6748 what I have taken where the support file is located.
And next one is we have to have the board support library under that there are some include files which are required for real time running.
So, then coming to the linker options we have to provide the search path.
So, one of the thing is as you have already taken RTS6740.library which reflects here and then the other one is what we have.
call this one although it is LCDKC6748, we can select EVM OMAP L138, BSL is for board support logic.
So, we need what is the board it is going to separate library what we have to provide.
And this is has been stored in this location that is how it is coming location of from where I am been including which has to be provided.
Then next again we have some libraries.
So, which are put in the board support library.
So, you can link.
them.
Once you have done the thing you can apply and then close.
So, these are the necessary things for running it.
The other files which we need it for running in real time is that is one is L138LCDK, AIC3106.init.c.h and then linkerdsp.cmd and then vectors interrupt.asm.
These four files have to be taken from the support files what we have it and then we have to include.
Once everything is done.
So, what you can do is whether your code is running correctly or not.
So, I can do a compilation.
So, if there is any error which it will be listed out here your syntax error then you have to go and then attend to that.
If nothing is there then what I can do is I can go and then build my system.
So, once I build this system you will be seeing that you will be seeing some green light it is coming here.
which is telling that it is going and then loading on to the board.
So, here you have seen that the complete code has been loaded on to the board, you will be seeing that C674X underscore 0 what it has taken the thing.
So, and then where it has started your entry point what it is showing that it has entered where the main is there.
So, what we will do is we will run this code and then you will be hearing a.
wave which is generated at 48 kilohertz.
So, I will run it and then you will be hearing the output from the speaker.
Hope you are hearing it.
So, this is how real time sine wave generation using lookup table has happened.
So, once I stop also you will be seeing that code has gone and then loaded onto the board.
And, then what is the thing the code is going to lie in the board.
So, unless I reset the board it will be running continuously this is what we call it real time.
Once I have taken the debugger I have downloaded all my code into the dumped into the board, then it will be continuously running for whatever input you are going to give it.
So, this is what we call it as real time.
So, here what is the thing happening is.
We are going to interrupt for every sample my CPU and collect the data into my buffer here and then I am taking it out and then playing it.
Here it is only in this case what we have done the thing is because we have generated the sign table, the samples are taken from the table and it is sent it out to the codec channel that is DAC output.
So, that is what you heard the thing.
So, the next one what we will take the example is.
So, this is the second sine generation, next one we will take it resonation using resonator how we can generate our sine wave.
So, we said that in IR filter we can push it to the resonator thing and then generate our sine wave.
So, here what is the thing here.
So, you will be seeing that we are calling it as a sign generator and then we will be redefining my y1 sample that is value is given here.
So, what is the value how we have calculated that we said that 3 samples what we have to give it after that the IR filter is going to resonate in on its own.
So, here it is sign f tone what you have taken the thing divided by f sample.
So, into 360 degrees what you are converting into.
So, in this case sine you want to generate 500 hertz divided by 48 kilohertz into 360.
So, what is it?
My f tone whatever the frequency I want to generate 500 hertz and sampling frequency I was have chosen as 48 kilohertz.
So, which will be equivalent to sine of 3.75 which is my.
y 1 value what it has been taken.
Then we define our equation A a as 1.9957178.
So, this we call it as 2 star cos 3.75.
You can go back in the literature where we have discussed about the IR filter application as a resonator.
So, you will get the filter structure and from there you will see that these are the coefficients what it has to be provided initially.
Then, this is the value what it has been taken for this.
Then you are calling y3 as you will be providing 0 first sample, then y1 is the other sample what you are providing it and then 0 and then our amplitude basically a is given as a a value.
Then you are going to run the code that is you will be making your.
Later on computation y 0 is my output, what is y 0 is equal to y 1 star a minus y 2.
This is our higher filter equation and then y 2 will be y 1 and y 1 becomes y 0.
And then y 0 what you will be continuously multiplying is you have given a scale of full 16 bit range what we are giving it.
So, multiplied with 32000 what we have taken.
So, that is what it says using a number slightly less than this such as 32000 maximum if y 0 becomes 1 I can go up to 32767.
So, if there is any overflow or underflow.
So, you are multiplying it by 3200 that is what it says prevent overflow.
Then you will be returning shard.
So, we recast the result to a short and then value upon returning it since your DTA converter is programmed basically to accept 16 bit signed values in this case.
But here you will be generating it in the on the board, but real time we will not be running it today in this class.
So, you will be what is it then signed data using sign generation.
a block sign value what I have to calculate continuously.
So, you will be putting it in the loop i is equal to 0 and for 0 to length whatever you have defined you will be calculating your i plus plus and then buffer of i is going to call the function sign generation basically.
So, then what happens?
You are calling your function block sign from the main and then you are calling the passing the parameters.
G buffer and buffer size.
So, that is what it says fill buffer with the sign data and then return.
So, your G buffer will be containing your output value we will see how it is going to show that whether we are getting IR filter in the oscillatory mode going to generate a sine wave for our application.
So, I am doing again debugging the code.
So, the code has gone and then loaded on to the board then we will run the thing because I am showing you in the waveform format.
So, I have given a break point in this case.
So, the code will be stopping there was a as you will see sometimes you will be getting the debugger is going to misbehave because my break point it has not.
taken the thing it has completely gone and then run and then it is unable to reach whatever you have given sometimes return 0.
So, it was unable to locate it.
So, hence it gave you an error.
So, to I will be reallocating my breakpoint here and then we will rerun it.
So, you have seen that it has come the breakpoint has come and then stopped here.
Now, I will be able to see the output.
Once I complete it, it comes out of it my memory gets erased.
So, I would not be able to.
see my what buffer has.
So, if you keep the thing also you will be seeing that what are the hex values your G buffer where it is located default it is going to show, hex value, decimal value and octal binary all the format whatever you want to view it you can see that.
Now, what we will do is we will see using a graph.
So, for that I will be going to tools.
So, if you are holding on in the.
with the break point then this tools option will be coming for you while running your code otherwise it goes off we will see it in a while.
So, I can do a single time.
So, I will got some 50 samples what I will be collecting it.
So, I can say that it is 16 bit signed integer what I am going to get the output.
So, then my start address is what we have is G buffer where the data is stored.
So, the if I give j buffer.
So, you will be seeing that the output is going to come here.
So, you can see that only half the sine wave what it has come because I have chosen number of samples small.
So, what I can do is hopefully I have control on the thing data what I can specify display properties will see it.
axis and other things what it is given.
So, otherwise what I can do is I can close it and once again go to the tools and then increase my data size here.
So, I will give it as something 250 let us see whether I have the thing and then this is 16 bit signed integer what I can select and again I have to do this G buffer and then I can give it.
So, what is the thing happening?
Since my it is generating only one single cycle basically after that you will be seeing whatever is in the memory is junk.
So, if you want to increase this so, you have to have more data what you will be generating it.
Number of samples what you will increase so, that for loop will be much more than the thing the what you can increase in this case length is chosen as where we have defined our length.
Buffer size is our length which is getting passed on there.
So, buffer size is what we have taken is 128 samples.
So, you will be seeing that at 128 samples.
I am going to get one cycle.
So, you can increase the buffer size and then collect more data.
So, you can get more samples in your waveform what you are looking at it.
So, this is how we make IR filter oscillate to generate sine wave.
Now, we will see one of the example what we have seen is sine wave generated only we have output.
Now, the other one is what we have is audio in and then out in the.
board that is it takes the input from any of your external devices and then whatever comes out of it is going to be sent out directly to check that whether your path from ADC to DAC it is through the board it is working or not.
How we are going to do that?
So, this is audio in and out.
Here you will be seeing that it uses the polling mechanism.
So, to differentiate between your polling and then interrupt driven.
So, the CPU has to go and then check if there is any data in the buffer.
So, once in a while it will go and then check and then collect it.
Whereas, in the interrupt driven so, as you know that whenever the person comes to your house they will be pressing the calling bell.
So, then you will go and then attend to that.
But if you are expecting the guest at that time and if he is a chief guest or whatever may be the thing once in a while you have to go.
and then check the person has come or not that we call it as a polling that is every 5 minutes or something you will be going and then checking.
So, if he has come then you will be bringing him that is how your polling is going to work whereas in interim driven as an example the person comes and then rings the bell then we know that somebody has come you will go and then attend.
So, that is the difference what I have given with an example.
Now we know that using the polling and then we are using the sampling frequency as 48 kilohertz.
So, we have taken both ADC gain and DAC gain as same way and then we will be using line input.
So, this is what the board will be using it then sample what I am going to get is input sample I will get it and I will be sending it out output sample sample.
So, what happens in this case?
So, you will be seeing that it is a 32 bit uninitialized int what you are calling it whatever data comes here.
you are sending it out.
So, we will see that how this is going to run in real time.
So, you will be see hearing some whatever speed signal if I give it, it will be coming out if it is tone it has to come out that is how it will be working.
So, we will do the debugging because I have checked for all the errors and other things.
So, directly I can run the debug if you are sure that there are no errors in your code directly I can go debug and then test them.
So, now we will run the thing.
So, there is nothing coming out of it.
So, just we will go and then see that some speech signal what I will be sending it out.
So, you have heard the speech coming out of it.
So, I can select.
If you want any audio you can select the audio also.
So, we will select here what I have is some tones different tones are there which has been generated.
So, you will be seeing that how they behave.
As you are seeing it is a 500 hertz sine wave what it is getting played.
So, we will see for the other tones anyway in the music.
the music you have heard of it.
So, how the pitch is going to change?
So, we will see 1 kilohertz how it is going to have a behavior ok.
So, different what you can generate the tone.
So, you will be seeing the shrill most of the thing will say it as a noise basically.
So, this is how your board takes audio in and then sends out it is not doing any processing.
So, most of the time what we do is if we want both audio in and out we will be taking here.
sample here input sample then we do the processing and send it out.
So, as an example we will see here there is a audio is getting what I will put it as attenuated.
So, but still you will be you may be able to hear a little bit of the thing otherwise you can try on yourself.
We have seen sine wave generation.
And, in the next class we will see how FIR filter can be put in between our audio in and out with noisy signal, how we can remove the noise.
We will look at it on the board we have seen already on using our lab MATLAB.
So, we will be designing the coefficient using MATLAB FDA toolbox.
So, I had shown you how to store that FDA coefficients in our file which we will be using.
in our FIR filter design in hardware.
Thank you.
Have a nice day.
In this lab class, we were doing the demo of musical notes.
So, I wanted to show that how the musical note is going to look like in the spectrum.
So, we will be doing the FFT of the musical notes.
So, I will get the complete spectrum.
So, have a patience to listen to this music again.
So, we will see the thing.
As you have seen the thing the note has got increased.
So, you will be seeing the spectrum of this.
So, you will be seeing from the basic frequency here it is approximately 200 hertz what it is kept.
And, then which goes up to 400 hits this will be my sir you will be seeing re ga ma pa the ni sir that is what you heard and you can find out from the spectrogram what are the frequencies present in your music not our audio functions.
So, today what we will do is as we are discussing about the filters in the theory.
So, we will have a look at how we can use the FDA toolbox.
to represent what all the design what we can have with respect to.
As I have been mentioning FDA toolbox is going to be removed from the recent editions of it, I can give filter design also what it will be taking it.
So, we will see that this is our FDA toolbox.
So, earlier all we have seen the thing that is I can have a.
response type, whether I want a low pass filter or high pass I can select the thing and then what kind of filter.
So, FIR filter either I can design the equi ripple filter.
So, if you click on this you will be getting the various modes of the filters.
If I want to use the window technique I can use it or any of direct implementation what you can see that you can select them.
For the time being we will select the window because we have comfortable with hamming and then hanning window in the theory.
So, even the KZ window what you can select it.
So, for the time being we will select first as the Blackman window.
Then what happens?
So, whether either I can specify my filter order or I will be going with the minimum order design.
So, I will click on the here what it is shown is the sampling frequencies.
So, we will bring it down to 8000 and this what we have seen in the last class is 1000 hertz what we will give it.
So, I can I it is not allowing me to design the minimum order.
So, only it is giving me specify the order.
So, I can specify as 30 is my order and then I can view the response of it.
So, we had seen in the last class that is.
So, this is my low pass filter what I am designing it and samples what I have seen this is my normalized frequency what it will be showing.
So, that is my 48000 kilohertz is 0 to 2 pi what you will 0 to pi on the right hand side you will be seeing it on the left hand side it will be 0 to minus pi the response will be.
So, here it is pointing to 0 to 30 is the thing order of the filter what it has taken this the impulse response.
In the time domain how it looks frequency domain in the theory we have seen it.
So, now, we are seeing how in the MATLAB what it is going to show it.
So, the next one is I can do the design of the filter.
So, we will design the filter.
So, you have to hold on for a while.
So, you will be seeing the response.
So, what is it I have given the cutoff frequency as 1000 Hertz.
So, you will be seeing that.
So, when I map this to frequencies this is going to go from 0 to 4000.
So, it normalized will be 4 what you will be seeing it in this case.
So, this is my approximately 1000 hertz.
So, which it should be giving me 3 dB cutoff what we say.
So, you will be seeing that approximately it comes down to this is my cutoff frequency .
comes down by minus 3 dB that is equivalent to 0.707 of the magnitude.
So, you have to be careful when you are designing your filter the output may be what I say is amplitude may be modified basically.
So, scaled version what you will be getting it.
So, if you want if it is 0 dB the frequencies what I can pass as you can see the thing is only up to 500 Hertz.
So, if you are doing anything beyond it.
So, you will be having the attenuation in the magnitude.
So, you may have to.
Now, we will see that how the band stop frequencies are going to look like.
So, here it has come down to approximately minus 80 dB what we can say using the Blackman filter.
So, it depends on how much down you want to come down.
So, you can think of it and then use one of the filter.
The order if I increase it as you will be seeing it.
So, I will make it as 50 order filter in this case.
So, we will see the Blackman filter itself.
So, I can design the filter.
So, now, you will be seeing that as and when I am increasing the order of the filter.
So, you will be seeing that the flat response is much more wider here that is the pass band will be for more frequency and this is my transition band what we call it from the.
0 to whatever the delta is represented.
So, it will be narrowing down as and when the order of the filter is going to increase.
So, now, I want to see that what is the group delay of this.
So, I can click on it.
So, you will be seeing that hopefully there is a trigger in your mind which is happening.
So, direct form FIR filter is designed.
So, the order is going to be 49 and then whether it is stable filter or not what you will be seeing it, it says S and then it is a designed.
So, why I am getting the group delay, it is a constant in case of linear filter.
So, here the delay is going to be although I have 0 to 49 samples, I should have had a delay of 50 samples since I have used the linear phase.
So, that delay because I will be combining it if you remember your structure.
So, which comes down by half basically.
So, the constant delay of this filter is going to be 25 units.
So, after that you will be getting it continuously your output if you are running for your real time applications.
So, coming to if you want to represent the face of it.
So, you are seeing that my face has to be linear in the pass band that is 0 to 1 kilohertz what we have given the thing this is cutoff frequency.
So, which you are seeing that.
it is constant.
So, if you want to represent your response is this and then if you want to see the filter specification you can go and then see that this is how my cutoff frequency low pass filter what I have designed.
So, like this you can go design your high pass filter or band pass or band stop.
So, we will see one band pass filter specification.
So, you will be seeing that there will be two cutoff frequencies that is fc1 and then fc2.
So, these are the two things what you have to provide.
So, as usual we can say that 8 kilohertz what I will take as my sampling frequency instead of 48 and then I will say my low frequency I want up to 400 hertz which has to be eliminated and then here I can give it as 3200 hertz.
That means, I want to allow frequencies between 400 and 3200 hertz.
and then rest of them have to be eliminated.
So, I will design the filter here same Blackman window I am doing it.
So, this will be the response what you can see it.
So, what is it?
So, 400 hertz is going to be this thing somewhere here what you will be getting it and then this is 3000 approximately 200 what you will get the thing.
So, this is what the filter design.
So, if I change my filter to So, you will be seeing the response what is the thing is going to happen.
So, you are seeing that there are ripples what you will be seeing it and then your response is going to vary.
So, when you view this, this is what you will be seeing in the time domain how the Hanning window looks like and then this is the frequency domain.
So, you will be seeing that your magnitude your ripples will be.
somewhere here that is minus 20 dB or whatever you will be getting it.
So, that is what it says main lobe width is minus 3 dB in this case you will be seeing it ok.
So, these are the you will be analyzing these things maximum relative side lobe attenuation what it says this is minus 31.5 dB.
So, somewhere here what you will be.
getting it below that.
So, this is how you can play with your design thing and then you can use it in your filter design.
So, you can use FIR 1 or FIR 2 to do the design or these are the coefficients one of the thing what you have to do is if you are using it for code composer studio.
So, you will be seeing there is a IDE generation of coefficients any other platform if you want to use.
Xilinx platform or HDL code you want to generate it or C header file if you want to use the C code you can generate using that or I will put it as code composer studio what I want to generate my coefficients with.
So, I have to specify the header file C header file and then I will be getting here it is numerator and the length is defined with the BL and then export what is suggested.
What it says is signed 32 bit integer what you export it as that is what it is showing.
So, and then I can specify the DSP board also select the target for which I am generating it.
So, or I can specify what I want it to be exported as I can export it as signed 16 bit integer or I can specify any other format I want unsigned or unsigned 32 bit or signed 8 bit.
8 bit integer depends on hardware which one you are using it for us 60 sin 16 bit is enough.
So, I have chosen sin 16 bit integer in this case.
And then if I call it as a generate it you will be seeing that it is going to generate and then it gives the name as FDA coefficient.
So, we can save it.
So, I will be saving it in the documents because I have lot of things and downloads.
So, better to save it here.
So, you will be seeing that it is saved as dot star dot h file.
So, that is fda coefficients dot h what it will be storing it.
So, we will go and then look at the values of it.
So, in the documents file what I have stored it.
So, you will be seeing that fda coefficients is stored here dot h file.
So, if you see the format here.
So, what is it?
It is filter coefficients, see source file what it is generated and then from filter design and analysis toolbox and MATLAB.
whatever version signal processing toolbox what it has used is 8.5 MATLAB registered what it says and generated when date and everything.
So, you will be seeing that what is the filter you have generated it is FIR filter direct form FIR what it says and the filter length is 51 because we gave order as 50.
So, it will be generating the order 1 n plus 1 what it will be taking it 51 is the order and linear phase.
it is using type 1.
So, if you want to change and other things you can go and then look at the manual and then you can do that.
So, it says that filter coefficients were truncated to fit specified data type because we gave sign 16 bit.
So, you will be seeing that b l is my length of the coefficients and then you will be seeing the values of these coefficients here.
So, it is from 0 minus 3.
So, you have already seen that it has taken care of truncation of the values in this format in the fixed point format what I have given ok.
So, this you will be using it in your code composer studio to run your FIR filter applications.
So, this is one thing.
So, we will see how one can run in MATLAB itself.
So, we can close this.
And, then what I will do is from the FDA toolbox I will be coming out of it if anybody wants to see rest of the thing.
So, you will be seeing FIR filter band stop or high pass filter one can design depending on your application.
So, coming back to this thing I have.
So, you can one by one run and then check it in the MATLAB dot m file what you can generate and then do the thing.
So, here usually I ask my students to generate a GUI for it will be easy to show that what is the filter they are using it and then how I can modify.
So, in this case as a demo I am showing you this one one of it which is developed.
So, I will be going into this and then running it.
So, you will be seeing that GUI is getting generated.
So, now, I have to specify here filter type what I wanted.
So, we will see that I want FIR filter we were trying it we can do that and then what is the response type what I want whether I want a low pass response or a high pass, band pass or band stop.
So, since we have done the low pass and then band stop design we will take up here band stop.
So, now, what is the thing is usually why we use filter in this case we are going to eliminate the noise.
So, we will play the original wave file and see what.
I will be getting the output as.
Remember, the force will be with you always.
So, this is the original speech file what you heard it.
Now, we will say when the noise is added how does it look like.
Remember, the force will be with you always.
So, there is a single tone noise what has been added to the speech and then.
which is fed as input to your filter.
So, that is what it says which tone has been added is 2100 hertz as noise is loaded into this.
Now, we can play the filtered output.
So, you will be seeing it.
So, this was a single tone what in terms of frequency what you are seeing it.
So, approximately 2000 although it says 2100 hertz.
So, you are seeing as a peak at 2500 and rest of it.
it is vanishing it is not staying.
So, your speech of magnitude filtered output what it is showed and then went off.
So, if you want to design an IR filter.
So, I can give this I can select a low pass filter IR filter.
So, it will be saying that some of the speech file with noise sign tone what it has added is 3750 hertz which is going to be eliminated since we have seen the original already.
So, we will hear for a change.
So, if you are keen in observing the note.
So, you will be seeing the difference between 2100 and then 3750 hertz.
Now, you play the same filtered output.
So, you have seen the peak frequency which got added has got changed to 3500 approximately in the thing.
Scale has not been normalized.
I have expanded the thing and what was the output.
So, this eliminates the higher frequency component present in the thing and then it is allowing the speech to come out as clean.
This is how what you will be experimenting with FIR and IR filter together that is it is GUI.
Otherwise you can run the code in MATLAB create a dot m file and then you can run them also.
So, that is what one of the example what we have seen using the MATLAB filter.
So, we will see in.
So, if you want to save or whatever it will be showing.
So, we said that our sine generation using the DDS we had seen in the MATLAB.
So, we will see in our DSK6713 board TI board as I have been mentioning it.
So, how it is going to generate the sine wave.
So, this is the C code what we have written.
So, we have to use library function and then the math function and we are defining my length of the thing as 256 and we are keeping the rest of the code what we had used in the MATLAB function.
So, if you correlate the equations it remains the same thing.
So, your desired frequency is 1000 and then the sampling frequency amplitude is 32000 and then pi in this case we have to define because there is no built in.
pi value in this case like in MATLAB in C as you know you have to specify that.
And then we have given the phase increment here and sampling frequency chosen as 48000.
So, I can generate both out 1 and then out 2.
So, what is this out 1 and out 2 we will see in a while.
So, one thing one has to keep it in mind when you are using the board if you declare them as global variable then you will be able to.
see their output.
So, if it is a local variable, so you may not be able to plot them.
So, that is the reason why output is kept as a global variable.
Then we will be using the equation for i is equal to 0 less than i less than n like even in math lab we did the thing.
So, we will be doing the phase increment and then what is it is desired divided by f is what we have it.
desired is 1000, f s is 48 kilohertz what we have used it and then increment the phase.
So, we are checking if phase is greater than or equal to 2 pi.
So, if it is so, then we will be subtracting it with 2 pi minus we will be subtracting with 2 pi.
So, we are counting as a modulus 2 star pi operation in this line.
Then, what we are calculating first one is the output 1 of i, this is magnitude multiplied by sine function what we are calling with the phase.
So, scaled what we call it as L in output and then we can feed it as a left hand sine one side and then the other one can be cos.
So, you will be seeing that output 2 is given as amplitude into cos f with respect to phase what you have calculated here.
So, when I So, these are the dot c file what I am showing it as a main dot c. Now, one of the thing is automatically when you open the new what we call it as give it as a new CCS project if I select it.
So, it will ask me what is the file name I wanted.
So, I will call it as here in this case sign dds because I have given underscore there.
Then, it will ask me whether I want the executable, we will say yes and then what is the family I am going to choose is C6000 and then we have given DSK6713.
If you are using the board then I have to use spectrum digital DSK EVM EZDSP onboard USB emulator.
So, and then you can give finish then you will be seeing that your main dot C along with it is going to be.
So, here you can write your code and then run the thing.
So, for that and then it will show this is the active debug folder or project which is selected.
So, for because we have already written the code.
So, you can go and then insert it.
So, I will be selecting this is my active code to be run in this case.
So, then I will select.
So, if I do this it will be doing the compilation and even the build is going to be done in this.
So, if there is any error in the thing please go and then fix them.
So, otherwise I can go directly for debugging, then what happens it debugs and then it is loaded on to the processor.
So, you are seeing your cursor has entered into the main function.
So, we will see that we will be going for the debug operation.
So, you have this has to come when you are doing it.
It says it has used spectrum digital DSK EVM DSP on board 671X what is the thing taken and then it has entered the main function.
And then interrupt what it is going to have is c underscore interrupt 0 0 it will be going into the boot that is the entry point for the thing.
So, to see that my output is coming out correctly.
So, if I run completely then I may not be able to see whether my output 1 and then 2 are sine and cos functions.
What I put is a break point here.
So, if you double click on it it clears it and then if you double click again it is going to.
put a break point.
So, we will run this code and then you will see that it stops here.
Now, what I have to do is see whether I am getting the sign a wave generated correctly or not.
So, I will be going to the tools and then I will be selecting a single time graph.
So, I have to specify what is my length of it.
So, we said 250 and then my output data type what I have declared is float.
So, I can use 32 bit floating point and then I will be giving this start address as output 1.
So, then if I give the thing, so you will be seeing that your sine wave has got generated using the DDS method.
So, if you want to again plot one more graph that is single time I will call it.
So, this also is going to be 250 and then this again what I have is a floating point.
32 bit floating point.
So, I want to see my output 2, where I am getting the sine wave.
Sorry, you will be seeing that this is the single time, this is what you have it, the other one is shown here.
So, you will be seeing that this is starting from 0 what you are having it, whereas your cos file you will be seeing that it starts from 1 which is in this case 32000.
is amplitude what we have taken.
So, that is what it is showing and then it is repeating.
So, if you want to see their FFT magnitude whether you are generating the sorry correct this thing frequency is getting displayed or not I can select the FFT magnitude.
So, taking is a 250 and then what I have is a 32 bit floating point.
So, I can give start addresses for one of it we will see the other one you can see it yourself output 1 and then what is the frame size we will be taking up spectrum analysis in little later classes.
So, if you want you can change the order of it.
So, I will give it as 10 2 power 10 will be my order of the FFT.
So, you will be seeing that.
This is how what it is represented because 1024.
So, if you want to represent in a lower thing.
So, to get 1 kilohertz.
So, you can multiply what is the magnitude of it.
So, the value what you are going to get it is going to show multiply with your sampling frequency into 1024.
So, you will be getting what is the frequency what you are getting it.
This is our k point where it is shown.
So, if you want to change it you can change your order of the filter and then see what output you will be getting whether you will get the 1 kilohertz represented or not.
So, this shows how we can use our DSK board using C function to generate sine wave.
So, in the next class we will in the next lab we will be seeing how to do the filtering after generating a sine wave that is using IR filter in the oscillatory mode and using do the filtering with different low pass and then high pass what we have seen in the MATLAB same way we will see it in code composer studio.
Thank you.
Welcome back to real time digital signal processing course.
So, we discussed about IR filters little bit last in the last class, today we will continue with the.
same thing.
So, as a recap as I said we have discussed little bit on IR filter how we have to design from analog domain to digital domain what we have seen the thing.
So, today we will continue on that.
So, what we said was it was structured one what we had taken the thing or direct form one.
So, here we will see how biquad has to be designed.
In the continuous domain first we will see the thing and later on we will go back to the digital So, we know that impulse response with biquad with poles sigma plus r minus j b where with sigma less than 0 or I can take it as a which is less than 0, but no 0s then the impulse response is given in the analog domain H of t is equal to c into e power minus s t cos bt plus theta.
So, pure sinusoid.
when our A is equal to 0 and pure decay when B becomes 0.
So, how we can implement in the breadboard what it is given nowadays nobody does the breadboard design, but one can test it how it is going to be and if you are satisfied you can go for implementation in the regular PCB.
So, we consider a single pole where is it is at minus 1 by RC.
So, we consider 1 percent tolerance for our breadboard R and C values and then C tolerance for the pole location what we assume is 2 percent.
So, we will say that how many decimal digits corresponds to 2 percent tolerance one has to look at it and how many bits correspond to 2 percent tolerance one has to look at it.
So, what we want is the maximum quality factor is about what we say is 25 for.
implementation of analog filters using breadboard resistors and capacitors.
So, if we use this switched capacitor filters, the quality factor what we said was maximum what we can achieve is approximately 40 that is for the tolerance approximately 0.2 percent.
And then integrated circuit implementation can achieve maximum up to 80.
So, breadboard you can see that.
it is going to be half of that of the Isis design.
So, coming to the discrete part of it.
So, we will be representing a plus r minus j b is equal to we put it in r into e power j theta.
So, where r is given by root of a square plus b squared is the pole radius.
So, assume because it is within the unit circle we assume r is less than 1 for stability with y is equal to.
2 a.
Then what happens to our quality factor q which is given by square root of 1 plus r square to the power of square minus y square divided by 2 into 1 minus r square.
Where we assume that half is less than or equal to r q which is less than or equal to infinity.
So, what happens when the poles are real?
We know that b is equal to 0, a is in between minus 1 and then 1.
So, r becomes magnitude of a and y will be equal to plus or minus 2 a and what we call that is q is becomes half that is impulse response is c naught into a power n in that into u of n plus c 1 into n a to the power of n into u of n. So, if the poles are on the unit circle then r will be equal to 1.
So, q becomes infinity that is we call it as oscillatory response and imaginary poles if we have it then a becomes 0.
What happens to our r becomes it is the magnitude of b and y will be equal to 0 and we call q will be equal to half into 1 plus r square by 1 minus r square which is nothing, but 1 by 2 into 1 plus b square divided by 1 minus b square.
So, in the 16 bit fixed point digital signal processor, so we say 40 bit accumulator will achieve a Qmax of 40.
So, you will be wondering when we took up the architecture we said the maximum adder length is going to be 40 bit accumulator what we will consider.
And filter design programs often use R as a approximation of quality factor.
So, how to implement IR filter?
Same approach in discrete and continuous time filter what we will be considering it.
So, the classical IR filter designs what is going to be considered.
So, filter order of n will have n by 2 conjugate roots if n is even or 1 real root and then n minus 1 divided by 2 conjugate roots if n is.
So, response is very sensitive to perturbations in pole locations.
Rule of thumb for implementing IR filter what is it decompose IR filter into second order section that is biquats what we call it and cascade these biquats from input output in order of ascending quality factors.
We will see little later also how we will be working it out what happens to our pole positions.
and then how it will be affecting the cutoff frequency we will see with little problems later.
So, for each pair of conjugate symmetric poles in a biquad conjugate 0 should be chosen as those closest in Euclidean distance to the conjugate poles.
This we will see it in the next class how it is going to be chosen.
Several IR filter design how it is done differ in the shape of their magnitude responses.
So, the first one what we call it as the Butterworth filter which is monotonically decreases in pass band and stop band will not have any ripple in that.
And when we consider Chebyshev type 1 which is monotonically decreases in pass band, but has ripples in the stop band.
The Butterworth you will be seeing it this is what we call it as monotonically decreasing and then will not have any ripples in the pass band.
So, when we come to the Chebyshev type 1, so we say I am considering the low pass filter.
So, here it is what it says is monotonically decreasing, but we will be having the ripples in this.
So, when you come to Chebyshev type 2, we will have ripples in the pass band and then it is going to be a flat response in the case of stop band.
When I come to elliptical, so you will be seeing that we will be having both ripples in pass band and then stop band.
So, which one do we prefer?
So, that is one of the challenge one has to look at it.
So, when we consider the order of the filter, it is an increasing order in this way.
And when you see the pass band attenuation whether you are going to meet a stop band attenuation what which one you want to meet it.
So, we call this is my delta is basically where it is coming.
And, this is my 1 plus delta p what we had represented this is 1 minus delta p. So, in this case whether we are going to select Butterworth I said the order is going to be more whereas, elliptical order is going to be very less compared to other filters, but I will be having the ripple in pass band as well as stop band.
Whereas, Chebyshev 1 has ripple in the stop band whereas, Chebyshev 2 have ripple in the band.
So, compared to which frequency we want to meet most of the time when we use a impulse invariance method it is better to go for the Chebyshev 2 which is going to be in between order.
So, I can allow little bit of ripples in the pass band, but I want to meet the flat response in my stop band.
So, that no aliasing is going to happen.
So, coming to Order of the filter it is as we said that with respect to Butterworth and then Elliptic it stands in between.
So, what it says is classical IR filters have poles and zeros except continuous time low pass butter filters only have poles ok. And all classical filters have bike paths with high Q factors.
So, we will be seeing why we go for the bike path.
in a while.
How we are going to do the optimization?
So, we will be starting with an existing basically classical filter design we are going to use it and we will do IR filter optimization packages from UT Austin which is developed in MATLAB simultaneously you can optimize on the filter order.
So, you will be optimizing on the magnitude response, linear phase in passband what we can achieve using IR filter also.
And then how we are going to control the peak overshoot in step response and how we are going to take care of the quality factors one has to decide and then do the design.
So, we will do little bit comparison of FIR and IR filter in this slide.
So, when we talk about the implementation complexity.
So, we will be comparing the same piece wise constant magnitude specification.
So, for that FIR filters will have higher order whereas, IR filters what we can achieve is with the lower.
So, the factor may be 4 lower compared to higher FIR filters.
Coming to minimum order design when we want to do the thing.
So, we can use Pax-McAleenan or Ramez exchange algorithm.
So, what is the consequence of it?
Coming to estimate minimum order for this algorithm by case may be off by 10 percent.
So, we have to search for minimum order is often needed in this case.
So, whereas, in the IR filter design we know that if we.
a low deviation both in the pass band and then stop band.
So, we can achieve elliptic design algorithm gives us the minimum order.
So, whether it is stable when we are putting a question mark we know that FIR filter is always stable.
So, we say that IR filter may become unstable when implemented.
So, it can tune design to implementation target to minimize the risk of it.
So, we have to see that all the poles are inside the unit circle so that we will get a stable filter.
Coming with the linear phase width can we achieve?
So, we know that if impulse response is symmetric or anti symmetric about midpoint then we always achieve a linear phase using FIR filters.
Whereas, in IR filters we will not achieve it, but phase may be made approximately linear pass band or other band in this case.
So, to conclude on the IR filter biquad section we will see that choice of IL filter structure matters for both analysis and implementation.
So, keep roots computed by filter design algorithms and then polynomial deflation that is routing reliable in floating point.
So, we will it is going to have polynomial inflation that is expansion.
may degrade the roots of it.
So, more than 20 IR filter structures in use.
So, that is direct forms and cascade of bicats are very common choices.
So, why we go for the cascade in our IR filter?
So, we will discuss it in a with a problem later.
So, that you will become convinced that why I have to go for the cascade section.
In the direct form IR expand zeros and poles it may become unstable for large order filters usually order greater than 12th order what we call it due to degradation in pole locations from polynomial expansion.
So, most of the MATLAB when we design our filter we use the MATLAB FDA toolbox.
So, it provides us we call it as stable filter coefficients.
will be using it in our implementation.
Coming with the further conclusion.
So, cascade of by quads that is second order sections only poles and zeros of second order sections expanded.
So, what happens to this if it is a direct form if there is any quantization in my polar 0.
So, the complete structures becomes may become unstable whereas, in the by quads.
If any of this pulses 0s is quantized only it is limited to that structure and it will not affect the other order second order sections.
Biquets placed in order of ascending quality factors.
So, this is going to become an optimization problem one has to look at it and then see that how I can achieve this and that is the way the biquets section will be.
optimal ordering of bike wads requires that is what it says exhaustive search.
And when filter order is fixed there exist no solution, one solution or an infinite number of solutions.
So, if you fix the order we may not have a solution or I may have one solution this is the way I have to connect all of them.
If it is a second order I do not have any choice only one bike wad section I can have it, but if it is more order.
is more than 2 then I can have if it is equal to 4 I may have in that case 2 options this can be first that can be later, but still my poles and zeros can I can alter from the sections and then see that I achieved the what I will say optimal filter structure as well as my instability is going to be much more reduced.
So, minimum order design not always.
most efficient in this case.
So, efficiency is going to depends on the target implementation.
Consider power of 2 coefficient design always and efficient designs may require search of infinite design space.
So, these are the drawbacks of IR filter design.
So, with this we will be still going ahead to design our IR filter.
So, what are the basic structures we need for.
designing our filters.
So, as previously we have seen the thing, but still to give a feel of that how a multiplier looks.
So, we will be putting an arrow and then if I say k then it is nothing, but k into x of n. And when we say adder accumulator is there it can be represented with sigma or plus sign also.
Then x of n and then w of n is the weight then we will be adding both of them x of n plus w of n.
If it is a delay of 1 time basically it can be represented by a square box.
So, you can either specify it as capital D here or Z minus 1.
So, then we know that it is a delay element.
So, x of n is the input output will be x of n minus 1.
So, coming to filter structures just now we said that comparison we did how the order of the filter is going to be.
So, here we are seeing.
second order biquad section for IR filter.
So, you will be seeing that it is a second order for the same magnitude response we need here FIR filter section is shown.
The equation for this is y of n is k is equal to 0 to n minus 1.
As an example in the table we have taken capital N is equal to 30, then how many structures and other things what it is required will be.
seeing in a while.
So, whereas, for the IR filter so, you will be separating this is my W of n centre point and then second order section what we have considered here.
So, W of n is given by x of n into x of n minus b 1 into W of n minus 1 minus b 2 into W of n minus 2.
What happens to my Y of n?
Y of n is nothing, but A naught into W of n minus A 1 into W of n minus 1 minus 8 into W of n minus 2.
So, since we have considered this is my feedback section and this is my feed forward section.
So, this is my whole equation of second order I a filter.
So, we will be seeing how many multiplications are required.
So, for the same magnitude what we said.
So, IR filter needs order 2 whereas, FIR filter needs 12th order then number of multiplications in this is going to be 12 h 0 to h 11.
And then whereas, in the IR filter because it is second order.
So, we will be seeing that number of multiplications in this is going to be 1, 2, 3, 4 and then 5.
So, that is what we represent.
How many additions do we needed?
Whereas, in this case we need 11 additions whereas, IR needs 4 additions you can count on the thing because we assume the addition and subtraction as equivalent.
So, you have 1 here 2 3 and then 4 additions.
And storage locations that is including coefficients and data.
So, how many we need it that is what one has to count.
We have 2.
12 multiplications and we have 12 what we say is coefficients for the h of n what we need it and 12 input what we need it and 1 output what we are going to have the thing.
If current sample is not consider x of n then we will be needing 24 locations to store both coefficient and data output we assume that it is going out of the memory or out of the port.
So, we need not have to have a storage for it whereas, in the IR filter.
As you will be seeing that we have 5 coefficients here basically and then the delay elements w n minus 1 n minus 2 and then what we have one of the input x of n what we needed.
So, you will be seeing that 5 plus 2 7 plus 1 8 is the number of locations that is memory what we need for this structure.
As the order goes.
very high in FIR filter you will be seeing that number of multiplications addition increase even the storage will be increasing it.
So, how we are going to consider the design stages for our digital filter.
So, we are going to start first we will be specifying the performance first and then calculate the filter coefficients and then if everything is according to our wish.
Then, we will go further realizing structure what we have to select and then see that finite word length effects analysis and solution.
Once we have selected that whether it is going to affect our input and output magnitude and then frequency responses or it becomes a unstable filter.
So, if everything is met then we will be going for hardware and our software implementation.
plus testing and then if it is not met here we will go for the redesign of it.
So, if any one of the stage here the finite word length is not met we can go and then fine tune any one of these stages.
So, if everything is feasible then we will stop our design.
So, as we said some of the structures also matters.
So, few FIR structures you will be seeing it.
effect.
This one gives our linear phase as you will be seeing that we said it is a symmetric or anti symmetric what we are going to take the thing.
So, here you will be seeing that this is h of 0 that is x of n and then x of what is the delay here you are going to get it.
So, 1, 2, 3, 4, 5 and then 6.
So, x of n and x of n minus 6 is combined and then you will be multiplying with h of 0.
The same way you can calculate which are the ones getting multiplied and then you will be summing up then you will get a linear phase.
So, if you want to use the transversal as you will be seeing that.
So, h of 0 to h of 6 are my impulse response and then x of n to x of n minus 6 will be the input and when you feed it into the thing.
So, you will be seeing single summation.
So, you may overflow or underflow in this case.
So, y of n will be the output.
How much tolerance you are going to give it?
As I said we are using the 40 bit adder.
So, the order of the filter in our sigma can usually we represent y of n equal to sigma k is equal to 0 to n minus 1 x of n minus k into H of k what we have it.
So, this value n can be up to 255.
So, which is in power of 2 if you take it 2 power 8 0 to 255.
So, it becomes 256 which is equivalent to 2 power 8.
So, what we say is if the our adder is 16 plus 16 bit what we are going to add.
or our registers are 32 bit I can allow a overflow of 8 more bit that is 32 plus 8.
We call this as the guard bits in our accumulator.
So, this we call it as a guard bit in our DSP processors to take care of 40 bit addition.
So, up to 255 that may not we may not have a overflow beyond that we may overflow in the.
FIR design.
So, one has to take care as we said it is almost stable, but the order goes very high then it may become unstable.
So, what are the DSP errors we are going to encounter in our design.
So, it has been listed main errors in DSP are first is our ADC quantization error.
So, this results from representing the input data by a limited number of bits.
So, I can choose 12 bit ADC, 10 bit, 8 bit depends on what type of ADC you want to have it.
And then next is as we have to have a coefficient to be represented in fixed point.
So, I am going to have the quantization error here.
So, that is what it says represent coefficients are DSP parameters by finite number of bits.
So, the coefficients a k and b k from stage 2 of filter design.
For example, are normally of very high precision, but in a DSP processor they must be quantized typically to the processor word length.
And then next is once I have done the coefficient quantization error I have looked in, next is overflow error.
As we are talking about addition or subtraction can give us overflow or an underflow.
So, we say addition of two large numbers of the same sign.
which produces a result that exceeds our permissible word length.
This is one more error what we have to look in.
The last one is the round off error.
So, what is this?
This is caused when the result of a multiplication is rounded or truncated to the discrete value or permissible word length.
So, when I do multiplication 16 bit into 16 bit.
So, I will be resulting in 32 bit, but I would not be able to represent that complete 32 bit as output.
So, I will be truncating them or rounding.
them to 16 bit and then I will be storing.
So, we have taken one example already in our fixed point multiplication and addition.
So, these are the errors.
So, first we will see how we are going to have ADC is going to cause as an error.
So, we know that in the analog domain the values are represented in continuous way.
So, my ADC input voltage what we have it.
on the x axis and y axis will represent what is the value or the depends on the number of bits what I have it.
So, I will be representing to one of them.
So, we know that so, from this 1 voltage to 2 voltage I will be representing with the same value and I will be changing it.
So, this is the staircase what you can look at it.
So, what we want ideal converter finite number of bits we say that ADC characteristics is one of the thing what it required.
So, what we say is it accepts analog input and generates a digital representation.
So, what is the quantization step?
We call it as delta.
So, it is going to be minus 1 LSB bit what it is going to be.
So, if we have full scale input range is represented as this thing minus 0.5 delta 2.
2 power n minus 0.5 times delta.
So, the total will be minus 1 what we are going to have LSB representation.
So, n is the number of bits that one processor has.
As an example if we assume it is a 3 bit processor, then the full voltage scale what we can represent with this representation is minus 0.5 delta 2.
So, this is the full scale range of our ADC.
To show that how the quantizer in expanded form.
So, what is this delta?
So, you will be seeing that from this point to this point this is we assume it as minus 0.5 and this side is minus 0.5.
So, which will be giving me delta.
So, that is what we say that is the error what we will be encountering from our ADC.
ADC quantization.
So, this is represents a zoom in staircase thing.
So, if we consider the pdf of quantization error, then I will be representing it as minus 1 by delta to 1 by delta and then this is your expected value what you will be getting it here p naught e which is what we call it as 1 by delta.
So, coming with the quantization error how we are going to calculate it.
So, we have to calculate.
take it as a noise.
So, will be noise variance sigma quantization noise squared what will be calculating.
So, which is nothing, but expected value of our error squared.
So, when we equate it is minus delta by 2 to delta by 2 into 1 by delta into E squared into delta E basically.
So, which is minus which is equivalent to 1 by delta into e cube by 3 and then you are substituting between minus delta by 2 to delta by 2.
So, when you expand it you will get it as delta square by 12.
So, we say that quantization noise sigma squared is given by or power is given by delta square by 12 and then we assume quantization noise we that is voltage quantization noise rms value is given as delta by square root of 12.
So, that is we say RMS value of a full scale sinusoidal input is given by if your maximum signal RMS value is represented as 2 power n by 2 divided by root 2 into delta.
Then we will be calculating maximum signal to noise ratio this is my signal and then this is my noise.
So, it is 20 log base what we will be calculating it.
This is my signal this is my noise.
So, when we equate this.
it approximately comes out as 20 log root of 6 by 2 plus 20 n log 2.
So, if we approximate it will be 1.76 plus 6.02 n. Accurate this equation is for n is greater than 3.
So, n is the effective number of bits what we are going to have it in our So, it is number of bits what it says is maximum signal to noise ratio minus 1.76 by 6.02 what will be getting the thing.
So, what it says is real converters do not quite achieve this performance due to other sources of error.
So, only we have taken signal to noise ratio there may be other errors we may like electronic noise or deviations from the ideal quantization level which will cause the error more.
To calculate for n is equal to 8.
So, what we are going to get signal to quantization noise ratio is going to be 50 dB what I can achieve 8 bit this one if I have n is equal to 8 then what I will be achieving is the 50 dB.
If n is equal to 12 I can achieve 74 dB signal to quantization noise ratio when it is 16 bits n then it will be 98 dB what I can achieve and if it goes to 20 bits.
what I can achieve is 122 dB.
CD quality what I was telling is approximately 90 dB what we want to have it.
So, we can achieve with 16 bit that quality signal to noise ratio.
So, coming we will work out a problem.
So, whether you have understood our dynamic range and then what should be number of bits required.
So, if the dynamic range of that is DR what we call it of an analog signal to be.
Digitized by our A to D converter is maintained at 60 dB by an automatic gain control amplifier preceding the A to D converter.
So, what are the things we have to determine?
One is minimum number of bits required in the A to D converter and what will be a signal to quantization noise ratio.
So, this is what we have to find out.
So, just we will solve the problem.
So, our dynamic range is given as 60 dB what we have to achieve.
So, we have the equation 20 log.
are log base 10 VFSR is the full voltage what we will be considering divided by delta.
So, in this case we will take it as n into delta where n is the number of quantization intervals what I want to have it.
So, when we substitute this it is going to be 20 log 10 n. So, n is equal to 10 power substitute them 60 by 20 which is going to give me 1000.
So, you know that minimum number of bits required in ADC to code n plus 1 always we take it.
quantization levels to n plus 1 different binary numbers is n should be greater than or equal to our log base to n plus 1.
So, if we do that log base to 1000 plus 1.
So, we say that what I need is 10 bits what I needed.
So, 2 per 10 we know that it is 1024 bits what I will be representing with that is the nearest.
So, now, we have to calculate signal to quantization noise ratio with number of bits selected as 10.
So, if you substitute 6.02 into n.
plus 1.75 dB.
So, which is substitute the thing what I will be getting is signal to quantization noise ratio of 61.77 dB.
So, the maximum what we can achieve what it says is number of bits if we substitute in this equation maximum signal to noise ratio minus 1.6 divided by 6.02.
So, if you see with this equation also you will be getting it as 9.67 bits what I needed.
So, the nearest one is 10 bits.
So, both way working out and using this equation what we had it.
So, both of them are giving us 10 bits.
So, you can try which is going to be less than 3 bits whether they are going to match or not ok.
So, this is what we cover in today's class.
So, we will see how the filter structure is going to affect our frequency component part of it center frequency.
in the next class.
Thank you.
Welcome back to real time digital signal processing course.
Today we will discuss continue with our fast Fourier transform.
So, in the last class we discussed about how to derive the equations from RDFT and then we drew the butterfly structure and then said that how our computation can be improved using FFT.
So, today we will see that what are the finite word length effects in FFT.
So, what are the one is the first one is we can have we are going to have round off errors.
So, which are produced when the product WKB as we can see is truncated or.
rounded to the system word length.
We have been seeing that when it is getting multiplied by this a butterfly structure will be going to be truncated or rounded.
Next one is what we have is the addition.
So, which is going to cause overflow.
So, errors.
So, which results when the output of a butterfly exceeds the permissible word length.
As you can see there is a addition.
So, when it.
exceeds the limit then we will have the overflow.
The other one is Rwk that is coefficients quantization errors this is the third one what we have it which result from representing that twiddles factors using a limited number of bits.
So, because we cannot represent Wk cell for infinite number of bits are not available depending on number of bits.
So, we have to truncate our twiddles factors.
So, that will be causing us coefficients quantization or sign and cause function what we are going to store them.
So, we will see first round of errors.
So, what is it we have we have taken here x naught plus j y naught instead of representing it as a we have taken split as x is input and this is x 1 plus j y 1.
So, this we have our twiddle factor is cos plus j sin function.
So, you are seeing the multiply sign and this is going to be multiplied by minus 1.
And, our output is going to be x naught dash plus j y naught dash.
So, what we are going to assuming that each butterfly generates identical, but uncorrelated errors the maximum noise power at each FFT output is approximately given as equivalent or W n it is nothing, but e power minus j 2 pi by n nothing, but cos 2 pi by n minus j sin 2 pi by n.
So, we represent cos function as c and then a sin function as s and we are taking the negative sin inside.
So, it is going to be c plus j minus of s and then we know that our a is cos into x 1 minus of minus sin function into y 1 same way our b is going to be represented in this fashion.
And then we know that x naught dash is equal to.
are real part x naught plus a what we have it a is given by this equation and y naught dash is nothing, but y naught plus b given by this equation.
And x 1 dash will be x naught minus a and y 1 dash is going to be y naught minus b.
You can verify whether we have got these equations correctly or not.
Then what happens?
Our butterfly computation requires four real multiplication what we have you can see the thing here what we need it.
So, 1, 2, 3 and then 4 real multiplications and 6 real additions.
So, how many of them you can count here this is 1, 2, 3 and then 4.
So, we have another 2 coming from your these 2 a and b here 4 plus 2 what we needed.
So, 6 real additions taking into account.
or subtraction is equivalent to addition that has to be kept in your back of mind whenever we do this additions.
And next what we see is then what happens to our round off noise power that is we call it as variance at the output of each butterfly is going to be given by.
So, we have derived our noise power as q squared by 12.
So, because we have 4 real multiplication so it is going to be 4 into q squared by 12 which is nothing but 1 by 3.
And, then we are substituting q is equal to 2 to the power of minus b minus 1 in terms of how many bits it becomes 1 by 3 into 2 to the power of minus 2 into b minus 1.
And then this is at each butterfly.
So, then we have how many butterflies we are going to have.
So, we approximate it as although we have n minus 1 is the thing number of stages what we are going to have it.
we have rounded it off to n. So, the noise power for n stages is going to be sigma naught squared is nothing, but n into sigma b squared.
So, when we substitute our butterfly sigma b squared which becomes n by 3 into 2 to the power of minus 2 minus b minus 1.
So, we need total number of butterflies required to produce an output sample is.
So, we will be seeing n by 2.
plus n by 4 so on 2 plus 1.
So, when you take the series expansion so you will be seeing that it is nothing but 2 to the power of m minus 1 no 2 to the power of m minus 2 so on plus 2 plus 1.
So, when you substitute it so which becomes equivalent to n minus 1 butterflies are required.
So, which was approximated as n. So, now you will be seeing that how the error is going to have its impact.
So, here you want to compute x of 0.
So, how many butterflies we need it?
We will we have to go back from here ok.
So, I need one butterfly here and the previous stage to compute this and this output here one butterfly is required in the stage 2 and this is the other butterfly required to compute the output of W this thing we need W n 0 in this case.
So, 3 butterflies.
And, in the previous case you will be seeing that we need all the 4 butterflies here.
So, this is 4 plus 2 6 plus 1 7.
So, it is nothing but n minus 1 butterflies contribute for 1 output.
This is x 0 if you take x 4 also what you will be needing the same thing.
So, as an further example if you take x of 2 ok.
This is x.
x0 and this is going to be x1 ok.
This is going to be x2 and this is x6 will be the output.
So, you will be seeing when you count how many butterflies are required you will be needing n minus 1 butterflies to compute 1 output.
So, that is the reason why what we call it as that is when we increase n that is doubling n which is equivalent to adding a stage to FFT.
So, that is what is going to happen.
doubles D noise power to retain the same noise power we increase the word length by 1 bit.
So, we will be seeing that sigma naught squared is nothing, but we are doubling the n 2 into n divided by 3 into 2 power 2 b and then increasing 1 bit.
So, it becomes 2 b minus 1 plus 1 which is going to be 2 power 2 b.
Then what happens?
The real and imaginary parts of our input sequence are.
uncorrelated and that each has an amplitude density that is uniform between minus 1 and plus 1.
Then our sigma x squared input noise power is nothing but 2 square divided by 12 which is nothing but 1 by 3.
So, we can equate it to signal to noise ratio sigma x squared is equal to n times sigma x squared.
This is sigma.
So, then signal to noise ratio sigma x squared by sigma naught squared is equal to 2 to the power of 2 into b minus 1.
So, what the note we are going to carry from here for FFT algorithm a double length accumulator does not help us reduce round off noise.
Since the outputs of the butterfly computation must be stored in b bit registers at the output of each stage.
That is what the note what will be carrying from this.
Just like in FIR filter by increase then the length of our accumulator we could hold on to the result till the end of it, but here we would not be able to do it because we have to use it for the next stage.
So, now, we will see how the overflow is going to cause error.
So, how we can avoid it overflow cannot be avoided.
So, how you.
So, how can by scaling and other things how we can avoid the overflow errors?
There are three methods one is we can do a static scaling that is dividing the input at first stage by n that is a maximum this thing division what we are going to do it or any stage by 2.
So, that way we can incorporate the static scaling.
The other method what we have is.
that is basically based on the dynamic scaling that is dividing the input at any stage by 2, if the largest absolute input value is greater than or equal to less or equal to 0.5 ok.
So, then what happens that is we are taking the norm of magnitude of x of k which is less than 1.
So, 0 to less than or equal to k which is less than or equal to n minus 1.
So, how you will be taking the thing to find the norm.
So, will be equation is nothing, but n is equal to 0 to n minus 1 x of n to w k n. So, we have to take the norm of it, which is less than or equal to.
So, we have assumed that twiddle factors have been scaled and then that within the limit, then it becomes the magnitude of x of n by scaling my input then.
that is 0 less than or equal to k less than or equal to n minus 1 I can overflow error can be avoided.
Just like our FIR filters so if we have more than n minus 1 stages the addition what we can take care of in our accumulator by having guard bits and then later on we have to.
do the scaling ok.
So, the first one that is what we said is static scaling that is dividing the input at any stage by n. So, what happens to the noise to signal ratio increases as n squared or we call it as 1 bit per stage that is if n is doubled corresponding to adding one additional stage to the FFT that is what we just now saw it.
Then to maintain the same signal to noise ratio one bit must be added to our register length.
So, this is our equation what we have it.
So, we will be adding one more bit to that.
So, we say our magnitude of x of n we say that it is scaled by 1 by n. Then what happens to our sigma noise sigma x squared.
input basically 2 by n whole square divided by 12 which is nothing but 1 by 3 n squared.
So, we call it as this is our signal power sigma x squared is approximately equivalent to n and then signal to noise ratio will be our signal is sigma x squared by sigma naught squared which is going to be 2 to the power of 2 into b minus 1 by n squared.
So, what in this case the assumption of a white noise input signal is considered in that case it becomes 2 by n whole square divided by 12 is our signal.
power.
For a variety of other inputs the noise to signal ratio is still proportional to what we call it as n squared with only the constant of proportionality is going to change as you can see the thing here ok.
So, if we do dividing the input at any stage by 2 what is the thing is going to happen.
So, I think there should be some trigger in your mind because why we call it by 2.
2 is we have a barrel shifter.
So, we can shift the dividing is nothing, but right shift by 1 bit is going to give us divide by 2.
So, that we need not have to spend any time in shifting our input.
What happens?
Very little noise only a bit or 2 what we are going to get affected is present in the final array and most of the noise has been shifted out of the binary word by the scalings.
So, you will be seeing that sigma naught squared is approximately equivalent to 4 into sigma b squared just we saw that because of the 4 butterfly which is nothing, but 4 by 3 into 2 to the power of minus 2 into b minus 1.
And then we are assuming our magnitude our norm of x of n is less than 1 by n in this range then what happens to our input noise power.
So, which becomes.
2 square assumption here also it is white noise signal what it is assumed then it will be 2 squared by 12 and then this is 1 by 3 which is equivalent to sigma x squared is nothing but 1 by 3 n. So, the result of an increase of half a bit per stage holds for a broad class of signals with only the constant multiplier in this equation being dependent on the signal.
So, what happens to our signal to noise ratio in the final sigma x squared by sigma naught squared you will be seeing that 2 to the power of 2 into b minus 1 divided by.
4 n in this case after substitution.
So, the other one is we call it as dynamic scaling that is we use the block floating point.
So, what is it definition you may be wondering what is the thing.
What we say is the original array is normalized to the far left of the computer word with the restriction that our magnitude of x of n is less than 1.
And, the computation proceeds in a fixed point manner except that after every addition there is an overflow test fine.
If there is a overflow detected the entire array can be divided by 2 and the computation is going to continue.
So, the number of necessary divisions by 2 are counted to determine a scale factor for the entire final array.
Then we will be calculating the signal to noise ratio depends strongly on how many overflows occur.
And, at what stage of the computation they occur.
So, the positions and timing of overflows are determined by the signal being transformed.
Thus, to analyze the signal to noise ratio in a block floating point implementation of the AFFT we would need to know the input signal.
So, when we call the block floating point is because each a stage we have different stages.
So, we know each stage what is the input required.
So, we will scale this input x of n what we will call it the first stage or I can call it as x 1 of n and then keep those values here.
Do this in the fixed point mode operation.
Then when we are coming out of it either take this values and scale.
So, we will call it as y1 of n which goes as input as an x stage ok which we call it as x2 of n. We can multiply and then do the rescaling of this or in the end what we can do is if there is a overflow then we will be dividing it by 2 in these cases.
If it is not so then we will keep these values till the end and when I come out of here whatever final I will put it stage I will multiply with these values and bringing back into floating point value.
So, that is one value where I know that just as an example.
So, we have 0 0 1 1 ok and the next one is 0 0 1 1 1 or the next value may be 0 1 1.
So, I know that So, these two bets I can call it as left shift and then keep it as 0.11 and then I will be working that is block floating point I will calculate whichever the common take it out and then use the rest of them to for my computation of FFT here ok.
Stage 1 or whatever may be the thing.
This is how our block floating point is going to work in our case.
So, coming to the what are the real time FFT considerations we are going to have it.
So, one of the thing is we have to consider the signal bandwidth, our sampling frequency, number of points FFT n what we wanted and what is the resolution.
So, we have seen the DFT resolution.
So, what we need it Fs by n and maximum time to calculate our n point FFT.
So, that is.
N by F s what we are going to have it whether we want to do fixed point versus floating point DSP.
So, in the lab we have done floating point implementation to do the fixed point implementation we may have to consider the block floating point and then do it.
So, whether we want the radix 2 FFT or radix 4 FFT.
So, if it is power of 4 whatever input it is advantages to use radix 4.
Because It is going to be minus 1 or minus j coefficients what we have to compute in radix 4.
You can refer to the literatures to how to do the radix 4 implementation.
So, we have seen the radix 2 here, but divide that is even and odd parts what we have taken and then how we have computed.
So, the next one is because most of the application is going to be will be using in the windowing filtering.
So, what are the windowing requirements one has to consider.
So, we saw an example in the lab that is.
case a window and then the rectangular window.
So, how our output is going to get affected with the thing.
So, now, to put the thing different radix implementation can be done.
So, if it is power of 2 all of them what is taken is power of 2, some of them of power of 4, some of them are power of 8 what you will be seeing it.
So, if it does not.
fit into any of this category and you are taking some radix format how we can do the split radix format also.
One can be 8 and then if it is order is 2 power 12 if we take the thing I can have radix 8 1 and radix 4 what I can combine and then how I can do the split radix.
So, that is what it shown in this table.
So, as an example this is the least n is equal to 16 what is considered and radix.
So, this 2 needs real multiplications of 24 whereas, as you can see it is come down to 20 because this is power of 4 number of multiplications real multiplications has come down to 20.
In the split radix it needs also 20 in the case whereas, real additions in case of radix 2 we need 152 additions in radix 4 it is 148 and split radix is 148.
we will see the last one 1024 rest of it you can look at yourself.
So, what we radix 2 as you can see that it needs 10248 real multiplications and 7856 in the case of radix 4.
So, you will be seeing that how much difference you are going to have with radix 4 with radix 2 and then we cannot implement the centred x 8.
So, that is why no nothing has been given.
and in the split radix still you can come down to 7172 ok. And then same thing with respect to your real additions it takes 30728 whereas, radix 4 takes 2336 and then split radix is still lesser.
So, depending on your application which radix format what you want to have it that is the application may need 1024 or 2048 or 4096 or if you want to implement much more than that you can see which radix format.
or different radix format at each stage what you can have it and then combine and then take the output if it is not power of 2 also ok.
So, we will see that how the our butterfly structure is represented in a flow graph that is radix 2 8 point decimation in time what algorithm what it has been taken.
So, you will be seeing each point what we have it.
So, you will be seeing that here you are seeing the.
4 butterflies here and in the next stage also 4 butterflies and then in the last stage also what you have the butterfly.
And multiplication and other things are represented with your weight factors as it is shown.
And then we said that to contribute for any of the 2 1 product we need n minus 1 butterflies.
So, there we have drawn everything.
With the flow graphs it is easy to see that we need n minus 1 butterflies ok.
So, we saw just now the signal to noise ratio.
So, you can go through the thing we have number of bits is equal to b bits and then we have seen that noise generated by a butterfly at one stage is fed into the subsequent stages that is in this case n minus 1 stages.
what we call it.
So, then our we said that our noise is represented in this way that is n minus 1 into sigma b squared.
And now you will be realizing for large n we can represent it as n into sigma b squared which assumed it in the previous case.
And then we have signal to noise ratio in this case is approximately given by this equation that is 2 by n to the power of 2 b minus 1.
So, if I want to this thing signal to noise ratio we call it as proportional or inversely proportional to n and directly proportional to number of bits.
As you can see that n is in the denominator and b is in the numerator.
So, that is how by increasing 1 bit you can nullify on whatever signal to noise ratio what you want to get it.
So, we said that overflow errors and scaling in FFT what it has to be done maximum what we call it as that is you will be making it a dash is equal to 1 and b dash is equal to 1 in that case it will be less than or equal to 2 times max of.
A and then B.
So, this implies that the maximum modules of the butterfly output increase from stage to stage by a factor of 2.
So, if the inputs of butterfly of each scale by 0.5, the output should not overflow provided the magnitude of the input data is within the permissible world length what we call it.
So, as an this thing a scaling how we have considered 0.5 as the scaling factor and then deriving what will be the magnitude of it is illustrated by this example.
So, we consider a dash is equal to our real part and then B, B r into cos x plus B i into sin x and this is our imaginary part and then we assume a dash is equal to 2.4142 plus j and then B dash is equal to minus 0.4142 plus j.
So, how we have got this?
If x is equal to 2 pi k by n which is 45 degrees then our cos 45 degree is equal to sin 45 degree which is nothing but root 2 by 2.
So, without scaling and with real and imaginary parts of inputs each is set to 1.
The limiting case we have from the equations from these above what is it?
a dash is nothing, but 1.2071 plus 0.5 g and then b dash will be this value if all of them are set to 1 this is what we will be getting it.
So, we know that.
what will be our maximum output from this butterfly structures.
So, to see that by adjusting how many bits are required to keep our signal to quantization noise ratio required, we will see that processor one problem in this case.
So, what it says a hardware FFT processor uses a fixed point arithmetic in its butterfly computations.
So, estimate the maximum word length required to.
perform a 1024 point FFT with an output signal to noise ratio of 40 dB.
In this case you are lucky to have just 40 dB.
So, assume that the input to each butterfly is going to be scaled by 0.5 which is nothing but 1 by 2 throughout the FFT.
So, then signal to noise ratio equal because we are scaling by 2 it is going to be 1 by 2 n into 2 to the power of 2 into b minus 1.
So, we have been given signal to noise ratio in dB as 40 dB substitute this put it as 10 log on the right hand side.
So, you will be solving this then I need b minus 1 is equal to 12.14 bits which is nothing, but 13 bits approximate it to the next higher number.
Then system word length for this is equal to be b is equal to 14 bits.
So, you can see if I want to have the CD quality which is 91 dB.
So, if you are this thing scaling is 0.5.
So, you can see that how many bits are required you can work it out and then come back with the answer.
So, this we have seen that how the quantization is going to affect our number of bits and then how many end points what we have to choose it.
And in the next class we will be covering overlap add and overlap save techniques.
to compute long input signal because as you are seeing in the present case the length of the input is also restricted to n minus 1.
Whereas, in our real time application input is coming continuously.
So, how we can apply this FFT using overlap add and then save in the next class.
Thank you.
Namaskara.
So welcome back to real time digital signal processing lab this time, so we have seen how overlap add and then same method is with an example.
So, we will use MATLAB code to see that how it is going to work in real time and then we will be seeing on the board also.
So, as you can see here some of the codes I have able to show you in the last class for DFT and FFT.
So, I had not explained you overlap although we have run some of it.
So, here it is going to run on.
an audio signal.
So, you will be generating what is it TIMIT 2 dot AAC file that is the speed sampled at 8 kilohertz with 16 bits what it is going to it is already stored actually.
So, if you want you can record your own speed signal and then load it in this area.
So, it can be if you have sampled at 8 kilohertz.
So, you can do it or you can change your sampling frequency and then record your own signal.
And, use that particular sampling frequency in running this code.
So, first we will be running the original speech and then you will be seeing that sound SC the stimative what file it has it and then it is getting sampled FS frequency and 16 bits what it is used.
So, you will be playing it first then what is it now.
So, your length of speech file as you will be seeing it for draw.
1 minute or whatever it will be there however long you have stored it that you will be using it here.
So, first you have to take the length of the signal and then your n is going to vary 0 to n x minus 1 and then f what we are going to introduce is 1 kilohertz.
So, frequency of sine wave is noise in this.
So, that will be using the filter in overlap add method.
So, we will be taking omega is equal to 2 pi f by f s and sine wave created with that amplitude is 2000 and then create this with sine of omega into number of samples is n that is throughout your speech signal this frequency is going to be present ok.
So, now, next one is what is that?
So, you will be combining with the speech signal, sine wave signal what you have generated that is basically corrupt speech by 1 kilohertz tone.
So, if you want you can have any other noise random noise or white noise you can add it and then see that you are going to eliminate using your filter basically.
So, we will be displaying thus and then you will be hearing the.
noisy speech signal with this command.
Then you can have a display of it how it is going to look like.
So, as we have discussed in the theory you can calculate the spectrogram using MATLAB function.
Here you will be using the case of window and then number of points what you will be putting it is 200 order and you are 256 points and then.
F is what you will be calculating and then if you are using the this is the latest MATLAB what it says you can select if you give a help on spectrogram you will be getting what are the parameters you have to use it.
So, earlier one what it says is older MATLAB will be using this only number of points and then sampling frequency what you have to give it along with the input signal.
So, you can give title to that noisy signal and then you can.
it the spectrogram and then pause it and then until you press the next key.
So, you can view your spectrogram there.
Now, you can define the window because sine wave what we have created is 1000 hertz that is 1 kilohertz.
So, I want to eliminate that.
So, your filter has to be band stop filter or a notch filter what you can design use the filter design toolbox or you can use here in command.
window also.
So, the stop band region is 1000.
So, you have given 900 to 1100 as your transition band and the sampling frequency is fs by 2 which is 4 kilohertz in this or 4000 hertz.
Then you compute the filter coefficients b, you can use the FIR 1 filter with what is the order of the filter you are going to provide 128 order filter what you are designing it, W n is whatever you have specified here stop band.
And, then you are calling it as a stop band filter what you want to design.
So, then you will be FIR filtering using overlap add method what you will be calling directly.
FFT filter will be using the overlap add method.
So, you will be giving Y n F s n then 16, b is your filter length and then F s is the X n is the input and then you will be seeing that.
when you pass it filtered signal through your sound sc command and you can plot your spectrogram also with respect to this.
So, what we will do is we will put a break point here.
So, then run the code.
So, the previous one you will be seeing it is a overlap with different frequencies what you are seeing it sine and cos function.
So, it has come to overlap of two spectral lines due to frequency.
So, you will be seeing it 60 and 61 what we had done.
She had your dark suit in greasy wash water all year.
This is the spectrum of the speed signal as you can see the thing.
So, now, it is going to do the filtering as you can see the thing overlap add technique what it is going to use to.
She had your dark suit in greasy wash water all year.
There it was the previous selected speech signal, now also you have selected the normal speech.
Now, you will be seeing that it is waiting for any key to be pressed.
She had your dark suit in greasy wash water all year.
As previously shown that is you have a sine wave constant, you are seeing that at 1 kilohertz what you have it ok.
So, and then these are the speech.
So, this is how you have overlapped with the speech signal you are.
noisy sign wave.
So, now, it is going to waiting for one more time to do filtering.
So, you will be.
She had your dark suit in greasy wash water all year.
So, you have heard that although there is a little sign tone is left out, but most of them have been eliminated.
So, now, you can generate your cause.
And, then take the this thing power spectrum what you can calculate to find the power spectral density and other things.
So, if we run the complete code you will be seeing that your power signal what it is going to be the complete signal y how it is it.
So, this is one sided power spectrum of your y and then you have the signal here.
So, one sided power spectrum of y y what you have it and then signal here what you have recovered.
So, you will be seeing that how both of them are look like and then you will be seeing in the output power signal y what dB or word length what it has it and y y what is it here will be seeing that you are finding the use the periodogram function with the rectangular window.
that is what you have used it in this case previous one was the case of window and then trying to do that here there is no overlap is going to have.
So, then what are the power signal what you will be achieving it is shown in this.
So, now, we will go with the resolution just now we discussed about it.
So, what is the thing is going to happen with n is equal to.
8 and then the sampling frequency chosen as 8000 we saw in the theory.
So, we will look at it how it is going to look like.
So, you will be having 0s padded here and then you will be computing sine wave and then you will be taking the FFT of the signal which have been combined here.
So, we will run the thing.
So, you will be seeing that for 8 bit.
this is what the resolution is going to be of your coefficients.
So, if I increase it to 16, so you will be seeing the magnitude spectra how it is going to look like.
So, one can use the subplot to plot one over the other and then see that how both for 16 point and then 8 point how it is going to look like.
So, the next one what it does is you can have a quantization effect built into this.
So, you will be seeing that what is it your sampling frequency is 1 into e power 6 and then your f x is 15 to e power 3 and then your f is magnitude is 1 and you are telling n is 2 to the power of 11 point fft what you are going to have and then you will be taking the input signal is a cos basically.
multiplied with magnitude 1 and then this is the normalized position what you can look at it and plot the signal and then you will be calculating N FFT as n point and then your s what you are going to define is 1 by N FFT into absolute of FFT of y comma N FFT and then your frequency you will be seeing the line space one sided power spectrum of y.
And, what you will be getting is you can see the periodogram with the rectangular window what you are going to use for the y signal.
And signal 2 what you will be taking is here you will be defining b is equal to 2 and delta is 2 by 2 to the power of b.
And then your fs is this and cycles what you will be choosing is 67.
And your yy signal whatever you are going to get it is this one.
So, then compute your power spectrum from the thing and you can do the quantization how it is going to look like ok.
So, we will run this and see you will be seeing the same thing what we had got it in the previous one.
This is our y, y by signal and then y 1 what is the output.
And this is the quantized one is the.
So, you can see that with number of quantized points what you have given the thing and this represents your original signal and then error between the original signal and then quantized signal you will be seeing that this is how the error is going to creep in.
So, you are seeing to the original one sided power to the quantized one you will be seeing there are little peaks what.
it is going to appear.
So, how much you can tolerate after quantization to fixed point what you can have a look at it in the case fine.
So, coming to we have discussed about overlap add and add method already usually students what then I give them is to design both overlap add and then save.
So, in this case I will be showing you what they have designed.
So, this is the sampling frequency we assume it as 8 kilohertz in the thing and then the whatever you have to generate 40 samples in one period.
So, that is 8000 divided by 40s the signal what you will be generating is 200 hertz signal in this case.
So, they will be using as we discussed in the IER filter.
to our FFT calculation we use sine generation using IR in the oscillatory mode.
So, to generate 200 hertz these are the values what it has to be generated.
So, your y 1 is 0 y 1 of 2 is given with these values and then for k is equal to 3 to 10000.
So, you will be generating your sine wave y 1 of k with respect to.
As you can see this is the IR filter, this all is your amplitude and then y 1 of k minus 1 is your feedback signal and then y 1 of k minus 2 is the second feedback signal, what you will be providing to oscillate the filter.
So, then what is it here one of the frequencies here it is 200 hertz.
So, you have to generate 3 sine waves usually I ask them to do the thing.
In this case they have taken x 1 is 30 samples which is going to give us 267 hertz and in the same way third one is 400 hertz what it is generated using our IR filter in the oscillatory mode.
Then combine all these 3 y 1 y 2 and y 3.
So, you will be getting 3 frequencies which you can plot it ok.
So, take the absolute FFT.
defined by the function in this case and then plot their magnitude.
Now, you will be generating FIR bandpass filter of 237 to 297 hertz to get the second frequency of order 350.
So, you can see that FIR 1 is a 350 order.
So, something should be striking in your mind to eliminate in a short this thing frequency.
So, what they have given is that is 237 to 297 is their transition band what it is being used.
So, this is the high order to eliminate one of the frequency from the 3 frequencies what it has been generated.
So, this will be passed through you will be seeing that filter basically what you can do the thing.
So, length going to implement direct convolution first what you will be doing it length of y.
And, then you are doing the convolution of it and generating the remaining length minus l length plus 1 elements of output what you will be doing again the second convolution.
So, this is how your overlap add method has been done.
So, here first one is overlap save method what it is going to be.
So, FFT length is defined as 512 and then the length of whatever the filter is.
what you have assuming it and then size of each signal segment is 162.
Then you will be padding with 0s and then your FFT of H is nothing but FFT of your H that is you are taking the FFT of your response of the filter.
And then you will be output array for final output what it is defined here.
And, you will be having the for k is equal to 1 what you will do it.
So, FFT of the first signal what you will do it.
So, you have 0s and then y 1 to s length and first you are padding with 0s and then y you have taken the thing.
And, then you will be doing the as you can see it is a convolution basically FFT of H dot into FFT of s that is.
basically in the DFT domain you are multiplying 2 DFT signals here both H and then S. Then you will be outputting the IFFT of this output.
So, this you will be plotting it and you will be doing for first one you have done it for k is equal to 1 and then 2 and then 3 and then afterwards you will be going up to the length by 2.
So, this is how you do overlap save method and the last one you will be doing it manually fine.
So, the thing you will be seeing that the first one is a overlap save method.
So, what we will do is we will put a break point here and then run our overlap save method.
So, you will be seeing that this is how we have generated.
3 distinct frequencies as you can see that it is 240 hertz, 297 and then 400 hertz if I am correct.
These are the 3 frequencies what it was generated and then you will be seeing at the fs was 8000.
So, you will be seeing the mirror image of the 3 frequencies on the left side also.
So, this is the input to overlap add save method the first one.
And, then after it is using a band pass filter as you can see.
So, it has eliminated the other two frequencies and then your can you tell me what kind of filter it is.
In the previous case we saw it was a band stop filter, here it is going to be a band pass filter.
So, you are using only one frequencies to be passed.
So, if you check the thing.
value what you will be getting it as 267 is passed the other 2 frequencies have been eliminated and that is using your overlap save method.
This was the direct convolution using direct convolution the same thing.
So, using the overlap save method also you have got the same thing.
Now, it is going to be using overlap add method.
So, we have discussed in theory the how it is going to work this is how this has been.
implemented as you will be seeing that how the 0s have to be introduced and then you will be adding the previous length and then doing it.
So, you will be seeing somewhere down the line the addition of it ok plus 1.
So, all the your x 1, x 2, x 3 till the length of it what you will be adding them.
So, then you will be calculating your inverse FFT and then adding them here out a what you will be seeing it here concatenation is going to happen here and you will output.
So, you can see that here also you will be seeing that only using the overlap add method this frequency what is it basically your 267 harmonic overlap save method this frequency is left out.
So, this shows that how our overlap add and save method to run different ways of it.
One we saw it with the audio file and then we have seen with the frequency generated using IAR filter in the oscillatory mode to eliminate the two frequencies only passed only one of the frequency using this method a using MATLAB.
So, we will take a break and then.
come back for CCS.
Thank you.
Welcome back to the course real time digital signal processing.
So, we are continuing with the IR filter.
Today we will see that.
quantization and then how it is going to affect our design basically.
As a recap we have been discussing from past two lectures IR filters you know how it is going to have effect on the quantization and then how to design it, why we have chosen IR filter and then compared to FIR filter except linear phase we are going to have.
few number of filter coefficient which is going to be designed.
So, that is the advantage of it and then we know that most of the earlier work goes on using analog filters.
So, we will see what are the quantization values what we are going to get it is here it is going to show me H of n. So, you will be seeing the FIR filter continuous signal.
The values which are represented is minus 1.2.
10 power minus 4 to you will be seeing that some more values are present.
So, when I do the quantization of it what we call it as H q of n quantized thing.
So, you will be seeing threshold what we will be putting these are the values which are not going to be represented.
So, you will be seeing up to some of the very low values which are going to become 0, then rest of it are going to be quantized to certain values.
So, you will be seeing in the end also.
So, some of the.
coefficients are made 0 although they have the values.
So, this is the quantization what it is going to happen.
So, in the FIR filter.
So, how the response is going to be we will see it in a while.
So, you will be seeing that the black representation shows that this is the frequency response with respect to magnitude.
So, you will be seeing based on the quantization which is shown in the dotted lines.
So, you will be seeing that my cutoff frequency or stop band just gets moved up.
So, from minus whatever it is around greater than minus 80 dB.
So, which will be dropped down to around minus 40 or 30 it is in the range minus 30 to 40 dB.
So, this is the coefficient quantization.
So, one has to consider when we are doing using in the hardware.
So, our design has to account for this quantization effects.
So, coming to.
So, the this thing this is the passband region what it has been taken.
So, you will be seeing how it is going to be represented this is in the terms of magnitude and this is in frequency in kilohertz.
So, this is black one shows are unquantized and then the dotted lines it shows that it is the quantized.
So, here I am supposed to get a flat response.
So, where what is the thing is happening?
So, there is a.
a ripple in my pass band in the representation.
So, these are the effects one has to consider.
So, what is the thing is going to happen with this quantization?
So, we will see in effects of it.
So, whatever we have h of n if it is un quantized then output is going to be a normal.
So, if there is an error because of the thing so, which is going to be added with respect to that.
output will be my impulse response coefficients what I will be getting it.
So, in terms of frequency domain we know that h of n is going to be represented as h of omega and then our error function is represented as a of omega.
So, output will be quantized basically h q of omega what will be the response of the filter.
So, how it is going to affect we will see in this.
block diagram that is basically dynamic range and accuracy requirement of different applications one needs it.
So, we know that in noise cancelling.
So, dynamic range in number of bits what we will be telling 32 bits what we needed.
So, whereas, accuracy it is 20 bits is enough whereas, in the radar processing it is 32 and then same thing 20 bits whereas, in case of broadcast quality picture processing.
So, both what we need is 20 bits.
So, we see in the image processing it is 30 and 20.
So, medical spectrum analysis if you are doing it both can have 20.
So, when you are going for the seismic data processing you will be seeing that the dynamic range what we need it 70 bits to 20 bits.
So, most of the cases whatever we are designing 6 7 1 3 DSK board what we are using it which is 16 bit.
So, almost it is nearer to the thing what we can.
So, coming to quantization so, all of us know that what we have to do is because most of the signal in nature is analog in nature.
So, we represent it analog input as x of t. So, if I want to do what is it band limit the signal.
So, I have to pass it through the low pass filter.
So, we call this as a anti aliasing filter also.
So, that will be.
limiting the stop band frequencies which are going to creep in.
Most of the stop band frequencies we say higher the frequencies are the noise.
So, we are limiting it and then we will be feeding it into our sample and hold circuit.
So, when it is closed you will be seeing that more than whatever the value of it.
So, we will be getting the output it sample and hold circuit is going to work then we are going to do the quantization.
So, we know that depends on number of bits.
So, the representation will be 0 to 2 to the power of n minus 1, n is the number of bits.
ADC circuit what it is going to have.
So, we have to do the encoding of this number, we use a logic circuit to do the thing and x of n will be my our digital output coming out of our ADC.
So, we have seen the different structures, here we are going to see that this is my direct form 2 what we derived it in the last class.
So, what are the coefficients for it is b naught b 1 b 2 and a 1 and a 2.
and then x of n y of n w of n and then w of n minus w of n minus 2.
So, these are the parameters what I have to store it.
So, when I see the direct form one structure.
So, we will be seeing that this is a 0s are in the feed forward whereas, poles are in the feed backward stages.
So, you will be seeing that I need so many coefficients to are 5 in this case also except that we need y of n minus 1 y of n minus 2 output also in the case of it.
So, that is 3 plus 2 5, but we need output to be fed back into the system.
Whereas, as we can see here I have one adder as I have discussed in the last class also the quantization effect may nullify sometimes here.
Whereas, in this case we have it may little bit over write.
So, that is the representation we have y of n is as we know about it is b naught into x of n plus b 1 into x of n minus 1 plus b 2 into x of n minus 2 minus a 1 into y of n minus 1 minus a 2 into y of n minus 2.
So, in both the cases it is the same, but the delay elements here what we need is.
4 delays whereas, in this case it becomes only 2 delays in the case.
So, that is the reason why most of the applications use direct form 2 structure compared to direct form 1 structure.
So, now, we have to see that when we have taken the direct form 2.
So, how the coefficients are going to be represented whether they are going to cause any instability so, we will be seeing that.
It is the coefficient values for a stable second order IR filter.
So, what should be the region of it?
So, we say this is our coefficients a 1 and then a 2 what we are representing.
Most of the time it is the poles which are going to have instability for the filter.
So, we will be considering a 1 and then a 2 coefficients what we have plotted.
So, we call this is the triangle which is going to be represented.
So, we know that.
1 is maximum and then minus 1 in this and then we will be having 2 for a 1 and minus 2.
So, the rest of the thing represented minus a 1 will be this is equal to 1 plus a 2 this location and then this is a 1 is equal to 1 plus a 2.
So, how we have arrived at this is shown with the poles here.
So, we consider the feed backward section and then analyze it.
So, what we have is 1 plus a 1 into z minus 1 plus a 2 into z minus 2 which is nothing, but 1 minus p 1 into z minus 1 into 1 minus p 2 into z minus 1.
So, we represent a 1 is equal to p 1 plus p 2 and a 2 will be p 1 into p 2.
So, we see that poles must lie inside the unit circle for our stability.
So, that means, that magnitude of a p 1 should be less than 1.
And, magnitude of P2 should be less than 1 in this case.
So, magnitude of P2 also has to be 1, then what happens magnitude of A2 what it is given by magnitude of P1 into P2.
So, which is less than 1.
So, A1 as you can see it is 1 plus A2, so it will be magnitude of it can go up to.
2 that is what we get it from this triangle this is how it has been plotted.
So, coming to the advantages of cascade section we will see with an example here.
So, impulse response of the filter in z domain is given as h of z is equal to 1 by 1 minus 0.9 z minus 1 plus 0.2 z minus 2.
So, if we consider the pole then what happens z is equal to 0.4 and z is equal to 0.5.
So, in the cascade form representation we represent this as h1 of z into h2 of z.
So, what is it?
We will be having h1 of z is nothing, but so 1 by 1 minus 0.4 z minus 1 and then h2 of z is going to be 1 by 1 minus 0.5 z minus 1.
So, actually this has been converted into 1 minus 0.4 z minus 1 into.
1 minus 0.5 z minus 1 will realize this equation that is how the poles are there.
So, if we say that I am going to represent it with 4 bits you have to call back our number system then what happens.
So, we have to represent all these values we will see in a while that is 0.9, 0.2, 0.4 and 0.5.
So, what is the nearest number I can represent with all these values.
So, this is the direct form what I have taken this is the second order section what we have taken the thing.
0.9 is represented as 0.875 and then 0.2 is represented as 0.125.
So, in the case of 0.4 we will represent it as 0.375 and then 0.5 directly is represented as 0.5 in our fixed format.
So, coming with the thing so, this is what we have done the second cascade section.
So, what happens to the pole locations?
In the direct form what we call it as because this is the quantized values what we are going to represent it.
H dash z is r z is equal to 0.1 and z is equal to 0.695.
In the cascade form what happens to our H dash of z.
So, here it is going to be z is equal to 0.375 and then 0.5.
So, you will be seeing that instead of point what we are supposed to get is 0.4 and 0.5.
So, in the direct form pole location is at 0.1 and 0.695.
So, you will be seeing it that very far apart whereas, in the cascade form you are seeing that they are nearer to whatever the values what we have represented.
So, that is the reason why we use the cascade form compared to the direct form.
So, you will be seeing that the poles are nearer.
The poles cascade realizations are closer to the desired or impulse response in the z domain what it shows.
So, now, how the because we are going to have many cascade sections it is only second order one section what we have taken the thing.
If we have multiple sections how we are going to combine because we will be arriving at poles and 0s.
So, how we are going to combine them is shown by this diagram that is first what we do the thing complex conjugate poles what we are considering here.
So, they have been named as first conjugate pole here and then the second set and this is the third set.
So, we say the closest to the unit circles.
So, that is which is closer to unit circle is named as 1 responsible for the greater overshoot are paired with complex conjugate zeros closer in frequency that is angle on unit circle.
So, we pair this one with this one.
So, that is the reason why we have colored them.
The first one which is shown with green is paired with this green, the next one is the blue.
So, that is what it says then the process iterate with the next complex conjugate closest to the unit circle.
So, this one with next 0s and then one is nearer to the 0 is connected with the nearer to the pole of 0s.
So, otherwise one has to do trial and error method or you have to see how the pairing is going to happen as we have seen in the last class.
So, the So, quality factor how it is going to affect our pairing also is one of the important aspect.
So, this is one of the method what one can use.
So, that we may get a good pairing of poles and zeros in our cascade section.
So, coming to the thing as we know that direct form 1, we said that there is no overflow it may or may not have it, but definitely we have in the cascade section.
2 adders which are coming in.
So, because it is the same what magnitude what it is going to be added or same sign magnitudes are going to be added.
So, I may have a overflow or an underflow.
So, to avoid this overflow and underflow we have to have a scaling factor.
So, you will be triggered with why did we choose a scaling thing that is barrel shifter what we call it either shift right or shift left which is required for scaling my input also in this case.
So, that is what it is shown here to prevent our overflow in storing at node W.
N ok, we need a scale factor to have a 0 dB gain from input to this node.
This scale factor what we call it as alpha k is commonly computed depending on the nature of signal that will be processed.
So, for narrow band signal in this case we have we use the L infinity norm, then we get alpha 1 as 1 by.
norm of 1 by A of f infinity norm what we are taking it.
So, if we want to process the wide band signal we usually use L2 norm.
In that case our alpha 2 scaling is going to be 1 by norm of L2 norm of 1 by A f input signal.
So, further more we have alpha 2 greater than or equal to A 1.
always this is at a higher this thing value compared to alpha 1 we are going to have the scaling.
This is the maximum scaling what we can provide.
So, how we are going to order that is what we said criteria for scale factor computation we are going to have it as L infinity or L2 norm one way one of the thing what we will be selecting it.
So, which norm of the quantization noise we want to minimize whether we want to L.
infinity that is the maximum value or L2 norm that is the power which is going to be considered.
So, these are the rules one has to apply.
So, L infinity for scale factor and L2 for noise that is we will be ordering the second order section ascending order of overshoot.
So, when we have L2 for scale factor and L infinity for noise then we will be having descending order of overshoot what we have to look into the thing based on this will be.
or second order section in ascending order or descending order depending on one of this.
So, if the same norm is used, so there is no preferred order.
So, you can go in whatever order you want to have it.
So, what is the practical application of IR parameter?
So, here we have considered P i is our pole positions which is given by R So, r is the radius of the circle into e power plus or minus j omega naught.
Omega naught is the angle of frequency what we are considering.
So, we assume that r p is in the range 0 and then 1.
So, the transfer function can be expressed in that case as we have h of z is equal to a divided by 1 minus r p into e power j omega naught into z minus 1.
into 1 minus r p into e power plus or minus j omega naught z minus 1.
So, when you this is my conjugate poles what I have taken the thing.
So, will be this is the second order sections what we are representing this is the first one and this is the second one what we are multiplying it.
So, then I expand the thing it becomes a by 1 minus 2 cos omega naught z minus 1 plus r p squared into z minus 2.
So, we represent these values as a1 and then a2.
So, what happens in the frequency domain?
So, if we are considering the normalized filter, the magnitude response is given by that is we will be substituting z is equal to e power minus j omega naught in this equation.
Then it becomes h of omega naught magnitude of it is given by a divided by 1 minus.
r p into e power j omega naught into j e power minus j omega naught and then the second term what you will be getting it.
So, the this condition can be solved to obtain the gain that is what is my a is equal to.
So, the magnitude of this.
So, some quantized values q minus r p what we will be assuming it into 1 minus root of 1 minus 2 r p into cos 2 omega naught plus.
So, how we can represent this ok.
So, this is my magnitude a x of n is the input and then what I have is z minus 1 is the delay.
So, the equation has in from the previous case what we are taking 2 r p cos 2 omega naught here.
So, that is what 2 r p cos omega naught is represented as a coefficient.
and this is my minus r p squared is the other coefficient.
So, which are fed into my adder and y of n is the output.
So, we say that this is the signal flow graph of our second order section.
So, what will be y of n if I consider this is the filter as the name says it is a resonator filter I will comment on it in a while.
This is a into x of n minus r.
a1 into y of n minus 1 minus a2 into y of n minus 2.
So, where we have a1 is equal to minus 2 rp cos omega naught t sorry cos omega naught and a2 is rp squared.
So, consider two causal impulse responses that is hc of n is given as cos omega that is the cos function what you have considered cos omega naught n into u of n.
So, the second one I can consider it as a sine function h s of n is equal to sine omega naught into omega naught n into u of n. So, then the equation as you will be seeing that the cos function is given by this equation and then sine function is represented this way.
Then what happens to my y c of n is nothing, but W of n minus cos omega naught into cos into W of or n minus 1 and y as sine function is given as sine omega naught into W of n minus 1.
So, we where we say W of n is an internal state variable that is updated as using this equation W of n is equal to cos 2 omega naught into W of n minus 1 minus W of n minus 2.
So, coming to the resonator.
So, all of us know that infinite impulse response why the name comes is once I remove the input.
So, I can remove the x of n. So, the system is going to oscillate on its own.
So, what is the advantage of it?
So, this resonating response what we will be using it in our generating sine wave.
So, we will see in the lab how we can giving only these 3 coordinates as we know that sine function is represented using the.
table, you can do the thing or we derived the harness way of representing it by expanding in series or you can use the math function, sine or cos function.
All of us know that when we use these functions, it is going to take a long time to compute.
So, with this IR filter with 2 feedback, we know that we can calculate the amplitude with 2 input because it is a LTI system usually we give initially 0 then automatically by giving x of n equal to 1.
So, it automatically start resonating and then we can generate different kinds of sine frequencies and then we can use it in our sine generation.
So, the next application is in the recursive quadrature oscillators.
So, those who are comfortable with communication you know where you need the quadrature oscillator.
So, how we are going to generate this?
So, you will be seeing this is a W of n and then W of n minus 1 in this case also.
So, you will be seeing that.
2 cos omega naught is the feedback signal what it is going and then feed forward what we have is a multiplication with sin omega naught.
And you will be seeing 2 delays this is W n minus 2 which you will be subtracting with the thing and you will be getting your cos and then here you will be getting the sin.
So, how you are going to get it?
So, you will be seeing that Ys of n is nothing, but a into X of n.
So, that is what you are getting the thing minus a1 into ys of n minus 1 minus a2 into ys of n minus 2 which is nothing, but if you simplify it is going to be 2 cos omega naught ys of n minus 1 minus ys of n minus 2.
So, with the initial conditions ys of 1 is equal to a sin omega naught and ys of 0 is equal to 0.
Then, I can calculate the frequency of it as cos inverse my magnitude of a 1 by 2 into f s by 2 pi into in terms of hertz.
This is the frequency what I will be generating it, where the coefficient magnitude of a 1 should be less than or equal to 2 which we caught it in our triangular representation ok.
So, this completes our IR filter for with respect to structure and then what is the quantization effect.
So, we will be solving some of the problems how a center frequency is going to change with quantization.
So, without quantization at with number of bits that is represented.
So, we will be seeing in our next class.
Thank you.
Happy learning in this class.
Namaste, welcome back to real time digital signal processing lab.
So whatever we have studied in theory regarding the adaptive filter will be.
seeing the demo first in MATLAB in the next class we will be seeing on the board using the code composer studio.
So today we will present the MATLAB.
So we will see the autocorrelation function with an example using MATLAB.
So what is it number of samples is chosen as 1024 and f1 is the frequency of sine wave what we will consider and f2 is.
other frequency component which is 200 hertz, f 1 is 1 hertz which is the sampling frequency both of them.
And then we will first we have to generate the sine wave using the sine function in this case what we are using it.
So, as we have discussed in the sine generation you can use any of the method either you can use the table, you can use IAR filter as an oscillatory function or you can use the sign function basically.
In this case we have taken sign function and then we can do the subplot and then see how it is going to look like.
Then what we this is the frequency what it is generated with sampling frequency of this thing what is it 8 kilohertz.
So, one it depicts that as the 1000 hertz and 200 will be 2 kilohertz what.
it is going to be generated.
So, then you will be calling the autocorrelation function in MATLAB Rxx which is nothing but X correlation of X basically and then we will plot it and then we can Rxx is getting plot and then we will see how it is going to look like.
So, this is the function in MATLAB what will be running it.
So, we will check the thing.
So, it will be asking me from which folder it has to take a default it may be there.
Since I have opened it or you have to go to that particular directory and open the file.
So, all the files are here as you can see.
So, it is running.
Now as you will be seeing the thing this is the sine wave which is correlated with the other sine wave.
So, you will be seeing the peak in the center and then which is going to be.
dying down in this case.
So, this is how it works and we will see that if we change the add a noise to it.
So, we have generated that is between the correlation between the two sine waves.
Now, if the sine wave is buried in a random noise what will be generating get so that is x plus the.
noise added and see whether we can see in that particular noise the correlation between the whatever input what we want to get that.
So, again we will be checking why is our noisy signal along with the original signal which has got embedded and then with the original signal we are trying to correlate and what will be our we call this is the cross correlation.
So, in this case because we are taking the correlation between two different signals.
So, if it is with the same signal we know that it is autocorrelation here it is between two signals.
So, we call it as the cross correlation basically and we will see how the output is going to look like.
So, this is the sine wave which is buried noise signal what you are seeing the thing.
So, this is y of n.
So, you are unable to make out the thing when I take the cross correlation.
So, you will be seeing that your signal is present that is what the cross correlation is going to show in this case.
So, now what is the next one we will see cross correlation.
So, this is between sine wave and then cosine wave first example what we will be seeing it.
So, you will be seeing that.
So, these are the T and T2 are the two frequencies what will be taking it, wave periods what you will be multiplying with and then sample period what you will take it.
Here over sample is 1024 in this case and frequency is 1 kilohertz and then you will be this is the sample period with the by over sample what you will be taking it.
So, you will be doing the generation of sine wave here.
and cosine wave and then you can see the correlation between sine wave, cos wave and then the sine wave and then see how it is going to look like.
So, we will run the code and you will be seeing that this is what our code looks like.
What we will do is, one thing what I have to do is for you to look at the think correctly.
So, I will try to reduce the display settings, so that you can view the thing correctly.
So, I will make it 100 percent and then only for the letters we may have to have it little bigger.
So, I can make it this is little bigger for you to view the signal.
So, you will be seeing that these are the two signals.
So, when you do the subtraction of it.
there will be something correlation coefficient is going to be more in this case.
So, that is what we will look at it and then we will see for the I will be passing sine wave and then I will be passing the other one is a exponent.
So, how does it look like we will see it.
So, I will be commenting the cos wave and then I am calling the with the same name because I need not have to change at this place also, but this is now the exponential decaying signal.
So, minus 0.1 into.
T whatever T is getting generated here in the same way ok. Then we can see it in T2 also what is the thing is going to look like.
So, we will run this again.
So, you are seeing that this is what your that is cross correlation between your exponentially decaying signal and then the sine wave.
When you add them out you will be seeing that it becomes 0.
So, that that shows that they are not correlated.
So, as we discussed in the theory if it is plus 1 it is positively correlated, if it is negative negatively correlated or if it is 0 it is uncorrelated.
So, this is what it will show.
So, we will see that with respect instead of t we will put it as t 2 and see whether it is going to make any difference here.
t 2 was the sample period which was getting generated with respect to.
are cause with signal.
So, we will run the thing.
So, you will be seeing that it is how the distance is when you add both of them you will be seeing that it is going to become 0 irrespective of whatever changes you have done.
So, this shows that how our correlation is going to look like some other functions are there.
So, you will be seeing that how to generate But, if you see the thing this is generating 64 samples of this thing sine wave with frequency 1 kilohertz.
So, how you can run that and then the other one will be how to generate your exponential signal.
So, you will be seeing that this is what how the exponential looks like which we this thing run the cross correlation with this exponent and then the sine wave generated.
And, then the other one you will be seeing it is generating what is it 64 with this thing unit impulse signal how to generate it what it is going to show some of the signal generation what you will be looking at it.
So, this is the unit response.
So, at 0 it is going to be 1 and rest of the places it is going to be 0s as you know how to generate it using MATLAB these functions show.
Now, with this correlation so, what we will do is we will go to adaptive filter.
So, we have already seen this adaptive filter in the last class.
So, what we will do is how to generate our LMS and then NLMS algorithm and then see the difference application what we discussed in the class.
We will look at it noise cancellation and other things and then how to generate our echo and then scrambler and equalizer with respect to matlab what we will see it and then the same thing we can look at it in the code composer studio also.
And we will be seeing these are the assignments done by as I have been mentioning by different students.
So, how they do that and then how your code also can be what we will look at it.
So, this.
will be a m file what it is going to run it.
I will be closing because we have finished the thing.
So, we can open this.
So, here it is doing a GUI.
So, LMS algorithm demo what we have seen the thing.
So, we will see NLMS and then RLS those who are interested can look into the thing and then see that how it is going to work want to work because it is a very complex equations one has to write and then it will take time for most of the applications either we will be running LMS algorithm which has faster because we know that time consumption for inversion of a matrix and other things will take longer time in our hardware.
So, we will be trying to avoid ok.
So, you will be seeing that.
So, this is what the how the creation of our LMS algorithm.
So, the order is defined with 20 if you want to change the order you can do the thing and then the weight functions are initially set to 0 and then mu is set to 0.006.
So, we have seen that varying the mu how it is going to get affected ok.
So, you will be seeing that up to the length of X minus order.
So, you will be putting it.
So, our y out of i is going to be ok. What I will do is now before running the thing I can increase the font size so that you would be able to see them properly ok.
I will make it as 125 and then when I am running the thing if the graphs are coming then we may have to reduce the thing.
So now you will be seeing length of x minus the order of your filter.
you will be putting that what is it buffer is initialized and then y out of i is buffer of into our y into your this thing weight function w into 2 and then error function is calculated of y i minus buffer into w and this is the weight function which is getting updated w plus buffer dot star mu into our error of i.
So, update the weights and then we will be computing it.
So, the next one is NLMS algorithm.
So, here we will be defining alpha.
Alpha is equal to 1 we said it is equivalent to LMS algorithm.
So, here alpha is chosen as 0.005 and then your constant what you will be calling it as 0.7.
So, you will be doing the same thing with.
your mu is calculated on the go as you can see it here.
It is 2 times alpha divided by because we said some small constant what we have to assume.
So, that divide by 0 is not going to happen and then you will be doing the buffer squared in this case ok. And then your weight function is going to be updated.
So, as you can see that this division also has to happen which is a costly affair as we have seen in the.
class.
So, multiplication is easier to do it we saw Braun multiplier, but division successive subtraction what we have to do it which is costly.
So, that that is the reason why most of the cases will be assuming mu and then will be running the LMS algorithm.
In the worst case if it is not ok then we may have to go for this.
So, the other one is RLS algorithm you will be seeing that.
So, your this thing will be calling it as a random function and then you have to length of the w is going to be 0s and then some constant what you will be providing.
In this case gamma is one of the constant one has to use it which is almost nearer to 1 what it is shown in the thing.
And then the equation you will be seeing that how you will be calculating your temporary value and then error.
function what you are calculating and then alpha is going to be calculated in this case using gamma plus r buffer basically.
And then g is the constant p into buffer divided by alpha what we will take and then the weight is updated based on these constants basically g value and then you will be calculating the that is p value power of the thing by gamma and then your y out is.
n is going to be your y temporary what you have calculated here earlier ok. And this is how you will be updating your this thing what is it mu value which is going to be calculated and then as you will be seeing that lot of division and then multiplication are involved in the RLS algorithm.
So, we will see but it is much more precise than the both of the algorithm.
So, we will run the algorithm as you will be ok I was able to see the thing otherwise I had to reduce my size of the what I will put it as screen to in any case to have a better clarity what we will do is put it in the 100 percent our display size.
So, that you will be able to see them clearly.
So, as you can see here.
I will make it maximize.
So, I will be loading the noisy signal.
So, I have to select the thing this is the noisy signal what I have it and then I have to load the reference signal both has to be fed into our algorithm.
So, this is the desired signal.
So, now, we have run it already in the previous class LMS algorithm, but to have the better understanding of it I will run the LMS algorithm and you are seeing that this is the noise.
added signal what it is shown this is the original signal when you do the LMS algorithm you are getting back.
So, we will play the thing it is the same speed signal what we will be doing it.
Remember the force will be with you always.
So, you will be seeing with the noise.
Remember the force will be with you always.
Here also single tone as we demonstrated in the filters same thing has been used for a adaptive algorithm.
So, you will be hearing the output.
Remember the force will be with you always.
So you can see initially there was a dip.
So we will run the same thing with an LMS algorithm ok.
So you have seen that the thing is little bit shifted and we will hear it how it is different from the LMS algorithm.
Remember the force will be with you always.
So now we will run the RLS algorithm which is much more precise.
as you will be seeing that this is your input signal and this is with the noise and you are seeing your output almost your complete noise is removed.
So, we will play this.
Remember the force will be with you always.
So, one has to pay for computation if you want to have much more clarity ok.
So, we will get back to our 125 percent so that we can see the thing and then when we running the code will go back again to our 100 percent.
So, this shows our NLMS and this thing algorithm.
So, what we will do is again as I said different students do different way here everything put together.
So, the other students what they do is some of them they do it in a different way it is directly LMS algorithm.
here it is going to run ok.
So, that is what is it you will be algorithm remains the same thing your order of the filter may vary and what tone you will be taking it is going to be different.
So, this is going to start from 120 this thing x and y arrays basically.
So, what you are storing it.
So, this will be your LMS algorithm i is equal to L you will be starting from L value down to 2 actually that is why minus 1.
So, you will be updating your X i in the reverse direction ok.
So, this consumes less time when you are doing the from the other end to this end.
Basically circular convolution should happen.
So, that is what is implemented here.
So, you will be seeing that.
x filter through the thing.
So, that is up to the filter length you are calculating your y, x of i into your w of i because n minus i what it is the thing what it is taking x of n i minus n you can take it and then you will be multiplying with w of i.
And then this is your error function which is given by WI that is desired signal big of n minus y you will be knowing even you may name it in a different way ok. And then update of W is going to happen.
So, that is mu error is calculated as mu into en error and you will be updating the WI.
You may be wondering why this has been done earlier why not in the other student what he had done was it is inside this loop.
I will be updating my error and then I will be using it.
So, can you guess what is the thing is going to happen because I am putting in the loop every time this constant has to be multiplied.
Otherwise I can there are going to be how many multiplications along with it 2 more multiplications I have to provide.
Here I have reduced it by 1 so that which is pre-computed this is not going to change.
according in the loop and then you can multiply and get the result.
So, you will be getting your error basically shown this way.
So, let me run the thing and then.
So, ok.
So, let me run the thing.
So, one of the thing is what is it?
This has not been calculated.
So, what we will do is I have to hopefully I will be able to uncomment it and then we will save it and then try to run the thing.
While it is giving an.
in the can you guess what is the thing it is unable to get voice and then tone dot wave file actually sorry I have missed to put the thing what will do is I can bring the thing from the other one and then put it here here both you have been I will put the copy it here and then we will see and then change the name with this name.
That is nice see sorry I should use capital save it and then I can run.
There is this thing because it is you will be seeing that index in position 2 exceeds array bounds this should not exceed what it says.
So, the problem with this is because it is a different signal what I have taken because they would have set it to their requirement as you will be seeing it I had to get this file here and then run the.
So, that we can see it in the hopefully I have the that thing it has not been copied for the thing.
I will get that signal so that otherwise we have to.
So, whatever error is coming what it shows is it is a two channel what it has to take it.
So, here it is having only one channel.
So, unable to read this file.
So, when they have combined the two thing together we have to read them.
So, what I will do either we have to correct this or because it may give some more error in the thing the way they have implemented it because it is two channel what it has taken the thing this is.
They are putting it as a first channel and this is going to take from the second channel.
As you know it is a stereo input.
So, stereo input the first channel what you can input is your desired signal.
In the second this thing that is left channel will be desired signal, right channel you can put the noise basically.
So, that you are depicting whatever we discussed in the class that is the signals are coming from two sources one is the desired signal the other one is your what is it.
noise separately captured from two places which has been combined and then put it as a audio basically in.
So, this has to be merged using the MATLAB code and then you we must be taking it in.
Here it is only one channel what it present that is why it is giving me error.
So, thank you for listening.
In the next class we will take up the scrambling and then.
what I will put it as echo generation, reverberation and then scrambler together.
Thank you.
Welcome back.
So, we are discussing about Pipelining and then Parallel Processing for Low Power Applications.
Continuing with the thing.
So, because we need for parallel processing the data has to be fed in parallel.
So, from sequential how will be converting into parallel we will see in the this figure that is what we say is critical path has remained unchanged in these cases, but the interaction period is going to be reduced in this.
So, what we say is x of n is the input then we if we consider in this case as we are seeing we will be considering.
4 parallel lines.
So, that it will give you a flavor of how 2 parallel lines we have to take it, how 3 and then now we will see 4 parallel line parallel units if we consider then what is the thing is going to happen.
So, the sample period what we will do is we will subsample it to T by 4 in this case.
Then we will go for serial to parallel converter and then we will be getting x of 4k plus 3, x of 4k plus 2, x of 4k plus 1 and x of 3.
k in this case and then in this case the clock period is going to be t for multiple input and multiple output system and output all the 4 of them will be coming out parallelly.
And then we have to convert back this parallel into serial converter.
So, how we can incorporate that?
So, in this way clock period is going to be t by 4 and we will convert back this parallel into serial.
So, which will be.
coming out from the circuit as y of n in serial mode.
So, we will see using the switches how serial to parallel converter and then parallel to serial converter is going to work.
So, this is my x of n and then input is t by 4.
So, we will provide the delay element in our path and we will be providing the switches basically to see that all the output whatever input has been given.
will have 4 of them.
So, every t by 4 clock cycle.
So, you will be switching on one of the unit.
So, all the 4 inputs are ready after my t by t clock cycle.
So, then what will be this is how will be feeding in all the 4 parallely.
Now, this parallel has to be converted into serial basically.
What we are going to do?
What we have it is via 4k plus 3.
2 and then plus 1 and then 4k.
So, what we have is this is going to operate at 4k the switch and then you will be closing them every t by 4 as you are seeing it in this y of n is the input and one of them is going to be opened and then you will be sending after a delay.
So, for the first this thing switching all of them will be switched parallely.
So, you will be.
Taking all the 4 inputs, so this will have a 0 initially what you will be putting it and then you will be switching on this and then you will be seeing that 0 is going to be percolated first and then you will be operating on one after the other 4k will be coming out first and then next this one after 1 unit of time and then next this one.
So, each one is clocked at T by 4.
So, in a 1 clock cycle in the 4 clock cycle so, you will be getting 4 outputs.
This is how we will be doing the serial and parallel conversion and then parallel to serial conversion.
So, what happens why parallel processing is required.
So, parallel leads to duplicating many copies of hardware and the cost is going to increase as well as if we are operating with same units.
or same voltage we know that our speed is going to be increased and power consumption is going to be more.
So, then why use this?
So, we say answer lies in the fact that the fundamental limit to the pipelining is at I-O bottlenecks.
So, that is referred to as communication bound composed of I-O pad delay and the wire delay.
So, in this case you know chip 1 and chip 2 is there, this is the between the two chips this is the communication delay what we are going to have it.
So, in the case of pipelining if my communication cost is more than pipelining then no point in going for the pipelining stages number of stages to be increased.
Then it is better to switch over to parallel processing then I can work on independent data in these cases.
So, what we call it as this is the parallel transmission what I can have it.
So, you will be seeing that T is my computation.
So, taking in the data from chip 2 to here and data going from chip 1 to chip 2.
So, this defines the thing.
So, we will see that how we can combine or find grain pipelining and then parallel processing.
So, you will be seeing the iteration we said that sample period is equal to T sample in this case.
Then what happens if I put both of them pipelining and then parallelism it becomes 1 by.
L m into t clock.
So, that means, to say 1 by sixth of t m plus 2 a it is going to be at iteration every iteration I will be getting one sixth of my what is it I have increased my clock speed.
How I can do this fine grain parallelism?
So, you will be seeing that input is x of 3k plus 2.
So, x of 3k plus 1 and x of 3k.
So, this is our parallel unit and then when I come to multiplier I can bifurcate in them into pipeline mode that is m 1 becomes 6 clock units and the other one I can take it as 4 clock units.
So, I have provided 2 pipelining basically m is equal to 2 and l is equal to 3 then my iteration time that is how it is going to be 1 by lm is 1 by 6 original time what it will be I will be getting the output.
So, you will be seeing just all the multipliers we have made it as pipeline multipliers.
So, that multiply clock time is made equal to the other side of the leg what we considered in the previous example.
So, what is the underlying low power concept we have to look in?
We said by I can increase 6 times the clock speed for my both the pipelining and parallelism or.
at the clock rate one sixth of it what I can operate, but how we are going to have a power low power getting the thing.
So, initially we said that this is the propagation delay equation what we had it.
So, the time period you will be seeing that for the sequential power consumption we call it as c total v naught square into f into t sequential is our clock period what we will be taking for every bit of data.
So, then what happens our delay is given by propagation delay P d is given by C into charge basically my capacitor charging time and then V naught what is the power input power and then k is a constant because this is proportional to we are assume the k and V naught is our input voltage and V t is the threshold we know that in CMOS circuit.
So, we have a threshold unit.
So, in NMOS we will be seeing that 1.5 volts whereas, in CMOS it is going to be 0.5 volts above that we consider it as 1 volt.
So, that way we will see that power consumption is given by P is equal to C total into.
V naught square into f ok.
So, for the sequential filter when I apply this, this is what I will be getting it and then when I put the propagation delay is substituted, I will be getting C charge into V naught divided by k into V naught minus V t whole squared.
So, we are substituting V naught with this and then into f. So, which is going to be 1 by time for sequential.
So, do the pipelining what is the thing is going to happen?
We say it is M level pipeline system, the critical path we say is 1 by M. So, that is capacitance tends to be charged in a single clock cycle becomes 1 by M. So, as you are seeing in the sequential I have to charge this capacitor in T sequential whereas, in the pipeline if I assume M is equal to 3 then the capacitor has to be charged as you will be seeing the time.
is going to be reduced basically we call that as beta into v naught.
So, here initially it was v naught and we will assume beta into v naught.
The clock frequency is if we maintain the same clock frequency and we say the power supply can be reduced to beta times v naught.
We say it is 0 is less than or equal to beta which is less than 1, 0 is less than beta which is less than 1.
So, coming to low power continuation.
We say power consumption what we said for the pipelining it is going to be c total into beta squared into v naught squared into the frequency.
So, which we apply it as a sequential thing which is beta squared into p sequential.
Then what happens to our propagation delay?
So, that is t sequential we will be having c charge into v naught divided by k into v naught minus v t whole squared and for the pipeline case.
We said the charging unit is reduced by m whatever in this case we have taken it as 3.
So, otherwise in normal C charged by m what it has to be charged to the in pipelining into beta into v naught we are substituting v naught with beta, beta into v naught.
And here also we will be substituting k into beta into v naught minus v t whole squared.
Then we will apply that sequential is equal to.
of pipelining stage.
If we substitute them then what happens by simplifying it you will be getting it m into beta into v0 minus vt whole squared.
So, which is equivalent to b into v0 minus vt whole square from this equation we will be getting our beta.
So, we will consider an example here.
So, we will consider a 3 tap FIR filter and it is fine grain pipeline version what we will be assuming it.
So, it is shown in the following figure that this is the original or 3 tap FIR filter and this is our fine grain parallelism what we have considered.
So, in this case what the parameters have been given is my multiplier unit is going to take 10 units of time.
And my adder will be taking 2 units of time and you have been given the threshold voltage is given as 0.6 volts.
and then V naught that is the supply voltage it is operating at 5 volts and the capacitor of multiplier is equivalent to 5 times that of the capacitor of the adder.
So, you will be seeing that pipeline filter the multiplier is broken into 2 parts M1 and then M2 with computation time of 6 units and then 4 units which will be totally accounting for 10 unit of time with capacitance of 3 times and 2 times that of an adder.
adder respectively what we will be considering it.
So, what happens to the our equation?
So, original what we had was C charge was given by C m plus C a.
So, we said C m is 5 times of C a which is going to be 6 times C a.
In the fine grain it is going to be C charge equal to C m1 which is equal to C m2 plus C a because we have.
1 pipeline stage there.
So, which is equal to 3 times that of C a what it is going to be.
So, then our equation we will be seeing that m is equal to 2 in this case we have assumed and then supply voltage v naught is 5 times beta minus v t is 0.6 threshold which is whole squared is equal to which is equal to beta into 6 is our.
basically minus 0.6 whole squared.
So, which comes there are as when you solve this equation.
So, it is going to be beta will be equal to 0.6033 or 0.0239.
So, we say that because our threshold voltage is 0.6 voltage what it has been given this value is much below that threshold.
So, capacitor will not be switching on.
So, we say that this is infeasible.
So, it becomes 0.6033 is the.
supply voltage what we can reduce to that is a ratio is we call it as beta squared when I take it the reduction is going to be 36.4 percent.
But we say that pipelining should have given me 50 percent, but in this case only the reduction can be 36.4 percent.
So, as you can see in this case.
When we do the comparison how it is going to be that is system is power is reference And, sequential FIR original if I take it that is in terms of my power reference and pipeline FIR without reducing the V naught what I will be getting is 2 times the original one I am supposed to get the output.
And then in case of with reduction in the voltage so, it becomes 0.364 times the whatever power consumed with respect to reference.
And, the clock period unit time what we are assuming is here it is going to take 12 units of time in the original because multiplier is 10 units and then adder is 2 units which is 12.
And, then in the case of pipelined so, it will be taking 6 unit of time whereas, when I without reducing the voltage, but if we reduce the voltage so, we know that the clock period remains as the original one which will be having 12 units of time.
And, sample period we know that this is 12 units and here it becomes 6 units whereas, in the pipeline with reducing power it will be still 12 units.
So, we will see that parallel processing for low power how we are going to achieve it.
So, we say that we have L parallel system since maintaining the same sample rate clock period is increased to L times the sequential one.
So, this means that your C charge is charged in.
L into T sequential and the power supply can be reduced to beta times V naught.
So, we are seeing that in the sequential the capacitor that is going to be charged with respect to T sequential at V naught voltage.
Whereas, in the parallel if I we are assuming L is equal to 3.
So, then what happens this becomes 3 times T sequential all of them and power the voltage reduction is going to be beta into V naught what we will consider.
So, we will same thing what we will be applying the equation.
So, the parallel will be L into c total into b into beta into v naught whole squared plus our frequency by L because I will be getting 3 outputs in 1 clock cycle.
So, I will be my frequency can be f by L. So, which we will be equating it as beta squared into p sequential.
Then, what happens to our propagation delay?
So, this is t sequential original c charge into v naught by this one.
In the parallel case c charge into beta into v naught whole divided by k into beta into v naught minus v t whole squared.
So, then l into t sequential is equal to t parallel.
So, we will be applying both together l into beta into v naught minus v t whole squared which is equal to beta into r v naught minus v t whole squared.
So, we will be getting beta from this.
equation.
As an example, we consider a 4 tap FIR filter shown in this figure basically and we have going to consider 2 parallel versions of this one.
Here we will be considering the first version in the next slide we will consider the second version what is the thing is going to happen we will see that.
The 2 architectures are operated the sample period 9 unit of time assume your multiplier is going to take 8 units of time and adder is going to take.
1 unit of time and the threshold in this case voltage is given as 0.45 volts above that capacitor is going to be charged 1.
So, V naught is equal to 3.3 volts what it is given that is supply voltage and then C m what we are going to have is capacitor for the multiplier is equivalent to 8 times that of the adder.
So, it is asking the question is what is the supply voltage of the 2 parallel filter.
And, what is the power consumption of the two parallel filter as a percentage of the original filter?
So, you are seeing the two parallel filter what we have considered.
So, here in this case what is it original or capacitor charge is equal to C m plus C a.
And, then in the case of two parallel section what happens C m plus 2 C a which is nothing but 10 times C a.
And, then if we apply the.
So, we will be seeing that 9 times 3.3 into beta minus 0.45 whole squared which is equal to 5 times beta into 3.3 minus 0.45 is the threshold voltage whole squared.
So, in this case beta becomes 0.6589 or 0.0282 as previous case we have to ignore this because this is less than the old.
voltage of 0.45.
So, we will be considering 0.6589 as beta, then for the parallel section 0.6589 into 3.3 volts which is going to come down to 2.1743 voltage.
So, how much reduction we are able to get it 43.41 percent in this case.
So, coming to the next section that is parallel here what we have done is.
you have the 4 this thing multipliers here and here also 4 multipliers and you will be seeing that x of 2k and x of 2k plus 1 are the input to this structure.
So, we will see that by modifying it the structure in this way what we have taken is x of 2k structure with little arrangement that is we call it as a linear phase.
FIR filter if I consider the thing H0 and H2 can be here and then the other thing I can derive from that that is H0 plus H1 will be multiplied here and the other one is H2 plus H3 what I can combine and H1 and then H3 are coming from this parallel section.
So, by doing little modification to the previous structure what we will be getting is output is going to remain Y2 of k and Y2 of k plus 1.
So, one of the assignment for you is.
what will be the output at here junction A and then junction B what you have to calculate as well as at C. So, we call this is area efficient 2 parallel multiplier.
So, you have to count how many adders and how many multipliers are present in this case.
So, we assume that we are charge is C m plus C a what we are assuming it which is going to be.
9 times CA because 8 cm plus 1 CA is equal to 9 CA and we have new 2 parallel that is charge of the capacitor is equal to cm plus 4 times CA what we will be having it because we have 2 parallel section.
So, which is equivalent to 12 times your original adder capacitor.
So, if we substitute in thus because here also it is 2 parallel section.
2 into 9 will be achieving this equivalent to 12 times beta into 3.3 minus 0.45 whole square.
So, then beta turns out to be 0.745 or 0.025.
So, as earlier cases this is infeasible and we consider our pipeline the parallel version of it is going to have 2.45857 volts.
And, then the ratio with respect to this you will be calculating it as 43.6 percent the saving in the voltage.
So, in the previous case you have saved 43.41, here you are saving 43.6 percent with area efficient because I have reduced my the adders and multiplies by introducing the delay in a proper.
So, please look into this.
So, now, can we combine pipelining and then parallelism together and then try to achieve better voltage reduction that is what we will look in this slides.
What is it?
We have the sequential as usual and then pipelining we have C char divided by m whereas, in the case of R parallel it becomes L time T sequential.
So, which implies that I will be making the left hand side as number of stages for pipeline into number of stages for parallelism which is given by m and l into beta into V naught minus Vt whole square which is equal to this.
So, if we consider both of them m is equal to l is equal to 2, then we are operating V naught at 5 volts, then what threshold is given as 0.6 volts.
So, if we compute the values.
beta becomes 0.4, then beta squared will be 0.16.
So, this is how we will be doing the thing, this is our sequential.
So, what we have done is 3 parallel units what we are going to have it.
So, and then one pipeline what we have considered.
So, to conclude this pipelining for low power, we discussed about 3 tap FIR filter for pipelining.
And then we consider for parallel processing also 3 tap and then 4 tap and 2 tap filters.
And then pipelining and parallel processing together how you can achieve low power that is what would demonstrated you can work out some of the problems and then see that how it is going to improve on your power consumption that is what it is going to be reduced.
So, in the next class we will be discussing about IR filters.
that is low pass and little bit on high pass filter.
And then as we know that IR filter is going to lag in the case of linear phase will be achieving only in FIR filter.
So, IR filter becomes non-linear.
So, we will look into that in the next class.
Thank you.
Today, we will discuss about Pipelining and Parallel Processing for Low Power Applications.
The recap of the last classes, we discussed about Linear Phase FIR Filter in length.
And, then how to build it that is what we have seen in the last class.
In today's class how we can use the architecture that is pipeline and parallel architecture to build a FIR filter for low power applications.
So, when I talk about the low power in this case we will be considering the capacitive load power consumption which is given by P L is equal to C L into V c c square into F naught into N S W. So, we say that.
the power is proportional to we say the frequency and square of voltage what we call it.
So, we can if we reduce the voltage we know that the power consumption is going to come drastically, but for speed we have to increase our frequency.
So, we have seen that we can use the architecture for speeding up our computation using pipeline and parallel.
So, the frequency is going to be increased, but in this case we will see that how we can use the thing by reducing our power consumption that use by reducing our operating voltage.
So, here we will give it P L as a capacitive load power consumption and V CC is a supply voltage and F naught is our output signal frequency and C L we call it as external load capacitance basically and N SW will be.
total number of outputs switching.
So, if we assume 1 bit what we are transmitting, so it becomes n is equal to 1.
So, switching load will be 1 in this case.
So, if we have more number of bits that also will be contributing to our power consumption.
So, we will see what is the basic idea of pipelining which I have already discussed that is we took either a car assembly in this case example is given Henry Ford in 1908.
So, what we call that example we took the water pipe in the last class.
So, we will be seeing that the pipe of the length of the water pipe is less than our latency is going to be less, but if it is long then we know that it is going to have a maximum latency we call it as critical path.
So, further increase the clock speed or sampling speed to or reduce the power consumption.
to for the same speed in a DSP system.
So, for the parallel processing we will have multiple outputs are computed in parallel in a clock period.
The effective sampling speed is increased by the level or parallelism if you want to increase the speed or we can reduce the power consumption.
So, why do we need pipelining and parallelism?
One is to reduce our critical path that is the longest path delay.
And, increase the clock speed or sample speed what we are putting it or achieve a reduced power consumption.
Same thing with the parallel processing not reduce the critical path here, not increase the clock speed, but increase sample speed and then we can use it for reduced power consumption.
So, we will see the data flow in parallel and pipeline structure how it is going to be implemented.
So, we say that.
We have 4 processors here P1, P2, P3, P4 if there is no data dependencies we know that all the 4 processors will be working on different data sets.
So, if we have the same number of processors in pipeline processing.
So, we say that each processor has to wait for the previous data to be finished computation to be finished and then it should be coming into.
the next stage.
So, each processor you will be seeing that the latency of this P4 processor is it has to wait for 4 clock cycles till it can operate.
So, once all the data have been filled then they can work in parallel.
So, that is what the latency of the pipeline whereas in the parallel processing all of them there are there should not be any dependency between the data in this case.
So, when we say that.
How it is going to have this thing data dependence?
We say that in parallel processing requires no data dependence between the processors, then only we they can run in parallel.
So, as you are seeing it that data flow in P1 processor is going to go in horizontal way same thing with respect to rest of the processor.
Whereas, in the case of pipeline we said there is a data dependency between the two processors.
So, P2 is waiting the data from P1.
The same way P 3 will wait from P 2 and then P 4 will be waiting from P 3.
So, this is how the data will be if they are dependent then the flow is going to be in this fashion.
So, coming to the usage of pipeline processing how we can do the thing?
We can do by inserting latches or registers between combinational logic circuits.
So, that way we will be reducing the critical.
path or it can be shortened.
So, the consequence of introducing this is will be reducing the clock cycle time and increase the clock frequency.
So, it is suitable for DSP applications that have we call it as infinity long data stream.
So, we are assuming that input data is coming continuously.
So, we have to operate on that.
So, method to incorporate this pipelining how we are going to do it we will see it in a while.
using the cut set and then do the retiming of the circuits.
So, we will define the cut set we call that as a set of edges of a graph.
If these edges are removed from the original graph the remaining graph will become two separate graphs that is there are no dependence between the two graph they have to become independent then only we call that as a cut set.
Usually, we apply feed forward cut set in our filter.
So, in this case we call feed forward because data move in the forward direction and all the edges of the cut set.
So, there will not be any feed backward data flow.
So, only we consider the if there is a feed forward data then we call that cut set as a feed forward cut set.
The other one is read timing.
So, how we are going to see the read timing.
of an algorithm is readjusted while keeping the partial ordering of execution unchanged.
So, that the results are correct.
So, we will see that how we will be doing that.
So, as an example we will take that this is the data flow graph what we have it.
So, data is moving from A1, A2, A4 and then A6 is the last thing or it can flow in this direction.
So, we say that d means there is a delay in this data path.
So, what will be the longest delay that is what we have to see in this graph or we call it as the critical path.
Since there is a delay, so we will assume that it will be going into this register, it can be a register or so that it is going to hold the data and then in the next clock cycle it will be going into this.
So, here we will be seeing that from A3 the data has to flow to A5 and then to A4 and then to A6.
This is the longest path in this.
So, which we call it as it is going to take 4 clock cycle or 4 unit time to get the data from one node to the last node in this case.
So, we said that we will put a cut set basically.
So, I can cut the graph into two pieces in this way.
And then we said we are going to introduce delay units wherever we have put the cut set.
So, or a shift register one of the thing what we will be using it.
As we can see that we have cut this into two parts this way, but we have forgotten to put a delay unit here.
So, that is how it says this is an error basically.
So, how if we cut this properly and then put all the delay units in the cut set.
Then what happens to our critical path what we will see it.
So, we say that from A3 to A4 I have a delay path and then from A4 to A6 it is direct and then what we have is from the delay unit if I take that the data is moving it has to move to A4 and then A6.
So, that way it takes 2 clock units to reach the.
maximum delay in this circuit or in the data flow graph.
So, what is it?
So, some of the concept what we will see how we will be representing our pipelining and parallel concept is represented.
In the pipelining we introduce pipelining latches along the data path.
So, this is the original circuits x of n is the input and then this is one of the a of n is the coefficient b of n minus 1 can be the other coefficient.
So, y of n is going to have it as.
A of n into X of n plus your V of n minus into X of n basically.
So, this is my Y of n when I say that the critical path is going in this case is 2 adders.
So, it has to pass through them to get my Y of n. So, I want in a single clock cycle my Y of n has to come out.
Then what I do is I cut this line into two parts and introduced a delay line.
So, I am putting increasing the hardware.
So, x of n is this it will be added in one clock cycle and this is going to be latched here and in the next clock cycle I will be adding with whatever data coming from here and the output in the current state is going to be y of n minus 1 and then in the next clock cycle I will be getting the y of n. So, I will have compared to.
previous structure I will be getting one delay output initial output after that it is going to come continuously.
When we talk about the parallel processing so we will be duplicating the hardware.
So here we have duplicated 2 units basically then what happens to the input it has to be x of 2k to the 1 of the stage for the other one x of 2k plus 1.
So here even the coefficients as you will be seeing it becomes a of 2k and b of 2k.
So, k will be varying from 0 to n minus 1 in this case only 2 what we have it.
So, the other input to the second structure is a of 2k plus 1 and then b of 2k plus 1.
So, coming to the thing when we use FIR filter we will consider as a 3 tap FIR filter.
So, if we use the direct form structure as you are seeing that I am talking about the structure even the structure is going to matter when we are designing our circuit.
So, here we have used the direct form in that case what is the equation for my FIR filter?
y of n is nothing, but a into x of n plus b into x of n minus 1 plus c into x of n minus 2.
So, we say that the sample period t sample should be greater than or equal to tm that is the multiplier plus the longest path in this is going to be from here to here which is going to incorporate 2 adders.
So, my sample period has to be tm plus 2 ta.
When I talk about the sampling frequency should be less than or equal to 1 divided by tm plus 2 ta.
So, depending on the time it is going to take to multiply and then add will decide my sampling frequency for this 3 tap FIR filter.
So, the coefficients what we have assumed is a b and then c. So, how will I get my y of n what is shown here.
x of n is the input and these are the delay lines x of n minus 1 and then x of n minus 2.
So, as the equation suggests here y of n is equal to a into x of n and b into x of n minus 1 plus c into x of n minus 2.
So, that is what my 3 tap FIR filter.
When I consider the sampling frequency what should be for this.
So, if I talk about the sampling period T sample should be greater than or equal to the time taken to do multiplication and because the longest or the critical part delay what we call it here is 2 adders what it is included 1 multiplier and then 2 adder.
So, it becomes Tm plus 2 times time for addition.
So, the sampling rate is going to be less than or equal to 1 by 2.
Tm plus 2 Ta.
So, we will see how we will avoid this.
One of the thing is as we said we can have a cut set in the because as you are seeing in the structure all of them in the feed forward path the flow what it is going.
So, I can have a cut set.
So, we said that it is taking 2 clock cycle to add whether I can reduce it to 1 clock cycle.
Then what I am going to do is I am going to put a cut set here as you are seeing in the blue line.
in the forward path that is what it is shown here.
Then I have to introduce 2 delays in the path because I have cut 2 lines here.
So, there will be addition of delays in this case.
Now you will be seeing the longest path in this case is going to be.
So, one multiplication and one addition.
So, we will come back what we are going to define what is my longest path ok. And from here to here also it is going to take 1 clock cycle.
and from this delay to my output is going to have one clock cycle.
So, we make this structure as first unit and the second unit what we have it.
So, what happens to the output that is what it says is critical path from 2a plus tm which is changed to ta plus tm.
So, the clock will see the what will be the output at 0 it the input to this is x of 0 then.
Node 1 what we call it, what is going to happen in this clock cycle is it will be multiplying a into x of 0 and then it will take b into x of minus 1 in this case.
So, in the next clock cycle, so you will be seeing that x of 1 will be the input to this unit and then the thing is going to be node 1, it is going to compute a into x of 1.
plus b into x of 0.
So, in node 2 because this has moved to the next clock cycle.
So, it will be a into x of 0 previous one plus b into x of minus 1 and in node 3 what we call it is here which is going to be c x of minus 2 and this will be my y 0.
And same thing you will be seeing that in the third clock cycle.
So, the all the units become full.
Then, y2 will be my output which is completely correct.
So, compared to the previous one you can draw this sketch for the one which did not have the cut set.
So, output will be start coming from here y0, y1, y2, y3, but in the this thing pipeline case, the in this case since we have put only one cut set the delay is going to be 1 clock cycle.
So, we will not be getting anything here it is.
or it is garbage what we will have it.
So, output starts coming from here.
We will see effect of pipelining.
What are the drawbacks?
We will be increasing the delay elements, number of delay elements, what we call it as registers or latches in the critical path.
This is a hardware addition what we have to provide.
This causes increase in latency.
Then what we say is a clock period limitation we will see it.
So, the critical path may be between.
an input and a latch we call it a latch and an output or between two latches on input and an output.
So, this we call it as the critical path.
So, this is how we measure how many multipliers or accumulators or how many hardware is in between these two things that will be the maximum critical path what I have to consider.
So, we say pipelining latches can only be placed across any feed forward cut set of the graph.
This we will be specifying every time and then we have to go through the thing.
Next one is as I was talking about the structure can we have a transposition theorem incorporated in the signal flow graph.
That is what we are going to do is reversing the direction of all edges in a SFG signal flow graph.
and interchanging the input and then output ports preserve the functionality of the system.
So, we say that x of n is the input y of n is the output this is in the feed forward what we have it.
So, this delay can be represented as a d or in the z domain we will call it as z minus 1 is going to be the delay.
So, each node will be representing my this as an adder and this is a multiplier.
So, now what we are going to do is my output I will be changing it as an input and then input as an output and all the direction are going to be reversed basically that is what the transposition theorem says.
So, as you see the thing y of n and then we will be keeping a b c as it is.
So, this has got changed.
Now what is the thing is going to happen?
So, we will incorporate in our data flow graph here.
from the signal flow graph, we call that as a direct form 2 structure, we call that as a data broadcast structure.
And in this case you will be seeing that the critical path without adding any delay elements it has become Tm plus Ta, we will see it in a while how it is going to be.
So, to have the understanding correctly what we have done from the previous thing, we have reversed the implementation of this graph actually so that.
We are not comfortable going from right to left.
So, we will put it back as a forward path itself.
So, you will be seeing that x of n is going to be broadcast to all the 3 multipliers.
Here it is c, here it is b and then a and then we have a delay element already present in the original one.
This is the original.
Now, you see the thing the critical path in this case is going to be one multiplier and one adder.
This is from input to output and then from input to latch is also 1 unit and then here also it is going to be input to latch is here only have a 1 multiplier delay ok.
So, the maximum that is critical path is 1 multiplier and 1 adder.
So, you can see that the structure if you choose it properly I need not have to have any cut set or any pipelining introduced in some of the.
graphs that one has to consider.
Now, we will say that all of us know that multiplier is going to take longer time compared to my adder.
So, as an example we call this as a fine grain pipelining.
So, let T m is equal to 10 unit time and adder takes 2 unit time and the desired clocks period what we want is 6 unit of time.
So, how we can achieve because multiplier is going to 10 units.
2 units will be my longest path in the broadcast section if I am computing it, but my clock period has to be 6 unit.
Then what we do is we can bifurcate or multiply into 2 smaller units with processing time of 6 and 4 units.
So, you will be seeing that 1 multiplier M1 is going to take 6 units and then M2 multiplier will take 4 units.
So, we are doing a cut set here in the forward.
path and then put a delay element in all the 3 legs of my filter.
And then we will be seeing that from anywhere to anywhere that is input to my this latch is 6 units in all the cases and from here you will be seeing this latch to this latch is only 4 units and the whatever shown in the blue will be the my critical paths basically.
From this latch to this latch it has 1 multiplier and 1 adder so which will be taking 6.
units of time and from here to here also.
So, this we call it as fine grain parallelism or sorry pipelining.
So, the next one we will see that parallel processing how we are going to work on.
We say they are dual basically and if a computation can be pipelined it can also be processed in parallel that is what we say.
So, how we are going to do this?
We say convert a single input single output SISO is my single input single output that is what x of n to this.
system into a multiple input multiple output we call it as MIMO system via parallelism.
So, you will have seen here input is x of 3k, x of 3k plus 1 and x of 3k plus 2.
You will be wondering what is it initially we took example parallel for 2 this thing parallel systems.
Here we are assume 3 parallel systems.
So, you will be seeing that your x of n will be changed as x of 3k in this case.
and y will also be y of 3k, y of 3k plus 1 and 3k plus 2.
So, this is 3 parallel system.
Then what happens to my input and output representation?
We have original what we have is y of n is a into x of n plus b into x of n minus 1 plus c into x of n minus 2.
When I pass this in 3 parallel section, what will be my output is y of 3k, 3k plus 1 and 3k plus 2.
How the inputs have to be you will be seeing it.
So, I will be replacing n with 3k, a into x of 3k plus b into x of 3k minus 1 plus c into x of 3k minus 2.
So, in the next case 3k plus 1 what will be adding with respect to n is 3k plus 1.
So, if you substitute that 3k plus 1 and then 3k plus 1 minus 1 will become 3k x of 3k in this case.
and then in the next case c into x of 3k minus 1.
So, you will be seeing even y of 3k plus 2 will be represented in this way.
Then what happens?
We call time taken for iteration is equivalent to t sample what we call it.
Here in this case it becomes 1 by L into t clock.
So, which is greater than or equal to because number of parallel section I have assumed is in 3 here.
So, which becomes 1 by 3 into 1 multiplier plus 2 adder because I have not put any pipelining here.
So, adder delay is going to be 2 units in this case.
So, what happens to 3 tap FIR filter how I will be representing it in the direct form 2 as you will be seeing it.
So, if we use the direct form 2 what is the thing.
So, this is the output what I want y of 3 k 3 k plus 1 and 3 k plus 2 and we will consider y of 3 k plus 1 rest of it you can work it out.
So, we will see that how we are going to get a into 3.
of A into x of 3k plus 1 what I wanted the first output.
So, you will be seeing that x of 3k plus 1 is coming here and then which is fed to my here this multiplier which is A into x of 3k plus 1.
So, which goes into the adder.
So, what the next one what I want is B into x of 3k.
So, you will be seeing B is here and then x of 3k is the thing which is coming here.
which is going to be multiplied with your b x of 3k.
So, which gets added.
So, what is the last one what I wanted?
c into x of 3k minus 1 what I want in this case.
So, how we are going to get the thing?
So, what we will do is I can take x of 3k plus 2 because when I introduce a delay line in this because this is the 3 parallel structure what we have taken the thing.
So, delay is going to be 3 units.
So, this becomes x of 3k plus 2.
minus 3.
So, which is with 1 delay.
So, it is going to be x of 3 k minus 1 this input which is going to be multiplied with c. So, all of them get added and then we will be getting y of 3 k plus 1.
So, you can check the rest of them whether you are going to get the this equation correctly with the structure or not.
So, thank you for hearing this lecture.
Namaste, welcome back to real time digital signal processing course.
So today we will look at adaptive filter.
So, in the previous class we discussed about the LMS algorithm, Leakey LMS and then NLMS algorithm how with little modification we can implement the adaptive filter.
So, today we look at little bit on the application of adaptive filter.
The first one what we will take is adaptive prediction.
So, how we are going to predict the system.
which is connected to the system ok.
So, what it says is the linear predictor it is going to estimate the values of signal at future time applied to a wide range of applications such as speech coding and then separating.
The equation for this is given as y of n is i is equal to 0 to l minus 1, w l of n into x of n minus delta minus l. So, you will be seeing according to the figure.
there is a delay of the signal which is going to be fed into the system to find out the error of the function.
So, y of n is taken out here and then we have the LMS algorithm here which is going to decide our weights on the system basically and this is the delayed signal that is x of n minus delta.
which is going to come into the system and then y of n is the thing this is what y of n is the predicted one.
So, we will be subtracting and then taking it out minimizing the error then what happens.
So, we will be predicting what is y of n basically in this case.
So, the filter coefficients are going to be updated by the LMS algorithm as you will be seeing that w of n my plus 1 is given by w of n plus mu is step size into x of n minus delta is the input to the this thing a weight function and then e of n that is error which is fed back into our LMS algorithm.
So, we say where x of n minus delta is nothing, but x of n minus delta is the first sample that is delayed by delta units.
So, the other ones are delayed as earlier we take it x of n minus delta minus 1 so on and then x of n minus delta minus L plus 1 transpose what will be giving as an input.
So, L is the length of the filter that is what we are going L small l is equal to 0 to capital L minus 1.
we are calculating our y of n. So, then as usual like LMS algorithm what we have is e of n is x of n minus y of n and filter using the reference input x of n minus delta to predict its future value x of n where delta is the number of delay samples.
So, continuing with the predictor.
So, we are going to consider an application of using an adaptive predictor to enhance the primary signal which consists of.
M sinusoids corrupted by white noise.
So, which is expressed as our x of n is the s of n plus b of n, b of n is our white noise basically what it is being considered.
Then what happens to our output M is equal to 0 to capital M minus 1, a M into because we have take considering the sign signal here.
So, a sign W M n plus phi M.
is the phase of the signal plus V of n, where V of n is the 0 mean white noise with unit variance assumed as sigma v squared.
So, then what is the thing is going to happen?
This is the error signal.
So, you will be seeing that and then it start coming down and then settles with the whatever the value of it.
So, now, you will be seeing that.
This is our output y of n and x of s of n is our input.
So, you will be seeing that initially it was small after that they are going to merge and then go one another.
So, we will be able to generate our whatever sign function what we have given the thing.
So, we are able to predict this is our output.
So, coming with.
Next, application is the adaptive noise cancellation.
So, why do we have to cancel we will see the noise.
So, here we are going to give a suitable delay that is unit delay of z minus delta is inserted in the primary channel.
So, here we are going to have the this is the signal source and this is our noise source and this is our primary reference signal and here is the.
reference sensor which is going to collect our noise source.
So, when we apply this we call it as the reference sources x of n and then primary signal source whatever we are collecting through the primary source which is going to be delayed by delta delay what we are going to give the thing and we say this is my desired signal what I wanted and this we will be adapting according to the LMS algorithm which is y of n.
and then we will be subtracting desired signal with output and then this error what we try to minimize and then which is fed back and then the weights are going to be updated based on our error function.
So, how we are going to define this?
Will be desired signal is nothing but S of n plus X dash of n basically.
So, what is that where if Y of n is equal to X dash n.
We obtain E of n as the desired signal S of n. So, what is it?
The widespread use of cell phones has significantly increased the use of voice devices under high acoustic noise environments.
Most of you would have observed that when you are using your mobile in the completely noisy environment.
So, sometimes what you would try to do is close one of the ear and then try to hear from the.
other ear.
So, that is what we are going to do the thing.
So, how you can do adaptively noise cancellation within the mobile based on the surrounding noise ok.
So, what happens that is intense background noise often corrupts our speech and then degrades the effectiveness of communication.
So, you will be using the adaptive noise canceller basically employs an adaptive filter with.
LMS algorithm and can be applied to cancel the noise components embedded in the primary signal.
So, we if we know the noise source and other things.
So, we can capture and then try to subtract it.
So, that will be cancelling the noise and then our output can be a clean speech signal.
So, as an example so, to apply adaptive noise cancellation effectively.
So, these are the two conditions which has to be satisfied.
What is it?
That reference noise picked up by the reference sensor must be highly correlated with the noise components in the primary signal picked by our primary sensor.
So, because we know that primary data is getting corrupted with the noise.
So, the noise sensor should pick up this noise from this thing and then it should be fed.
So, the reference sensor should only pick up noise.
That is it must avoid picking up signals from the signal source.
So, you are going to have a contradiction in this case.
So, one has to look at this.
So, how it is going to be?
So, you will be seeing that X0 n is the input or this thing phase shift that is we are going to give 90 degrees phase shift for the thing which we call it as X1 of n. And then you are seeing the FIF filter what we have.
used in this case to fine tune and then do the noise cancellation.
So, W naught n to W 1 of n are filter thing what you are looking at it that is second order filter what you have seen it.
So, this is going to be fine tuned based on what is the thing like our LMS filter.
So, this is the desired signal what I have given as a input.
and then based on this we will be calculating our y of n and then as usual we will be subtracting it.
So, now, what is this error signal is fed into our LMS algorithm.
So, this is going to take both x naught n and then x 1 of n as input and then adjust the weights based on our error.
Basically it is written little below so that.
we are not smudging our crossover of the line is going to happen from this input and this input and it is shown separately.
This is what we call it a single frequency adaptive notch filter what we have designed in this case.
So, you will be seeing that what is the desired signal is given here and then you will be seeing that output error signal E of n. So, which is going to correspond to our.
output basically what we are going to get out of the thing fine.
So, noise cancellation has happened in this case and then we will get the signal correctly.
The other one is how we are going to inverse model the channel in this case example is our communication channel is one of the application what it will be considered that is what it says in practical applications we have to estimate the inverse model of an unknown system in order to compensate its effect.
severe distortion can be solved by designing an adaptive equalizer in the receiver that contracts the tracks the unknown and changing channels.
How we are going to design this?
So, you will be seeing W of z is nothing, but 1 by C of z.
So, we are taking we assume that C of z is the filter at the transmission end at the receiver end.
you will be designing the inverse filter.
So, one must be thinking how the inverse filter is going to be designed.
So, you should have what we call it as minimum order filter basically.
So, all the poles and zeros of the input filter should be inside our unit circle.
So, that when we design the filters 1 by C of z.
So, which is both 0s and then poles will be getting interchange.
So, they should not be going out of the unit circle.
So, this is what one has to design and then what we call that when we do the cross multiplication c of z into w of z should be equal to 1 such that our x hat of n is equal to x of n. So, this is what shown in our equalizer as an example of inverse modeling.
So, what is it?
So, we have the input x of n and then this is c of z what we have the thing and then output is y of n and then which is FET or LMLS algorithm as well as our weight function for calculation.
It passes through the filter here and then the x hat of n is the output what we are.
calculating and then this x of n is going to be delayed by delta and then which is fed as desired signal.
So, when the difference is minimal then we will be knowing that x hat of n is equal to x of n. So, this is how we will be trying to get our out whatever we have passed through the communication channel will be received in this.
So, almost it is equivalent whatever we receive x hat of n is equivalent almost x of n. And as usual our error will be through the LMS algorithm and then taking the input from y of n. So, we will be designing our weight function.
So, how we are going to do the channel equalization is shown in this because this is an experiment where it is going to be used.
adaptive equalizer using the complex LMS algorithm for a simplified ITU standard communication standard what you will be taking it V.29 is a fax modem.
So, for various other this thing we call it as audio or speech we have different standards.
So, in this case for the fax modem this is the standard.
one uses.
So, according to this V.29 recommendation the modem operates at speed up to 9600 bits per second on the general switched telephone network lines.
And the equalizer for modems can be realized using our adaptive FIR filter what it is shown here.
So, in the absence of noise and inter symbol interference the modem receiver decision logic output can precisely match the.
transmitted symbols and the error signal will converge to 0.
This is the ideal case one is considering then error can reach to 0.
So, what is the this thing graphical representation as it is shown.
So, we have the received signal and we have the received filter constructed here.
So, the output of which is going to go to our adaptive algorithm and then the same thing will be going for the adaptive equalizer weights calculation.
And then we will be putting a decision device here depending on the thing.
So, either the switch will be turned on to find out the error, if it is this thing adapting to the channel noise and if there is no noise you can put the decision to this one, change over to here ok, the output will be coming.
So, here you will be passing it to the training of the signal.
if the decision is on the other side and you will be using this training the signal to adapt itself ok.
So, algorithm uses the thing.
So, we will be here also we will be trying to minimize our output of the error.
So, this will be our equalization output what we will be getting it.
So, the next application what we call it as voice crampling.
So, we will be using filtering and then modulation techniques here.
to do the scrambling of the voice.
Why one has to scramble the voice we will see it.
So, the approach makes use of basic algorithms for filtering and then modulation with voices and input the resulting output is scrambled voice we will get it.
So, the original de-scrambled voice is recovered when the output of this from the kit if we are using the hardware or if we are using the MATLAB the output of this is given to to input to a second kit running the same program or in the same place we can run this our program and then imitate that we are depicting that two places that is wherever we have recorded the voice we have scrambled it because I want to have it as a private one.
So, that I know how I have scrambled my speech or audio then at the receiving end the person knows how the scrambling has happened.
So, he will use the same concept to.
So, that way you will be calling it as a watermarking on speech and then audio signals.
So, how we can do it using scrambling we will see in the experiments both using MATLAB and then our code composer studio.
So, even in the code composer studio what you can use is if you have two kits you can connect one kit to do the scrambling the other kit will be re scrambling and then you can get the correct speech depicting both.
transmission and then receiving concept.
So, the commonly referred to as frequency inversion in this case is going to happen.
It takes an audio range in that is 300 hertz to 3 kilohertz.
So, we call this as our narrow band frequency what we will be using it and which will be welding because we are going to scramble with.
whatever the input frequency.
In this case we will be using 3.3 kilohertz as the carrier signal in this case and we will be merging with the thing will it will be folded and then it will be sent.
So, the frequency inversion is achieved by multiplying or modulating the audio input by a carrier signal causing a shift in the frequency spectrum with upper and lower side bands.
So, we will be getting both higher one with 3 and then 3.3 it will be 9.9 kilohertz and then the difference will be 0.3 kilohertz.
So, one will be upper and the other one will be.
lower one.
So, this lower side band that represent this audible speech range the low tones are high tones and the vice versa.
What happens?
So, these low tones becomes high tones when we have received it whereas, the high tones will be converted into low tones.
So, this is what we will be getting it as an example how it is going to be done is shown in the figure.
So, I have taken input as a.
this thing audio input which is sampled with 8 kilohertz.
So, or a speech signal which is going to be sampled at 8 kilohertz then we will be representing between 300 to 3 kilohertz is our speech signal which is going to come.
So, then this has to be this thing what we want is the frequencies above 3 kilohertz has to be cut off.
So, we will be putting the low pass filter with cut off frequency of 3 kilohertz.
and then we call this as point A.
Then we take 3.3 kilohertz as our carrier signal that is using the sign generator which you will be multiplying with our this thing input signal which is cut off at 3 kilohertz and we will be generating B.
So, this can be fed through the 3 kilohertz low pass filters eliminating high frequencies and we will be getting C as the scrambled signal as our.
So, what it shows is scrambling at point A we have an input signal band limited to our 3 kilohertz and at point B we have a double sideband signal with suppressed carrier basically.
And then at point C the upper sideband and the section of the lower sideband between 3 and 3.0 kilohertz are filtered out.
So, the scheme is attractive because of its simplicity.
Only simple DSP algorithms namely filtering sine wave generation and then amplitude modulation are required for this implementation.
So when we come to the reverse of it we can rewrite the C can be given to our as a input signal ok.
I will write instead of my input C is the one and same thing C kilo 3 kilo hertz low pass filter we can design the thing.
then this is given to our multiplier and then same reference signal what I am going to keep it as 3.3 kilohertz ok.
So, this goes to our this thing make a multiplier here and then the output B is going to be pass through 3 kilohertz low pass filter.
So, output will be equivalent to our input whatever we have given at the.
end, this is the thing is going to happen at the I will put it as this is transmission.
And here at the receiver when you want to recover your voice or your audio if you have want to protect your thing, this is the way one can do it and then you can at the whoever wants to receive it you can tell them how you have done your modulation.
So, they can depict this in hardware and then at the receiver they will be getting whatever input you are.
intent for that particular person.
So, that is how the scrambler is going to work.
So, then continuing with the thing ok, how it is going to will be seeing how the carrier frequency and then low pass filter will be mixed and then how our filter response is going to be in the frequency domain is shown here.
So, what is going to happen?
First the sample speed signal is filtered by a low pass filter we said, h of n is the order of the filter whose cut off frequency what we will be calling it as f naught.
is high enough not to cause distortions of the speech signal.
So, that is the ideal filter what we are going to call it here as you can see in the figure.
This is the low pass filter and then what is it?
Its band is minus f naught to f naught and then what happens to the thing the sampling rate f is the sampling frequency is chosen such that.
4 times f naught is less than f s. So, that means, to say that your sampling frequency has to be greater than 4 times of the frequency component what you want to pass.
So, the filtering operation can be represented by the convolutional normal expansion.
So, we have y naught n is nothing but m is equal to 0 to order of the filter you can take it as l minus 1 or if it is the l th order or m th order m minus 1.
So, we will have h of m into x of m.
So, if you have taken L as the thing so it will be becoming h of L into x of n minus L is our convolution thing.
So, the notation can be any one of it what you assume.
So, the filter output y naught n gets modulated as this thing cosinusoidal carrier signal whose frequency coincides when the filters cutoff frequency f naught resulting in the signal as shown here.
filter, what is it?
y1 of n as you can see that x of n which is uses a low pass filter with cutoff frequency f naught which will be equal to y naught n and then this is the carrier frequency what you have chosen as f naught.
So, which is that is desired signal s of n what you will be putting it.
So, you will be multiplying them and y of 1 of n is the output of it what are the.
things it contains.
So, S of n into y naught n where your S of n is equal to 2 times cos omega naught n where omega naught is given by 2 pi f naught by f s. So, then you will be passing it through your low pass filter with cutoff frequency as same as this one f naught to eliminate the higher frequency component present in it.
And then output is y 2 of n is the scrambled signal.
So, when you can see that in the frequency domain how the thing is going to be getting shifted what you can see it.
So, that is f minus f naught is the shift what you have given the thing.
So, the signal you will be seeing that it is shifted spectrum what you are seeing in this case and then when you take the inversion at the receiving signal.
So, this is how the inverted signal looks like this is our y 2 of f here in the with respect to frequency domain.
So, this is minus f naught to f naught and we have f s by 2 what it is.
marked in this case.
So, this is how what you have to say that your f is greater than 4 times the frequency component of your basically filter cutoff frequency f naught of the filter what one has to assume ok.
So, continuing with the thing how it is going to be represented that is unscramble the signal already I have put the thing one may apply the scrambling steps y naught y1 y2 whatever it was shown.
to the scrammed to the scrambled signal itself.
So, this works because the inverted spectrum will be inverted again recovering in the original spectrum.
So, in the lab so, you will be studying a real time implementation of the above procedures.
So, we will be demonstrating.
So, those who are interested can look into the code and other things they can run your own algorithm to.
equation for designing the hamming window.
So, which is 0.54 constant minus 0.46 into cos 2 pi n divided by m, n is going to be your input sample.
So, when you pass through that this is passing through your hamming window.
So, our convolution equation is given as y 2 of n is our output.
So, this will be depending on your order of m in this case 0 to 99 what it is going to be h of m into y 1 of n minus m and then h of n is going to be our impulse response has to be restricted with respect to window because this is a continuous minus infinity to infinity what we assume.
So, this is w of n into sin omega naught n minus m by 2 whole divided by pi into n minus m by 2.
So, here n is between 0 and then m basically and omega naught is given by R.
2 pi f0 by fs in this case it is 3.3 divided by 16 kilohertz and W n is the hamming window which is given by this equation.
So, n will be between 0 and m whatever we have designed in this case we have assumed it as 100 ok.
So, the next application what we will be doing it is echo.
So, here we will be doing the generation in the next class we will take up the cancellation.
So, how the echoes are going to be generated first synthetically we can do the generation.
So, most of you would have visited where you have a rocks and other things when you speak.
So, you will be hearing the echo coming back to you, your own voice goes and reflects that is what we say reflection of sound.
So, which is going to come back to you little bit delayed ok. How we can synthetically generate?
So, using our code what will be.
So, approaching at the listener later than the direct sound.
So, as you can see is this is the sound source.
So, you will be seeing that all the places it will be reflected your sound when you are speaking and there is a hard surface that is what you will be seeing it.
What happens it goes and hits and then it comes back to you.
The first one is the direct sound what your it is coming to you the later on you will be getting the reflected sound.
to your listener this we call it as a echo basically.
What it says a true echo is single reflection of the original sound.
So, that is what we call it as echo ok. We will see if multiple of reflection comes what we call in the next slide.
The time delay is the ratio of the extra distance to the speed of sound.
An echo can be realized as a signal wave that has been reflected by a signal wave.
medium which has the discontinuity in the propagation medium and returns with sufficient magnitude and delay to be perceived by our human here.
Some places it gets absorbed then you may not be able to hear it as echo.
So, where you have sufficient magnitude and then delay then we will be hearing it as an echo.
So, that in echo effect the true sound and the artificial sound are clearly separated.
with gain what we can get the echo signal.
So, we assume gain should be less than 1 in this case because we have the magnitude of input is 1.
So, we assume this is less than 1 due to losses in the echo path that is what we are going to imitate and then look at it.
So, this is again continuing with the generation.
So, as it is seen that signal propagates from the source to the listener in 2 paths.
In this case we have assumed that this is going to reflect and these are going to be absorbed only 1 path get reflected as I said.
signal from the source goes directly to the listener, second the signal goes to the wall and then reflected to the user.
So, the second process will take more time than the first process.
So, the listener will hear two sounds in a different period of time and the signal power from the second process will be attenuated due to the reflection process this is what we discussed.
So, how we can digitally generate an echo by showing in this diagram.
So, how we are going to do the thing.
So, when dealing with audible frequencies human ear cannot recognize the identity of an echo from the original sound if the delay is less than one tenth of a second.
So, as you can see that if it is within this then you may not hear it as an echo.
Thus since the velocity of sound is approximately what we call it as 343 meter per second at a normal room temperature of about 20 degree centigrade the reflecting object must be more than.
16.2 meters from the sound source for an echo to be heard by a person at the source.
So, these are the thing then only you will hear you would be wondering wherever I speak I should be able to hear my voice back.
So, most of the you will be seeing sound recording rooms you will be having a what we call it as a echo cancellers.
So, padding width.
not to reflect the sound ok.
So, it is going to absorb so that only the pure voice is going to be heard.
So, you as an example even I am sitting in a room where recording room where my voice is going to be only heard and then outside noise and everything is cancelled even whenever my voice hits the wall.
So, you will not be getting any reflection in this place.
So, in most situations.
With human hearing echoes are about one half second or about half this distance since sounds grow fainter with distance.
So, the strength of an echo is frequently measured in dB sound pressure level what we call it as SPL sound pressure level relative to the directly transmitted wave.
So, we will be generating in the lab that is input is given.
So, the same input will delay.
We can see that by varying the delay how we will be perceiving it.
And, then we are going to multiply with the gain and then this is the delayed input which gets added with the normal input and output what will be hearing it as the echoed signal in the output.
So, the next one is application is the reverberation.
As we said you can see that there is a sound signal here.
So, you will be seeing that one can be direct and then there are multiple reflections in this case that is what I said it is a single reflection what we call it as echo when it happens with the multiple reflections.
So, what you will be seeing that.
This may be coming early and then the other after heating here it may be coming these are the late ones what you will be getting it.
This may come early.
So, you will be hearing multiple this thing reflections that is what it says reverberation is the persistence of sound in a particular space after the original sound is removed.
And in the reverberation or reverb what we call it is observed when a sound is created in an enclosed space causing multiple echoes to build up and then slowly decay as the sound is damped by surrounding walls and then air.
It is the sum of all sound reflections what we will put it.
Most noticeable when the sound source stops, but the reflections are going to continue decreasing in amplitude until can no longer be heard.
So, the principle of reverberations is more like echo, but in reverb the sound reflections comes very often in a short period of time.
So, you will be seeing that this is the direct sound what it is happening and then these are the earlier reflected what you will be seeing it.
This we call it as during the pre delay what you will get it.
And, then these are the early reflection time from here to here what will be perceiving it after that these are the late reflections you will be seeing that it is slowly dying it out.
So, this is the reverberation time what we call it when it is going to die down slowly.
So, considering the thing comparison to distinct echo that is 50 to 100 millisecond after the initial sound reverberation is many times.
1000s of echoes that arrive in very quick succession that is 0.01 to 1 millisecond between echoes.
So, with the elapse of time the intensity of the multiple echoes is reduced till the echoes are inaudible.
So, in reverberation how we are going to generate the thing output will be input plus delayed output into gain.
So, in this case we will be considering the this thing feedback signal that is A into y of.
n minus d output is getting delayed by d plus with the input x of n. So, then the response of the system is given by h of z is nothing, but 1 by 1 minus a into z to the power of minus d this is the delay in the RZ domain.
There are two important parameters reverberation which are the ones.
One is the pre delay as we have seen in the previous case we have the pre delay and then we have the amount of time of the first sound reflection.
Then the reverb decay is the period amount of time that reverberation since the input stop.
So, we have seen that this the reverberation this is the pre delay which is the early reflection which has going to come.
Then how does it look like because we have said n minus d.
are the delays what we are going to have it.
So, this each reflection you will be saying that they are spaced at 2 pi by d. So, I will be getting a peak here, next peak is going to be 4 pi d and 6 pi d and so on till 2 pi.
So, and then you will be seeing that this is our unit circle and then we have the this is our this thing.
2 pi by d spacing what we are going to have it and rho will be the radius of the or where the poles have been located.
So, you are seeing that poles are all around the circle and that is what it says is these are the poles what you will be putting across the thing at distance of 2 pi by d. So, coming with the reverberation.
This shows the thing that is this is our microphone what we have it and the performer is here.
From here to microphone you comes direct and we know that loudspeakers are in the sideways.
So, sometimes as you will be seeing that even in the mobile or when we are switching on for conference call or something we will be telling if there is one more loudspeaker we have it or this thing input we will ask them to switch it off and keep only one performer signal this thing receiving end also both mic and speaker should be switched on.
If both the speakers are on even now you would be hearing that.
the echo will be coming.
So, whenever because I think pandemic has taught us very nicely that online classes and other things.
So, when two devices are on side by side we will say that please mute the other device and only one devices of the two of them are sitting together be on.
So, that will not have any echoes or we call it as a reverberation coming into our picture.
So, how to generate just like our echo digital reverberation is shown in this figure.
This is our input.
And, then the output is going to be delayed and then fed back there in the echo case input itself is delayed and then fed into our system.
Here the output is going to be delayed and then fed with into the system with gain actually.
So, this is delayed output what will be hearing the reverberation.
So, you have to differentiate between an echo and then reverberation when we run the example.
So, thank you very much in the next class we will be considering echo cancellation.
and then equalizer why do we need it.
So, what will be taking it up in the next class.
Thank you for listening.
Welcome back once again to real time digital signal processing course.
So, today we will discuss about IR filters.
So, as a recap in the last two classes we discussed about FIR filters, their linear phase and how we can represent them, how we can design using the window techniques.
So, today we will see little bit on recap of FIR filter that is we said it is a linear phase filter.
So, the importance of it as you can see with an example in the speed signal.
We use phase differences in arrival to locate the speaker.
So, in this case it is we may not need the phase part of it if there is any delay in the thing.
So, you locate them that is we call it as delta D is equal to C into delta T. So, this is how the speaker thing and then our ear automatically adjust to whatever there is a delay in the phase of it that is what it is shown here.
Once speaker is located ears are relatively insensitive to phase distortion in speech from that speaker.
So, this is used in speech compression and cell phones, where linear phase is crucial we will see in the audio signals in images and in communication systems.
So, in these cases we need linear phase response filters, FIR filters and then a realizable IR filters cannot achieve this linear phase response over all frequencies.
So, coming to one more example of where the phase is important.
that is vital visual information in face is shown with the matlab original image here.
So, when you take the FFT of the image and set face to 0 and take inverse FFT as you will be seeing only you will be seeing the blank that is a black in this case no picture whatever was in the originally seen.
Whereas, if you take the FFT of the image and set magnitude to 1 take inverse FFT as keep imaginary part.
So, this is how the imaginary part looks like when you take the IFFT and this is with respect to real part if you take IFFT.
So, combined will give us the original image.
So, coming to representation of our finite impulse response filters, we know that duration of impulse response h of n is in this case is finite.
So, this is 0 valued for n outside interval 0 to m minus 1.
So, we say that y of n is nothing, but x of n into convolution with h of n which is represented in the sigma notation in this way and then this is minus infinity to infinity.
So, in our case FIR filter is going to be because we will be designing order of the filter is m. So, the summation will be between 0 to m minus 1.
So, in this case output depends on current input and previous m minus 1 inputs.
And, summation to compute our y of k reduces to a vector dot product between n input n input samples in the vector domain as it is seen here.
X of n is represented in vector and then our impulse response is represented in vector.
Then it is going to be a vector multiplication what we will call it.
So, we know that filters play many roles we have seen the thing just to give one more brief.
So, look at the thing is noise removal, signal and noise spectral is separated basically in that case.
Example is we can use band pass filtering to suppress out of band noise and in the case of analysis synthesis and compression.
So, for we use a spectral analysis basically to see how much of data what we needed and which are the ones we can do the compression in the frequency domain.
method is in the spectral shaping.
So, that is in basically for data conversion we use the filters and for the channel equalization we know that in communication input channel has to be reconstructed.
So, we take inverse filter basically there and then do the channel equalization whatever noise coming out of the channel.
And then in the symbol timing recovery also will be using the filters and in carrier frequency and phase recovery.
we need filters.
Coming to next is the infinite impulse response IAR filter.
So, we see that impulse response of infinite duration that is what we call it.
So, what is that mean we will be seeing in a while.
So, if I give the impulse response h of n is equal to half to the power of n into u of n that is the step function.
So, the same thing in our frequency domain or in the z domain what we represent is h of z.
which is n is equal to 0 to infinity half to the power of n into z minus n. So, which will be representing it as change it to 0 to infinity.
So, expand this summation which becomes 1 plus half z minus 1 plus etcetera.
So, we will be getting 1 by 1 minus half to the z power minus 1.
So, how to implement this?
IR filter by computer what we look at it.
So, we say let x of k be the output signal and y k the input signal and then y k be the output signal.
Then what happens is that z domain representation is going to be y of z for our output and then x of z.
Then the impulse response h of z in the z domain is represented as y z by x of z.
So, or If we want y of z then we know that impulse response into our input x of z.
Then what we have taken this is our impulse response y of z will be becoming 1 by 1 minus half into z minus 1 into x of z.
Then if we simplify the thing it becomes half into z minus 1 into y of z that is y of z minus half into z minus 1 into y of z which is equal to x of z.
So, what happens to our when we take the inverse Z transform what happens to our y of n which is equal to half y of n minus 1 that is a previous sample which is equal to x of n. So, if we transform this half y of n minus 1 to the other side we will be seeing that y of n will be equal to half into y of n minus 1 plus x of n. So, x of n is the current sample and y of n is n minus 1 is the previous sample.
output sample which is used for calculating the currents output sample.
So, what we say is recursively compute output y of n for n greater than or equal to 0 given y of minus 1 and then x of n. So, how we can represent this filter in a different way?
So, we will be seeing the difference equation first.
So, y of n is given as half into y of n minus 1 plus 1 by 8 into y of n minus 2 plus.
x of n. So, that is we are going to do the recursive computation needs what are the input values what we need is y minus 1 and then y minus 2.
For the filter to be linear time invariant, so we assume that y of minus 1 equal to 0 and y of minus 2 equal to 0 and the block diagram to represent this difference equation is shown in this figure x of n is the input and y of n is the output.
So, with the delay we will be generating y of n minus 1 which is going to be multiplied by half and then other unit delay will give us y of n minus 2.
So, which is multiplied by weight vector 1 by 8.
So, all the 3 are getting summed up and then we will be taking y of n as the output.
So, the transfer function what we see is it assumes a linear time invariant system.
So, y of z is represented as half into z minus 1.
into y of z plus 1 by 2 into z minus 2 into y of z plus x of z and impulse invariance response of this is given by y of z by x of z which is nothing but 1 by 1 minus half into z minus 1 minus 1 by 8 into z minus 2.
So, we say that poles are at minus 0.183 and plus 0.683.
How we are going to design this?
We say it is designed with respect to biquad 0, z 0 and z 1 and poles will be represented as p naught and p 1.
So, always we use the biquad section.
So, in that case how it is going to represented h of z is given by c is the weight factor what we have it z minus z naught into z minus z 1 by z minus p naught.
into z minus p 1.
So, how we represent the magnitude response?
We will be taking in the frequency domain we substitute z is equal to e power j omega then take the magnitude response.
So, our z is equal to e power j omega has to be put in here also and this represents our magnitude response.
And then our we say that magnitude of a minus b is distance between our complex numbers a and b.
And, e power j omega minus p naught magnitude is a distance from our point on unit circle e power j omega and pole location at p naught.
So, that is how we represent the thing when poles and 0s are separated in angle and poles near unit circle indicate filters pass bands and 0s on near unit circle indicate the stop band.
So, we can see that.
how the poles and 0s have to be placed to achieve our pass band response and then this stop band attenuation how we can arrive at.
So, coming to biquad example continuing with the thing the transfer function is given by this equation and when transfer function coefficient are real valued then poles we say x are conjugate symmetric or real valued and then 0s we represented with 0 or conjugate symmetric.
or real valued.
So, filters below have what magnitude response one has to answer this.
So, what you see is these are the two complex conjugate poles here and corresponding 0s are outside the unit circle.
This is our real axis and this is our imaginary axis.
So, as we say that 0s are on the unit circle basically.
And here you will be seeing that poles and 0s are.
inside the unit circle and the other one you will be seeing it poles are inside whereas, 0s are outside the unit circle.
So, poles have radius r 0s have radius 1 by r that is what we represented.
So, we have what kind of filters we can design using IR method or FIR method low pass filter, high pass, band pass.
band stop or all pass or even notch filter what we can design the thing.
So, first we will see the direct form IR realization how it is going to be represented.
So, rational transfer function what we call it.
So, our impulse response H of z is given by y of z by x of z.
So, we say that b of z represents our zeros and a of z represents our poles.
So, which is given by b naught plus b 1 into z minus 1, b n will be z b n into z minus n. So, we have n 0s and we say m poles.
So, 1 minus a 1 into z minus 1 plus etcetera or minus etcetera a m into z minus m. So, which implies that my y of z is represented as 1 minus.
sigma small m is equal to 1 to m a m into z minus 1.
So, this is my represents my poles basically which is equal to x of z into this will be varying k is equal to 0 to n b k are the 0s into z minus k. We say direct form realization that is dot product of vector n plus 1 what we are assuming it coefficients and vector of current input and previous inputs what we call it as FIR section for our 0s and dot product of vector of m coefficients and vector of previous m outputs.
So, that is FIR filtering of previous output values what we will be taking it here as it is represented.
And then computation of m plus n plus 1 multiply accumulate what we need it as we can see the thing.
And, memory is also going to be m plus n words for previous inputs and outputs and then m plus n plus 1 words for the coefficients as it is represented here.
This is our previous output and this is our input represented with the coefficients bk.
So, when we represent this equation in this form.
Now, what happens to our structure we will see x of n is the input and we see that b naught b 1 b n coefficients are in the feed forward.
So, we have the unit delay and this is x of n minus 1 to x of n minus n which are going to be summed up in this unit and then output is going to be R y of n. So, what is the feedback here?
So, we will be delaying with 1 unit delay and coefficient is going to be multiplied with a 1.
So, will be a 1 into y of n minus 1.
So, which goes up to y of n minus m into a m.
all this is the we call it as the feed forward path and this is the feed backward path.
So, completely added here if there is as we have seen in the earlier case it is minus a 1 into r y of n minus 1.
So, some of the coefficients as we will see they may add and then get subtracted and then they may nullify and we may not have the overflow may or may not we can.
tell that y of n may be overflowing or not overflowing in these cases depends on the coefficients what we are using it.
See we call it is when we want the full precision.
So, what we need is word length of y of 0 is going to be 2 words.
So, as we have seen the thing multiplication and then addition.
So, it will be going up to 2 words.
So, what happens to word length of y n if we start putting y of with 2 words.
will be seeing the output next time is going to be forward surge it goes on increasing.
To avoid this what we have to do is we have to come back our y n representation with whatever n bit representation.
So, that we are not going to have overflow in our representation of y of n. So, and then m and n may be different we do not know what kind of order of the filter we are going to design.
So, they may be same or they can have different values for them.
Then, how we are going to represent again the direct form of IAR filter as it is shown here.
So, will be rearranged transfer function to be cascade of an all pull IAR filter followed by an FIR filter.
So, that is y of z into x of z into b z divided by a of z.
So, we represent this as a v of z x of z by a of z as v of z.
into B of z where that is what V of z is given by this equation.
And then we say here V of n is the output of an all pole filter applied to x of n that is what we call it.
So, V of n will be x of n plus all the poles m into V of n minus m basically m will be varying of 1 to m. And Y of n you will be seeing that it is represented with our 0s.
multiplied by V of n minus k. So, the implementation complexity it we can assume m can be greater than or equal to n, then number of computation what we need is m plus n plus 1 max in this case.
And memory is going to be m double words for past values of e n and m plus n plus 1 equals for the coefficients.
How this is going to represented as you can see here, this is our V of n.
n point and we have summation here and summation here.
So, x of n is going to be multiplied with all IAR filter feedback basically that is this is the feedback structure.
So, V of n minus 1 V of n minus m which is going to be summed up.
So, which is going to be given as you will be seeing that that is our V of n.
which is getting multiplied we will be seeing that b k into v of n minus k with that and then summed up here with all feed forward are 0s and y of n will be output.
So, as you notice from single summation what we have come down to double summation.
So, the critical path what we call it is or overflow or underflow because here all of them are negative we may underflow in this case and all of them are positive we may overflow also.
are the two critical nodes what we call it.
One has to take care that summation is not going to overflow or underflow in these two points.
From one single critical node we have bifurcated into two critical nodes, but as you can see that the delay units have come down by two compared to the previous direct form structure representation.
So, that is what the advantage.
Now, comes with the stability because we are more worried with respect to stability.
So, we will be seeing that our linear time invariant system is.
what we say is bounded input bounded output Bebo's table what we call it.
So, if for any bounded input x of n such that x of n is within this bounds what we call it between x of n is less than or equal to our some bound value which is less than infinity.
Then the filter response y of n is also bounded what we claim it that is whatever b 2 it should be less than infinity.
So, coming with the FIR filter that is h of n what we have it.
So, we said x of n is bounded already then when the FIR filter is going to be stable that is BIBOS stable if and only if what we claim is magnitude of our impulse response h of n is less than infinity for n is varying from minus infinity to infinity.
So, we say every finite impulse response of LTI system.
even after implementation is going to be bounded input bounded output stable.
So, we say causal infinite impulse response LTI system is BIBO stable if and only if its poles lie inside the unit circle that is what the meaning of it.
So, continuing with the thing.
So, what we says is rule 1 is for a causal sequence poles are inside the unit circle.
applies to Z transform functions that are ratios of 2 polynomials or the rule 2 is unit circle is in the region of convergence.
In continuous time imaginary axis would be in region of convergence of Laplace transform what we claim.
As an example a to the power of n into units step function when we take the Z transform of it which is nothing, but 1 by 1 minus a Z minus 1.
for all magnitude of z greater than magnitude of a.
So, stable if magnitude of a is less than 1 by rule 1 applying it or equivalently stable if magnitude of a is less than 1 by rule 2 also because magnitude of z is greater than magnitude of a and magnitude of a is less than 1.
So, that way we will be achieving the stability.
So, we will see how we can represent z and then Laplace transform what is the relationship.
So, that is transform differential equations into algebraic equations that are easier to solve.
So, our complex valued functions of a complex frequency variable what we call it as Laplace in transform what we represent S is equal to sigma plus j 2 pi f.
Whereas, in the Z transform we will have Z is equal to r into e power j omega.
So, the transform kernels are complex exponentials, eigen functions of linear time invariant systems what we call it.
So, we have Laplace is equal to e power minus s t is equal to e power minus a small sigma t minus j 2 pi f t. So, which is nothing, but e power minus sigma t and then these are the exponential function to exponential function what we are representing.
So, in the z domain what we have z minus n is equal to r into e power j omega to the power of minus n that is z we are replacing with r into e power j omega.
So, which is nothing but r power minus n and then e power minus j omega.
So, we constitute that e power minus sigma t and then r minus n as dampening factor whereas, the other exponential factors e power minus j to pi ft.
e power minus j omega n are the oscillation term in our representation.
So, no unique mapping from z to Laplace domain or from Laplace to z domain.
So, we can have mapping one complex domain to another is not going to be unique and one possible mapping is impulse invariance.
So, make impulse response of a discrete time linear time invariant system be a sample version of the.
impulse response of the continuous time LTI system.
So, how what is that I have a function f of n. So, in the z domain I represent pass it through with h of z that is my impulse response and what I will get output is y of n. Whereas, in the case of Laplace transform so, will be continuous time signal is represented with f tilde t which is transformed using h of s. So, I will be getting the.
y of t. So, how do we represent in that case h of s is given as h of z at z is equal to e power st that is we call it as impulse invariance mapping.
So, coming to the mapping how it is going to happen in the impulse invariance what it is shown here.
Mapping is z is equal to e power st where t sampling time what we call it as t s basically.
So, we will be seeing the axis, our real axis and then imaginary axis.
The poles on the left hand side of our what we call it as Laplace transform which is going to be mapped inside the unit circle.
And our imaginary axis which is shown in blue actually s is equal to j 2 pi f t gets mapped on the unit circle which becomes 1.
And then the 0s on the right hand side of side of it can be mapped to outside r unit circle.
So, this is how from Laplace transform to Z transform the transformation is going to happen.
So, what we have is omega max is nothing but 1 in this case which is f max which is given by 1 by 2 pi f which is implied that f should be greater than 1 by pi.
So, we assume let F s is equal to 1 hertz what we are assuming it.
Then what happens are poles s minus 1 plus or minus 1 j in the is getting mapped in the z domain as 0.198 plus or minus j 0.31 into t minus 1 second.
So, 0s will be getting mapped as s minus 1 plus or minus j is getting mapped as in the z domain 1.469 plus or minus j.
2.287 into t minus 1 second.
So, you will be seeing the Laplace domain left hand plane inside the unit circle which we discussed and imaginary axis is the unit circle and right hand plane is going to be our outside unit circle.
So, what we say is with this we will be having low pass, high pass, band pass, band stop, all pass are notch filter what it is going to be designed.
So, how we are going to represent our continuous time IR biquad section.
So, second order filter section with 2 poles and 0 to 2 poles what we can have 0 to 2 0s that means, to say I need not have to have any 0s in our second order filter.
If m and n are different if they are equal then we will be having 2 poles and then 2 0s and that is what will be representing.
And in the transfer function is a ratio of 2 real valued polynomials what we consider.
and then poles and 0s occur in conjugate symmetric pairs.
And what we define the quality factor it is technology independent measure of sensitivity of our pole locations to perturbations.
For an analog biquad with poles at a plus r minus j b where a is less than 0 then the quality factor what Q is given by.
root of a square plus b square divided minus 2 a, where it is going to be half less than or equal to q which is less than or equal to infinity.
So, if we have the real poles then b will be 0.
So, the quality factor will be half that is we call it as exponential decay response.
And if we have imaginary poles a will be 0.
So, q becomes infinity.
So, we say we are going to have the oscillatory response.
Thank you.
Welcome back to second lab of real time digital signal processing.
As I was mentioning in the first lab.
anybody is ready to dirty their hand.
So, you can start doing it.
So, we will start with first in this lab sign generation.
So, what is it?
As a recap we discussed how to use code composer studio and for dot products and then sign generator what we did.
Today we will see that only one sign wave generation last class we have seen.
So, we have multiple ways of representing sign generation.
So, we will be using both matlab and then code composer studio.
today and then how to create a basic music.
So, people who are music lovers you can create your own music and then hear how it is going to come.
So, the first sign generation what we will say it as direct digital synthesizer technique.
So, in this case we will have variable initialization section that is we say lines 2 to 6 here.
So, we will be initializing.
or amplitude as 32000 signal amplitude what we can call it.
So, compared to this detail on the left hand side the code is given on the right hand side for MATLAB implementation.
And some codes function are constrained to the range between plus or minus 1 which requires an amplitude scale factor of a what we call it or the.
DAC output whenever we want to output it on to DAC of our board then we have to enhance the amplitude of it for that we have taken some amplitude equal to 32000 in this case.
So, we use the tiny portion of the full range of what we call it as plus 327672 minus 32768.
I think there should be an alarm ringing in your thing.
So, we are using the 16 bit signed representation in this case.
So, the number of bit for the fractional representation what we will be using is 15 bits one for signed bit.
So, for a constant output frequency the calculation of the phase increment that is what is shown in line here phase enhancement which is given by the equation 2 times pi into frequency component what it is chosen f as 1000 that is 1 kilohertz here divided by the sampling frequency.
In this case sampling frequency f is assumed as 48 kilohertz.
So, we will be calculating the phase increment based on this unit.
And for a constant output frequency the calculation of phase increment as we said in line 9, the calculated value of the phase increment must be usually we restrict between minus pi to pi.
Here that is what it will be less than or equal to pi or signal aliasing is going to happen.
So, for that reason so, you will be seeing the actual algorithm to generate our sinusoidal signal requires only 3 lines of code that what you are seeing line 13 to or 15 basically is the code to generate our sine wave in this case.
Rest of them are initialization functions.
So, inside a for loop and then simulate the.
or execution of interrupt service routine in C if we are writing it.
We will consider this writing of interrupt service routine in the next lab class that is called each time a new sample is going to arrive.
So, these lines of code accomplish the following three task each time an interrupt service routine is going to be called.
What is the first one that is line 13 basically.
adding the phase increments value to the phase accumulator and then in the line 14 you will be calculating perform a modulus basically that is 2 pi operation to keep the phase accumulator in the range 0 to 2 pi.
Either you can have minus pi to pi or 0 to 2 pi is the range what we are going to take it.
Here in this case we will be seeing that if it is going to cross 2 pi then output is going to be modulo value what will be taking it.
In the line 15 we will calculate the systems output value by scaling the sign of the phase accumulator value by a.
So, that is what we are going to do in the thing just we will see that how this is going to run.
So, we will run the MATLAB code in this case.
You will be seeing the code sign generation dot m using the DDS method.
So, you will be seeing that your magnitude a in this case I can assume 1 or there it was 32000 we can vary we will see it in a while.
And then my frequency component what I want is 1000, 1 kilohertz frequency what I want to generate.
This is a variable so you can play around with it.
And then you will be initializing your accumulator that is phase accumulator as 0 and sampling frequency 48 kilohertz.
So, this also you can vary depending on your requirement.
And then your this thing number of terms what in this case we are generating 50.
This also if you want more waves basically you can increase that.
That is what it says is calculate this number of terms basically.
And then calculated and then output terms are going to be your phase increment.
this is the increment what we are providing it.
So, the phase increment and this is the one loop what it is going to be implemented.
So, for i is equal to 1 to number of terms because we need 50 terms.
So, we are accomplishing this one.
So, instead of putting it on the DAC here what I am doing is I am going to store the output in a loop basically array which is given by this equation.
And, then if you have to have the interrupt service routine algorithm for the sign loop we will be providing it here.
And, then this output will be going through the interrupt service routine to our DAC output in the real time scenario.
So, here at the end of our routine we can plot and see whether I have able to generate using this function.
So, what MATLAB does is any of the MATLAB version you can take it in this case I am using MATLAB 2020 B version.
So, you can use any one of them.
So, when I run this code, so you will be seeing that.
So, my sign generation is running.
So, the 50 samples is the output what I have given.
So, you will be seeing that you are getting in complete one.
a period of 50 samples here.
So, by varying this value this is one way of generating our sine wave.
So, if I increase my magnitude to whatever was given in that I can do it as 32000.
So, ok.
So, I can rerun my code.
So, you will be seeing that.
the magnitude which was 1 in the earlier case it has gone up to 10 power 4 in this case.
So, if you want to change your sampling frequency and the frequency part of it.
So, you can vary here f can be I can give it as here now 2000 hertz basically and sampling frequency I can keep it at 8000 hertz also because I have been meeting my whatever the sampling theorem says twice that of the maximum frequency.
So, f n is 2000 which is greater than or equal to twice that of it.
So, I am.
little more than the thing.
So, I can rerun this code as you will be seeing it.
So, you are able to get 2000 hertz whatever.
So, how do you know that you have got the 2000 hertz signal?
So, you have to wait for A50 class or you can run if you are comfortable with MATLAB you can put the A50 magnitude if you calculate the thing you will be getting.
the as we can see that.
So, we can rerun the thing.
So, you will be seeing that my FFT function has a what is it error in the thing.
So, you can go back and then correct it and then see that you will be getting your magnitude function.
So, what is the frequency you have represented.
So, coming back to my slide what is the other method of running our generating our sine wave.
So, this was the first one that is direct digital synthesizer what we have taken.
Next one can be using a table lookup technique.
So, what how do you generate your table?
So, as you can see in the right hand side here so, you have the signal represented as 32000, 0 minus 32000 then 0 that is we call it as a cosine signal values.
So, what you have chosen f is by 4 case what we have taken the thing.
So, coming with the thing it is a variable initialization section that is what lines 2 to 4 on the right hand side what it is going to be.
So, what it will take.
Then we will be establish the code and then variable signal that stores the required values of the output signal and then you will be reusing them.
So, what is that we will be doing the period determination from the line 7 as you can see it is n is equal to length of signal what you have taken the thing.
So, will be period.
determination is done by this code and then actual algorithm to generate our continuous sinusoidal signal is again lies from 11 to 15.
So, you are checking whether index has increased to n plus 1.
So, what the range we want is 1 to n. So, length of the signal.
So, if it is exceeded n plus 1 then you will be starting index again from.
So, this will be if statement what will be using it and then my for loop is going to end here and then output is going to be signal of index and then index you will be incrementing it by 1.
So, your interrupt service routine can be written here and then we will be ending the code for the for loop basically.
So, we will go back and then see again in MATLAB whether it is running correctly or So, I have chosen this.
So, you will be seeing that signal is represented by these values and index is 1 and number of terms also I have chosen in this case 50 and then n is going to be length of signal whatever you have chosen and then for i is equal to 1 to number of our terms.
So, this code is going to be repeated.
If n is greater than or index is greater than n for the n plus 1 index will be reset to 1 and output again putting it in a array so that we can plot it and then see whether we are getting it correctly.
So, we will run the code.
So, you will be seeing that it has generated our sine wave as you can see in this case.
So, this is how.
second method what you can run with lookup table.
So, it is going to help us that you have pre-calculated and then kept the thing.
So, it depends on how much memory what you need it.
So, just as I was telling so to generate using the sign concept can we generate a musical note.
In this case basic of music what I have taken it is Carnatic music whatever you call it it is Sarigamapada Nisa what will be generating it.
So, what is the thing is going to happen we will set the sampling frequency is 8000 hertz and then t will be varying between 1 and then fs and my sur note what we have chosen the basic note in this case is 440 hertz.
So, that is what we put here and then we will be generating the notes.
The next note is as you can see is 494 either you can use the equation whatever the you know musical literature gives.
and then do it or if you have pre calculated I can select the frequency part of it for all the node.
So, in this case Ga is going with 554 and then Ma will be going with 587 and then Pa with 660 and Da with 698 and then Ni will be 784 and then the last node as you know it will be twice that of the first whatever base node what you have taken the thing.
which is going to be 88 hertz.
So, and then what we do is we will be concatenating them that is all of them will be horizontal concatenation is going to happen.
So, we have the function horizontal cat actually all these notes and then we will be playing that.
So, just hold on a while.
So, we will see how our music is going to come out of it.
So, this is the code written.
So, if you want you can treat it nicely and then say that with the comments what you can put the thing.
So, here basic thing what I wanted to show in this lecture.
So, go to the editor.
So, you will be running this.
So, you will be hearing it and then you have to comment whether you have heard the Saragamapadani correctly or not.
Want to hear it once again.
I will play the thing.
So, if you have your notes basically some of the students played their own happy birthday song and then our national anthem, so which we can play when everybody is around.
So, you can go and then write your own musical compositions and then generate it and here that you are getting it correctly.
So, the other way of doing it is whether I can do sign generation using my polynomial approximation.
We call it as GNU math library here.
So, this is the approach using the scientific library which stores the first 11 coefficients of the approximation.
So, what it calls is harness form is used.
What is that harness form we will see it once now.
The number of operations required in this case is a to the power of 10 into 10 plus a power 9 into 9 plus a power 8 into 8 plus etcetera.
So, this will be a power 0.
So, you will be seeing that how the harness form is going to be.
You will be doing a power 10.
into your this thing what is it 0 x, x is the input value what you have to give it plus a power 9 into x.
So, and then plus a power 8 into x.
So, so on what you will be putting the thing so that your power calculation is going to be reduced plus a 0 what you will be doing.
So, to generate sinusoidal frequency f naught we need only few stage for each steps for each sample.
So, you will be calculating the cos theta via the approximation above and then send the value to the DAC.
And then increment theta by omega naught is equal to 2 pi f naught by f s and then check if theta is going to exceed 2 pi f basically, then 2 pi if it does subtract 2 pi to prevent the overflow or loss precision.
I want you to write the code for this in MATLAB and see whether you have got the.
sine wave generated correctly using this polynomial approximation.
So, what this says is this method produces a very accurate signal, but requires roughly 20 multiplications and 20 additions as you can see in the bracket there.
Per sample in addition to the storage of the coefficients.
So, you have to store all the coefficients and then run them.
And then it is also extremely flexible since at us to change the frequency as we please by simply changing the amount at which we increment theta.
So, by doing theta increment varying.
So, you will be able to get whatever frequency you want to generate.
So, coming to the next one some of the lab thing component we will be seeing that how to generate real time sine wave generation and FIR filters.
So, you have enjoyed the sine wave generation and then music generation in MATLAB.
So, the same thing what we will see in the next lab class.
on DSP processor.
So, you can play with it with whatever music you love.
Thank you.
So, see you in the next lab session.
Welcome back to real time digital signal processing course.
So today we will discuss discrete Fourier transform in detail.
So, coming to the previous class, so we covered the FIR and IAR filters in the previous module.
So, we saw how quantization affects the frequency response for the IAR filter and then how we have to do the scaling and other parameters what we have to take it into consideration to design our IAR filter.
So, coming to now we will go to the frequency domain.
Why we have to go to the frequency domain?
So, first of all what we have to say from analog time domain we have to move to frequency.
So, the time domain the components which we are unable to see basically.
So, whether the other domain that is in the transform domain which is going to give us the parameters what we are looking for.
So, for that we go to the Fourier domain basically that is frequency domain.
So, in this case today we will be discussing about discrete time Fourier transform first and then we will see that how discrete Fourier transform the thing is developed.
So, in that is what we are going to tell that is we introduce the discrete time Fourier transform for the theoretical analysis of our discrete time signals and systems and the discrete Fourier transform which can be computed by our digital hardware for practical applications.
So, coming to the definition, so we know that discrete time Fourier transform d t f t is for the discrete time signal x of n t is defined with this equation that is x of omega is equal to sigma n is equal to minus infinity to infinity x of n t into e power minus j omega n t. And we say x of omega is periodic function with period pi.
So, the frequency range of discrete time signal is unique over the range that is minus pi to pi.
or we can consider 0 to 2 pi.
So, d t of t of r x of n t can also be defined using the normalized frequency.
So, if we take that then it is going to be x of f which is equal to n is equal to minus infinity to infinity x of n t into e power minus j 2 pi n capital f into n where our f is frequency is given by omega by pi.
which is nothing, but f by f s by 2, f is the signal what we are interested in and f s is the sampling frequency.
So, we say that normalized digital frequency in cycles per sample.
So, how we are going to represent the spectrum of discrete time signal.
So, we said that it is periodic sampling imposes relationship between independent variables T and N as T is equal to.
which is nothing but n divided by fs.
So, that we can show that x of f is equal to 1 by t k is equal to minus infinity to infinity x of f minus k into fs.
So, we will be seeing that x of f is the sum of the infinite number of x of f what we are going to say which is the Fourier transform of our analog signal x of t.
It is scaled by 1 by t and then frequency shifted to k times fs.
So, it also state that x of f is a periodic function with period t is equal to 1 by fs.
So, we will be seeing the spectrum here.
This is our x of f what we are considering it and this is the maximum frequency in our input signal.
It varies between minus f m to f m and then f is the x axis.
So, coming to the next one if why we are going to have the replication that is discrete time signal caused by sampling basically.
So, this sampling extends original spectrum whatever we have considered x of f repeatedly on both sides.
So, we will be seeing this is extended on both sides.
So, we call this as.
minus fs by 2 and then fs by 2.
So, we will be getting the images of the spectrum basically.
So, what happens if our maximum frequency is less than or equal to our half the sampling frequency according to Shannon sampling theorem.
So, then what happens?
So, we will not be seeing any overlap in the thing.
So, that is what the theory says.
that our f m is going to be much away from our f s by 2.
So, in the next case if f m is what we say is more than our f s by 2 or f s amplic frequency is less than that why is the maximum frequency component present in our signal.
Then what we are going to have is we will be seeing the overlap of it.
So, f s by 2 is here.
minus f s by 2 is here or f m has more than f s by 2.
So, you will be seeing that we will be getting the aliased signal.
So, this we may not be able to reconstruct to the original signal it may map it to some other signal as we have seen aliasing in our sine wave generation also.
Coming to discrete Fourier transform.
So, what we have is it this is we call it as a finite duration.
whereas, DTFT was discrete in time, but frequency was continuous in omega.
Here both frequency and then time have been discretized.
So, x of n of length in is defined as given by x of k. So, n is equal to 0 to n minus 1 x of n into e power minus j 2 pi by n into k into n. k will be varying 0 to n minus 1.
And, then we will be seeing that n is varying 0 to n minus 1.
So, we call k is the frequency index.
So, we will be saying x of k is the kth DFT coefficient.
The summation bounds reflect the assumption that x of n is equal to 0 outside the range 0 to 0 less than or n which is less than or equal to n minus 1.
So, we call DFT that is n samples of DTFT of X of omega over the interval omega in between 0 and then 2 pi.
At n equally spaced discrete frequencies that is omega k what we call it 2 pi k by n here k is going to be 0 to n minus 1.
And the space between two successive X of k is nothing but.
2 pi by n we call it as a resolution of the DFT.
So, we say the unit for this is radiance and then if we represent in terms of sampling frequency it is going to be fs by n hertz.
So, then what we can see that as an example if the signal n is real valued and n is even number.
So, we can show that x of 0 if we substitute that is n is equal to 0 to n minus 1 which is nothing but x of n into e power minus j 0 which is nothing but x of n. And then x of n by 2 any other n divide by 2 is represented as this way n is equal to 0 n minus 1 e power minus j pi n into x of n. So, this is we know that e power minus j pi n is nothing but minus 1 to the power of n into x of n.
So, what we observe from this is the DFT coefficients x of 0 and x of n by 2 are real valued.
That means, if x of n is real valued then output even the DFT coefficients are real valued.
So, if n is an odd number x of 0 is still real, but x of n by 2 is not available.
Now, we will consider the.
sequence or signal of finite length which is given by x of n is equal to a power n, n is varying between 0 to n minus 1 and then a is in between 0 and 1.
Then DFT of x of n is computed as that is x of k substitute x of n with a power n and then we have e power minus j to pi k by n into n. So, by simplifying.
So, what we will be getting is 1 minus a to the power of n by 1 minus e power minus j 2 pi k by n and k is going to vary between 0 to n minus 1.
So, we can represent this DFT as W n k we call this as a twiddle factor which is given as e power minus j 2 pi k by n into k n. So, we know that we can split our exponential into cos and sin function.
So, cos 2 pi k n by n which is real.
and then minus j sin 2 pi k by n is the imaginary part.
Both k and n will be varying between 0 to n minus 1.
So, then if we substitute w and k in our equation.
So, x of k will be equal to n is equal to 0 to n minus 1 x of n into w n k n, k is varying between 0 to n minus 1.
So, that is what I said twiddle factors of DFT, w n k n are called.
And then we know that n roots of unity is a clockwise direction on the unit circle.
We will see it in a while hold on.
So, then what we call W n, n is nothing, but e power minus j 2 pi which is equal to 1 which is nothing, but equal to W n 0.
So, we can see that the DFT is periodic in nature.
So, that is the reason why we take 0 to n minus 1 when we.
substitute x of n is equal to n basically that is n is n then what happens?
k r n becomes n it becomes e power minus j 2 pi which is 1 which is nothing but w n 0.
So and then the centre point what we will check it up w n that is n by 2 which is equal to e power minus j pi so which is nothing but minus.
1 and W n k what we call it between the other values as k is equal to 0 to n minus 1.
So, if we extract the symmetry property then what happens?
We can split this into two parts that is W n k plus n by 2 which is equal to minus W n k. So, k is in between 0 to n by 2 minus 1.
And, if we consider the periodicity property then what happens?
W n k plus n is nothing, but W n k. So, we know that the inverse discrete Fourier transform we call it as IDFT.
So, is used to transform the frequency domain coefficients x of k back to time domain signal x of n. The IDFT is defined with this equation x of.
n is equal to 1 by n, k is equal to 0 to n minus 1, x of k into e power j 2 pi by n into k n. So, if we represent with twiddle factor, it will be 1 by n into k is equal to 0 to n minus 1, x of k into w n minus k n in this case, n will be varying between 0 to n minus 1.
So, we can see that how the twiddle factors of DFT.
in case of n is equal to 8 is assumed so on a unit circle.
So, we will be seeing that this is w 8 0 which is equal to 1 and then what we have is w 8 1 and then w 8 2 w 8 3 and then n by 2 what we just now saw that w 8 4 which is nothing but minus w 8 0 which is equal to minus 1 and then we know w 8.
5 is equal to minus W 8 1 and then W 8 6 will be equal to minus W 8 2.
And we know that when we come to W 8 7 it comes out to be minus W 8 3 you will be seeing that this is what it is minus W 8 3.
And when it becomes W 8 is equal to 8 just now we said n W n n is equal to W n 0.
here it is W 88 which is equal to W 80 equal to 1.
So, these are the twiddle factors depending on power of 2 if you are considering it will be on the unit circle this way and then it is going to be repeated after a period in this case we have assumed n is equal to 8.
So, the equation now again repeated for DFT what it is shown.
And then in terms of twiddle factors w what we call it w n k n where 0 is less than or equal to k and then n is less than or equal to n minus 1 both k and then n are in 0 to n minus 1.
How we can write the in a matrix form that is all these coefficients are first row is 1 and first column is 1.
After that we will have w n.
and then 4 1s in the column then this is W 4 1, W 4 2, W 4 3 and W 4 2, W 4 4 and W 4 6 so on in the last line odd you will be seeing it.
When you expand them so in terms of e power then you will be seeing that W 4 1 is nothing but minus j and W 4 2 is minus 1 and W 4.
3 is minus of w for 1 which is plus j.
So, here also you will be seeing the thing this is how we will enter the thing and we have been given x of n is this value.
So, this is our coefficient and then this are our x of n when we do the matrix multiplication.
So, the DFT of the sequence is nothing, but 2 1 minus j 0 and 1 plus j.
So, to see that whether our DFT is correct or not we will take the IDFT.
So, we assume that fk is equal to k into fs by n, k will be varying between 0 to n minus 1.
So, then what happens to our x which is nothing but 1 by 4 that is 1 by n in this case.
So, we will substitute our matrix is going to be just our DFT matrix, but you will be seeing that the twiddle factors are.
negative in this case.
So, we will be substituting all this values when we do that.
So, 1 by 4 this is our DFT coefficients in the IDFT basically.
So, you will be seeing that it is a complex conjugate of this DFT coefficients which it will be resulting in what is it?
After multiplication with our x of k that is 2 1 minus j 0 and 1 plus j.
So, we will be getting back our x of n that is 1 1 0 0.
So, you will be seeing that this is the DFT and IDFT with an example how there what I will call it as analysis and then synthesis equations what we call them.
So, what is the frequency resolution in this case?
So, we said identical to DFT with exception of the normalizing factor 1 by n and the opposite sign of the exponent of the twiddle factors that is what we said.
So, the DFT coefficients are equally spaced on the unit circle we saw that usually we call it as the z plane at frequency intervals of f s by n or it can be 2 pi by n because that is what we mapped.
in the omega that is in the frequency domain 0 to 2 pi and then here sampling frequency is f s up to 2 pi.
And we say that frequency resolution of our DFT delta is nothing, but f s by n this is the sample samples or the period between two samples.
Frequency sample x of k represent the discrete frequency.
So, where f k is given by K to Fs by n for K is equal to 0 to n minus 1.
So, we assume that if I do not know what is the frequency I am getting at the output, if I know the K is equal to I will put it as 1 and we have assumed Fs sampling frequency is 8 kilohertz and then I am going to pass it through n is equal to 8 to be simpler to calculate this.
Then what is the frequency FK component in this case is going to be?
k is 1 and I have chosen 8 kilohertz as my Fs divided by number of samples is 8.
So, then you will be seeing that Fk is what I am representing at k is equal to 1 is 1 kilohertz.
So, if I draw the thing, so this will be my magnitude x of e power j omega what I can put the thing magnitude of it and this is the Fs.
in kilohertz what I will put it and this is my 0, this is 1, 2, 3, I will put it as 8.
So, I will be getting the peak here which is my f k in this case what I am representing.
So, this is how you will be calculating depending on k value is going from 0 to here 7 in this case, 8 will be f s by 2 point.
So, it will be repeated.
So, this is how you calculate and then we know that DFT coefficients x is complex variable.
So, it can be expressed in polar form as x of k is equal to magnitude of x of k into e power j phi of k. So, this represents my phase and this represents my magnitude.
So, that is how we will be representing it here, how we can compute our magnitude and phase spectrum for a given signal.
So, the first is the magnitude spectrum will be calculating magnitude of x of k is nothing, but all of us know real part of x of k whole squared plus imaginary part of x of k whole squared under square root.
So, will give me the magnitude of x of k and then the phase spectrum always we represent in terms of tan inverse.
So, phi of k is equal to tan inverse imaginary part of x of k real part of x of k. If tan real part of x of k is greater than or equal to 0.
So, if it is less than 0 then we will be seeing that it will be pi plus tan inverse of imaginary part of x of k divided by real part of x of k. So, now, how we are going to represent our DFT and then Z transform.
What is the relationship we will see in the slide.
So, the DFT questions can be obtained by evaluating the Z transform of the length n sequences of x of n.
on the unit circle we have seen it already.
At n equally spaced frequencies wk which is given by 2 pi k by n, k will be varying between 0 to n minus 1.
So, we what is it x of k is equal to x of z, z is equated to e power j 2 pi by n k where k will be going from 0 to n minus 1.
So, some of the terms how we will be going from one domain to the other domain what is shown in this figure.
What is it x of t is my time domain by doing the sampling of the signal I will be entering into digital domain that is x of n t. And then if I take the Laplace transform for in the time domain then I will be going into Laplace domain which is represented as x of s. And then how I can traverse to my digital z domain by substituting a simplest impulse invariant method that is z is equal to e power st I can enter into a z transform basically in the digital domain.
or from the digital signal I can use that Z transform to calculate my X of Z and if I calculate the Fourier transform I will be entering into the Fourier domain that is X of omega.
And then how these two are related as you can see by substituting Z is equal to e power j omega I can get the frequency component from Z domain ok.
So, the sum of the units and then variables and relationship and range is shown in this table.
So, if we represent it as capital omega we call it as radiance per second.
So, we say that capital omega will be 2 pi f and this is the range for our capital omega that is minus infinity to infinity and f we call it as cycles per second in hertz.
So, which is f is equal to capital F by T which is capital F is assumed in this case as sampling frequency.
As you can see cycles per sample that is f by fs.
And, then this also varies between minus infinity to infinity and omega usually we represent it in radiance per sample and omega is equal to 2 pi f which varies between minus pi to pi omega or it can vary between 0 to 2 pi.
And, this is between minus half less than or equal to f less than or equal to half.
So, this is what the relationship with respect to.
Z transform and then DFT.
So, now we will assume that how to go with we said that DFT is a periodic function.
We will see how to calculate the circular convolution.
So, all of you must be conversant with your linear convolution and circular convolution.
Usually DFT will be represented as a circular convolution.
So, we have a x of n and h of n are real valued n periodic sequences, y of n is a circular convolution of x of n and h of n. So, which is represented as y of n is h of n into.
This is the circular convolution notation what we use it with x of n which is given as h of m into x of n minus m mod n what we will be taking it.
That means to say n minus 1 mod n non negative modular n operation will be considering it.
n is varying between 0 to n minus 1 in this case.
So, how we represent in the this is what we have in the time domain and in the frequency domain.
So, it results in the multiplication of.
2 Fourier transform of that is discrete Fourier transform of x and then h. So, y of k will be x of k into h of k where k will be varying between 0 to n minus 1.
So, that is what it says if the shortest sequence must be padded with 0s in order to have the same length for computing circular convolution.
So, what do we mean by that?
So, x of k and h of k are of different length.
So, to make them equal length one of them have to be padded with 0s.
So, we will see in that linear convolution in slide 21.
So, how we have padded with 0s and then made power of 2 and then used in our circular convolution.
So, how we are going to compute our circular convolution?
So, usually it is represented with two concentric circles and we will be seeing that this goes in the clockwise direction x of n and h of.
n are aligned actually then we will be moving h of 0 in this direction n minus n plus 1 and then so on.
And then next last one will be h of n minus 2 h of n minus 1.
Whereas you will be seeing that x of n goes in this direction anticlockwise x of n minus n plus 1 and then we will be coming to x of n minus 2 and x of n minus 1.
So, this is how we will represent we will see with an example how we are going to come.
compute this.
So, as an example as I have been mentioning x of n is given as 1, 2, 3, 4 and our h of n is 1, 0, 1, 1.
In this case as you can see both are of the same length we will do the circular convolution.
So, the steps have been written here.
So, how to arrive at this steps using our concentric circles we will see the thing.
So, my x of n is 1, 2, 3, 4 it is written in this way anti-clockwise.
and then h of n is 1 0 1 1 is in the anticlockwise.
Sorry this is in the clockwise the x of n is in the anticlockwise.
So, when I do the first time we have aligned the x of n and then h of n together and we multiply these two numbers and then all of them we multiply you will be seeing 1 into 1 is 1, 2 into 1 is 2, 0 into 4 is 0 and then here 1 into 2 3 is 3.
So, when you add it up this is what the step what it is given at n is equal to 0 y of 0 is given by 1 into 1, 1 into 2 plus 1 into 3 plus 0 into 4 which gives me 6.
So, then what we are going to do is I can move this as the arrow shows one step each time my h of n in this thing and I keep this one as it is.
So, when I do that next.
value is going to be 0 into 1 plus 1 into 2, 1 into 3 and 1 into 4 when added up summation it comes out as 9.
So, this is 6, 9, 8, 7 when I do the circular convolution.
So, you will be seeing that how we can implement linear convolution just if you have done the thing.
So, just I will write it here most of you would have used this method to.
compute your linear convolution.
So, when I put the thing all of us know that we put x of n I can put it here 1, 2, 3, 4 this is 1, 0, 1, 1 what I can represent then I will be multiplying with the 1 into this number this is 2, 0, 2, 2 and then 3, 0, 3, 3, 4, 4, 0, 4, 4.
So, how we are going to get the thing?
So, you will be knowing that.
This is the way we will be adding it up and then result in the linear convolution.
So, you will be seeing that this is 1, 2, 3, 7 and then 5, 7 and then 4.
This is the equivalent of linear convolution.
So, whereas circular convolution you can see that 6, 9, 8, 7.
Can I use this method to implement linear convolution?
That is what we will check in the next slide.
So, you will be seeing that what we have done is we have these are the two values.
So, that is for the linear convolution using circular convolution we have to do 0 pad of L plus M minus 1 is the length of the sequence what the result is going to be.
So, we have to pad both of them with these 0s L plus M minus 1 L is the length of X of n M is the length of H of n in this case we have both of them equal 4 plus 4 8 minus 1 7 will be the length what we have is 4 lengths.
So, we will be padding with.
3 zeros and then the other one also will be padding with 3 zeros.
So, now we have although we have the equal length to simplify if I want to compute power of 2 then what I have to do is I have to make them 8 as you will be seeing that 2 concentric circles I have divided into 8 parts.
So, we will be putting 1, 2, 3, 4 and then 4 zeros what we will be padding instead of 3 zeros.
Here also we will be doing 1, 0, 1, 1 and 4 zeros.
Same way as the previous one you can shift the thing.
The resulting values with circular convolution you will be seeing that 1 2 4 7 5 7 4 is achieved which can be evaluated verified using MATLAB or the next slide shows that how it has been implemented.
So, I showed you how it has been done in the previous example.
Same way if you do the thing you will be resulting with this value.
The last one will be 0 which you can discard and then keep these l plus m minus 1 values.
for your result.
So, you can see that we have taken little bit of DFT in to show that circular convolution property.
Other properties you can look into the book and then come out with it.
In the next class we will be seeing the complexity of filtering and how we will be deriving from DFT FFT equation.
Thank you.
Welcome back to real time digital signal processing course.
So, last class we were looking into.
So, we will see that how we are going to derive this one in today's class.
So, we have started with the adaptive filters, why do we need it and what are the applications it is going to be used one of the application we saw it as our hearing buds and then other things.
So, today we will see that how we can derive our adaptive filter that is basically least mean square LMS algorithm.
So, we discussed about the method of steepest descent in the last class.
So, that is it is a iterative or recursive process technique that starts from some arbitrary initial weight vector w 0 and it is going to descent to the bottom of the bowl what we said.
So, by moving on the error surface in the direction of negative gradient estimated at that point.
So, you will be estimating it and then going down in the thing.
So, for l is equal to 2.
So, this is the error surface what we have got it and this is the error contours in concentric circles what we will be getting it.
And then how we are going to calculate we said we will be deriving this shortly.
So, that is the weight update that is future weight update n plus 1 is going to be done with the current weight minus mu is our step size basically as you can see in the error surface how you will be coming down.
and then the gradient vector eta of n. So, that is what we call it as gradient of the mean square error function with respect to our weight function.
So, negative sign indicates that the weight vector is updated in the negative gradient direction.
So, we will take up an example and see how we will be coming with work on the steepest descent algorithm.
So, the function given we need to obtain the vector.
that would give us the absolute minimum what we are looking at.
So, y of c 1 comma c 2.
So, which is given capital C 1 square plus c 2 squared.
So, it is obvious that c 1 is equal to c 2 is equal to 0 give us the minimum basically.
So, this is the quadratic bowl c 1 is in this direction c 2.
So, we know that this is what we are expecting.
So, in the bowl how we will be traversing and coming down what we will see.
in practical applications we may not reach 0.
So, as an example so assume that c1 is equal to 5 and c2 is equal to 7 in the beginning.
And we are going to select the constant mu if it is too big we miss the minimum, if it is too small it would take us a lot of time to hit the minimum.
So, in this case we will select mu is equal to 0.1.
The gradient vector is defined by this which is dy by dc1 and then dy by dc2.
So, which is equal to 2c1 and then 2c2 what it is going to be.
So, our iterative equation is what we are going to have it is c1 and c2 of n plus 1 is given as c1 c2 n minus 0.2.
multiplied by R gradient vector.
So, which is nothing, but c 1 c 2 this thing n minus what we have is because we have 2 c 1 and 2 c 2.
So, if we take it out.
So, it is going to be c 1 c 2 n into 0.1 what we are going to get the thing.
So, when we substitute this 1 minus 0.1 will be.
are 0.9.
So, this is 0.2 divided by what you are going to have it is 2.
So, that is the reason why what you will be getting it as 0.1.
So, now, what we are going to substitute is iteration first what we have c 1 c 2 is 5 and then 7 is been given and in the second iteration.
So, c 1 c 2 according to this equation substitute c 1 c 2 and then solve the thing 0.9 c 1 c 2.
what we are going to have it.
So, the next iteration so, by multiplying c 1 c 2.
So, you will be getting it 0.9 times 5 is going to be 4.5 and this becomes 6.3 and then continue this in the iteration 3 4.5 into 0.9.
So, this is what we will be getting it and c 2 is this value.
So, at iteration 6 t as you can see that the value has come down to 0.01.
So, you will be seeing that initial guess what you have taken the things C1, C2 and then you are traversing down the thing.
So, here it is going to be 0.01, 0.013.
So, as we can see the vector C1, C2 converges to the value which would yield the function minimum and the speed of this convergent depends on our step size.
So, in this case we had taken it as point 1 is our step size mu basically.
that is what we have assumed in this case.
So, now what is the thing is going to happen?
So, how to calculate the mu or how to arrive at the least mean square algorithm what it is shown here.
So, in many practical application so, statistics of our desired signal d of n and x of n are going to be unknown that is input signal.
So, the method of the steepest descent.
cannot be used directly since it assumes the mean square error is available to compute the gradient vector.
So, then what happens you will be seeing the LMS algorithm developed by Widerow.
So, you can go to the net and then see he is the one who designed our least mean square algorithm uses the instantaneous squared error e squared of n to estimate the mean square error.
So, which is given by eta of n is you will be putting it as E squared of n. So, the gradient estimate is partial derivative of this cost function with respect to the weight vector.
Then what happens to our gradient which is going to be given by 2 times our gradient of error vector into error vector what we will be putting it E squared of n. So, then since we know that our error function is given by d of n minus y of n.
and y of n substituted with w transpose of n into x of n what is substituted then what we have is our gradient of E of n is given by when you take the gradient of it which results in minus x of n. So, the gradient estimate becomes as it is given by minus 2 into x of n into E of n.
And, the weight vector w of n plus 1 is going to be w of n plus mu x of n into e of n. So, what is the from where you got you have substituted the gradient thing with respect to this I think you can derive the thing.
So, the constant mu what will be putting it into our update vector here.
So, then how we are going to calculate our LMS algorithm.
So, the diagram on the right side it shows that it has an input and then we have the weight vector here and then y of n is our output and this is the desired signal the difference between the two will give us the error which is fed to our LMS algorithm which will modify the weights based on our input x of n.
So, this is what the figure shows and we will write down the steps which are going to be followed in the algorithm calculation or weight calculation and then the output calculation and error.
So, we are going to determine the values of L is the order of the filter, mu is the weight vector and W of 0 is the initial values for our weight vector.
So, that is what it gives the thing this is the step size and W 0 is the.
x of n. So, which is nothing, but it is l is equal to 0 to l minus 1 w l of n into x of n minus l. And we will be computing the error signal as e of n is given by in the second step d of n minus y of n. So, we have calculated y of n and weight vector initially we have assumed as 0 and then we will start with it.
And then whatever the desired signal what we have given minus the output.
will be the error.
Initially as we know that y of n may be 0.
So, it will be error will be very high because we have assumed the weight to be 0 and then x of n. So, error will be high and then you will be seeing once it starts coming down it will be adapting to weights are adjusted.
This is how we will be calculating our w l of n plus 1 is going to be given by w l of n plus.
mu into x of n minus l into E of n. So, where l is the length of the our filter which is going to vary from 0 to capital L minus 1.
So, hence you will be seeing that number of computations what it is going to have in calculating the LMS algorithm is 2 L additions and 2 L plus 1 multiplications what we are supposed to do to get the output.
So, that is what the computation complexity of the LMS algorithm.
So, coming to the thing how our graph is going to converge.
So, we will see the thing unknown channel of second order what we have chosen the thing and then this graph is going to illustrate that is what you have the initial guess here and then this is our E 1 and then C 1 and then C 2 what we have selected initially as we said.
So, then what happens so it will be traversing depending on our mu will be traversing in this way in the concentric circle.
and try to we are supposed to get to 0.
So, as we know that it is in practical situations it is not possible to achieve this.
So, we could only decrease the error below a desired minimum so that we will be able to work on it.
So, there are different modified LMS algorithms to reduce our computation time.
What are the thing there are 3 types to improve the computation?
One is the sign error.
LMS algorithm.
Here as you can see W of n plus 1 is given as W of n plus mu into x of n and you will be taking the sign of the error n. So, sign data LMS algorithm the other one sign of a of n is given as 1 or minus 1.
So, if error is greater than or equal to 0 we make it 1, if it is less than 0 it is going to be minus 1.
So, that it is either negative of it or positive.
So, that we are avoiding the multiplication by error of n in this case.
So, the sign the other one is sign LMS algorithm.
Here it is based on the sign error the other one is on the sign on the data what you are going to have it.
Then in this case what happens sign of X of n. So, that you are reducing your The other one is sine sine LMS algorithm.
So, this algorithm requires no multiplication and designed for mostly VLSI or ASIC implementation to save multiplications.
So, in adaptive differential pulse code modulation that is ADPCM uses for this algorithm for speech compression.
So, I think we will be taking the speech coding little later.
So, we will see why we need the compression.
there ok.
So, how it is going to work for a complex signals that is LMS algorithm we have seen the DFT and other things for the complex signals.
Here also we have to see that how it is going to work from least mean square.
Applications dealing with complex signals the frequency domain adaptive filtering require complex operations to maintain their phase relationships in this case and then the complex adaptive filter uses.
that is complex vector x of n and complex coefficients w of n. So, then x of n is real part of x of n plus j times imaginary part of n and w n of is also represented both in real and then imaginary parts in this way.
Then we know that complex output signal y of n is computed as y of n is w transpose of n into x of n what we have it.
So, where all multiplications additions are going to be complex operations.
So, the complex LMS algorithm adapts the real and then imaginary parts of W of n simultaneously as in this fashion W of n plus mu E of n into x conjugate of n. So, adaptive channel equalizers use x conjugate of n as x real of n minus j x imaginary of n.
So, we will see these applications little later.
So, we have to see the performance analysis of our LMS algorithm.
The as we know that IR filter we consider the stability constraints.
So, we have to see first one is the stability, next is how we are going to have the convergence rate and then we will be seeing that X is mean square error.
and how it is going to have the finite word length effects on our algorithm.
Just like any other our linear filter we have to see in the adaptive filter also.
So, how these parameters are going to affect us.
So, the first one is the stability constraint.
So, that is 0 less than our mu which is less than we have taken it as 2 by lambda max is the one lambda max is the largest eigen value of the autocorrelation matrix R.
So, as we have will be seeing in the lab that we selected wave mu is equal to 1 how our output was getting affected.
So, this is the wave otherwise arbitrarily we can choose the thing and then what is the thing is going to happen.
So, we have looked in the lab.
So, here what is should be the mu value which should be less than 2 times lambda max, lambda max is our autocorrelation matrix.
Now, eigen value of our autocorrelation matrix R. So, we know that computing our autocorrelation matrix and finding out the eigen value is compute intensive and then how we are going to take the thing that is lambda L are the eigen values of our matrix R in that the maximum value what will be taking it and then divide 2 by that value.
So, The other way of doing selecting our mu is from the stability point of view.
So, we can have a mu 2 divided by L into p x, L is the length of the filter and then p x is we know that it is the autocorrelation function of the first this thing input signal which is nothing, but expected value of x squared of n is the power of are x of n. So, this equation provides two important principles for determining the value of mu from these two constraints what is it?
The upper bound of the step size mu is inversely proportional to the filter length here.
Thus a smaller mu must be used for a higher order filter and vice versa.
Since, step size is inversely proportional to the input signal power.
A larger mu can be used for low power signal and vice versa.
The other way is more effective technique is to normalize the step size mu with respect to power p such that the convergence rate of the algorithm is independent of mu that is what one has to look at it.
So, now coming with the convergence speed continuing with the thing.
So, each adaptive mode has its own time constant for convergence.
So, which is going to be determined by the step size mu as we know and the eigenvalue associated with lambda L with that mode.
Thus the time needed for convergence is clearly limited by the slowest mode caused by the minimum eigenvalue and can be approximated as time to calculate minimum mean square error is approximated as.
1 by mu into lambda minimum.
So, lambda minimum is the minimum eigenvalue of the matrix R what we are considering this is the maximum time what it is going to take place.
If we choose a lambda max then we know that time to compute this is going to be lesser.
So, we say because our time tau mean square error is inversely proportional to the step size mu using a smaller mu will result in a larger time basically that is slower convergence and when our tau max is very large only a small mu can satisfy the stability constraint.
So, these are the things one has to consider when you are selecting your mu.
So, if lambda minimum is very small the time constant can be very large resulting in very slow convergence here also.
The slowest convergence occurs when using the smallest step size mu is equal to 1 by lambda max.
So, you will be seeing that both of them are inversely proportional to our mu step size and then lambda minimum.
So, both will be contributing to the slow computation time for our adaptive filter.
So, then what is it?
We say that our mean square error time is given by less than or equal to lambda max by lambda min.
And, which is by substituting lambda min we can do that which is less than or equal to lambda max divided by minimum is approximated as maximum x of omega that is magnitude of x of omega whole square divided by minimum of x of omega whole square.
So, how is this?
We know that x of omega is the dT of T of x of n. So, we will be seeing that eigenvalue spread can be efficiently approximated by the.
spectral dynamic range in this case.
So, we can see how the computation is going to be more.
So, now, other way of is how we can control our mean square error by using Xs mean square error.
So, which is eta Xs is given as L into Px into eta minimum.
So, we know that.
So, the approximations shows that the Xs mean square is directly proportional to our mu.
And, then use of larger step size mu is going to result in a faster convergence rate at the cost of degraded steady state performance by producing more noise.
This is what we saw in the lab or you will you can yourself see that by making mu larger step size only it will be giving you noise.
So, therefore, there is a design trade of between the excess mean square error and the convergence speed when choosing the value of mu.
So, now how we can normalize this mu basically or step function.
So, then later on what it was developed is normalized LMS algorithm.
So, which is given by this equation that is 0 is less than mu which is less than n by your p x.
So, as it L is the length of our filter and p x is the power what we have to calculate.
So, you will be seeing that it will take more time than LMS algorithm.
Then your update function for W of n plus 1 is given selecting this mu with our x of n and then a of n. So, you will be seeing that where mu of n is the time varying step size one has to calculate it is not pre computed as and when you are depending on your input power you will be calculating your step size.
And then it can be normalized by the filter length and signal power as mu of n is given as alpha constant divided by L into px of n plus some constant c where our px of n is the estimate of the power of x of n at time n. So, and alpha will be taking the value between 0 and 2 which is a constant and c is very small constant.
So, that we are not going to have when this becomes 0 division by 0 is avoided by this constant.
So, very small so that this is not going to get affected or using a very large substrate for a very weak signal at time n one has to note that Px of n can be estimated recursively.
So, an LMS algorithm will take little time compared to our LMS.
So, how we are going to choose this Px of 0 as the best a priori estimate of our input signal power.
So, a software constant may be required to ensure that mu of n is bounded if it is very small when the signal is going to be absent so that divide by 0 is avoided.
So, how we are going to do this one?
Software implementation is shown in with few steps that is we will be assigning our mu E of n is assigned as mu into E of n.
For l is equal to 0, l less than or length of the filter.
So, you will be continuing it this is the W of l is calculated with respect to mu into whatever you have calculate mu e n into x of l. So, that you will be you need not have to do this multiplication inside every time which is a consume you know that within the loop if you do the multiplication it will be adding on.
Instead of that you compute and keep it outside and then use it for you will be reducing the multiplication.
So, you can see that the updation can be done once in sampling period what we will be doing it.
Instead of every sample to reduce the computation and to take care of the pipelining delays.
So, the delayed LMS algorithm which is expressed as W n plus 1 is nothing, but.
W of n plus mu into E of n minus delta this is the delay what you are going to give it and even the input signal is going to be delayed by delta x of n minus delta.
So, if you assume delta is equal to 1 then E of n minus 1 that is previous sample what you will be taking it sorry previous error what you will consider and then even x of n minus 1 will be the previous sample what you will be calculating to.
update our weights in the future of it along with the current weight.
So next one is the finite precision effects one has to consider.
So, what is this we have seen this effect in case of IR filter the same thing we will be using it.
So, we have assumed the range input is going to be in the range between minus 1 and 1.
So, we will be scaling our signal.
So, that the input if it is a sine wave the magnitude is going to be between minus 1 and 1.
So, any either even the cause function if you have considered or any speech signal or any audio signal you will be considering the magnitude to be between minus 1 and 1.
So, later on we have to do scaling finite word effects and arithmetic errors can be considered.
So, However, we have done in the case of IR filter.
So, we will be taking care of the scaling and then finite word effects representing our coefficients even mu has to be approximated after the thing and then whatever additional what we are doing it the errors have to be considered.
So, we know that A of n that is feedback for coefficients scaling is going to be complicated.
So, what is it earlier in the FIR filter we did not have the feedback.
So, you will be seeing in the figure we have a from the error we are having a feedback path in the thing.
So, this also has to be considered then what happens?
Also the dynamic range of the filter output is determined by the time varying filter coefficients which are unknown at the design stage.
In the FIR filter we have computed our coefficients and then we knew that.
what will be the maximum precision what we are going to get it.
Here what is the thing is going to happen is because we are on the go our weight function is getting updated.
So, we say that it is a time varying filter coefficients what we have to calculate and we do not the design stage whether they are going to overflow or underflow or one has to consider that.
So, we say for adaptive air filter with LMS algorithm.
The scaling of the filter output and coefficients can be achieved by scaling the desired signal that is d of n. So, the scaling factor a which is in between 0 and 1 is used to prevent overflow of the filter coefficients during the coefficient update.
So, reducing the magnitude of d of n reduces the gain demand on the filter.
And by reducing the magnitude of the coefficient values.
Since, a only scales the desired signal.
So, it is not going to affect the convergence rate which depends on the magnitude spectrum and power of input signal.
So, that is x of n. So, d of n is not going to come into our spectral calculation or power calculation.
So, it is not going to degrade our performance when we do the scaling of desired signal.
So, y of n minus d of n.
So, which is going to be kept in not to overflow fine.
So, what will be the thing now continuing with the finite precision LMS algorithm can be how it is going to be described that is using the rounding operations.
So, we know that y of n is equal to that is value is going to be rounded.
So, here it is not the autocorrelation matrix what we are representing it is the rounding.
So, the magnitude of whatever the equation we have FIR filter equation which is going to be rounded.
Then E of n is going to be resulted as rounded of r a times d of n that is scaling of our desired signal minus y of n the magnitude of it will be rounding it.
Then what happens to our weight function updation function.
So, that is also going to be rounded.
And, then you will be having W of n this equation x of n minus l into e of n, l we will be varying between 0 to l minus 1.
So, that is what it says is R of x in this case fixed point rounding of the quantity x.
So, when updating coefficients the product whatever product we have it is a double precision number because.
E of n is floating point number even mu is also going to be floating point and x of n is also going to be either fixed point or floating point.
Still the result of two floating point numbers has to be double precision if we has used 32 bit for both of them then it becomes 64 bit which is double precision number.
So, which is added to the original stored weight value W1 of W L of n and then rounded to obtain the updated value W of L of n plus 1.
So, adaptation will stop when this update term is rounded to 0.
If its value is smaller than the LSB of the hardware what we consider this phenomenon is known as stalling or lock up.
So, this problem may be solved by using more bits.
And, are using larger step size mu to guarantee that convergence of the algorithm ok.
However, we know that using a larger step size will increase our X's mean square error.
So, the other variant of our LMS algorithm is the leaky LMS algorithm.
So, this is defined that is to reduce numerical errors accumulated in the filter coefficients.
So, this algorithm prevents.
coefficient update overflow from the finite precision implementation by providing a compromise between minimizing the mean square error and constraining the energy of the adaptive filter.
So, which is given by expression is given as V times W of n plus mu into X of n into E of n. So, where V is leakage factor one is going to consider it is going to be between 0 and 1.
So, if it is one we know that it is going to be LMS algorithm.
So, the Leakey LMS algorithm not only prevents unconstrained weight overflow, but also limits the power of output signal y of n in order to avoid non-linear distortion of the transducers basically such as loudspeakers driven by the filter output.
So, we know that when we are having a speech or audio work thing the output is going to loudspeakers.
So, this distortion is going to be reduced by using our Leakey LMS algorithm.
The excess power of errors caused by the leakage is proportional to what we call it as 1 minus v whole divided by mu into the power square.
So, 1 minus v should be kept smaller than mu in order to maintain an acceptable level of performance.
This is adaptive.
FIF filter objects.
If you refer to the book here the book is cove with the reference is going to be given.
So, you will be seeing that adaptive field dot LMS, these are the functions one can use for adaptive filter that is direct form leak LMS algorithm.
So, different methods have been given.
One has to keep it in mind that this adaptive field dot LMS has been removed in the latest version of.
MATLAB that is 2020 B.
So, you have to use it as DSP dot LMS filter.
So, and then properly modify the codes and then you have to use it in your assignments or your work when you want to implement these filters.
So, the code what it is given that is you will be having the random seed what it is generated and then you have been given the coefficients of.
So, you will be filtering the signal and then you are assigning your mu value as 0.05 and then call this function which has to be modified.
So, we will see how we are going to modify these to the 2020 B MATLAB and then use this filter to filter the things.
So, these are the steps.
So, when you observe that this is the desired signal D of n what it is plotted.
And, then you will be seeing that error signal which was very high which is shown in red which is going to slow down and then you will be what is it almost minimized here.
So, this is what your output signal y of n is going to look like and error signal.
So, initially you will be seeing that our output signal has little bit of noise and other things.
So, when error is minimized so, it will be following the.
or input signal.
So, in the next class we will be seeing our adaptive filter applications.
So, thank you for listening to this lecture.
Welcome back to real time digital signal processing lab.
So, today we will see that how we are going to find the contour basically.
error surface and error contours and then see that how adaptive filter is going to work.
The examples what we have taken is from the book as you will be seeing that it is from real time digital signal processing fundamentals implementation and application.
This is the third edition book that is from Saint-Cobb-Bowbley and then this thing publisher is John Willey and Sons.
So, here you will be seeing that compute and plot the.
3 dimensional error surface for L is equal to 2.
So, how it is going to do the thing?
You will be seeing that w 0 and w 1 L is equal to 2 coefficients what it is being chosen and then you will be considering the mesh grid given by this define w 0 and w 1 arrays or 3D plots what you are giving it and error is given with the equation 0.34 minus.
0.6 into w 0 minus w 1 plus w 0 into this thing w 0 plus w 1 into w 1.
So, we know that this is the error signal what we wanted to plot what we have considered in the class also.
So, you will be doing that mesh w 0 and w 1 with error that is what it says plot the mesh using where color is proportional to mesh height add major grid.
lines what it says.
So, you will be adding on the grid and title is error surface what he has given and then label x label x axis is represented with w 0 and y label is w 1 and then the z label we have is MSE that is mean square error what it is going to put.
So, we will run this code and then see that how it is going to look like.
So, So, you can see that this is x axis is w 0, y axis is w 1 and then mean square error what you have given it on the z axis.
So, you will be seeing that whatever we saw in the theory, so you will be seeing the x points y and then z.
So, this is the mesh on the grid what you have plotted.
So, as we have increased the resolution.
So, we have to delete from here.
Next one is how the contours looks like.
Error contours of mean square error whatever given in the example we have taken the same example same from the same book.
So, you will be seeing that it is instead of as you have seen the thing here it is mesh grid with this and then this you will be finding out the contour of this error that is weights basically w0 and w1 with error and then we said for the 15 is the iteration what we will be fixing it.
So, this also we will run it and then see.
So, you will be seeing the you will be seeing 15.
what is it concentric circle.
This is how you will be implementing to see that your weight vectors what it is given if it is more then you can get your contour and then surface basically using this function.
So, now the book we have seen in the last lab that is students how they write their codes and other things.
So, we will see that how the book is going to give adaptive filter.
Because, I have this is from the Welch book what I have taken the thing.
So, you will be seeing that different books have been referred for different applications or for any of the solutions you can refer to different books and then you can get the code and then, but you have to understand how they have been implemented and what is the thing happening.
So, here you will be seeing that.
you are taking the order of the filter is 20 that is number of adaptive filter coefficients what you are assuming it and mu step size is selected as 0.01 that is the convergence of factor.
So, and then f naught is 1000 here it is going to generate a chirp start frequency and f 1 is 5000 chirp stop frequency.
So, chirp is basically like you can birds chirp what we call it.
So, they will be having different tones what they will be creating it same way between 1000 and 5000 hertz you can create in steps of it using this function.
And then our step whatever stop is 20 that is time for the chirp to be at f1 what it says.
So, that is you will be having steps of 20 with varying thing from 1000 to 5000.
So, what you are going to give is your voice with the sampling frequency what you will be taking it from this voice recording dot wave.
So, you can record your own voice and then store it as a dot wave and then you can use it.
Then we will be using the audio read function in the latest MATLAB.
versions and then you will be convert the column to a row vector in this case.
The output is going to be in column format.
So, you are doing the transpose.
So, you will be getting it as in the row format.
Then what happens?
M is the length of the voice what you are taking it.
So, how what was the duration of voice you will take that length that is number of samples to be simulated and t is the time which is going to go that is create a time vector for the chirp command.
So, you will be creating 1 to m divided by f s. So, noise is what you are going to have it as a chirp which is t f naught t stop comma f 1.
So, you will have 20 points that is creating a chirp signal here.
The function in MATLAB what it is called ok in as chirp.
And then what you will be doing you are create the noise storage array.
x is going from 2 to n, noise of whatever n minus 1, previous 1 minus 1 you will be down sampling and then 1 this is the step size what you will be taking it.
Then initially your weight vector is going to be 0s, 1 to n the length of the filter that is what it says initialize the adaptive filter coefficients.
Then you will be doing the storage of your voice plus noise, create the signal.
plus noise in this case and then you will be what is it you are going to normalize the storage how we are going to do it that is divided by maximum of absolute of D storage what you are taking it.
So, that is the positive highest value dividing by that what you are going to do it then your Y storage will have 1 to M 0s.
that is storage array for filtered noise and e storage is going to be your errors you can make I think you would have got the hint of it.
So, which are going to be 0s 1 to m that is storage array for the cleaned up signal what you are going to have it.
So, what is the algorithm for filtering?
So, you will be doing J is defined n to m what you are going to do in this case that is interrupt service routine simulation starts here.
input the 2 channels of data that is x of l noise j what you are going to have it, interference of noise signal and d will be the desired signal from d storage of j that is voice signal plus interference what you will be taking it as the desired signal.
Now, you are going to have adaptively filter the interference signal.
So, you will be making it y is equal to 0, the length of the filter what you will go n minus 1.
y will be y plus you can see the weight i plus 1 what will be considering it multiplied by x of n minus i.
So, then end the thing and your error function is e is given by d minus y.
So, then update the filter coefficients.
So, you will be seeing that w of i is updated as w of i instead of calling.
So, we can update in the present state itself.
So, that our storage is going to be reduced W of i star 2 into mu star are error x of n minus i plus 1 what will be taking it.
So, this is the loop it will go and next is prepare the x array for the next input sample.
So, we will be taking the next sample from this and then we will be working on it.
And, then the interrupt service rotation simulation is going to end here and you will be doing a storage after the post simulation.
So, you will be putting y storage of j will be y whatever the output after finishing your up to filter length and e storage of j is going to give you error e. Then you will be listening to the results basically.
So, with the original voice what you will see it voice comma fs.
signal with interference you will be pausing for 24 seconds and then a de-storage which is added with noise you will be seeing with the same sampling frequency.
Then you will be hearing the adaptive filters output that is where it has stored e-storage will give you the filtered adaptive filter output there.
So, these are the plots what you will be seeing it normalized one.
how the original voice and then the record by signal they are overlapped and then you will be seeing the output.
So, we will run the code because we have understood how it is adaptive filter is going to work.
So, we will run it.
Testing 1, 2, 3, 4, 5.
Why do you need this book?
If you want to learn about real time digital signal processing, DSP, this book can save you many hours of frustration and help you avoid countless dead ends.
Why do you need this book?
If you want to learn about real time digital signal processing DSP, this book can save you many hours of frustration and help you avoid countless dead ends 1, 2, 3, 4, 5 and stop.
So, you have word first was the original voice, second one was with the added chirp signal.
So, you saw that how the chirp signal is generated.
it had a varying frequencies and then later on after adaptive filter you have seen that how the noise is eliminated almost what you can put it because we would not be able to go up to 0 what we said the error cannot be completely 0.
So, you are seeing this is the audio signal overlapped with chirp signal what you are seeing it.
So, if you want to see.
portion of it.
So, I can increase I think I may have to go back to original resolution because we try to increase so that we you can see the thing.
So, the filter thing is plot is going little up.
in any case you can see yourself by that is expanding the thing how the chirp signal is going to look like.
So, now, we will see the input and output.
So, you will be seeing blue is the input signal and then red is going to be the recovered signal.
So, some places you will be seeing that red is little normalized both of them.
So, you will be seeing that it is little low.
So, can you guess what will be delay of our output in this case?
The order of the filter is 20 ok.
So, there will be 20 samples delay in the case of adaptive filter to start our output.
So, you can see initial stages what delay we are going to get it.
So, this as you can see it is marked recovered voice signal.
from the thing.
So, you will be seeing that some of it is whatever you will see the thing the magnitude is lessened in some places.
So, this is the output what you will get it and then, but most of the cases we were able to recover from the noise signal or output.
So, in the next class we will be seeing how to implement the same thing in code composer studio.
And, few more applications what we will be taking up using adaptive filter both in MATLAB and then code composer studio.
Thank you.
Namaskara, welcome back to real time digital signal processing lab course basically.
So last class we had seen some of the.
FFT, how it is going to run in MATLAB.
So, today we will see how we can implement the same thing in our code composer studio that is on the hardware DSP processor.
So, the first thing what we have here is a C code what it is written for FFT.
So, you will be seeing that we will maximize this so that.
You can see the thing the code.
So, what is it?
So, we define the math function because extensively we will be using the sign and then cos functions in this case.
Otherwise, we have to derive it in hardware using series expansion.
So, here number of points DFT points what it is defined is 64.
We call it as FFT or DFT interchangeably.
So, you have to know about that and then in this case I said in matlab we had defined pi as it is, but here we have to specify the value of it.
So, it depends on what is the length you want to define it either 3.1415 usually we stop it and then if you want more accurate value you can take it up to this.
And then the structure what defined is float real and imaginary is defined which is a complex variable.
And, then it is going to call FFT function in this case.
So, the prototype whatever return basically and then I O buffer is going to take the input and then both output buffer.
So, it takes the input values and then output is also going to the buffer that is the reason why it is called I O buffer.
And then your intermediate buffer is also float.
We are seeing that some of them are defined as float, some of them are short values.
So, the index variable i is defined as short and then buffer count is also initially it is made 0 the samples in the I-O buffer.
And then the flag what you are going to set 1 by interrupt service routine when I-O buffer is going to be full.
So, then you have to use the complex that is w points basically you have defined points 64 in this case we have it twiddle constant stored in w.
The next one is samples that is primary working buffer in this case that is also of length this.
And the frequency what will be generating is 10 hertz in this case.
So, we will be computing twiddle factors using cos and then sine function that is what one is the real part of it what we have twiddle constants and imaginary this thing twiddle constants are computed with this.
Now using this.
You will be what is it generating the I-O buffer of I with sine function with 10 hertz.
So, that is frequency what it is given and then 64 is the sampling frequency what you have chosen in this case.
So, you will be initializing the samples initially to 0.
Then you will be calling the buffers basically to swap them.
with new data and that and then later data.
So, you will be going up to 64 that is 0 to 64 you will be computing your FFT.
So, first is imaginary component you are making it 0 and then you are calling the FFT function by sending samples, points in this case it is 64.
So, samples are also going to be 64 in this case.
call function fft.c in this case.
And then once you have called the thing, so you will be getting both real and imaginary values as written.
So, you will be doing i is equal to 0 to i less than points compute the magnitude of it.
So, how you are going to calculate the magnitude?
So, x1 of i is nothing but square root of samples i dot real with real squared basically.
plus samples of imaginary dot imaginary.
So, both the squared under square root what you will be calculating.
And then you will be incrementing your p with p plus 1 and then this will be ending our main function.
So, we will go to this thing.
So, it will be in line with it.
So, we as usual we will be calling the project.
as I said one of the student who has done the thing.
So, we will do the first compilation.
So, you will be seeing that it is intact here it is using the inbuilt FFT function which is being called with whatever samples you have it.
So, you have the sorry FFT function we did not see the thing.
So, we will see it with the thing.
Here also it is points is 64 and structure is your float and then complex basically and then you will be defining this complex you are calling it as extern because you will be passing from between function and then your main function and then FFT function.
So, you are calling this as a FFT function which is complex y is the output and int is our length of.
are FFT.
So, input sample array and number of points as you are seeing it.
So, these are the temporary storage variables and these are the loop counters and then we have to calculate upper leg and then lower leg are calculated separately that is even and then odd part of it are computed of the butterfly separately.
So, then difference between the upper and lower leg what you will be calculating and you will be defining number of stages.
So, that is to have the interaction and then you will be defining some of the step through twiddle constant and then i is equal to log base 2 of n points that is number of stages what you will be doing it.
So, you will be doing up to number of stages plus equal to 1.
So, i will be i to the power of i is 2 times i what you will be doing it and defining your while function this way.
So, you will be calculating the leg difference that is difference between upper and lower legs step between values in twiddle dot hedge what you will be doing it and then for n point A 50.
So, this is the end point.
You are calculating i is equal to 0 to number of stages what you have it and then initially index will be 0 and then the other loop is going to be j is equal to 0 to less than leg difference.
So, you will be computing it and then here it is the upper leg what you will be calculating it some of the temporary variables you will be seeing it and then y is calculated in this fashion.
And you will be indexing is going to be incremented depending on the step size.
And, then the leg difference is going to be leg difference by 2 and then step is going to be multiplied with 2.
So, again j is equal to 0 you will be doing the as we know that bit reversal has to be done for our c calculation which is done using this computation.
So, you will be seeing that hardware is not being used.
So, if you are writing in assembly as I have been telling in the thing you can use the hardware to do the bit reversal.
Here it has to be done.
manually as you can see the thing using the code.
So, this is how you will be calculating your this thing imaginary and real part are arranged for your FFT and then you will be coming back from this FFT function fine.
So, we will run this and then see what is the magnitude squared function what we have got it.
So, this is we are debugging our DFT.
So, we are seeing that build has finished, you are seeing that it is connecting it to the board basically.
So, you will be seeing that where the target has been connected and memory map whatever there is going to be cleared and it will be set up for this function and it will be.
calling the memory is DDR2 in it at 150 megahertz is going to be done.
So, this processor is running at 150 megahertz at present.
So, it goes and loads the code basically.
So, we have to see the debug.
So, you can see that the debug window has got opened.
So, it has gone and loaded in the this is the entry point basically main function where it starts the thing.
This is the entry point of the code in our board.
And then you will be seeing that here the pointer is pointing to the main basically.
So, it is ready to execute.
So, as we have seen in the last class when I took up the demo of the code composer studio either you can continuously run put a breakpoint and run.
So, here there is a breakpoint as you can see which is been set.
So, we will run the code continuously.
If you want to do this there is any error if you find then you can go with.
So, we will run the code.
So, as you have there was a little this thing memory map issue with the thing.
So, we will set the debugger again and then I can either do a debugging or I can because it is already debug has been done we can go and then.
From the run command, so here I can you will be seeing a lot of variations will be available.
So, you can go and load your program.
So, if it is already finished the debug and you have not modified anything and then if you want to run a resume from the run stage you can do that or if you want to terminate or if you want to go to main or if you want to reset the processor, whether you want to do the CPU reset or system reset.
reset the emulator basically whatever is running on the thing you can do it.
And then if you want you can restart or you can step into or step over that function if it is loop then I do not want to see every step of it I can do the step over in that.
And then if I want to do assembly step into I can do the thing.
So, these are the functions what you have it.
Now what we will do is we will have a run here either from here or here I can give the I will give the run from here ok.
So, because this is not finding the exit dot c that is why what it is little bit cribbing on the thing.
So, we will see that what is our this thing output basically.
So, what I have to see is my magnitude square function.
So, we will we can go to tools, we will go to graph, we will find it a single time and then we have said that it is 64 point FFT what we have run.
So, input data will be 64 and then this is a floating point what we are running the thing.
So, I can define it as 32 bit floating point number and then the start address in this case is x 1 is our output where we are calculating our magnitude and even the display data size I will change it to 64 and then we will say ok.
So, you will be seeing that what was our input frequency it was 10 hertz ok.
So, you will be seeing.
computing FFT from your thing which approximately gives you peak exactly if you want to look at the thing it is somewhere around 10 ok.
So, you can see that your code is running fine.
So, how to check this whether you have got your frequency correctly or not, what we can do is our samples what we have generated here.
We will be seeing that.
I O buffer is going to give a sine function.
So, we will see that whether that also has 10 hertz as a sampling frequency.
So, we will go to graph again.
So, sorry I will cancel it because single time for we will see single time and then come back.
So, I can give 64 and then this is again a floating point number 32 bit floating point number and then the start address in this is going to be R.
I O buffer ok.
So, I O buffer what I can give the thing and then even display points will be 64 because we have not gone beyond it.
So, we can give the thing.
So, you can see the sine function how it has with 64 point it is not a.
complete pure sine wave you will be seeing some of the points here has a problem, but it is approximately going with the thing.
So, now, what we will do is we will see FFT of this.
So, again I will go to tools and then I will go to my graph in this we will calculate FFT magnitude.
So, this is 64 points what I have it 64.
64 which is going to give you 60 hertz.
So, if you are unable to see this what we will do is we will again do go to tools and then graph we will do FFT magnitude and then this is 64 and then this is my this thing 32 bit floating point and here sampling frequency what I have to give is 64 and then start address is Ivo buffer.
And, then this is our thing is 64 what we wanted.
So, we will give this and we will plot.
So, you will be seeing that it is showing 10 hertz is the input frequency computed from the built in function.
So, what calculated you will be seeing that in the single time.
So, you will be seeing that by writing your own FFT code so, you are generating the.
10 hertz signal what you have computed without knowing what is the frequency component of the input signal.
Here we know the thing in normal cases we may not know what kind of signal we are going to get it.
So, once I find the frequency spectrum, so what are the frequencies present, but I should know how many what is the sampling frequency at least used most of the cases as I have mentioned in my theory class that speech if it is a narrowband speech we use 8 kilohertz as the sampling frequency.
And if it is a wideband speech it is going to be 16 kilohertz and then we know the rest of the thing audio and then video thing.
So, those are the sampling frequencies.
So, from that what you should be able to find out that whether what signal you want to keep it and then eliminate by doing filtering one of the application using from the frequency domain you will know what are the frequencies present which you want to keep it and which you want to eliminate also you can see.
Most of the ECG signals as you will be knowing that line frequency in India is 50 hertz whereas in US it is 60 hertz that will be present in the ECG signal.
So, first thing what you will be doing is.
eliminate that frequency using filters.
So, this is one of the example of FFT in using our board basically.
So, now, we will see we have seen the overlap add and save method using what I will call it as MATLAB we had seen in the last class.
So, we will see how we are going to do.
using our C code in hardware.
So, here we will be defining number of points there it was 64 points we had defined here it is 512 points and the length of it is 512 and you will be seeing that our filter length is gone to 351 and then input signal length is 3000 length and then our signal block length is 162.
So, this is again pi is defined and then you will be defining variables just like the previous FFT case and then what you will be having is you are going to contain the filter coefficients in column dot dat.
So, there you are generating your filter coefficient.
So, here you can compute and keep it in your data as the file.
So, you will be seeing that filter coefficient is called this is the 351 using MATLAB what it has been taken and then put it in.
file as that file.
So, the other one is you will be calling fft.c function here this thing it is a 512 points.
So, we have seen this fft with what is the thing bit reversal also which contains the thing there it was 64 bit here it is going to be 512 bits what we will be doing it.
So, coming to the main.c what is it?
So, we have to compute our this thing.
Input signal, what are the frequencies that are generated here?
It is 200 hertz just like in MATLAB what we seen the example for these frequencies.
Same thing what will be implemented in C code also on the board.
So, 200 hertz, 267 and then 400 hertz has been generated using sine function in this case.
So, you must be thinking why sine is used.
So, it will take time either you can use the IR filter in oscillatory mode to generate our sine wave or we can use this.
So, taking the FFT of this one and then saving it.
So, we can compute our this thing you will be seeing that it is using the convolution using a overlap save method fine.
So, that is how you will be calculating your.
So, you will be calling the FFT and then you will be taking your this thing you will be computing IA50 using the new twiddle factor array.
So, and then IA50 is just do FFT in this case by providing your twiddle factors with the complex conjugate.
And then you will be doing a stage Y in this case.
for k is equal to 2 and then you are doing all this computation and then later on k is equal to 3 and then k is equal to 4 to that is floor of length s divided by s length that is in this case what it is taken as 64 because you have done already 3 of them.
So, 64 is the length of your FFT what you are do using it in overlap save mode.
for computing the length of your data.
So, you will be doing it and the last one the 62nd one you will be repeating it by providing what is the k value of it.
So, you can see the length of the code what it is running here.
So, again we will put a break point and then see whether there is any error in the thing.
So, it says it is up to date because we have checked it earlier and then brought it.
And then so, we will be doing the debugging as usual.
So, one of the thing one has to remember is what we have to look for here in this case.
So, what is it?
Here it is out s what we are going to look at it.
So, it has gone and then loaded onto the board and then it is pointing at the main.
So, the breakpoint what we have provided is here.
So, this is out s is what we have to look at it I do not think there is a calculation for our magnitude squared.
So, one has to remember or to see that which one I want to monitor ok.
So here what is my input output if I know the thing then I will be able to see that what is my output.
So here what has been declared is product of FFTs and IFFT in the out temp that is what I have to look at the thing.
So anyway we will run the code if there is any difference.
So, we will find out with the thing.
So, now, again as I said because it is unable to see exit dot c sometimes in c function.
So, that is why the code has gone beyond and then it is looking for the thing.
So, anyway we will look at what is our single time graph.
So, we said that it is o temp is our thing.
So, we can give it as our acquisition buffer of 3000 what we have it.
And, then it is a floating point.
So, I can give it as 32 bit floating point and then the sampling rate I will not mention, start address what I will mention it as out s ok, we will try to map the thing.
So, you will be seeing that ok, so something I made a mistake.
Here anybody can look at it what I made the mistake was only 200 samples are getting mapped.
So, but my length is 3000 what I have given the thing this is the sine wave because you have done the IA50 also in this case.
So, we can see what is the frequency we have it 32 bit floating point and then start address is out as sorry vote.
temp where my output are there and then here acquisition also I have to make it that is display data size for 3000.
Now something you will notice I want you to look at the thing.
So for 3000 samples what we have done the thing so what I will do is I will we will make it.
full scale.
So, you are seeing you are this thing what is the frequency here somewhere around 260 hertz what you are retaining it.
filtering out the other two frequencies.
So, there were three frequencies what were present others have been eliminated.
So, one of the thing what we can do is we can see in the other points basically.
So, I can see samples ok.
So, what it is going to give you?
It should give me my inputs.
So you can see my .
some of the samples what it looks like this ok.
This is not the complete sine wave.
So, this is not the input, my input is going to be somewhere generating it as SI only the problem is here I would not be able to see this SI, why is it going to strike something to you because this is SI is a local variable.
So, for me to plot it I had to declare it as a global variable and then I can do the plotting.
So, this exercise you can take it up and then look at it.
So, like this you can go and then run your codes and then see whether your FFT code is working.
One more is DFT code what it has is this is from the book.
So, if you are able to download the code book and then run your code.
So, you will be seeing that it is from the real time digital signal processing fundamentals implementation and application.
This is the third edition most of the time I will be using it also which has the C code to complete compute your float FFT test dot C. So, even MATLAB codes are there.
So, you people can use the thing and then some of the functions that is floating point complex header files is created.
And, then fft dot h and then data file input also is going to be you can declare and then you will be using it.
So, if you say that your input f dot data you will be seeing it as.
So, this is your input data what you have it input 7 f floating point data for experiments ok.
So, you can look at running these book codes.
So, just we will run the thing.
So, we will see that how it is going to run in our board.
One has to keep it in mind that it because I have already checked the things there are no errors.
So, that it can go and then load on to our this thing board and then it is going to run.
As you can see the thing it is pointing here.
So, I can put a breakpoint here in the printf statement.
So, and then I can run the code.
So, he will be running FFT frames basically, there are 13 frames run in this case and which are the ones running and what will be the value of it you will be seeing it.
So, it will take a little time and then you can observe it.
So, you can see that.
experiment is completed at the 13 frames basically.
Frame wise computation what it is happening.
So, that means, to say that either you can sample wise what you can do it or the complete frame you can run and then have a look at it.
So, here output is going to be present in the spectrum of i.
So, we will display that basically.
So, tools go to your graph single time.
So, this has a 64 sample thing and we will call this as 32 bit floating point and start address is spectrum and even the display we have to have it as 64 because that is what what we will be getting it.
So, you will be seeing that I will magnify the thing.
So, you will be seeing that this is what somewhere around 12, 7 hertz or whatever 6 or 6.9 to 7 hertz is the frequency what it is getting generated.
through this ok. With that we will close the FFT computation on the DSP processor board and then we will look at the other applications in the next lab session.
Thank you.
Namaste, welcome back to real time digital signal processing lab this time.
So, we will see that.
how we will be implementing least mean square algorithm that is LMS algorithm in MATLAB today we will look at it.
So, this is the as I will be mentioning usually we will be taking asking the students to implement it.
So, this is one of the student who has implemented.
So, which I am taking it for your presentation.
So, here this is going to call a GUI function basically.
as it is easier to run with different input signals.
So, we will see how our LMS algorithm is going to work.
So, we are going to some of the name and structure you will be seeing it GUI definition.
So, those who are interested in writing their own GUI you can refer to this example.
So, we are interested in seeing that how our LMS algorithm is going to work.
So, we are going to call the variables here as you can see we have the declaration because for parameters changing they have to be declared global here also x y and then y out have been declared as global and the order of the filter is 20 in this case.
So, you can vary this order and then see how your LMS algorithm is going to.
So, now, what you have to do it.
So, you are going to weight function w initially you are making them 0s.
And then in this case mu is selected as that is time step is selected as 0.006.
So, we will see first we will see what happens with the 0.006 and then later on we can see by modifying it step size varying it if you have not calculated it properly.
what is the thing is going to happen.
And then for the length of this thing filter minus the order what will be taking it that is n plus l minus 1 what we have it.
So, buffer is going to be configured.
So, this is going to be order i plus order minus 1 because you are starting from 1 and then you will be taking the transpose basically and then y out of I is nothing, but so, you have buffer star w star 2 what you will be calling it.
Then error I is going to be y I minus buffer of w whatever value is the thing.
So, this is the updated what we are going to have it as error and then our weight function w here it is not represented as n plus 1 w is equal to the current value of w plus.
You will be calculating, you will be seeing that whatever the value here into mu into error of i which you will be taking it as transpose that is update the weights basically and then you will be ending the code.
So, then you will be plotting it.
So, we will run it has all the 3 algorithms that is NLMS that is normalized least mean square algorithm and RLS algorithm is also there.
So, I have considered here only LMS.
for this class.
So, we will see NLMS and then RLS how the function is going to be used and we will as I mentioned in the class we will not be deriving the equations for it those who are interested can run the code and then check it ok.
So, we will run this code you will be seeing that LMS algorithm is going to come up as I.
So, some of the laptops will have resolution problem.
So, we will see that we will be running this code as LMS algorithm first and then we will see the thing.
So, we will run the code this is going to give us as you are seeing it adaptive filters both LMS and LMS and as well as RLS has been.
integrated in this and in the next class we will see separately how we are going to design the thing.
First is I will be loading my noisy signal.
So, this is my noisy signal what I will be loading on to the system and then what desired signal I want to in this case I know both of them.
So, I will be loading it.
So, open it and then we can run our LMS algorithm.
So, both I have loaded.
So, this is the original signal and this is the noisy signal what you are seeing it and using the least mean square algorithm with mu set to 0.006 that is the optimum what usually found out by trial and error you can do it or you can exactly calculate.
So, we will see in the class how we are going to calculate that.
So, we will be getting back approximately our original signal as you can see although amplitude has got a little bit modified compared to the original one.
So, this is what we have taken is input is the signal.
Remember the force will be with you always.
Something must be striking in your mind we use the same input for our FIR and IR filter.
So, same thing we are using for our LMS algorithm also.
So, we will see the noise here whatever noise was added in using the MATLAB which was stored as the noisy signal in this case.
As you can see single frequency tone was added.
So, if you want you can add any noise and then if you have your desired signal you can this is after running our LMS algorithm that is filter output.
So, we can play.
Remember the force will be with you always.
So, you can see that your noise got eliminated.
So, this is how one can run the thing with whatever mu selection what we have done.
So, we will see that if mu is equal to 1 what is the thing is going to happen.
So, we will run this case and we will see whether we are going to get back the signal or it is going to have some noisy signal present in the thing.
This is the desired signal what I have to load it and then run the LMS algorithm.
You can see that my input step size is 1.
So, you are seeing that if you play the thing nothing what you are going to get it.
So, you will be seeing how the steepest algorithm is going to work.
Now we will go back and then change our thing and then re-run.
So, this was the maximum one I have taken the thing.
So, we will start from point 1 and what is the minimum what we are going to get we will see.
So, if it is going to work for 0.1 this is the trial and error method what I am using it, but how we are going to calculate as we have mentioned that the calculation of mu has to be using the if you are calculating on the go then we have to do the inverse of the matrix or I can calculate using the are coefficients basically you have to do matrix inversion.
This is a noisy signal.
So, we will be loading the desired signal again and then I can run the LMS algorithm.
So, you will be seeing that most of the thing you have got back with point.
Remember the force will be with you always.
How your steps size has to be one has to calculate.
So, it depends on how much iterative algorithm you are going to run.
And, then we will run our LMS algorithm.
So, you will be seeing that my step size is too low in this case.
So, this is what the your plot gives you and then if I play what you will hear you can you guess it?
So, your what is it audio is completely reduced or the speech has got very I do not know whether you heard it or not here we can hear it very minute value under that amplitude what we are hearing.
So, there is a single tone sine wave also which is going.
So, you have to compute your mu what should what is going to give you.
your minimum value.
So, if you want to plot your weight function, so you can plot them also.
So, we will see by, we will see plot w because I am in this thing what is it GUI I may get error.
So, we will load it again.
I think.
So, my plot is outside.
So, that is why it is not shown with the thing.
Let me see by taking it inside whether it will be giving me the thing.
Otherwise just without GUI we will run in the next class our LMS algorithm ok.
So, there will be error in the thing because if I come out of it, it is going to it is not plotting basically and if I am inside you can see that it is going for the plot and then it is not coming out of the handle.
So, we can reduce to 0.001 and then look at it how this is going to have the impact on our output.
There was error in opening the GUI.
It took long time to open it.
So, we will clear all and we will open the function again.
We will run the thing.
So, our load noise is signal and then we load the desired signal and then we will run our LMS algorithm.
So, you will be seeing that.
compared to the original with 0.001.
So, you will be seeing that there are attenuation happening with the thing.
So, when you play the sound.
Then the force will be with you always.
Then the force will be with you always.
So, it is a little bit working on the thing.
So, what usually you have to find out what is optimum you what you can run with the thing.
So, thank you.
We will see separately running and then how the weight function is going to adapt itself in the.
next class.
Thank you.
Welcome back to real time digital signal processing lab.
So here in the previous class we saw how the MATLAB is going to run our filters.
Today now we will see that how our board is going to respond to whatever the same corruptive voice what it is going to be given to our board also and we will be designing the filter and we will see that what will be the response ok.
So, as we have been telling that it is the C code what we will be writing.
So, which is going to be ANSI C and you will be using the.
AEC 3106 is the codec chip on the L138 board here we are using C6748 board.
So, which uses this and then we are including the cof file here I have given it as 200 order.
So, you will be seeing that this is the what I will call it as I have given number of coefficients basically although.
It is the same frequency whatever component what it has been taken in FIR filter in the MATLAB same components what you will be seeing it.
So, you are seeing that H of n this is defined continuously.
So, if you want to put it in this format.
So, you can refer to any of the real time signal processing book.
So, they will be giving how to convert from single line to this.
Otherwise, it will be if you have given a return it will take it as a next line.
So, we want to arrange it in this way.
So, that we are not going to lose the thing.
So, either I can we can have the here it is 55th order.
how it can be represented the coefficients what it is the shown.
So, one way of doing it either we can create a dot h file and then put all the filter coefficients here and then or we can provide in our main dot c itself the value of it.
So, you will be seeing both the ways being used.
Now what we will be telling is the initialization of it that is codec has to be initialized so, here we are using the polling technique.
There are 2 ways actually 3 ways of it today we will see 2 ways of doing the same thing.
One is using the polling technique as I have mentioned in my theory class in the architecture.
The polling method CPU will be going and then checking whether there is a new data which is present that is how it will be working on it.
So, it will go and then check if there is any data in our LCDK line input that is codec input.
will be using that and we can specify the sampling frequency what I am going to use it.
In this case we have designed all our thing is in 8000, 8 kilohertz.
So, we will be using FS8000 and we will be looping continuously here because I will be getting the data and then I will be working on my filter and I will be sending the out on to the codec chip.
So, you have to initialize y of n is my output which is going to be initially 0.
So, you will be getting the first sample x of 0 is always I will be taking the first sample from my input data that is whatever is connected.
So, this is input sample that is from ADC what I am going to take it and then I will be looping it you will be computing filter output basically and this is delaying our data in circular manner.
So, for i is equal to 0 i less than.
you are n actually will be doing i plus plus and then you will be computing h of i is the coefficient into x of i whatever data is coming in.
And then you will be shifting i is equal to n minus 1, i greater than 0, i minus minus your x of i will get x of i minus 1 and then the output y n will be whatever you have stored in x of 0 what you have computed.
So, that is how we will be computing for every sample until the order of the filter.
So, then what we are going to do is we will be we can directly output left sample because we have taken in from the left sample audio in has both left sample and then right sample.
Here we have taken only one input sample data from left channel and then we are processing and then putting out on the left channel itself.
So, I can call it as this thing uninitialized interrupt 16 basically y of n what I will be going to output DAC.
Since the volume is going to be little feeble so, what we have done is we have shifted it by 4 basically to increase the output.
amplitude of the signal.
So, we will be putting it to output DAC this value ok.
So, this is how we will run our FIR filter.
So, we will as we know first I can do build debug for project this is going to take surrogam APA itself as input like MATLAB and then you are seeing that it is up to date because I have already run it if there are any errors.
So, you have to take care of them.
So, now I can go and then build this project.
So, we have created the project and we need the codec initialization and then it is H file also and then linkerdsp.cmd will be specifying what how the memory mapping is going to happen just to give a flavor of it.
So, you will be seeing linkerdsp.cmd.
So, you are specifying stack.
heap and then memory.
So, I have a RAM and then there is some shared RAM and then some external RAM also the their length and their origin is given in hex basically in this case.
And what are the sections I will be using is some of it is dot text wherever it appears you have described your comment and other things text has to lie and constant if you have declared that define it will be lying here and this is the BSS section basically where the.
entry point and other things is going to have.
And dot for will be some memory which is away from the thing which is going to be stored in this DSP 12 RAM.
And then you will be seeing even the stack and then switching and even dot data it is getting stored here ok. And initialization part of it we call it as where the entry point to our program is going to be that we call it as initial unit thing which is here.
So, if there are system memory is also in this.
And then you will be having I O whatever also the location is in that and then vectors also whether it is polling or interim driven.
So, the vectors have to be specified where it is going to lie this is the memory and then you will be calling that external RAM as your external RAM.
So, this is how your memory storage is going to be in your DSP processor.
So, we will see that how the thing is going to run in our.
So, you will be seeing that it is doing the debug.
So, you are seeing that it is going and then loading on to the board.
So, it has finished and you will be seeing that this is ready to run.
Either I can do single stepping or I can run continuously.
Since if it is not codec based, you can do single stepping and then see each step what is the value which is getting computed.
So, here you have seen that it has come down to entry point here, int main is our entry point and you will be seeing h and x values where they have been defined and our h value is already it is a float which has been taken in this case.
If you are taking it as quantized one you can go and then take them.
So, these are the values of our coefficients basically and these are the input initially what.
So, what we will do is here it is a sarigama with noise what I will be putting it.
So, we can run this from here which is the input that is through the output of laptop jack you can connect it to the input of the board and then the output we are connecting it to the speaker for you to hear the thing.
So, this is running continuously.
Now we will see what is the thing is going to happen when I run my board ok.
So, what it says is if you are not going to hear anything you have to go back and then reset the board and then you have to restart it.
So, you are unable to hear any of it.
So, we will see again do the debug whether we can hear something we will see.
You will be seeing that.
Even after stopping it the board is running because we have given it as it is a while loop 1 ok, until I reset my board the code will be running on the board.
So, you will be seeing the complete FIR filter, you are hearing the noise because even in the passband we have little noise.
So, as I mentioned in while running my MATLAB code.
So, this is how.
there will be little noise also which is going to be amplified in our boards.
So, I have to go for very high order filter here although it shows it is 200 order FAR filter still I may have to increase, but most of the time as when we took up the stability of the filter for FAR although we said it is stable, but at least up to 256 order it may remain same, but beyond that it may become.
So, better to design all your filter orders for FIR in for the board less than or equal to 200 what I say my students not to go beyond that somewhere around 120 to 150 what we do it.
So, that is how what you saw that little noise is left out ok. Now, we will see the same thing whether I can use the interrupt driven.
So, what is the different between polling and then interrupt driven we will see in a while.
It is the same code what I will be having it.
So, you will be seeing that same surrogama F i F i r dot c. So, you are using the I can use the LP 55 coefficient I have not renamed it or I can use this as renaming for both the coefficients are there I can try on both the things.
So, or I will be taking this itself 200 dot coefficient whichever previous one what we have run.
So, you will know that there is no difference between polling and then.
So, here what it says same thing will be initializing the codec, but what is it I have to write the interrupt service routine here.
Because I am going to interrupt the CPU whenever there is a new sample which is coming again then what the CPU is going to do is there is a location where it is specified here it is interrupt 4 is the one being used.
So, you will be seeing that there is a assembly file.
for vectors interrupt dot ASM.
So, you will be seeing that it is calling all vectors I have the entry point is underscores underscore int 00 where your main basically will be entering it here and then there are predefined vectors here 1, 2, 3 which is not accessible to the user and then the interrupt 4 is accessible to the user and rest of it is not accessible to the user.
So, you will be seeing that this is the entry point and where they will be branching you will be seeing that this is the entry point.
then how it is going to branch this is a assembly code sample in TI processor what you will be seeing it.
This is store word basically B0 in B15 this becomes a stack basically and then you will be moving constant here from this B0 lower portion of it and then a higher.
All the registers are 32 bit so we will be loading the address 16 bit lower version and then higher here and then you will be branching wherever this is pointing.
2.
This is the pointer what it is given and then this is our usually we as I said W15 represents our stack pointer where the entry point has been given ok. And then you will be loading back whatever wherever you have stored the where was the entry point that back so that it can return to its safer place ok. And you will be seeing that there will be some knobs to account for the delay.
So, those who are interested in assembly programming So, if type permits I will show one of it how I can exactly count how much clock cycle it is going to take.
So, this is how your entry points are going to be where it is it says it is reset as you can see that entry vector, vector 1 is non-maskable interrupt I think there should be some trigger in your background what is happening and then these two are reserved and this is a interrupt service routine what we have it.
So, the others are kept it as dummy ok.
So, this is where our interrupt routine is going to start.
So, the CPU will jump and see whether there is any data and then it will take it and then process it.
So, what we are going to do is we will be writing our FIR filter code in the interrupt service routine.
So, X0 what we will be taking the sample from the this thing codec chip and then we are going to process it just like polling and then we will be doing the delay lines assignment circular buffer what we have to call it.
We are doing that and then we will be outputting the sample same way as the previous one right shifted by 4 bits basically.
And then here also we are using the sampling frequency is 8 kilohertz and these are the ADC and DAC gain basically we keep it as 0 dB and then LCDK line input is the codec input and output and we will be looping forever.
So, we will see that thus how it is going to behave.
So, this is how one is with the polling and with the interrupt what we have run the thing.
So, now, we will move on to our IR filter.
So, here it is a notch filter what it has been designed like the previous one.
So, we will see that how this we call it as a interrupt driven only what it has been taken.
So, if you want to run polling you can very well use this as a sample this thing the first one.
there you can go and then put the code.
So, you will be seeing that this is my this thing LCDK initialization.
Next I am going to define my constant it is here int coefficient what it has been taken.
So, for 900 hertz to remove that these are this coefficients what it has been given ok.
So, you will be seeing that and then for the 2700 hertz what I have to remove it.
These are the coefficients values which have been designed in MATLAB and then we have taken the coefficients.
And then we have to this thing sections what we will be having.
So, x of 1 because it is the sixth order filter.
So, you will be seeing that x 1 2, x 6 what you are calling it as signed integer.
So, you are seeing not a float here it is running in integer format.
So, this is how you will be generating the thing.
So, and then our y1 to y6 also has to be defined for both numerator and then denominator you are initializing them separately.
Now since it is the interrupt driven, so you will be see service routine has to be written.
So, some of the variables what we need it for IR filter what it is shown here.
So, output there are temporary files what it has been created.
So, you will be seeing that for 900 coefficient 900 comma input.
So, and then our input in this case is the sample which is coming from my codec that is ADC basically for sample what I take it in input and I will be passing it.
So, next one we will be passing it as you can see that.
output what we have to pass it to temp 1, you are doing the filter IR you are going to pass it through that, that is the second stage of it.
This is the first section, this is the second section which is running and this is the third section.
So, after that because it is a sixth order filter what you have it as I mentioned earlier.
So, the other for the 2700 hertz what you will be doing you will be taking this from the input of this section you will be feeding into this.
This is in what we call it as series what we have fed in the thing then from this output will be feeding to this one fine.
Output of temp 3 goes to our temp 4 which is eliminating my this thing 2700 hertz sine wave what is we call it as a noise.
So, this is finally the output temp is going to have the last stage output.
Then we will be doing output left sample to that is codec DAC output will get from the temp that is left sample what it is going to be.
So, now, will be after that will return from the service routine this is my main function.
So, which is also running at 8000 and then line in.
Now, we have to see that what is my IR filter is going to do because I have I am calling how many times.
3 plus 3, 6 times I am calling the filter.
I have to pass what are the values and then it has to run the thing.
So, you will be calling with star x star y it is their locations what you are giving and then constant sign int even the star h and then integer x 1 what you will be giving it.
So, now, we are initializing here also this is a local variable as you can see temp is 0.
And, then it will be taking x 1 as the input that is copy input to this memory and x of 0 is going to be you are assigning this value.
And, then temp will be calculated that is h 0 into your x of 0.
So, h 0 is int you are pre defining the thing input and then x of 0 is already int.
So, you are doing the integer multiplication.
And, then you will be what is it adding it to temp.
So, h 1 into x 1.
So, you will be continuing up to h 6 into x of 6.
So, you can see that sequentially what the computation is happening.
This is for the first stage of this thing 0 basically and this is going to happen for your poles that is divide temp by coefficients a 0 what you are going to do that.
So, you will be so, if you want to normalize the thing then you have to divide by that otherwise you are passing it through your y1 to y6 here.
So, then what you are going to do?
You are going to because as we know that multiplication and addition is going to result in 32 bit.
So, we have to.
So, else if temp is less than this thing minus 32767, this is this is overflow what you are avoiding it, here you are avoiding the underflow.
If it is less than this, you will be making it maximum as minus 1.
So, the thing is varying between minus 1 to plus 1 that is what we are restricting and then we are putting as y 0 as temp value.
So, you can shuffle the values for the next stage.
because, it has to take y6 should be taking the value from y5, y of n minus 1.
So, you will be and even x of n should take it from x of n minus 1 do this and then you will be returning the temp value.
So, this is how the code is going to run.
So, we will take a demo of it ok.
So, here my input is going to be correct voice with this is the Surigama what we are running.
So, we will take the corrupt voice what we have run it with the MATLAB.
So, sample files we have it.
So, this will be IR corrupt voice what I will be feeding into my system.
So, this is running let it be running by the time we will run our code on the board we will see the thing.
So, I will be doing the debugging.
First what you have to do is compile it see for any errors since as I have been telling you that.
I will be usually running it first and then because time shortage and other things it will take little more time to figure out the errors and then do the debugging.
Usually everything is corrected and once it is running what I will be putting it for the demo ok.
So, we will run the thing now.
Remember the force will be with you always.
always remember the force will be with you always.
As usual output is still remaining.
So, you have seen that both the whatever frequency that is 900 hertz and then 2700 have been removed and you are hearing the clear voice from it.
So, if you want to hear the corruptive voice what I will do is the connection what we have given it to the pod I will remove it.
So, you will hear that.
2 tones as you heard in MATLAB.
So, now, I am connecting back to my board and then if I rerun the thing I can here I need not have to run debug every time.
I can go to the project, I can what I will say I can go to run, I can load the project now whichever because all have been compiled.
So, I need not have to read a debug it again.
If I go and then click on them, it will be running loading on to the board and then we can run it directly.
So, it will take.
So, you have heard the clean speech now coming out of it.
So, once I reset the thing it stops.
So, you will not be.
hearing the thing it is running.
So, usually it goes and loads after the only for debugging purpose what we have to use our laptop once all the code has been running on the board.
So, till you remove the power supply.
So, it will be continuously running on the board.
So, if there is any power failure then you may have to that is go and load into the board and then run it.
So, this completes our demo of FIR and IR filter both in MATLAB and then in hardware.
Anyway we have seen that resonating frequency, how we are generated using the C code is shown in the previous class.
So, if you want to make this a real time that is you can either write a polling driven.
or interim driven.
So, one of this can go as an assignment for you to run this in your hardware.
So, that how I can generate my tone and how multiple frequencies I can generate using the sine wave.
So, that within just as you can see that with y 0, y 1 and y 2 and then x 0, I will be able to generate my required frequency component.
using IR filter in resonatory mode.
So, thank you and then all the best in your labs.
Welcome back to real time digital signal processing lab.
So today we will be discussing about.
the filters in detail.
So, you will be seeing that first we will discuss the MATLAB and then we will go to the code composer studio how we will be verifying whatever result we are going to get from MATLAB which is going to match with our hardware implementation.
So, you are going to see that the same thing Saragamappa what it we generated sine wave that is has been taken as a input or FIR filter.
So, you will be seeing that all the 8 nodes getting generated using the sine function here.
And then you will be concatenating just like last time what we had taken the thing and then we will be sounding all nodes.
And then if you are hearing the nodes before adding noise and then you can check that after noise what is going to happen, what is the noise here we are going to add in this case.
So, you are adding the for all nodes.
you are adding 0.3 times the random number generated with size of all nodes.
So, we will play this after adding the noise what we are going to hear.
Then what happens?
So, we know that anything beyond in this case what is the maximum frequency we have taken is basically 5 times that of the You will be seeing that is 5 times star FSA what it is been taken divided by 6.
So, what is this?
This is 440 FSA and then we will be going up to 880 hertz in this case and sampling frequency chosen is 8000.
So, after 880 hertz, so you are going to eliminate the noise present in the thing.
So, for that the coefficient has been designed in this way.
So, you have to go to FDA toolbox which we saw in the last class and design the FIR filter to remove the noise.
So, you can have two different ways of having it.
So, we will see both the ways how it is going to look like.
Then what you are going to call it as filter out initially you will be calling them as zeros and then concatenate and then you will be going from thus up to 56000.
So, the order of the filter is 121 in this case.
So, you will be going 1 to 121.
So, you will be calculating that is count coefficient j all nodes i minus j plus 1.
So, you will be shifting them get the first sample and then rest of them you have assigned them 0s.
So, you will be seeing that filter out of i is nothing, but filter out of i plus the count initially count is 0.
So, you will be increasing it and then once all the samples have been field you will be getting the filter output.
So, then you will be playing this note filter out actually and then you can do the plotting also.
So, you will be doing that is next power of 2 from length of y what it will be taking it n FFT or normal FFT it will be padding zeros and then it is taking it.
So, the length of it L what you will be taking it FFT is chosen as 8000.
and then original what happens notes and then that is original FFT of the notes after adding the noise what you will be looking at and after filtering what is the note will be getting it ok.
So, this it is going to be displayed using our plots basically we will be having subplots.
So, we will run this and then see that how it is going to look like.
This is the original note what we have generated using sign generation.
So, that is what is getting played here now.
Now, what we are going to do is it says press any key to listen to the noisy notes.
So, you will be hearing it.
This is the noisy note that is random number 0.3 times the value of that is magnitude of it what you have added to all the notes.
So, still you are able to hear the notes because only little bit of it what it is added.
Now, we will see how our FIR filter is going to work.
Still there is a little noise present, why?
Because you have added in the complete region the noise in the domain of input.
So, you can see that there is little noise left out in the even in the passband region.
So, that is what it is seen and anything beyond the passband region.
So, you are seeing that it is a flat response.
So, I will be closing this, this is the output.
magnitude plot original this thing signal and then you will be seeing plot noisy plot.
So, you are seeing the noise in the passband region and then here also you will be seeing the noise and then the filtered noise you are seeing that it is getting eliminated and then little noise you will be seeing to the original which is being left out.
So, this is what the we will say using.
or FIR filter in MATLAB what we have done that.
So, now what we can do is we can run our IAR filter here and then we will go to demo of filters in board basically hardware.
So, we will run this IAR dot m.
So, in this case you will be seeing that your input and then f is so, you are going to read a file that is corruptive dot wave form what you are going to read using audio read.
So, this is how your wave read has to be changed to audio read in the latest version earlier versions have wave read.
So, you will be sounding thus.
And, then you can print f whether we are same thing what we are going to do.
So, now, what is the thing you have to design your IR filter using MATLAB and then you will be seeing that you will be calling numerator is a floating point values what you are going to have it and then denominator values for the f 1 represent the first section.
So, you will be getting the denominator always a0 will be 1 and then you will be having the rest of the this thing values a0, a1, a2, a3, a4 what you are seeing the thing.
So, the second section what it has is it is f2 and denominator we represent it as 2.
So, the same thing here it is instead of a bicoid it is a fourth order what you have been.
reason you will be having the scaling factor that is present in this.
So, now you will be going that is you will be initializing it and then you will be having 4 counts what you are going to have it.
So, you will be going with numerator f1 with 2 size of it what you are going to take it and then you will be counting them basically.
So, that is based on your numerator f1 of i into.
x of i minus j plus 1 and then count 1 what you are keeping it for the first structure and then you will be checking the count 4 that is denominator f1.
So, you will be adding it and then adding count 3 for that and then you will be making all the counts equal in this case.
So, that you will be able to move forward.
So, you will be calling filter output.
1 of i will be giving using this count 2 minus count 4 divided by denominator f11 and then your filter out initially you will be making them 0s and then you will be seeing that count 2 is numerator 2 into j, j is varying from 1 to size of numerator f1, 2.
So, you will be computing count 2.
And, if it is i is greater than g, so you have to count in this way and then count 4 is denominator what you are counting it.
So, you will be getting again you are making it count 1 count 2 that is if the order of because we are doing it continuously we have to come back to our filter that is circular buffering what we should have it.
So, that is how you will be computing the second section also.
But what is it there is an error in the audio read that is corruptive voice dot wave.
So, what we have to do is I have to give the path for it which is not available in the current folder.
So, one of the way of doing it is I can push that corruptive voice dot wave here and then we can run it.
So, what I will do is it is present in my sample files here.
Or I can give that complete path I can give it and then run from there.
So, I can do the copy and then we will go up to the MATLAB portion of it and I will be putting my this thing I will be pasting it here.
Now I can do as all of you know CLC will be clearing all the thing.
So, I can go back and then rerun the thing.
So, what we have.
added here is a one single tone sine wave frequency what it is getting added to your speech signal that is what you are hearing it continuously.
So, now, what I will do is I will press the thing.
So you can see that it got eliminated.
So, what is the thing here it is there are two frequencies sorry in this it is 900, it hurts one peak.
And then the other one is 2700 peak.
So, which was added to the input speech to check that whether we are going to get the output correctly.
So, you have seen that initially there was this thing filtered output you will be seeing that only my speech signal is present in this.
So, you will be seeing these two peaks have got eliminated.
So, what I will be designing is a notch filter from.
So, for my application, so how I can design the notch filter.
So, again we may have to go back to our FDA tool and then if you remember the portion of it.
So, we will see that how to design the notch filter or a bind stop filter what we called it ok.
So, notch is the single frequency what we will be eliminating it.
So, this is my filter design.
So, here as we said that either we can design the frequency component which I want to eliminate.
So, I will be taking IR filter.
So, either I can take Butterworth elliptic 1 or 2 one of the thing.
So, in this case what I want to design is a.
notching what I am going to select in this case.
So, then it says it is the comb filter what it is designing here.
So, if you do not want this single notch what I can eliminate one at a time or both together I can comb filter if I provide two frequencies what I can eliminate it that is why what you are seeing is there is the 4 this thing 0s and poles what you will be seeing it.
So, if I give a single notch only one frequency what I can eliminate.
So, I can specify the order or I can do the minimum this thing, hertz is here fs is 8000 hertz.
So, the notch what I want to eliminate is 900 hertz first time ok.
So, we will see what is the thing is going to happen.
So, the bandwidth what it is asking me bandwidth I will keep it.
as 100 hertz here ok.
So, Q factor what we want is 45 and units in dB pass band what I want is 1 dB ripple.
So, I can design the filter.
So, you are seeing that this is the pass band and it comes and then removes the 900 hertz here.
So, you will be seeing that the magnitude and phase together what it is showing here.
So, if I want to see the if I want to see the group delay.
So, you will be saying that although it is a second order filter the maximum delay what I am going to get is almost 50 samples.
So, in the case of FIR filter we can count how much delay that is what we saw it last time.
If it is the 50th order filter the delay if I use the linear phase which is going to be 25.
If I do not use the linear phase concept then the delay of that filter is going to be 50.
But whereas, although this is a second order filter so, you will be seeing the group delay is almost approximately going up to 50 samples in this.
So, and then if you want to.
Select the target, code composer studio what I will be selecting it here and then one part one has to remember in this case it is a 16th order filter basically and 16 bits are there as we did the in theory that minimum of 2 bits required for my integer part to represent my filter coefficients.
So, hence the what will be using here is if I want sin 32 bit integer I can do it or I can say that sin 16 bit integer what I can generate from it.
So, then we will see that will generate the filter and then it will be saved as fd always it is going to store it as.
So, we will be storing it in this itself and then we will see what we are going to get from that.
Since we have not specified the debugger again the error will come.
So, this is our MATLAB code what we will see it.
So, we have stored the FDA coefficients here.
So, you will be seeing that it is a discrete time IR filter what it has designed and direct form 2 what it is designing and then or it said the length of it is 2.
So, order of the filter will be a length plus 1.
3 basically and denominator length also in this case 3.
So, you will be seeing the values how it is generated.
So, this is numerator length 3 what it has.
So, you will be seeing 3 of them.
If you want you can do it in floating point you can run the code and the denominator all the 3 samples sorry 3 poles what you are seeing it here ok.
This is how your FTA coefficients will be coming out.
So, this is what it was stored in our.
demo of it as you are seeing it here.
So, it is the fourth order.
So, there are one for your this thing one of the filter that is 900 hertz the other one is designed for 2700 hertz.
So, we will see that whether we can give it as a comb filter and then we can specify two frequencies here.
So, instead of single notch I can select it as a comb filter.
And, then order I can specify it as basically fourth order let us see how it is going to look like.
And then I have want the 8000 hertz and bandwidth still I will be giving it as what I will give let us see 900 and 2700 whether it is going to accept it ok.
So, it should be single.
So, we will give it as 900 hertz.
So, what is the thing happening here?
So, you can see that so, even the approximately 900 into 3 is going to be a 27.
So, I can design this and then this is my pass band region what I will be selecting it and there is going to be notch here and stop band what it is happening here.
So, I can use this.
to take my filter coefficients and then run it also fine.
So, or you can take individually and put both together.
So, one after the other filter what you are will be running it fine.
So, this gives the little bit inside of how to use the FDA tools in our and one more thing as you see or seen in the thing I can go back and then store this.
filter descriptor to know that what filter I have designed, how I have taken and then I am using it in my sorry it is asking me I have to give that I need not have to store this ok.
So, it came out of it.
This is to remove our 900 hertz sine wave what it has and the other one is to remove our 2700 fine.
So, this is how we design and then cross verify it and then go back and then run this design filter coefficients whatever we have done the thing and then check in our hardware.
So, we have one more this thing filter dot m if you want to design the thing.
So, that is FIR filter you can direct method if you want to run it.
So, you can design the thing each one will have their own way of.
putting the thing.
So, the books gives that is that is what it says is sinusoidal noise components from a corrupted speech signal.
Here it is 2 bandpass filter with rejection frequency of 900 hertz and 2700 hertz are used ok.
So, this should be band stop filter not a bandpass or you will be having a 2 bandpass filter to eliminate this 900 hertz.
and then 2700 hertz.
So, here also you can different ways of writing code what I am showing you.
So, you will be directly what you are going to do is b 1 comma a 1, b 1 is our 0s basically and a 1 is my poles basic what we will be designing it.
So, we will take Butterworth what it is being used you are giving the WP 1 and then WP 2 that is pass band what you are giving.
800 to 1000 hertz what we want is the stop band frequency.
So, that is we are eliminating the frequency from 800 to 1000 and then I can do the quantization here that is basically fixed point implementation what I wanted.
So, then what is the bits I am going to give 16 bits in that coefficients represented with 13 bits that is Q13 format.
I have been mentioning because coefficients need 2 integer bits.
So, that is why we will be designing Q 13 bits and you will be seeing b 1 quantize Q comma b 1 and then a 1 also you quantize that and you will be seeing that how the poles position is going to be.
Then we can do filter that is eliminate only one portion of it and then we can say that how I am going to here one frequency after removal.
and both together and second time I will be running it and then I can see that the last one how does it look like.
So, we will start from the thing actually the first one what we have is you will be hearing the original corruptive voice.
So, we will run this code.
You have heard the corruptive voice.
So, how to find out what are the frequency component present in it.
So, this is the this is FFT of the voice it is not the clean voice.
So, it is gone to present the last one after removing the frequency component, that is sine waves from that.
So, you will be seeing that 2 poles and then 2 zeros what you have it here.
This way coordinates and then you will be seeing that these are the complex conjugate poles and 0s what you will be presenting it in the z plane and you will be seeing this is my audio over that what we have put in here the 2 frequencies are somewhere around 2, 7 and then 5, 3 or something like that.
So, each one have a individual way of putting their own frequency and then try to eliminate that and then you will be seeing that real part how does it look like these are the 2 poles and these are the 2 0s.
of the R filter.
And then you will be seeing that the mirror image of the frequencies both together that is this is what you have is approximately 900 hertz basically what we have it.
The other one is 2700 hertz you will be seeing that approximately you will be getting it as 2692 or whatever it is got generated 962700 hertz.
So, now, I will what I will do is because all of them if they are run.
So, it will be causing an overlap.
So, you will not understand the thing.
So, you have heard the corruptive voice now.
So, to comment in MATLAB we use this percentage sign.
So, coming to the next one I will remove one of the thing and we can eliminate one frequency and then first is the 900 frequency what you are eliminating and you will be hearing the 2700 hertz here.
So, we will run this again.
Same thing you will be looking at.
Only you have seen that 900 hertz is eliminated and only this frequency is present after the first round of it ok.
Initially was these 2 frequencies present in the voice signal, one got eliminated.
Now what we will do is we will comment on it.
So that we can uncomment the last one.
So it goes through biquite section and then.
So, we will be hearing whether both have got removed or not.
Remember, the force will be with you.
So, you are hearing the clean voice that is what the clean voice what it is shown here.
So, the original voice and this should have the same thing and these are the what will you will call it as the second order section of the second filter and you will be seeing after the first one there was one component left out which was removed by those two poles and zeros.
So, the I am going in the reverse direction these two poles and zeros have removed the whatever present are 900 hertz thing.
So, this is how we run our MATLAB code.
So, you can have your own imagination add your own sine wave or any noise to this and see how you are going to eliminate those noises.
So, we will stop for this class with the MATLAB demo.
So, in the next class we will take up completely our DSP processor board demo.
So, that you will see that how little bit of.
noise whatever left out in the passband is going to emphasize in the port we will be looking at it although we have designed the same kind of filter in that.
Thank you.
So, welcome back to real time digital signal processing course.
So, we will cover today little on adaptive filter.
So, to give you as you can see this is a module 3 what you would be covering.
So, what are the two modules we covered in the previous classes is listed here.
That is we covered in module 1 basic architectures and some number system.
And then in the second one we discussed about filters both FIR and IIR filters.
And then we went on to see frequency domain algorithms discrete Fourier transform.
and how this can be made faster using Fourier transforms.
So, in the last class we little bit discussed about random process and then we will be taking up today continuing on that.
So, before that we will discuss about in module 3 what are the subjects we will be covering.
So, first one is adaptive filters, so we will be taking least square mean square algorithm.
algorithm and its applications and then we will just say a normalized LMS and then even the RL is we will just discuss we will not go on to derive the thing, but more derivative we will be doing it on the least mean square LMS algorithm.
So, later on we will cover basics of image processing basically we will be covering discrete cosine transform with little bit of introduction to our image processing.
and how we will be implementing in the hardware which is going to give us the full site just like our FFT algorithm.
So, coming to continuation of the random process.
So, little bit of theory in the last class we have covered.
Today we will discuss about little on the autocorrelation function of the random process f of n defined as Rx is of n comma k which is given by expected value of x of n with respect to x of k. So, we say random process is stationary if it is a statistic do not change with time.
So, the most useful and relaxed form stationary is the wide sense stationary what we call it which is named as WSS.
So, process that satisfies the following two conditions.
So, that is we call it as wide sense stationary.
The mean of the process is independent of time in this case what it is given as expected value of X of n is given as mx.
So, we say thus mx is constant that is what we see it is independent of time.
Then the autocorrelation function.
function, it is going to depend only on the time difference which is given by Rxx of k which is autocorrelation function given by expected value of x of n plus k into x of k. So, we say k is the time length in digital domain.
The two important properties of our autocorrelation function Rxx of k with respect to our WSS process is defined.
in this way.
First is the even function.
So, what do we mean by that?
So, Rx 6 of minus of k is nothing, but equal to Rx 6 of k which is this the other property is it is bounded by giving that that is the magnitude of Rx 6 of k is less than or equal to Rx 6 of 0.
So, here we call Rx, x of 0 as the expected value of square of the input signal x of n. So, we call it as mean square value or the other name is power of random process x of n. So, if x of n is 0 mean random process, then what we have is expected value of x squared of n is nothing but a standard deviation sigma x squared.
So, continuing with the thing consider the sinusoidal signal as an example which is given by X of n is equal to a times cos omega naught n. So, we have to find its mean and then autocorrelation for of the X of n. So, for the mean what we substitute is mx which is nothing, but amplitude a times expected value of cos omega naught n.
So, which is going to be 0 this is mx equal to.
So, we know that our cos function is given by.
So, you are taking the expected value of this cos omega naught n over the thing.
So, when you add them up you will be getting 0.
So, for the autocorrelation function.
So, how we are going to calculate the thing which is nothing but Rxx of k which is given by 0.
expected value of x of n plus k into x of n. So, here we have taken x of n here which is nothing, but a squared into cos omega naught n plus omega k into cos omega naught n this is the function what we have to solve.
So, when we solve with respect to cos omega naught n plus omega plus omega k into cos omega naught n when you expand the thing.
Then, it becomes as we know that it is a squared by 2 into expected value of cos 2 omega naught n plus omega naught k plus a squared by 2 cos omega naught k which is equivalent to a squared by 2 into cos omega naught k. So, that is what is left out from that other the terms are going to get cancelled.
So, you can expand it and then look at them.
So, And that what is the thing that autocorrelation function of a cosine wave is the cosine function of the same frequency omega naught.
So, as we started with cos omega naught n. So, we will be seeing that it is a function of omega naught itself.
So, coming with how we are going to calculate power spectrum and then cross correlation next function we will see the thing.
So, we are using the widely used random signal for many applications.
which is we said it is white noise what we will be considering V of n with 0 and variance as sigma V squared.
Then its autocorrelation function is given by r V V of k is equal to sigma V squared into delta of k. So, is we know that delta of k is a delta function with amplitude what we call it as sigma V squared at lag k is equal to 0 and its power spectrum is given by.
PVV of W which is nothing, but sigma V squared into magnitude of omega.
This is less than or in this case what we consider magnitude of omega is less than or equal to pi.
So, this shows that the power of the random signal is uniformly distributed over the entire frequency range.
So, now defining the cross correlation function between two wide sense stationary process.
x of n and y of n which is defined by Rxy of k which is given by expected value of x of n plus k into y of n. So, this function has the property that is Rxy of k is nothing but R yx of minus k. So, what we said here it is a even function.
So, even the cross correlation is a.
even function what you can look at it.
So, then what happens to R y x of k is simply the folded version of what we call it as R x y of k. So, now take an example to see that what will be the cross correlation of FIR filter with input output equation what it is given by equal to y of n equal to x of n plus a x of n minus 1 plus b into x of n.
n minus 2.
So, you can assume this is small y of n equal to.
So, we assume the white noise with 0 mean and variance sigma x squared in this case as the input signal x of n. Find the mean that is m y and the autocorrelation function Rxy of k of the filter output y of n what we have to do it fine.
So, for the mean what we are going to substitute m y is equal to expected value of y of n what we are going to take it which is nothing, we will be putting it on the right hand side.
Expected value of x of n plus a times expected value of x of n minus 1 plus b times expected value of x of n minus 2 which we will be substituting it as 0.
Now, the autocorrelation function, so what happens to the thing.
So, we will be seeing 1 plus a squared plus b squared whole into Rx of k we are considering the autocorrelation as you can see plus.
a plus a b into r x x of k minus 1 plus a plus a b into r x x of k plus 1 and then so on we will be substituting for these functions.
So, which is given by what is the thing.
So, 1 plus a square plus b square into sigma x square if k is equal to 0 and it is going to be a plus a b into sigma x square if k is equal to plus or minus 1.
what we have is we call it as mx tilde equal to the average value of it what we will be taking 1 by n, n is equal to 0 to n minus 1 x of n. So, where n is the number of samples available for the short time analysis.
So, this is the mean is defined with respect to this equation.
And then how we are going to take for the same sample what will be the autocorrelation function.
which is defined as Rxx of k is nothing but 1 by n minus k into n is equal to 0 to n minus k minus 1, x of n plus k into x of n and k will be varying between 0 to n minus 1.
So, the next is we will take up an example for to see that what will be our mean and autocorrelation and cross correlation with respect to finite length signal.
Here we have assumed x of n is equal to a cos omega naught n plus v of n. So, the mean of this corrupted we call it as v of n is the error signal what we have put the thing is signal is given by mx is equal to a times expected value of cos omega naught n plus expected value of v of n which should be equal to 0.
So, from the previous example.
We know that for cos omega naught n it is nothing, but a square by 2 into cos omega naught k plus this one will be sigma v square delta of k that is our autocorrelation.
So, what happens to its power basically P x is of omega it is nothing, but a square by 2 into delta of omega naught plus sigma v square.
So, this one should be magnitude of omega should be less than.
pi in this case right.
So, now we will see how to look at the adaptive noise cancellation.
So, what is that adaptive noise cancellation?
We will first derive it and then we will see that how we can do the cancellation of it.
So, the adaptive noise cancellation is nothing, but this is an effective method to remove additive noises from the contaminated signals.
When do we say that it is additive along with the input sequence you have the noise that is what we consider we often hear.
So, with the desired signal if there is a noise then we call in the added fashion we call it as a additive noise.
So, it has been widely used in the fields of what are the applications in telecommunication.
Radar and sonar signal processing.
So, telecommunication we know that communication channel basically has the noise.
So, it depends on which channel you will be using it.
So, how to eliminate or cancel the noise we know about it and we have looked in the little bit of examples of radar and sonar I discussed in the previous classes.
So, radar when it is sending the signal.
when it comes back.
So, you know the medium may affect the signal.
So, how we are going to adapt to the different noises that is what it is going to be and even in the sonar we know that it is in the sea.
So, there will be different signals which is going to be refractive in nature.
So, those how you will be getting it and then from along with the rest of the noises how you will be separating it.
So, we have to cancel the noise and then take the signal that is what we call it as it is going to happen in adaptive way.
So, we say that one more example is most of you use ear earphones and then headphones.
So, what it says is your earphone and then headphone if they fit perfectly then what you say is you are unable to hear any outside noise.
So, they have to be filtered out and then you will say that high frequency noise is coming from your co-worker which has to be cancelled out.
So, you call them as chatty co-worker, I do not want to listen to them.
Then if nothing is going to come when you are wearing your earphone or headphone, then you say that you have cancelled the noise perfectly.
So, this we call it as active noise cancellation.
So, in this case it can be there are two noises what we call it one is passive noise and the other one is the active noise.
Here we call it as if you are unable to hear from outside as a passive noise.
So, we will define it in a while basically and then in the active noise cancellation.
So, what is the thing is going to happen your headphones are here, but neutralize the ambient noise.
So, you will be seeing that.
But in an aeroplane this thing engine noise or in a car engine noise is going to cause.
So if you are outside noise when you are driving or whatever may be the thing if you want to cancel it out you can use the noise cancelling technology basically, but still you will be left out with noise not completely gone.
So this we call it as a active noise.
So what is it?
Active noise work by incorporating.
microphones into your headphones which listen to the outside noise and generate a phase inverted sound that effectively cancel out your ambient noise before it reaches your ears.
So, exactly we want to cancel it which is may not be possible.
So, that is the reason why in the active noise cancellation you may hear little bit of noise present it most of it is suppressed.
That is what it says in other words your adaptive noise cancellation or active noise cancels noise by creating equal, but opposite noise.
So, when it will be desirable not desirable one can look at the literature and then work out what you want to design that is what it is going to depend on.
So, in the active noise cancellation it is best suited for real time implementations because.
When you are using the microphone recording some of the open air what you will call it as speech or music or whatever may be the thing.
So, if you can take with the one more mic the surrounding noise and use it as a noise and you want to suppress that you can do that.
This is how real time is going to work.
So, we will see some examples how we will be doing this cancellation.
So, we will ask the question whether the which has better sound quality whether whatever you have used the earphones and then earbuds are when you do the active noise cancellation which one will be good.
So, we will see two sets of earbuds ok, when you will say quality I have to compare two sets basically of earbuds.
So, in this case we will say it is from the similar build.
And, tuning quality what we have it is also similar and then the earbud with better passive noise isolation will be sounding better than the ones that rely on active noise cancellation to block out ambient noise.
So, you will be seeing that sometimes passive noise cancellation is better compared to active noise.
So, passive noise cancellation what we call it as PNC or isolation is when you are in headphones, earbuds or earphones or your monitors in ear monitors naturally block outside noise.
So, in other words in your earbuds are isolating you from ambient noise instead of actively using technology to cancel it out that is why you will hear this technique called both passive noise isolation and passive noise cancellation.
So, that is what the name given to it when you are fully disconnected from the external noises.
So, now we will see why we need adaptive filters.
So, we have discussed about the linear filters.
So, it should be triggering in your mind that both FIR and IR filters we used in the previous classes we have a.
They are called linear filters, it is not linear phase filters, they are linear filters.
Output is linear function of the filter input.
So, what are the design methods that are available?
So, we will see the classic approach, one is we can use the frequency selective filters such as we can use low pass, band pass or notch filters.
As you know low pass if I want to eliminate higher frequencies.
Band pass is only the frequency of interest what I want to pass it and notch filters you know certain single tone or multi tone you know the this thing frequency of them you can use the notch filters to suppress that.
As an example we had taken it as a line this thing frequency that is our electric lines 50 hertz what it is.
So, we can use the notch filter to eliminate it.
The other one is what we can design is the optimal filter basically.
So, how we are going to use this we will see it in a while and then this is mostly based on minimizing the mean square value of the error signal.
So, from the desired signal so, will be this thing subtracting from the original signal and see how much error is left out whether we can try to minimize that error what we will look at it and then design in.
optimal kind of filter.
So, there are 4 aspects involved with our adaptive filters which are they.
The first one is the signals being processed by the filter.
So, whatever input signal you are going to feed it how the filter structure is going to behave with it.
The other one is the structure to design this filter defines how the output signal of the filter is computed from it.
input signal.
The third one is the parameters within the structure that can be iteratively changed to alter the filters input output relationship.
So, usually we call this as weights by modifying the weights whether my input and output structure can be changed that is what we will be looking at it.
So, the next one is the adaptive algorithm that describes how the parameters are adjusted from.
1 time instant to the next times.
So, these are the 4 aspects of definition what we are going to follow.
So, now, we will compare with the real world signals basically.
What we want we are looking at is it is desired to extract a certain component of we call it D of n as the desired signal from the y of n whatever we have the output from that we want to extract our desired signal.
So, that this was contained in our input signal what we call it x of n or it may be to isolate a component of d of n within the error e of n that is not contained in x of n. So, whatever error which was introduced in between whether we can minimize that or isolated from that desired signal what we are looking at.
So, what does it look like here it is input is contaminated with noise.
So, we are trying to extract the desired signal.
The other one is if we know the error then we can model it and then get the thing.
Here what is it from the it is not contaminate input is not contaminated with the noise, but the channel make have a noise just like your communication channel is going to introduce the noise.
Any of that for that matter.
So, whether we know the thing whether we can extract from that the desired signal.
So, then what happens to get these things only we may vary the weights W of n and we may not be interested in what is my input, what is my output or even desired this thing input what I am going to have or a function.
So, I want to see the weights so that if I can match X of n and Y of n I know that what I want to have it as a result.
So, there are situation which.
in which what we say in the real time D of n is not available at all basically.
So, then what is the what you are looking at is also one of the important thing if you do not know what you have to look for it in such situations adaptation typically occurs only when D of n is available.
So, if you know only D of n or you pinpoint something what why I want to look at it then I can apply adaptive algorithm.
So, when d of n is unavailable then how we are going to deal with this kind of signal.
We typically use our most recent parameter estimates to compare our y of n in an attempt to estimate the desired response signal d of n. So, I know in the previous case I have got this output y of n and this output similarly looks like the previous one.
So, then I will try to see that.
this is what I wanted to have because in the previous one I had the desired signal basically.
So then I will be looking in the present situation this is what I am looking at.
So in some more real world situations what is it?
D of n is never available there it was not available it will be never available.
In such cases use your hypothetical blind that is predefined statistical behavior or amplitude characteristics to form suitable estimates of your d of n from the signals available to the adaptive filter.
So, such methods are collectively called blind adaptation algorithm.
Already I have told you hypothetical basically blind.
So, that is what you will be applying to get the desired signal.
So, these algorithms there are two varieties, one is the steeped descent algorithm.
The other one is the maximum likelihood of optimization.
In this present situation we will be covering steepest descent algorithm.
Those who are interested can look into the literature for maximum likelihood optimization algorithm to get the signal from the real world.
So, we will see now what is the generic block diagram for adaptive filter.
So, the signal along with noise.
or without noise characteristics are often non-stationary and the statistical parameters vary with time that is what we define our signal basically.
And then adaptive filter has an adaptation algorithm that is meant to monitor the environment and vary the filter transfer function accordingly.
So, based on the actual signals received, so what we are going to do?
Attempts to find the optimum filter design is going to be considered.
So, you are given the generic block diagram of an adaptive filter here, what does it contain?
X of n is an input and then what we have is the digital filter here, how these weights are going to be altered is from the adaptive algorithm.
As you can see dotted line which is going to change the weights of this filters.
Based on what this algorithm is going to work on, it is going to take the input.
And, then it is going to take we know in this case desired signal is known and then we will be subtracting our output from the filter and then the desired signal which we call it as error E of n. These are the two inputs to our adaptive algorithm.
So, based on the thing so, we will be minimize the error by varying our weights.
So, that is what error minimization here what we are going to do it.
So, how we are going to apply this adaptive filter for our FIR filter as an example we will see it.
So, this is our block diagram of FIR filter.
So, our data flow diagram what you can call it x of n is the input and earlier in a FIR sequence we had taken it as B0 n, B0 1 and then B L-1 of n.
So, L length filter what we have considered here we will call them as weight function because we are going to vary these weights w0, w1 and wL-1 and our input z-1 we know that in the z domain it is going to delay our input.
So, we will be delaying x of n as x of n-1 and then last one will be x of n-L plus 1.
So, this is the L length filter.
So, we know that convolution theorem y of n is given by.
L is equal to 0 to L minus 1, WL of n into S of n minus L. So, instead of giving X is input this is our source signal what we call it S of n minus L and WL will be weight of the filter what we will call it.
Now, represent this in terms of equation what we call it as a vector basically notation.
So, which is given by x of n will be x of n, x of n-1, x of n-l plus 1 transpose what we will have it.
So, and the coefficients vector also represented in this format, w of n is equal to w0n, w1, wl-1, l length coefficients what we are taking it, they transpose what we will be looking at.
So, now.
So, how we are going to represent now our y of n is nothing but w transpose of n into x of n or x transpose of n into w of n. So, you can see our summation in terms of vector multiplication is going to be represented in this fashion.
So, the filter output y of n is compared to the desired signal d of n to obtain the error signal.
So, we said from this equation we know that E of n is given by or y of n will be equal to what is it error function is nothing but desired signal d of n minus y of n. So, which is equal to d of n by substituting y of n with this it is going to be W transpose n into x of n then what we call it as error as.
in terms of our this thing random variable eta of n what we call it as error function which is equivalent to our expectation of e squared of n basically what we represent.
Then what is the thing here our eta of n is given by so expected value of we are taking the square error squared what we want to minimize basically.
So, we are taking the square on both sides of.
these 2 sides.
So, it will be eta of n is nothing, but expected value of d square of n. So, it is nothing, but what I am putting from here is we are calculating E square of n which is nothing, but d of n minus y of n whole square what we will be taking it by substituting y of n.
expanding it, so you will be getting this equation.
So, what is it?
Expected value of d squared of n minus will come to this because why we have called it as P transpose W of n plus W transpose of n into R into W of n. So, expand this where P is the cross correlation vector defined as expected value of d of n into X of n.
which is nothing, but the sequences Rdx of 0, Rdx of 1 etcetera and then Rdx of l minus 1 transpose what we will have it.
And then Rdx of k is nothing, but expected value of d of n plus k into x of n and then R is our autocorrelation matrix which is given by expected value of x of n into x transpose of n.
So, when you equate it here you will be seeing that d of n minus W transpose x of W transpose of n into x of n whole squared.
So, which comes down to you will be seeing that equal to d squared of n.
minus 2 into d of n into our w transpose of n into x of n and then what is the thing?
W squared function you will be getting it transpose x squared n.
when you take the expectation on both the sides, we have represented e squared of n as the expected value of e squared of n as the eta of n. So, you will be substituting it here in this equation.
So, you are seeing that Rdx is nothing, but expected value of d of n plus k into x of n that is our desired and then n what will be taking combining with the thing ok.
So, that will be our.
desired signal and then R is the autocorrelation matrix which is given by you will be seeing that which is nothing but expected value of X of n into X transpose of n. So, which is given by Rxx of 0, Rxx of 1 and then Rxx of L minus 1 is the filter length up to here and you will be seeing that Rxx of L.
and then 0 L minus 2.
So, you will be filling up this matrix in this way this is Rx is 0.
So, what is this matrix?
We call this is a symmetric matrix and Topolitz matrix since all the elements on the main diagonal are equal.
So, you will be seeing that all the things are equal here also you will be seeing that they will be equal ok. Then, consider the optimum filter with a fixed coefficient W1.
as which was illustrated in figure which will be shown here.
So, we say W0 is equal to 1 and W1 is the weight of the filter that is what shown in this figure we are assuming that and if the given signals x of n and d of n have characteristics given by this that is expected value of R x squared of n is equal to 1 and then expected value of x of n and x of n minus 1 is given as 0.5.
And then expected value of our desired signal d squared of n is given as 4 and then the cross correlation d of 1 and x of n is given as minus 1 and this thing what we call it as expected value of x of n with the delayed of its signal x of n minus 1 is also given as 1.
Then what is the problem to solve find the minimum square error.
function eta based on the fixed coefficient vector.
So, what are the coefficient vector we are going to have it.
So, in this case R has to be Rxx0, Rxx1 and then Rxxs1 and Rxx0.
So, which is given as 1 is 1 the other one is going to be 0.5 as you can see the thing x of n and x of n-1 is 0.5.
expected value of x square of n is 1 substitute this in the as a matrix form.
So this is 1, 0.5, 0.5 and 1 and your cross correlation matrix as you will be seeing it what is given as your rdx0, rdx1 that is what we are going to have it.
So what after substituting it is going to be minus 1 and then 1.
And, then eta is given by expected value of this equation d squared of n minus 2 P transpose W plus W transpose into R into W. So, substitute all the values.
So, we have been given expected value of d squared that desired signal is 4 and then minus 2 into this transpose minus 1 and 1 and then W is the vector what we have W naught is 1 and W1 has been given to you.
1 and w1 plus what we have minus 1 and w1 basically whole into your transpose what you are taking the thing.
So, it is 1.5.5 1 and then 1 and then w1.
So, now substitute the optimum the equation boils down to w1 squared minus w1 plus 7.
How we are going to calculate optimum filter we call the name as w0 basically.
Minimizes the mean square error function this eta of n that is by substituting r w not equal to p basically.
So, we will say that it is expected value of sorry eta of d squared of n r not into minimum of it what we have to compute fine.
Thus the optimum filter can be computed as.
W naught will be equal to this is what we will be substituting is R inverse P from this equation.
So, something is going to trigger in your mind.
So, we have to calculate the inverse of a matrix in this case.
So, you know the challenges will be facing in hardware implementation.
To give an example for the optimum filter, so we are going to consider.
an FIR filter with 2 coefficients w0 and then w1 the desired signal d of n is given by root 2 into sin omega 0 n for n greater than or equal to 0 and the reference signal x of n equal to your d of n minus 1 delayed function of it find w0 and then eta minimum what it is been given.
So, as we calculated with the previous example Rxx of 2 is given by expected value of x squared of n. So, which is given as expected value of d squared of n which is nothing but 1 and Rxx of 1 is equal to cos omega naught in this case and then Rxx of 2 is given by cos 2 omega naught and Rdx is 0 that is cross correlation and then which is equivalent to Rxx of 1.
Rdx of 1 is nothing but Rxx of 2.
So, by substituting these values, so we know that W0 is equal to R inverse of P, this is nothing but 1 and cos omega naught cos omega naught 1 and then minus 1 and then you will substitute your other parameters.
So, then by simplifying it, so what you will be getting is.
Eta is going to be with this function minimum what you have to calculate.
So, in practical applications what we call it as the computation of the optimum filter requires continuous estimation of our R and P when the signal is non stationary.
So, in addition if the filter length L is very large the dimension of the autocorrelation matrix that is L cross L is large thus the calculation of inverse matrix.
is going to come it becomes a bottleneck which requires intensive computation.
So, coming with the other example, so if the length of the filter if it L is assumed as 2, the error surface forms a 3 dimensional space called an elliptic paraboloid.
So, now if we cut the paraboloid with planes above eta minimum.
that are parallel to w naught minus 1 plane.
We have obtained concentric ellipses of constant mean square errors values.
To give you a flavor of it this is how it will be when you cut into the thing you will be getting the concentric circles what you can see it.
So, then these ellipses are called the error contours.
So, that is what was written there also and then we are going to consider an FIR filter with coefficient 2 coefficient w naught and w1.
And, the reference signal x of n is the 0 mean white noise with unit variance.
So, we have derived the thing this is our desired signal b0 x of n plus b1 into x of n minus 1.
So, the coefficient b0 and b1 have been given as 0.3 and 0.5.
So, you have to calculate the error surface and error contours basically using this equation as the derived signal.
So, you will be because it is a second order with the previous example and this example combined actually you are.
autocorrelation matrix is going to become 1 0 and 0 1 and then your p vector is going to be b0 and b1 and we have this is the error function eta what we are going to calculate.
So, put it in this equation and then substitute all the values then you will be combining b0 square plus b1 squared minus 2 b0 into w0 and minus 2 b1 w1 plus w0 square plus w1 square and substitute b0 is equal to 0.3 and b1 is equal to 0.5 then your eta is going to be.
0.34 minus 0.6 W naught minus W1 plus W naught square plus W1 squared.
So, the error function is given as this fine and if you calculate the contour for that using Matlab function defining giving these are your W naught are the 2 coefficients and then W other one coefficient what you will give it and error for 15 that is W1.
your 15 contours what you want to have it and then you calculate right plot the surface function.
So, using the steepest descent algorithm what you will be putting the thing ok.
So, when you calculate using the MATLAB what is it descent method is an iterative recursive technique that is starts from some arbitrary initial weight vector W of 0 and it is going to descends to the bottom of the bowl.
So, somewhere here you will be selecting it and you will be moving on the error surface basically in the direction of the negative gradient what you are going to go down.
So, that is estimated at that particular point and then go down.
So, examples of the error surface and error contours for L is equal to 2 what it is shown fine.
So, we will consider the what is it W of n plus 1 is the future.
weight vector is going to be computed by this equation.
How we are going to derive and then how we are going to calculate the steepest decent algorithm technique we will see in the next class.
So, we will be deriving the least mean squared error algorithm also using this technique.
So, happy learning and thank you.
We will meet you in the next class.
We come back to real time digital signal processing lab part of it.
So, we will see last class we have seen FIR sign generation, how we can use them in resonator.
and how the sign table can be used to generate a audio wave.
So, today we will see how the filter can be designed and then how it can be stored in different ways.
So, we will go back to our MATLAB and here again I will be using FDA toolbox to generate my filter coefficients from MATLAB.
So, you will be seeing that as I have been mentioning it will be using the filter designer in the next.
versions and other things.
So, still it accepts FDA tool at present.
So, we are going to design a low pass filter, I can make it full screen and then we can design the FIR filter.
So, here we will use the window technique and then I can specify the order here.
So, we will specify it as 30.
So, I will be getting n plus 1, it is going to be 30, 31 coefficients what it is going to generate.
So, window I can give it as Hanning window.
And, then the sampling frequency what we can give is 800 hertz and then we will see that cutoff frequency is 1000 hertz what I will give it.
So, then design the filter.
So, you will be seeing the magnitude response in this way.
So, you will be seeing that the cutoff frequency Hanning window is somewhere around between minus 40 and then 60.
So, you will be seeing the attenuation after 1 kilohertz it is dropped down.
1 at 1 kilohertz it will be minus 3 dB that is 0.7307 what it is going to come down and then it will be coming down fully.
So, you will be seeing that the response that is this has a linear response that is what we have been telling FIR filter in the pass band region as you can see it here.
Now, as last time we will be importing this coefficients to our this thing file dot h file what we can use it.
So, if you want what it suggests is double precision floating point, but since we are using in our processor.
So, I can specify that it can be 16 bit signed integer what I want to generate it.
So, if you want to give the processor board you can give here, if you specify here I am going to specify it as 6478.
So, this is going to select the target.
And, then we will generate the file basically as you will be seeing that variable name in the header.
So, what I am generating is fda coefficients.
So, we will go back and then put it in the document file at present I am storing it as you can see it is already there.
So, I can give it as fda coefficients 1 dot you are seeing the header file is generated is dot h file.
So, it says the board is not available.
But, still it is fine with us.
So, we will go and then check in our documents file.
So, you will be seeing FDA coefficients 1 here.
So, one of the way of doing get I will come in a while.
So, you will be seeing that the filter length is 31 and we have the direct form FIR representation and linear phase what it has designed and then type 1 filter what it has used it.
And then you will be seeing that it is stored in T and W types dot H basically in this.
file if you want to directly include it in your processor.
Since it has not taken it gives the warning.
So, we know the length is 31 and then it is in 16 what we have given the thing.
So, what I one of the way of doing it is I can take this coefficients and then go and paste it in my filter basically.
Here you are seeing that FIR is in the range of interrupt driven is there I will come to that in a while.
So, here I have one more FIR 1 kilohertz what it shows the thing I will be there are so, many main dot c. So, if you want you can call by this name.
So, that will not have any confusion.
So, you will be seeing that here in this case it is declared as float here.
So, what is the problem with R thing is I have declared it as.
int 16 underscore t in the thing.
So, whether we are going to go back and then declare it as float we will see it now.
So, we can go back and then I can call it as single precision which is going to be 32 bit float what I will be creating it and then I can generate it.
So, I will be overwriting on the same thing.
So, I want to overwrite this ok.
So, and then if I go and then open this one.
So, these are the values what you will be seeing in the floating point.
So, I can take this values control c what I can do and then go into my CCS studio and then I can paste it.
lot of it which has got opened.
So, that is why it was hiding in the thing.
Now, what I can here because I thought I will not change this n that is the reason why I gave even 31st order.
So, if I want I can go and then paste here ok.
So, the what was the cutoff frequency used in this case is 1 kilohertz.
So, that is a name what it gives is FIR 1 kilohertz.
So, what we will do is we will do.
debug this code.
So, you can see that it is building the console and then it is now written on to the board and then we have got the code ok.
So, what I will do is I will select the frequency here.
component what I have to run ok.
So, we will select this as 800 hertz.
So, which it should be able to play on our output.
So, I will run the thing here my code.
So, and then play the 800 hertz sine wave.
So, you will be hearing a tone coming out of this.
Hope you are able to hear the tone.
Otherwise, you can try it on your own and then you will be hearing that tone of 800 hertz to come out.
So, sorry I will what I want to show again is that when we are playing one little more than the 1 kilohertz.
So, you will not be hearing the tone.
So, we will change the tone here so that it becomes.
I can go and then search in the directory.
So, we have tones generated lot of them.
So, if I press 2000 hertz it should have got attenuated.
So, you will be hearing blank in this case.
So, I will play this.
As you can see that.
is attenuating anything above 1 kilohertz in this case.
So, that is the one of the example.
Now how to store our coefficients in a different way we will see it.
So, in this case what we did was we cut and pasted within the code.
The other way of doing it is as you can see that in this I call it as FIR interrupt driven basically.
So, you see that your main FIR filter is here and then you can include the file lp55.h.
So, you are seeing that as a include file whatever generated from MATLAB as you can see that this is the 11th order filter what you have it here generated.
So, you will be seeing this one completely as a dot h file directly you can store it in the thing.
In this case how this FIA filter is working, we will just see the code once.
So, what we say is as I have been mentioning this is a interrupt driven, here interrupt 4 is going to be accessed.
So, what happens to this, we are calling our i is the continuous counting length what we are going to have it and then you are initializing your output to 0.
And then you are getting the.
input x of 0 is the first input.
So, we know that it is a float and then we get from the right sample from input from ADC compute your filter output.
Then what you are going to do for i is equal to 0 to i less than n. So, you should be calculating your y n plus this is the length of the filter what I have it.
So, from here you will be computing your.
y n plus equal to your h of i multiplied with x of i.
So, how you are going to update your weights in the filter.
So, for i is equal to n minus 1, i greater than 0, i minus minus.
So, your updation has to happen in the reverse.
So, the last what we call it as h of n has to be thrown out and then the rest of them has to be moved into here.
So, that this axis circular buffer basically and x of i is going to be x of i minus 1 value what you will be storing it.
So, that and then x of 0 first one what you will be taking it later.
Output channel so, which is multiplied by 32000 basically we have that is a maximum value as we discussed in the last class also.
So, it goes to our DAC and then return and then as usual in the previous demo we have seen that it is initially it is interrupt driven what we have taken it.
and then 8000 hertz what we are running.
So, both ADC and DAC gain we have made it as 0 and then we will be taking it from the line input of the board and this will run for continuously.
So, if I stop here also the code will be running unless I reset the processor from the board or you will be recompiling and then putting one more code on to the thing.
So, that is what is going to happen.
So, this is how will be what will I will call it as MATLAB and then code composer will go in hand in hand for designing your FIR filter.
So, coming to IR filter.
So, demo we will see in the next class, but we can do the MATLAB design here.
So, I will be showing you the demo also although we have seen it in the last class I do not know how much you have given attention to that.
So, I will give that as IR filter.
So, whether I want Butterworth filter or Chebyshev.
So, we will see their responses as I have been mentioning get.
So, we will go for the minimum order design in this case.
So, we have to what we are going to match exactly whether I want to match stop band criteria or the pass band criteria.
So, if you are not sure it is better to select stop band criteria because.
are what we call it as aliasing is not going to happens.
So, it is better to choose top band criteria to meet the thing.
Based on it the order of the filter is going to be designed.
So, what I will design is here 8000 hertz and then my pass band I can keep it as this thing 3 dB what I want to come for 1000 hertz and then I want 1200 what I can choose it as my stop band.
So, and I have to specify in IR filter.
So, what is my pass band ripple usually we keep it at 1.
So, if you want 0.5 we can select the thing it depends on your application.
And in the stop band whether I want to go down 80 dB or 90 dB or 60 dB what we have to specify.
So, we will see that we will at present we will give this and then design the filter.
So, you will be seeing that your filter is getting designed and you can see that the order has gone to 48th order fine.
If I have not given any specification for the order, it has gone to 48th and number of sections as we know we will be using the second order sections it is 24.
In the theory class what I mentioned was.
not to go beyond 12th order filter what I said the thing otherwise we may have the oscillation.
But MATLAB has the capability whether it can design a stable filter.
As you will be seeing that if it gives it is a stable filter still you can go with this order filter.
And then how will you will be seeing the response as you can see the thing and we will see its phase response.
As we are telling that it is not going to maintain its this thing phase.
So, this is together what I am plotting the thing.
So, this is my frequency response and then this is my phase.
So, if you want to see only the phase magnitude response is this way and then this is my in dB what it is going to show me the magnitude response up to 1 kilohertz.
it is almost 0 after that it is start coming down ok.
So, this is just the phase response.
So, you will be seeing that pass band is 1 kilohertz what we have given the thing like FIR filter it does not have a linear phase.
So, for every frequency you will be seeing that there is a change in the thing that is why we call it as non-linear phase.
IR filter ok.
So, what I want to do is how I can order of the filter I can come down ok.
So, I do not want to design so much better order.
There are two ways of it.
One is I can increase my transition band and say that then with the same Butterworth filter I can go down in the order.
The other one is either I can select the Chebyshev or Elliptic actually.
So, we will see Chebyshev type 2 what is the thing is going to happen.
So, we will design the filter.
So, my you will be seeing that your what is it phase response is not going to be linear even in this case.
So, you are seeing that from 24th order it has dropped down to 16 using my Chebyshev design.
So, then what we are going to do is we will see what happens with the elliptic.
So, you will be seeing the magnitude response sorry.
this is the magnitude response.
So, you will be seeing in Chebyshev 2 you have the oscillation in the stop band and it is going to give you a flat response in the pass band.
So, if you do not can allow oscillations in the pass band and then you want a flat response because I do not want any other frequency that is higher order frequencies aliased into my system then what I can do is I can go for Chebyshev type 1 and then I can design the filter.
So, you will be seeing that your magnitude it is I have to increase the thing.
So, in the stop band you will be seeing no oscillations are formed.
So, I want the lowest order then what happens I can go with the elliptic design.
So, you will be having match exactly both of it I will be designing it.
So, you will be seeing how much order it is going to come down.
So, you are seeing that order has.
come down to 9th order and number of sections have to be 5.
So, the last section will not have the it will be a first order section instead of second order because it should be multiple of 2.
So, the fifth section will have only the single order filter.
So, we will see the coefficients in a while.
So, as you can see you have a ripple in the pass band as well as in the stop band.
So, if I want to save this.
So, this is what the filter specification you have given.
So, I can give the same target as my code composer studio.
So, you will be seeing now from the FIR filter you have got both numerator and then denominator coming in.
So, IR filter as we know it is a feedback concept what it is going to use.
So, it will be having both numerator and denominator.
So, I will be still keeping it as single precision float.
And, then I can generate this and then we will call it as FDA coefficients 2 ok.
So, I can save this and then go and then check the thing.
So, as you can see how much order which has come down from 31 order to 9th order using our elliptic filter using the IR filter.
So, you will be seeing that what it says is it is a real.
And, then number of sections is going to be 5 and then whether it is a stable filter or not what it will give you.
So, it says yes and then how the coefficients are going to be represented in this because I need both what we call it as numerator and denominator.
So, it will be shown as this is the scaling factor what we discussed in the last class today also we will be seeing it.
Why we have to go for the scaling?
Static scaling for each sections.
what MATLAB is going to give out ok.
So, it will be this is my this thing coefficients what I have it in the because these are 2 are 0s, this is my a 1 is 1 always you will be seeing it, this is my a 2 coefficient minus 1.2315 and sorry this is a 0, this is a 1.
and this is a2 ok. And then you will be seeing 0s here.
So, that is how the scaling function.
So, and then the second section what you will be seeing it here and then all what it says is it has 3 values what it will be giving you the thing.
So, we will discuss our scaling and then come back and then see the thing.
how many sections I am going to have it you will be seeing it.
So, there are 5 sections in this case fine.
What output you will be getting?
The last one will have only 2 of them.
So, this is how you are if you want to see the pole positions you will be seeing it in your MATLAB.
So, you will be seeing second order section filters what you will be seeing the thing ok.
So, you have the pole 0 positions based on it.
So, you are seeing that circles are represented with 0s and then what you are seeing this cross are your poles, how they are located what you are seeing that this is a complex conjugate what you are going to.
have it and then the grouping it is going to do automatically using MATLAB.
So, just if you want to see the values of them.
So, what it is going to give?
So, you will be seeing that numerator is 1 and then this is b naught is 1 and b 1 b 2 is 1 and this is b 1 value and denominator value this is a 0 a 1 and then a 2 and gain of that section what it is giving the section first and then after that you will be going with section 2.
So, this is how you will be getting the values as your output from the MATLAB.
So, we will see the demo and then come back.
You will be seeing how IAR filter code is going to be written.
So, this is with DSK6713.
So, you will see signed integer and then how this is order of the filter is what it is shown filter coefficients this is how band stop filter for.
900 hertz what it has been designed and then this is for a 2700 hertz.
So, we will see the demo of this in the next class.
So, this is how you will be writing the code in C, the more detail of it what I will come back and then discuss.
So, we will see this thing MATLAB code how it has been written.
I have to change the folder ok.
So, one of the issue with this is what will be reading is the corruptive voice dot wave in this.
So, what wave read has been removed and then in the latest version it is the audio read basically.
So, these are the ones.
So, one has to change it to as you can see it is telling it is error ok in the line 8 if you go with the thing.
So, it says that it has to be audio read instead of wave read sorry I have given let us see whether it is going to run or not otherwise whatever still I have a error ok.
So, this is.
also here which has to be replaced with audio read basically.
So, it needs these are the errors file name range and then data type what it has an error in the case which has to be fixed and then we have to correct it and then come back fine.
So, this is how you will be.
from one version this was implemented in 2016 B basically version and now what I am using is 2020 B.
So, we will see the corrected one in the next class.
So, thank you for listening.
So, we will come back in the next class for the demo.
Welcome back to real time digital signal processing course.
Today we will discuss about continue with our FFT.
So, in the last class we discussed about FFT for fast computation.
how it is going to help us in speeding up our computation from DFT and then we saw that what are the quantization effects of our FFT in computation and then how we are going to do the scaling.
So, today we will talk about little bit on computation aspects of DFT and then FFT with examples.
So, we call discrete Fourier transform pair as analysis and synthesis equations.
So, analysis equation is given by x of k is equal to n is equal to 0 to x of n e power minus j 2 pi n by n where k is going 0 to n minus 1.
So, we can represent this with the piddle factors and inverse DFT as we know it is IDFT which is given by x of n we have the scaling function 1 by.
n for k is equal to 0 to n minus 1 x of k into W n k. Here it is W n k, here it is going to be W n minus n k what we will be taking it according to the twiddle factors.
To derive this x of n what we can do is we can substitute our x of k with this equation and then derive the thing.
So, for this derivation that x of n becomes x of n.
And why we have the 1 by n scaling function also you can refer to any of the digital signal processing book.
So, which will give you how to derive our that is analysis substitution in synthesis get our x of n back.
So, now we will see with few examples.
So, we first will determine the endpoint DFT of the following sequence for n greater than or equal to our length l what we call it.
So, x of n is equal to 1 in the 0 to n.
than or equal to n less than or equal to l minus 1 and which is going to be 0 otherwise.
So then we can represent our DFT of x of n up to length l minus 1.
So that is x of omega or x of k what we can take it which is going to be in this case we are assuming x of omega that is DTFT discrete time Fourier transform.
Here the amplitudes are discrete.
And, then our frequency is continuous that is the reason why omega is there which omega is going to vary 0 to 2 pi basically.
Then DTFT is given as x of n into e power minus j omega n and then when we substitute that we have got x of n is equal to all 1's.
So, then what happens to that n is equal to 0 to l minus 1 e power minus j omega n. So, this what will be representing with sin omega l by 2 divided by sin omega by 2 into e power minus j omega l minus 1.
divided by 2.
So, what happens to our x of omega?
So, this is what our equation is I think something it must be boggling in your mind basically we call this as a sinc function.
So, x of k if we calculate that in the DFT domain this was in the DTFT.
So, then what happens to this equation sin 2 pi k by n l divided by 2 and then here also sin 2 pi k by n.
divided by 2 and then this e power minus j 2 pi k by n into l minus 1 divided by 2.
So, this is what we will be getting it if our x of n is we call it as unity step function basically here u of n basically n is in this case l minus 1 length.
So, then we will take a simple example to see that how we are going to compute.
are DFT from small example.
So, what it says is we have to do the plot and calculate the magnitude phase spec plot the magnitude and phase spectrum of the sample data sequence it is just 2001 ok, 4 point what we have to calculate.
So, which was obtained using a sampling frequency of 20 kilohertz and verify the DFT result using IDFT also whatever DFT values we have got it.
how to verify it.
So, we have to do IDFT then we have to get back the signal.
So, we will see with the because it is the small value what we have taken the thing 4 bit.
So, our x 0 what we will calculate first.
So, for that n is equal to 0 to 3 x of n because our k is equal to 0 in this case correct.
So, e power minus j will be 1.
So, it is x of n. So, it is nothing, but 2 plus 0 plus 0 plus 1 which is equal to 3 which is magnitude is 3 and then it is at an angle of 0 degrees.
And then we will calculate x of x1 basically, n is equal to 0 to 3 and then x of n e power minus j.
So, which is equal to what is it x of n into e power minus j pi by 2 because it is n capital n is equal to 4.
So, which comes down to minus j pi by 2 into n basically.
So, when you substitute the values for expand your summation it is going to be a first one is x of 0 is 2.
2.
So, it is going to be 2 and the other 2 values what we have taken for simplicity is 0 and then the last one is 1 when n is equal to 3.
So, this becomes e power minus j 3 pi by 1.
So, if you substitute for e power minus j in cos and sin you will be seeing 2 plus cos 3 pi by 2 minus j sin 3 pi by 2.
So, you will be getting this as 2 plus j.
So, this is 0.
and this is minus 1.
So, it will be plus j 2 plus j.
So, when you calculate your magnitude it is going to be 2.236 at an angle of 26.57 degrees.
So, magnitude is computed with square root of real squared plus imaginary squared ok.
So, that is the value you will get it and then the angle will be tan inverse what you can see imaginary divided by your real.
So now, calculate the x 2 next stage.
So, here also you will be seeing that 3 components are left out it is going to be e power minus j 3 pi.
So, it is going to be cos 3 pi minus j sin 3 pi.
So, this comes out as you can see that it is going to be minus 1 and this j term is 0.
So, it becomes 2 minus 1 which is equal to 1 it is also 1 at an angle of 0 degrees.
There are 2 ways of computing your x 3.
So, one is here what is shown is direct computation.
So, what you arrive at is 2 minus j.
So, this is at a 2.236 at an angle of minus 26.57 degrees.
This is one method.
The other one is you can use the periodicity property basically and we know that x3 is equivalent to x1 conjugate.
So, then what happens I will be taking 2 and minus j.
So, this is the way what you will be substituting.
So, now we will see how the magnitude and phase response is going to look like.
So, we have been given the sampling frequency fs as 20 kilohertz and then our n is 4.
So, if I substitute fs by n is nothing, but 5 kilohertz.
So, we will be seeing that f in the this thing x axis will have points of 0, 5, 10 and then 15.
are the sampling frequencies.
So, 4 points what we have to have our magnitude.
Magnitude of our X r is going to be we know that first one is 3 what we have got it and second one is 2.236, 1 and then 2.236.
And then we have calculated our angle also at these frequencies what you will be putting the angle.
So, first one is at 0 is 0 and here we have a 26.37 degrees and then the.
at 10 kilo hertz we have 0 and at 15 kilo hertz it has minus 26.57 degrees.
This is how manually you can do the thing.
So, we will seeing in the lab that how we can compute our magnitude and phase spectrum using either matlab or code composer studio in using C language.
So, now comes the thing so we have to verify whatever DFT values we have got it.
using the IDFT that is inverse discrete Fourier transform we are going to get back.
So, we saw our analysis and synthesis equation.
So, we will be making use of our synthesis equation which is 1 by n is nothing, but 1 by 4 in this case.
So, our r will be varying between 0 to 3 x r what I have to put the thing.
So, 1 by 4 into 3 plus 2 plus j plus 1 plus 2 minus j.
So, you are.
Already seeing that we have got back our original signal 2 that is first signal.
So, this is going to be 3 plus 1, 4 divided by 4 is sorry 3 plus 1 plus 4 plus what is the thing?
We have it here you can see that this is 2 plus 2 is 4.
So, 4 plus 4 is 8 what we have it 8 by 4 is nothing, but 2 plus j and minus j are getting cancelled in this case.
So, now we will see x of 1.
So, this is 1 by 4 r is equal to 0 to 3 r x r e power j 3 pi by 4 into r r. So, which by expanding we are going to get it as that is we will be getting it 1 by 4.
So, we have to apply whatever DFT equation what we have got it values for them 3 plus 2 plus j is the.
x1 and then this is e power j pi by 2 plus e power j pi plus 2 minus j into e power j 3 pi by 2 in this case.
So, when we expand this so we are going to get it as 0.
So, you can simplify this and you can see that the output is 0.
So, how about x of 2 now same way what we have to work it out substitute all the values.
And, then you will be seeing that that also comes in 0.
So, we know that using the symmetry property we can calculate x of 3 or manually by calculating to verify that you are going to get it 1 what you can see it.
This case we may not be able to compute the other value because it is 2 0 0 1 is our value.
So, we have to go with manual computation and you will be seeing the last stage what you have it is these are the values.
by simplifying you get it as 1.
So, you will be seeing that what was original case 2 0 0 here and 1 is the output.
So, you will be seeing that DFT and then is analysis equation and IDFT is your synthesis.
So, whatever value you have sent it you are getting it back basically.
So, no compression is happening.
So, why I am calling it as compression sometimes we use our DFT for compression also we can eliminate some of the low values and use in compression.
Now we will see that how we can use the previous one was decimation in time what we have used it using the FFT that is fast Fourier transform using the butterfly structure.
So, we have x of 0 and next one is x of 2, x of 1 and x of 3 are the 4 inputs what we have to give it.
So, this you will be seeing that this is 2.
x of 2 is 0 and x of 1 is 0 and then 1 is x of 3.
So, it does not make the order reverse in this case because both of them we have 0.
Then we have to calculate our this thing twiddle factors since n is equal to 4.
So, our w r what we call it or w k which of the 1 we are conversant will be using notations it may little bit vary from 1 to 1.
So, we you can have one notation to use the thing.
So, it becomes e power minus j 2 pi by n into r. So, which will be equivalent to it is 2 pi by 4 r. So, which is nothing, but e power minus j pi by 2 into r. So, we will see that w 0 always we know that it is 1, what is w 1 is nothing, but putting r equal to 1 it is going to be e power minus j pi by 2.
So, which is nothing, but cos pi by 2 minus j sin pi by 2.
So, we know cos pi by 2 is 0 and sin pi by 2 is 1.
So, we are going to end up with minus j.
So, these are the only twiddle factors what we need in computation.
So, you will be putting this is 1.
and this is minus j here.
So, now, do the simple multiplication and addition.
So, what is my E 0 is nothing, but x of 0 plus x of 2 ok, because we assume that this is 1.
So, this is first one is x of 0 plus x of 2 which is nothing, but 2 plus 0 is equal to 2 and then same way we will calculate E 1 here which is nothing, but x of 0 minus x of 2.
So, you can see that how we are going with the thing 2 minus 0 is equal to 2 and compute your o 0 and then o 1 this is a even part what it is and this is the odd part.
So, what you will be getting 1 and then minus 1 in this case.
So, these are the e 0 e 1 o 0 o 1.
Now, we have to calculate because it is in this thing in order output x 0 x 1 x 2 x 3.
3 what we have it.
So, what is x 0?
So, you will be seeing that x 0 is E 0 plus r x 1.
So, it is 2 plus 1 is equal to 3 in this case and then r x 1 is nothing, but what is what we have E 1 fine and then next minus j into O 1.
So, that is what it is written.
So, it is nothing, but E1 what we have is 2 plus minus j into 1 is our thing is minus 1.
So, this we will be getting it as 2 plus j and you will be seeing the last what if you substitute the thing you will get it as 2 minus j.
So, x 3.
So, whatever DFT you have seen that.
how difficult is to calculate here using the butterfly structure that is fast Fourier transform.
We were able to do it in two steps to compute this values and one weight factor what we have to calculate and then put it in our butterfly structure.
Now we have to see that whether we are going to get back the results using FFT.
So, what is it?
Here x0, x1, x2, x3 are in sequence and our output will be out of order x0 that is bit reversed output what we will be getting it x of 0, x of 2, x of 1 and x of 3.
This we call it as decimation in frequency.
So, you will be seeing that we use this decimation in frequency which is nothing but 1 by n, 1 by 4 what we have to put scale all of them and then we have the butterfly whatever we use for DFT which is going to be reversed in this case as you can see the thing.
And you will be marking this as A naught, A1, B naught and B1 and you are this thing it is 1 coefficient.
Here minus j conjugate you will be getting it as plus j in this case.
So, and then rest of the butterfly you will be multiplying with minus 1 at the second part of it the top one is going to have plus 1 as you can see the thing here plus 1 and here also plus 1.
So, to this computation you will be seeing that you have to get back your output.
So, we have a 0 a 1 b 0 b 1 first computed and in the next case you will be calculating x of 0 x of 1 x of 2 x of 3.
So, you are seeing that you are getting back 2 0 0 1 as your output.
This is how both of them decimation in time and decimation in frequency work for your analysis and synthesis equivalent of DFT.
Now, some of the important DFT properties we are seeing in this slide.
So, the properties of DFT are different from those typical what we use it for discrete time Fourier series and discrete time Fourier transform because they are circular in nature.
So, that is they apply to the periodic repetition of the signal.
Here you can have DTFS or DTFT, it can be this thing continuous signal minus infinity to infinity whereas, this uses a circular property.
So, the first one is your notation what is it time domain is represented as x of n and frequency domain we represent it as x of k. So, the first one is the periodicity.
So, x of n is equal to x of n plus capital N is nothing, but this thing what will be getting it x of n itself.
So, which is equivalent to x of k plus x of n plus n in the frequency domain.
And, what is our linearity property?
So, if x1 is multiplied by any coefficient a1 and x2 multiplied by a2 and if you add them the result in frequency domain also it should be pre multiplied by a1 with respect to your frequency domain conversion that is x1 of k plus a2 into x2 of k. So, you can have the time reversal in your time domain.
So, here it is going to be in the frequency domain it is with respect to k what you are going to get the.
time reversal.
And then you can have the circular time shift with respect to n. So, which is going to be reflected in your frequency domain as x of k into e power minus j 2 pi k L divided by n ok. And complex conjugate x conjugate of n is nothing, but x conjugate of delayed function that is n minus k. And if we do the circular convolution in the time domain, it is circular multiplication as you will be seeing x 1 of k into x of k.
x2 of k. So, with respect to multiplication here it becomes the convolution circular convolution divided by scaling factor 1 by n. So, we know the Percival's theorem.
So, it is x1 of n into y conjugate of n in the time domain.
So, which is represented as 1 by n times k is equal to 0 to n minus 1 x of k into y conjugate of k.
So, now we will see that how our hardware complexity using DFT and FFT in processor is going to reflect.
So, as an example DSP system is based on a floating point processor we have considered and we say that it is capable of performing multiply and add instruction in one machine cycle which is going to take 15 nanosecond.
So, we have ignored in this case all I O operations.
So, only we are looking into the computation aspects of our hardware.
So, and we have a next one what this it is defined is that is suppose that the system is used to implement the DFT directly and is required to output the DFT of 512 input sample points within an interval of 64 samples.
That is Chang's.
So, this is the case of 64 samples are going to.
come out and then what we have to do it that is estimate the maximum sampling frequency if sine and cosine function are pre computed and stored in a lookup table.
So, we are not going to use the library function.
So, we are saving little time.
So, we will be calculating for 512 points both sine and cos is computed and then kept in the table.
So, we are using that to compute our DFT values.
So, what is it?
Using the DFT means we know that are either x of k or x r what we can give it, n is equal to 0 to n minus 1 is phi 11, x of n into cos 2 pi by phi 12 R n minus j times n is equal to 0 to phi 11 x of n into sine of function 2 pi by phi 12 into R n. That is we have split our e minus j into cos and sine function.
So, we can see that.
This involves what is it?
512 possible sine values and 512 possible cosine values are pre-computed.
So, we are not taking the computation time of it because we have kept it in the look up table and then what happens to this now.
So, frequency point requires 512 multiplications what we need it here and then we need 511 additions as you I think something it should be coming.
Then in n multiplications and n minus 1 additions what we need it for real and then.
imaginary parts separately what we have to do it, then it is order of n if I take it 2 into 512 times what we wanted, but what we have is k or r is going to go between 0 to 511.
So, then what happens to this it is 2 into 512 squared is our computation time to do our n point DFT.
So, and then we have been given.
We are ignoring because multiplication and addition we are combining it which is order of n squared.
So, which takes 15 nanosecond what we have been given with.
So, then this comes to about 26.21 millisecond and we have been given that 64 samples of chunks are going at a time.
So, we will divide this 26.21 by 64 which gives us 0.4095 millisecond to do DFT for And we know that maximum frequency what we can operate this circuit with is 1 by 4095 millisecond which comes to about 2442 hertz or 2.442 kilohertz.
So, this is what with the DFT.
So, we will see with the FFT how we are going to compute it.
Except for stage 1 which is going to have only additions.
So, each stage we have to do.
N by 2 complex multiplications that is 256 complex multiplications and we have discussed in the last class that each complex multiplication is going to take 4 real or ordinary multiplication.
So, it becomes 4 into 256 multiplications and we said addition is going to causes 2 into 256 addition or subtractions fine.
So, each complex addition is going to take 2 additions.
So, that is the reason why 2 into 256.
number of additions for the rest of the stages what we needed.
So, if each complex multiplication is implemented by executing the multiply and add instructions, four times the number of multiply and add instructions required to execute at each stage that is 4 into 256 what we wanted, it has to be executed ok.
Complex additions at each stage except stage 1 also require an addition of 2 into 512 times we said additions.
So, what happens the total number of computation stage is log 2 512 which is nothing, but 9 stages what we have it and we said stage 1 we do not need any complex multiplication in the thing.
So, we only we need 512 additions in this case.
So, if the execution time of addition instruction is assumed to be same as the multiply and add instruction.
So, although we know that multiply may take little more time, but we are assuming at present it is going to have addition also same time.
Then the computation time required for 512.850 what we are putting it.
So, this is 4 into 256 plus 2 into 512.
what we have it or additions as you can see the thing complex additions is nothing, but 2 into 512 into because the first stage we are having only additions which is assumed here 512 stages.
So, n minus 1 stages here 9 minus 1 is going to be 8.
So, these are the ones which are causing our complex multiplication and then complex addition which is separately taken into account.
And then whatever complex addition with multiplication is coming we are assuming that it is consumed in this.
This is the other additions what we are showing it here.
So, into 15 nanoseconds is going to give us 0.8448 millisecond.
And, then we said that it is 64 samples in this time period what we are outputting it.
So, divide by that will give us 13.0 microsecond.
And the maximum sampling frequency is going to be 1 by this which is going to be 75.757 kilohertz.
As you can see at 2 point some kilohertz in using DFT.
Using A50 we are going to have 75.757 kilohertz.
75 kilohertz.
So, that is the comparison.
So, you will be seeing that it is equal into 31 fold increase in the computation speed.
So, now we will see that how we can implement FIR filter using FFT.
So, we will be taking the DFT of our input signal and DFT of our coefficient and then we have to do complex multiplication here XR into HR and then we are going to take IDFT.
So, this is what our circular convolution which is going to happen.
So, how we are going to calculate this?
If we are taking a 4 point then we know that 4 squared is 16 what we are going to get the thing and then multiplication and 4 into 4 minus 1, 12 additions why in the direct circular convolution for 4 point.
Now we are assuming the same thing and then trying to see that whether we are going to have 5, 12 multiplications.
So here we will require 5, 12 multiplications and.
512 into 512 minus 1 whatever we said that additions for direct using DFT.
So, we will be seeing that add instruction we can do it as 512 squared basically what we are going to have it as it is seen 512 squared here it is 512 squared.
So, what we say is 512 squared into 15 nanosecond.
So, it is going to be 13.11 millisecond what we needed.
So, now we will see using FFT although I am going to take it DFT and this thing.
So, previously we calculated our each FFT needs 0.8448 millisecond and then how many times I have to do it here 1, 2 and then 3 of them what I have to do it because even IDFT is equivalent to DFT.
So, we can compute it as 3 into 0.8448 millisecond plus.
we have to do this complex multiplication here.
So, each complex multiplication as we know we have it as 4 normal multiplication 4 into 512 into 50.
So, this is the additional.
So, which runs at 2.6368 millisecond and then we are calculating that is 3.11 millisecond in the thing.
So, here it is 2.6368 millisecond.
So, we are still using all this complex method or FFT method is still 4.97 faster than that.
direct DFT.
And one more thing one can keep in mind that I because this is a predefined coefficients basically.
So, I would not be recomputing every time only our input signal is which is coming continuously.
So, if we apply a DFT and keep it precomputed values here.
So, we can avoid one of the DFT online.
So, then it becomes this one 2 into 0.448.
So, which reduces to 1.7.
to millisecond compared to our 2.6368 millisecond.
So, still we will be gaining with the thing.
So, we will see in the next class because we say that our x of n is continuous how we will use the overlap add or save method to compute our FFT.
Thank you.
Welcome back to real time digital signal processing course.
So last class we discussed about the discrete Fourier transform.
In this today's class we will see the complexity of filtering.
and then how FFT is going to be derived.
So, that so, what is how we represent our digital filtering we know that the equation for our FIR filter for a simplicity what we will take it here.
So, X of n is our input and H of n is our H of n be real signals that is.
2 signals if you want to take it or the impulse response of the filter what we will consider it as h of n. So, if we assume the coefficients it becomes b of n in FIR filter.
So, x of n is we are representing it as 0 to n minus 1.
Then we have to compute our y of n using the as we can see here the star indicates the linear convolution.
So, how we can represent k will be varying between minus infinity to infinity.
x of k into h of n minus k or we can represent k is equal to 0 to n minus 1 because this is what our length of sequence input sequence.
Then what we will show is x of k into h of n minus k or we can as you know that since this is a LTI system.
So, we can have x of n minus k for my x and then h of k for my coefficients what we have seen in our.
DSP implementation.
So, both the ways are correct.
Here we will be assuming at present to derive x of k into h of n minus k. So, what is it?
So, we have to say that what is the complexity of computation of this linear convolution.
To make it simpler instead of convolution we will assume it as a multiplication at present.
k will be varying between 0 to n minus 1 and then x of k into h of n minus k. So, how many real multiplications I am going to do it because it is 0 to n minus 1, n real multiplications.
and with x of k into h of n minus k and then we have to have the summation which is going to be 1 less we will be assuming it n minus 1 real additions are required.
For all n varying between 0 to n minus 1 then if we assume that my n is also length of 0 to n minus 1 then total number of multiplications for our filtering required is.
n into n that is n squared we say order of n squared real multiplications are required.
And then addition we know n into n minus 1 additions which is nothing, but this also results in order of n squared real additions.
So, total number of multiplications and additions are required is order of n squared which we consider it as very high ok.
So, how we can do filtering in the frequency domain which can reduce our complexity.
what we will be looking in few slides.
So, what is it?
We will say discrete Fourier transform.
We say it is a frequency analysis of discrete time signal.
It is how we can perform it on the DSP that is what we will be looking at.
So, both time domain and frequency domain in the signals must be in the discrete format.
So, x of t is our analog input after sampling I will be getting x of n in the.
digital domain and x of omega which is omega is continuous after sampling it we will be getting x of 2 pi k by n or we call it as x of k. So, we will be representing 2 pi k by n as k in this case that is capital K. So, we will be see some of the duality of the Fourier's domain thing one is in the time domain what it is represented in the frequency domain if it is a sinc function.
in time domain which is going to be rectangle in frequency domain.
So, if it is rectangle in our the sync time domain it becomes a sync function in our frequency domain.
So, if I think some of you would have heard sync squared function it becomes triangle in frequency domain vice versa.
And we will be seeing that it becomes a ringing in case of time domain then it becomes a truncation in the frequency.
So, the other way round.
So, if it is discrete in time domain which becomes periodic in our frequency domain and if the input signal is periodic then it becomes discrete in our frequency domain.
So, if it is continuous it becomes aperiodic in frequency and if it is aperiodic in time domain it will be continuous and then you can have many more like this in the duality what you can consider.
So, few of it which is required for our derivation what we will be using it here.
So, coming to DFT.
So, we know that if the signal is aperiodic plus discrete in time domain, then if I take the Fourier transform of this.
So, that means, to say if x of n is aperiodic and my h of n is discrete in time domain, what I will be getting the result is continuous time signal in Fourier domain plus periodic in frequency what I will get it.
So, by doing the sampling.
I can reach this discrete signal what I can get plus periodic in frequency what I can achieve from this stage or I can have a periodic signal in the time domain plus DST in this thing discrete time signal here.
Then I can get discrete plus periodic in frequency when I do the Fourier transform or if the signal is periodic plus discrete.
Then, if I take the discrete time Fourier series basically if I convert it then the output is going to be periodic plus discrete.
So, we will be seeing that one period of our discrete sample DFT I will be getting one period of discrete samples here.
So, here n is equal to 0 to n minus 1 in this case we will be having k will be varying between 0 to n minus 1.
So, now, how to represent it both in time and frequency domain relation what it is shown here.
So, you will be seeing that this is a periodic plus discrete time sample what it is taken in the time domain.
So, you are seeing that this is my x of n.
And, then when I take the DFT, so I will be getting x of k here.
If I take the discrete time Fourier series, then what you will be seeing is periodic plus discrete in this thing time domain.
So, this is how the samples have been represented in that.
So, this will be x axis will be k and then our y axis will be representing periodic plus DST in frequency domain.
So, coming with the thing how we are going to do the frequency domain sampling what we are going to achieve.
So, that is we have already said sampling in time domain we said it is going to result in periodic repetition in frequency.
So, when I represent x of n. So, we say that it is a repetition of it x a of t we represent t is equal to n t then take the Fourier transform we result in x of omega.
which is nothing, but 1 by t into k sigma k is equal to minus infinity to infinity.
This is the this thing periodic signal x a into omega plus 2 pi by t into k. So, similarly sampling in frequency results in periodic repetition in time.
What we will be seeing it that is this is the periodic signal what we are representing.
as x p of n in the time domain then it is going to result i is equal to minus infinity to infinity x of n plus i n and then I will be taking the Fourier transform which is equivalent to x of k which is nothing but x of omega in this case omega is represented by 2 pi by n into k. So, now we will see the thing how the sampling is going to happen.
So, we know that n is proportional to omega that is sampling rate.
So, that is n samples per 2 pi what we are going to have it in this region is the 0 to 2 pi we will have n samples.
So, we know that x of n when we take the Fourier transform we will be getting x of omega.
So, the periodic representation x p of n if we take it Fourier transform we will be getting x of k in this case.
So, we are seeing that is samples of x of omega.
used in the reconstruction of x p of n and from x p of n we can get x of n can be reconstructed in this fashion.
So, we will be seeing that this is what we are varying 0 to n minus 1 next one will be the n sample k is going here and this is our omega x axis.
So, here it is you are seeing when n is equal to 2 pi this is the axis.
And, then n minus 1 point will be 2 pi minus 2 pi by n. So, this is the resolution what we will be calling depending on our n samples.
So, coming to the how we can do the reconstruction because we have gone from time domain to frequency domain, but my output I want it in the time domain.
So, how we can do the reconstruction?
So, this is shown with n is equal to 4 in this case.
So, you can see that this is my x of n.
which has 4 samples the magnitude you will be seeing that this is 0 1 0 1 what you have taken rest of them are 0s both the sides negative and then positive side this is my n basically.
And then we will see that we are assuming because I have n is equal to 4.
So, we do not have any temporal aliasing in this case.
So, this is my X of basically this is the periodicity what I have taken.
So, you will be seeing that the magnitude sorry at x is 0 it is 2 and then x is equal to 1 it is 1 and then x is equal to 2 it is 0 and then this is 1.
So, you will be replicating them on both the sides as you can see it.
So, these 4 samples you will be seeing that it becomes 2 1 0 1 2 again.
So, on the negative axis also what you will be?
doing the repetition.
So, we do not have any aliasing because they are distinct in nature.
So, you will be seeing that x of n is a unit step response all of them are 1, then what happens in the time domain.
So, we said that if it is a rectangular window it should result in your sinc function.
So, here you can see that what is the happening is in the periodic if I take the thing.
Then, you will be seeing that these two are 1s and then that is magnitude is 2 and then 1 and then which is not equivalent to my x of n. So, the sampling rate if you have n is equal to 4 you have to kept it, but x of n is what you have given more than n. So, I would not be able to reconstruct the signal.
So, you are seeing that aliasing happening instead of one magnitude of what I have supposed to get it.
So, two of the samples which have got aliased and then which has gone to peak.
magnitude 2 in this case.
So, what is sampling and then reconstruction how they are related in the frequency domain we will see it.
So, x of n can be recovered from our periodic x p of n if there is no overlap when taking the periodic repetition.
So, if x of n is finite duration and then non-zero in the interval 0 to l minus 1 then what we say is x of n is equal to xp of n in this domain 0 to n minus 1 when n is greater than or equal to l. So, if it is less than then we know that aliasing is going to happen for the periodic signal.
So, if n is less than l that is what it says cannot be recovered from our periodic xp of n. Also x of omega cannot be recovered from its samples that is x of omega.
2 pi by n into k due to time domain aliasing what has happened.
As the previous slide shows that what was the initial thing, but here all of them are 1.
So, we are not getting back in this case ok.
So, now, what is the relation between our DTFT, DTFS and then DFT.
So, x of n for all n if I take the DTFT then it becomes x of omega for all omega.
and then the periodic signal in the time domain x p of n for all n and if you take a discrete time Fourier series then it is going to become x of k for all k. So, we say that x tilde of n that is periodic DFT if I take it results in the periodic x of k. So, here x of n periodic what we are represented instead of x p of n.
So, for n is equal to 0 to n minus 1 it will be 0 otherwise and then what happens in the frequency domain x hat of k will be x of k in this 0 to n minus 1 other thing is 0.
So, what are the we have seen the DTFT pair.
So, now, we will see the DFT pair.
So, that is we have taken the example and we took the IDFT.
So, we call them as pair.
So, this is the analysis function and this is the synthesis what we call it.
that is capital X of k is given by n is equal to 0 to n minus 1, X of n into e power minus d 2 pi by n into k or k n by n by n whatever way you represent it, k will be varying between 0 to n minus 1.
The inverse what we have seen it is X of n is the nothing but 1 by n. So, k is equal to 0 to n minus 1, X of k into e power pi same thing instead of negative here it becomes positive.
In this case n will be varying between 0 to n minus 1.
So what is the complexity of DFT what we have seen the thing.
So with respect to our signal processing hardware we will see what is the complexity of our DFT.
Complexity of filter what we have seen the thing we have to see the complexity of our Fourier transform discrete Fourier transform.
n is equal to 0 to n minus 1.
So we know that X of into W and k and k will be varying between 0 to n minus 1.
So we know that straightforward implementation of DFT to compute X of k for k is equal to 0 to n minus 1.
requires just like our filter order of n squared here it is not real multiplications it is going to be complex multiplications.
Because x of n has to be multiplied with cos and x of n has to be separately multiplied with our sine which is imaginary part and they have kept separately.
So, that is why it needs complex multiplications in this case.
And then we need one complex multiplication is equivalent to what we call it as.
AR plus JAI into BR plus JBI if I do it this is what I am doing.
So, both Xn and then my coefficients are we call it as complex Xn is also complex I have we have assumed.
When we do this multiplication you will be seeing that it is nothing but AR into BR minus AI into BI plus J times AR into BI plus AI into BR.
So, what does it show 1, 2, 3 and then 4 real multiplications.
So, one complex multiplication is equal to 4 multiplication plus I have to have even we take it as subtraction as addition because we do in 2's complement if you call back your number system.
So, we have 2 additions real additions.
So, what happens to our total computation time which is equivalent to 4 into.
n squared which is nothing, but order of n square real multiplications what we needed.
So, which is same as that of our filtering.
So, we will see that how we can reduce or take that forward.
So, in this case we said only multiplication we covered the thing.
Now, we have to see from the addition point of view.
So, what is it our filtering was needing n into n minus 1 real time additions, but in this case it is going to be n into n minus 1 complex additions.
How do we represent one complex addition?
that is AR plus JI this is what we say is plus BR plus JBI.
So, this is my equation AR plus JAI plus BR plus JBI.
So, it will be AR plus BR plus J times AI plus BI.
So, that is how we will be resulting in two real additions and then.
When I want to do the total complex multiplication and then we take that 2n into n minus 1.
So, we will be deriving it once again when we take up the problem.
So, it will be coming it as 2n into n minus 1 plus 2n squared that is which is arriving from my complex multiplication.
So, some of the additions taken from there.
So, this many number of So, what I need is real additions.
So, what does it mean?
So, this is the complex addition.
So, 2 times because each complex multiplication we are taking it as 2 real addition.
So, which results in 2 into n into n minus 1 from this stage and then we know that from the complex multiplication we have addition which is resulting.
So, which comes to 2 n squared.
So, that is what it is rendered from complex multiplication I have to take this also into account.
So, this is what our total number of additions required for computing my DFT.
So, in that case.
the maximum is 2 n into n minus 1 if I take it if we absorb this also inside.
So, additions also what we need is order of n squared that is the complexity of DFT both real multiplication and real additions are order of n squared.
So, we know that already we have pointed out in the filtering it is too high.
So, linear increase in the length of the DFT increases the complexity by a power of 2 basically.
And if you are given them this thing what is it magnitude of applications that is number of them where Fourier analysis is employed that is we will call it as linear filtering or correlation analysis which will be taking it up little later.
And then do the spectral analysis what are the intention of our applications then we will say that.
How many this thing what is the complexity of it that is efficient computation is required.
So, that is reduce the complexity by exploring the symmetry property of our complex exponential.
So, how we can do that?
We have the twiddle factor.
We saw that W n k plus n by 2 is equivalent to minus W.
So, we will see the left hand side is nothing, but W n k plus n by 2 is equal to e power minus j 2 pi substituting k with k plus n by 2 k plus n by 2 by n which is nothing, but e power minus j 2 pi k by n into e power minus j 2 pi n by 2 by n. So, this results in minus 1 that is what it is shown here e power minus j 2 pi k.
k by n into e power minus j pi which is nothing but this cos minus pi plus j sin minus pi when we expand e power minus j pi and then we know that cos minus pi is minus 1 and sin pi is going to be 0, pi or minus pi is 0.
So, which will be minus 1.
So, when we represent this is nothing but minus.
So, that is how the derivation between the two has been arrived at.
So, LHS is equal to RHS.
So, whatever we are representing that is symmetry properties true.
So, now, how we can extend this usually we call it as decimation in time basically that is x of k is equal to n is equal to 0 to n minus 1 x of n W n k and this is our normal DFT equation k will be varying between 0 to n minus 1.
So, now what happens?
So, if n is even then n is equal to 0 what we will be taking it x of n plus w n k plus that is we are considering even and then odd parts.
Next n is odd x of n w n k. So, here it is going to be we are changing the little bit of notation from n actually m is equal to 0 to n by 2 minus 1 x of 2 m because it is a E 1 and W n k times 2 m, n is substituted with m in this case.
And this is our art part m is equal to 0 to n by 2 minus 1 x of 2 m plus 1 W n k times 2 m plus 1.
So, this is how we can split our DFT equation into even and then art parts.
So, when you can see that.
We represent x of 2 m as f 1 of m and we are seeing that this is become already W n 2 k m and then this we call x of 2 m plus 1 as f 2 of m equivalent to and then this is W n 2 k m into W n k. So, we are going to split like this, this mission in time and then we know that W n 2 is nothing but by substituting k is equal to 2.
e power minus j 2 pi by n into 2.
So, which is nothing, but e power minus j 2 pi by n by 2 what I can take it.
So, the twiddle factor it is going to be W n by 2.
So, then we will represent x of k is equal to what we have is f 1 m and then f 2 m. So, by putting substituting this f 1 of m and then we are substituting our W n.
2 actually with respect to this it becomes W n by 2 into k m plus we know that W n k is independent of n. So, which will be taking it out W n k and this is our sigma for the f 2 f m W n by 2 into k m. So, you will be seeing that this is n by 2 d f t of f 2 of m that is what we have it.
Then, if we represent this as this is n by 2 DFT of f 1 of m, if we substitute that as capital F 1 of k plus this is going to be W n k f 2 of k, k will be varying between 0 to n minus 1.
And then we know that f 1 k and f 2 k are n by 2 DFTs.
So, you will be seeing that f 1 of k plus n by 2.
and f2 of k plus n by 2 and x of k is going to be that is DFT of fit will be f1 of k plus w n k into f2 of k. So, now, what we are going to represent that k also will be taking the symmetry property will do it as k plus n by 2.
So, we can have it as f2 k plus n by 2 plus w n k plus n by 2 into f2 of k plus n by 2.
k plus n by 2.
So, here it is f 1 of k plus n by 2 plus w and k plus n by 2 into f 2 of k plus n by 2.
So, which is nothing but f 1 of k minus w and k into f 2 of k.
So, how this has come you will be seeing that W n k plus n by 2 what we have to solve the thing which is nothing but e power minus j 2 pi by n k plus n by 2 which you solve the thing.
So, which is nothing but e power minus j 2 pi by n into k into minus 1.
So, this is our W n k. So, you can see that.
k plus n by 2 results in W n cube.
So, we can split this decimation in time further.
So, that is x of k is nothing, but f 1 of k plus W n k f 2 of k, k also will be going between 0 to 1 to n by 2 minus 1 and then x of k plus n by 2 is given by this equation as we have already computed minus W n k into f 2 of k.
0 to n by 2 minus 1.
Now, this is what we call it as Radix II FFT that is n decimation in time what is happening step by step till we go up to last stage is 2.
So, you will be seeing that repeating decimation in time f 1 of n and f 2 of n. So, we will be obtaining f 1 of 2 n and f 1 of 2 n plus 1 we call it as v 1 1 and v 1 2.
So, you will be going n is equal to 0 to n by 4 minus 1 next stage.
and then v 2 1 of n is nothing, but f 2 of 2 n and then f 2 of 2 n plus 1.
So, which will be going by n by 4 minus 1 when k is equal to divided by 2 further.
So, that is how you will be continuously going on splitting the thing that is f 1 of k is nothing, but v 1 1 of k plus w n by 2 k v 1 2 of k. So, which is going between this then f 1 of k plus n by 4 if you take the thing.
this is what you will be resulted and then that is the next f to what is split into this.
So, which has n by 4 DFTs in this case.
How we can represent in decimation in time?
This is my for n is equal to 8 it is a simple one to consider we have considered it.
So, the first one is x of 0 the next value is what we need is x of 4.
So, we will be doing the 2 point DFT.
And then x of 2 and x of 6 will be doing the 2 point DFT which is going to be combined with 2 point DFTs here.
And then the other 2 odd part what you can see it x 1 of 1 and x of 5, x of 3 and x of 7 other 2 point DFT what you can do it and then combine them.
And then finally you will be combining as a 4 point DFT.
So, you will be getting output as x of 0 to x of 7.
So, you can see that input is bit reversed what we have considered in the number system and DSP architecture we said we need input in the bit reversed format output will be in order.
So, we have seen the example how to generate the bit reversed also using hardware adder.
So, when we represent this as the from the previous thing.
In terms of what we call it as this is the butterfly structure.
So, this is my x of 0 and x of 4.
So, this will be my weight W80 and this is minus WNK what we have it here it is going to be minus 1 and then we will be combining these two and which goes to the stage 2.
This is stage 1, this is stage 2, this is stage 3 where all the things are combined.
Whereas, in the second stage my twiddle factors what I need is W80 and W82.
So, in both the cases and we know that W80 is 1 ok, I have to compute only this twiddle factor W82.
Whereas, in the last stage we need 3 twiddle factors that is W81, W82 and W83 has to be computed and then as usual W80 is 1.
So, we will be getting the output in.
order.
So, to do FFT computation for n is equal to 8, we know that log 2 of n 8 is nothing but 3, we need 3 stages.
So, we will be seeing that how we are going to reduce the thing computation.
So, we will be seeing that with respect to this what we have given computational efficiency of n point FFT we will see it.
We know that it is n squared complex multiplication and addition what we needed and FFT.
So, we we need n by 2 log 2 n. So, we said that for 8 point it was 3 stages.
So, if it is n point then we need log 2 n and we can use a symmetry property it is going to be n by 2 complex multiplications what we needed using FFT.
So, you will be seeing some n points and then what is the DFT multiplication and FFT multiplications with respect to n. So, if it is 256 we see that 65536 here what we need is 1024.
So, FFT efficiency we compute it as 64 is to 1 for our DFT.
So, as and when our n point increases.
So, you will be seeing that computation of DFT.
increasing very much and then FFT you will be seeing low and you will be seeing that 68 683 is to 1 is the ratio for 4096.
So, this is how we do the computation of FFT.
So, in the next class we will be seeing quantization of FFT, how it is going to affect our world length and then even the coefficient has to be quantized.
So, number of stages is going to increase.
So, it is pipeline structure what we are going to have it.
So, we will see what are the quantization effects in FFT in the next class.
Thank you.
Welcome back to real time digital signal processing lab.
So, in the previous lab we have saw how we can do the DFT and FFT in.
using MATLAB.
Today we will see how we can use our code composer studio to run our DFT and FFT code.
So, you would have seen such a simple calling FFT function in MATLAB.
Here we have to write our own routine here in C language and we will be running it.
So, welcome.
So, we will see the code actually.
So, the first one is the simulator code what it has been written.
So, number of points here it is selected as 512 FFT points and FFT length is also 512 chosen.
So, if it has to be modified we can modify it.
So, that is what it says both are same just defining 2 for convenience sake basically and define FFT length is 351 that is filter length what it is chosen and then the define length is that is signal length is chosen as 3000.
And, signal block length so, you will be seeing that here it is going to be overlap method is going to be used to compute our FFT.
So, signal length is signal block length what it is chosen is 162 and we have to define pi here unlike MATLAB where pi can be directly taken into the thing.
So, we have to define some structure.
So, here you will be defining float real and imaginary.
And, we are calling it as complex ok.
So, you will be calling the function fft, I will be showing you fft dot c what it is going to do.
So, you are passing your y and then n is the your number of points what you will be passing it that is fft prototype.
And then we call the function complex, we are going to do the complex multiplication.
So, x and then y separately and then you have to define some of the terms as you can see the thing and then your flag is going to be set that is interrupt service routine when I-W buffer is full that is what it is going to be set.
And then we have w points is the twiddle constant stored in a w and then complex what we have samples points primary this thing working buffer.
And, then we will be calling it FFT H number of points and then out temporary are the complex what we have defined ok.
So, the include is the data file this is the filter coefficients what we have it.
So, we will try to open this.
So, you can see that these are the filter coefficient values 351 of them have been pre computed using MATLAB and then stored in this file.
So, are the twiggle factors.
So, you will be going into the main and then you will be doing to the length of your signal.
So, you will be generating your sign basically that is 200 into i and then you have a 267 and then 400.
This is the input what you are generating at ok.
So, you will be taking a 50 that is using the coefficients.
So, you will be calculating w i of real and w i of imaginary.
So, these are the cause and then this is the sign function.
So, real component of twiddle constants and these are the imaginary constants what we have it.
So, then you will be computing f of t that is h of i that is real part of it.
So, you will be assigning it and then you will be with the new data what you will be calculating this.
So, how you will be calculating your imaginary components initially you will be setting it to 0.
and then call the fft function with fft hedge as you have computed here with number of points ok.
So, the bottom one will be showing you convolution with overlap.
So, we can here also we can set the break point and then see whether we are going to run only fft of it.
So, the thing is what we have seen the data file.
So, we will see the how the fft dot c function is written here.
So, this is again number of points what it has been defined and you will be seeing that that is whatever you call it as upper leg, lower leg, index of upper and lower butterfly leg what you are going to implement it and then you should have a loop counters and difference between upper and lower leg what you will be having it and then how many steps you are going to have it.
twiddle constant and then number of stages what you have to do it.
So, using butterfly structure will be computing our FFT.
So, as we know that number of stages is going to be locked to n. So, for that what will be computing our thing.
So, the code will be shown in this way step is step between values in twiddle what you will be taking it.
How you are going to calculate?
So, you will be calculating your lower like and then temporary files what you needed to store them.
And then you will be calculating y1 y of lower leg and then upper leg separately that is real and imaginary separately is computed.
And then you will be setting your index t is equal to how many steps what we have taken into.
And then you will be calculating the leg difference by 2 and then you will be setting your step to 2.
So, we will be starting this one more loop for i is equal to 1, 2.
less n less n minus 1.
So, bit reversal for what is it arranging our data in the bit reversed manner.
So, you will be seeing that how you will be putting them in your input ok, bit reversal in see what it is done.
So, whereas, in the case of if we use the assembly program then we can directly access our bit reversal.
module what we discussed in the architecture in our DSP processor.
So, you will be calculating the complex multiplication what you will calling the function.
So, you will be doing the real you are seeing it real come multiplied and imaginary multiplication and then imaginary part separately.
So, you are seeing 4 multiplications and 2 additions are happening in R 1 complex multiplication ok.
Then you will be returning the z and then it will be continuing.
So, what we will do is we will just chosen this is the active debugger what we have to choose it.
First what we will do is we will compile the thing for any error in the thing.
So, it is simulator as it shows dot out is up to date because I have pre compiled and then done the thing.
If there is any modification is done so, it will be doing the recompilation.
So, now what we will do is go to the debug mode.
So, we will be seeing that our output will be in we have the So, the As you can see we have put the break point here.
This will show our using overlap save method has been implemented here.
In the MATLAB you saw overlap add method.
So, we can run the code ok.
So, what is happened is it is unable to find the break point.
What I can redo is one way of doing it is I can go and then check.
work on the graph that is single time what was our variable some it was 512 was the samples and then I can because we have called it floating point we can represent in full floating point.
So, sampling frequency at present we will keep it at this and then I can give it as let us let me see samples is declared here.
So, you will be seeing I can make it full.
So, you are seeing some garbage in the thing.
So, what we will do is we will minimize this.
So, this is.
I can close this and you will be seeing some memory map.
why it got this thing that is it gone till the end of it.
So, that is why disassembly will be having a problem because it is unable to come back.
We will start computing on the board.
So, you will be seeing that there was error.
So, what we will put the thing main dot c as you can see that the breakpoint was removed.
Otherwise in the end what you have to.
put the break point.
So, we will decompile the thing, it is loading on to the board.
So, you have seen in the main it has entered the main function, you will be seeing the pointer program pointer is here.
So, we will see whether I have the breakpoint hopefully it will come up to this breakpoint we will look at it when I run the thing ok.
There is some abortion is happening it is unable to detect this breakpoint.
So, we will come back to this program little later we will start stop the thing and then we will go back to the.
other demo what I have it ok.
So, this is one of the student who has developed the FFT basically here it is for the 64 point.
So, you will be seeing that even the it is in the same way what the simulator has it has been developed.
So, you will be seeing that because I have put the break point here to see that because n means sometimes it will be.
going the handle is given somewhere.
So, whether it it would not be able to stop the thing.
So, we will see that whether the A 50 is using this method that is 64 point will be going through ok.
So, I will give the run command ok.
So, we can see that that is graph single time.
So, W is the thing.
So, with we will see what has been declared because this will be floating.
So, we will be declaring it as 32 bit floating point and start address will be W. Here also it is samples what it has been selected, we will select the thing and we will display it.
So, what you are seeing in the You will be seeing that there will be an error because the processor has got reset.
So, we will be coming back to this.
So, x1 of i will be the magnitude what it is going to be computed.
So, as you can see that there was because I had switched on the board little earlier there was a issue with the thing.
So, now, we are seeing that it has reached the break point.
So, this is how what you have to debug your code whenever there is a problem you can software reset or sometimes what you have to do is unplug the power supply to the board and then reconnect it.
In this case only have a switch actually reset button which I pressed it.
Now, we will do the plotting of it.
So, because it was giving me all garbage values last time.
So, we will be seeing that x of I think 64 points what we have it.
I will go to the this thing 32 bit floating point start address is x what I am interested in and then we will sorry it is x 1 not x that is why it was giving me an error.
So, you will be seeing that the peak.
has got generated.
So, what is the frequency?
You can see that what is the peak value of it what you are getting it sample somewhere around you can see that they have generated it as 10 hertz or something.
So, 9 hertz what will be getting it in this.
So, you will be seeing that this is the frequency we can go back and then check the thing.
This is what is it 64 minus what I am supposed to see 60 minus 7 or something we will cross verify and then come back.
What is the frequency we will see it sorry I forgot to check the thing.
So, what is it 10 hertz basically.
So, you are seeing that there is an little error what it has got generated that is what we want to see the frequency value is 10, it is coming somewhere around 9 or something like that ok.
The error with respect to whatever the computation.
So, this is how it runs on board.
So, we will go back to we will stop this and then.
will see directly whether I can compute my DFT.
So, here I have used the FFT to show the thing.
So, whether we can do directly DFT.
So, here what I have is FFT calculation again.
So, but I can go back to and then see that I can put individual this thing what is it.
.
So, .
So, DFT DFT dot c files to check in the same thing whether I am going to get my DFT and FFT correctly or not ok.
So, we have the this thing first what I will do is we will run this is FFT dot c is there.
So, you will be seeing n is equal to 128 point complex what you have this thing declared them and then you will be calculating just like your twiddle factors cos and then sine functions what you are keeping it and you will be using it and we will call the FFT of samples what you are going to pass it ok.
So, this will be your FFT dot H samples of FFT function taken from the book Rolfs Chasiang basically.
And, then dot h file will be defining all of them.
Let us see whether this is going to run because I have not tested it.
I will be testing in front of you.
So, we know that it has completed its running.
So, that means, to say that there are no errors in the code.
What it says is real input data stored in array samples.
So, you will be calling FFT function.
So, you will be seeing that it is going to give you a printf done and then we have to see these samples whether we have got it or not in our memory.
One is I can plot and then see how we have got the values.
So, you will be seeing that PIDL factors how it has been generated here.
So, you have.
had 0 to 99 and then 100 to 127 what it is showing.
So, in the this thing decimal or octal what you want to display it you can display.
So, one of the sorry fine.
So, it has entered into the main function what we will do is we will put up break point otherwise I will be losing the control on the thing I want to be in the same.
basically.
So, we will run the thing.
So, you will be seeing that input data stored in array samples what it says.
So, we will see thus I can view I can use the memory browser and then I have to enter the locations here.
So, we will give it as samples.
So, you will be seeing the samples in this what is it?
It is representing it as 32 bit hex.
Texas instrument style.
So, if you want to have it as this thing floating point 32 bit floating point.
So, you will be seeing that the samples are stored in this both you will be seeing that dot real and then imaginaries are 0s basically.
So, the real values have been stored in this case fine.
So, this is how you will be implementing and then you can do the IFFT.
So, to see that you have got back your what is the input what you have passed into the system.
So, what it says is test frequency is 800 hertz and then sampling frequency chosen as 800 hertz and then I should be getting here it is magnitude square function is not found out.
So, you can include your code and then check.
we are going to get the results correctly.
Otherwise what you are seeing is this one.
So, one thing what we what I can do is I can put the graph single time we will put it.
So, this is I will put it as I think number of samples I did not check the thing it may be 64 samples what it is generated.
So, we will put it as 32 bit floating point and then start address can be your this thing.
what we have is samples.
And if I want I can specify sampling frequency I know I can put it as 8000 frequency.
So, you will be seeing that the plot is coming.
So, you are seeing that one p cut here what is the value just it has to be little here somewhere around 25 point.
07 what you are seeing the peak ok.
So, this is what you are you will be seeing that if I calculate the magnitude absolute of it alone I will be getting the thing.
So, what we can do is I can generate the FFT of it let us see FFT magnitude alone what I want to have it.
So, I will give it as 6 hopefully it is 64 anyway.
Again I did not check how many points we have chosen the thing.
So, you can look at it.
So, I will be giving my sampling frequency is 8000 and then start address is samples.
You want to find the FFT magnitude of it.
It has taken frame size I will give it as 6 in this case also will put the thing.
So, you will be seeing some garbage output is going to come.
have to plot it basically.
Hopefully, samples dot real is not defined with the thing only I can select the samples.
So, what you can do is magnitude square function what you can calculate for this output of the samples and then see that your magnitude perfectly represented with 800 hertz what we are supposed to get the thing.
Because this is what this test frequency what it has been generated.
So, at what k value of you will be getting 800 hertz is a 1, 1 has to take it up fine.
One more what we can do is I can remove this fft dot c and then include a dft if I am required.
So, I will put it as add files.
So, I am showing you how I can use the same project file to run.
my different programs basically.
So, I have to select where my codes are lying.
So, I will be taking the LCDK book files and then I can versions CC 5 what I have it according to the chapters what you are going to have some of the codes.
You will be seeing that There is a DFT code also.
So, if you want directly you can take it or there are different codes what it is there in this directory.
So, you can use the that is world level DFT what you can use it and then normal DFT is there or FFT you can use or you can use the library which is present in the thing.
So, what we will do is we will include this file.
in the program.
I am copying it.
So, this is my DFTC dot that is L1386748 board what we are using it and then in this n is defined as 100.
Here also sampling frequency is chosen as 800 and 8000.
So, you will be seeing result and then real and imaginary.
So, x of k is going to get result function.
And, then this is your main function what you are passing it you are calling your DFT with samples and then you will be completing it.
One more thing you have to remember in when you are using a code composer studio that most of the variables if you have defined as a global variable just like C, then you will be able to what is that.
view them in the graph.
Otherwise if it is a local variables you may not be able to view them.
So, this is one thing what you have to keep it in mind.
So, you are seeing the complex samples is a global variable.
So, we can still viewing the thing.
So, these are the what is it how you will be calculating your these are my samples real whatever cause functions sampling frequency real my imaginary part is 0 and you will be calling.
DFT of the function.
So, we will do the running of it.
I can put the break point at the return.
So, that I am within the my leg of it.
So, your DFT is declared here as you can see complex comma x and then you will be.
computing directly here real part and then imaginary part separately.
So, you will be adding them up and then to the length of it.
So, your output is going to be in the result which you are giving back to your sample.
So, I can run this code.
So, you are seeing that it is holding on here.
So, what we can one of the way of doing it is I can look at the values here as you have seen the thing when you show in the red.
Those are the modified values what you will be looking at it compared to your FFT and here.
So, these are the little bit modified values what you will be seeing it.
So, that is one way of doing it in 32 bit floating point or if what is it samples is declared as complex and then we have a float basically.
So, I can give it as 32 bit floating point.
So, if you want to.
view the graph.
So, we can go to single time again and the number of samples I can give it as 64 and then it is going to be 32 bit floating point and start address will be samples.
You will be seeing that again your peak is somewhere around because number of points what I have chosen it is approximately 20 hertz what it has.
taken it ok.
So, can you make out what was the thing 800 hertz was my sampling frequency.
So, what was the number of samples what we have taken here is 8000.
So, where you are going to get your peak what you have to look at it fine with that we will stop.
this lab here if there are any doubts I will be open to solve your doubts.
Thank you.
Welcome back to real time digital signal processing course.
So, today we will discuss about overlap add method.
how to use our FFT in for the continuous time signal.
So, coming to the recap of it.
So, we have completed FFT, it is butterfly structure and then we have seen some examples using both DFT and then FFT.
So, how to use FFT in for overlap add method.
So, we will see some of the definitions.
So, we will see modulo indices and how it is going to be used for the periodic repetition.
So, as we can see here.
anything n with capital N is our length of FFT.
So, it is equivalent to N itself.
What does it mean?
That is mod of N is nothing, but remainder of N by N. So, in this case X of N if we have 4 samples.
So, we say that it is periodic with period 4, the repeated pattern will consist of what is it X of 0, X of 1.
x of 2 and then x of 3 and the length is n then we say that the repetition is going to happen after x of n minus 1 samples n is usually we take it power of 2.
So, as we have seen in the example n is equal to 4 what we have taken.
So, we have seen the repetition what it is going to happen.
So, we will see visually here n is going to vary from minus 4 to n.
8 is the long sample what we have taken and then small n which is going to repeat after 4 that is 0, 1, 2, 3 and then later on again 0, 1, 2, 3 and 0, 1, 2, 3 and then the last one is 0.
So, we say that n by n is nothing, but integer plus non-negative integer which is less than n divided by n. As an example, so because we have taken capital N is equal to 4.
So, the fifth sample what we have to take it then what is the thing is going to happen?
This is 5 by 4 which is nothing, but 1 plus 1 by 4.
So, this is what the integer plus non negative integer what we are taking it.
Here if it is minus 2 by 4, then the integer is going to be minus 1 plus 2 by 4, this should be non negative integer what we have to assume.
So, this is how we will be taking the modulo indices and then after that it is going to repeat.
So, what we are going to do with overlap during the periodic repetition.
So, we say that periodic repetition makes an aperiodic signal that is x of n. So, periodic to produce x tilde of n. So, there are two important parameters in this case that is the smallest support length of the signal x of n what we needed and period n used for repetition that determines the period of r x tilde of n. So, we call I.
smallest support length which is greater than period of repetition and repeating the thing i there will be overlap, i will be the smallest support length period of repetition and i there will be no overlap these are the condition there will be overlap and no overlap condition and x of n can be recovered from our periodic signal x tilde of n. So, how do we represent our x tilde of n is equal to i is equal to.
minus infinity to infinity x of n minus i n. So, i will be defined with these parameters.
So, to show that how the periodic repetition is going to be that is if we consider no overlap and then n is taken as 4.
This is our x of n then what happens to our the repeated signal.
at L is equal to 0.
So, we know that we have 4 samples here, then this is our x of n, then at L is equal to 1 it is going to be x of n minus n that is we are repeating the 4 samples.
Same thing at L is equal to 2 will be repeating x of n minus 2 n. So, that is what dot dot what we have it and then what happens on the negative side of it, it is going to be L is minus 1 it is going to be x of n plus n actually.
So, the 4 samples are repeated here same way and then all of them get added and then we will be seeing that there is no overlap the support length what we have taken is 4 is which is equal to n. So, our x tilde of n you will be seeing that this is the x of n and then this is l is equal to 1 and this side l is equal to minus 1.
So, you will be seeing the repetition of it this is the.
periodic repetition what is shown pictorially.
So, coming to if there is a overlap that is periodic repetition how it is going to look what we will see it here.
So, here also taken as n is equal to 4.
So, what we have is our x of n sample has 6 samples in this case and then we are taking n is equal to 4.
So, initially what we have is 6 samples.
at the 0 basically then x of n is put in since it is repetition what we have is n is equal to 4 you will be seeing that there is a overlap on the positive side as well as on the negative side.
So, you are seeing that there are two of them have been repeated on this.
So, you will be seeing that they are overlapping even here it is going to overlap.
Then what happens to our x tilde of n.
So, we say that support length is 6 which is greater than n then we will be seeing that because we are adding them up.
So, you will be seeing in the magnitude which has got increased with these two samples the other two samples remain same.
So, you will be seeing that this repetition is going to happen on the positive side as well as on the negative side.
So, one has to keep it in mind that how the periodic repetition is going to happen.
have a overlap when our length is greater than our n. So, coming to the thing we will see that how we are going to have the periodic repetition once again what you will be seeing the thing.
So, you have x of n here.
So, then what is the thing is going to happen only we are taking the samples here which are length 4.
So, you will be seeing that the magnitude of them is 2101.
And, then x of n has support for n is equal to 0 to n minus 1, then our x of n capital n will be it is n mod n what will be taking it as x tilde n which is given by the equation i is equal to minus infinity to infinity x of n minus i n. So, how this is going to be represented?
So, this is our x of n this is what we have taken the thing.
So, when we do the repetition you will be seeing that modulo of n is going to be 2 1 0 1.
So, because the support size and period size are the same there is no overlap when taking the periodic repetition of our x of n. So, you will be seeing that it is same.
So, now, coming to the this thing modulo indices same thing periodic repetition how it is going to look like what we will be seeing with the thing.
So, you will be seeing that the same.
values have been taken 2 1 0 and 1 and then when we take the module of it.
So, you will be seeing that it is going to go in the 0th here then minus 1 will be this is the way and then 1 next what will going to have the thing.
So, it will be repeating the value at different intervals what it is shown here.
So, which is shown again in this manner.
So, from here to here what will be going from here to here and from there.
we can show it pictorially that this is the way what we are going to represent in the periodic of form.
So, that is x of n modulo n is nothing, but our repetition x tilde of n which is shown there.
So, from here what you can draw your diagram as x and y coordinates repetition of x of n in this manner.
So, now, we have to look in for the circular convolution.
So, you must be remembering we have taken some examples and then we repeated the computation of the circular convolution.
So, there are 2 interpretation the first interpretation what we will see it.
So, we are assuming x 1 and x 2 have support n is equal to 0 to n minus 1.
Then take the periodic decryption of our x 2 of n with period n we are assuming both are of the size n in this case.
Then what happens it is going to be k is equal to 0 to n minus 1 x 1 of k into x 2 of n minus k.
modulo n what we are going to take it or we can write it x 2 of k into this thing modulus of r x of x 1 basically here.
So, both are the same thing.
So, we can use any one of them.
So, conduct a standard linear convolution of x 1 and then x 1 and x 2 tilde n for n is equal to 0 to n minus 1.
So, we remember that circular convolution has the symbol like this x 1 and convolved with x 2 of n.
or the other way round what we will be seeing it x 1 of n convolved with our distinct linear convolution x 2 periodic tilde of n what we can give it which is same.
So, this is the equation.
So, what we have it?
So, we will be seeing that this is minus infinity to infinity.
So, we cannot compute in our hardware.
So, it will be reduced from 0 to n minus 1 x 1 of k into x 2 tilde of n minus k.
So, what happens to the circular convolution of it?
It is going to be 0 for n less than 0 that is what we have assumed and n greater than or equal to n this is what we have given the equation.
So, that is it makes sense that is what we take it.
Since x of n modulo of n is nothing, but our repetition x tilde of.
So, another interpretation is what is it?
So, they have the support of 0 to n minus 1.
So, we are going to take the periodic repetition of x 2 of n with period n in this case.
So, you will be seeing that x 2 of n minus k n and then we conduct the linear convolution instead of circular convolution we will be doing the linear convolution of x 1 and x 2 for n. Then what happens x l is represented as the linear convolution of n is given by X1 of n linearly convolved with X2 of n. So, equation what you are seeing minus infinity to infinity.
So, which is going to be reduced to k is equal to 0 to n minus 1 for the implementation X1 of k into X2 of n minus k. So, compute the periodic repetition of your XL of n and window the results for n is equal to 0 to n minus 1.
So, you will be doing X1 circular convolution is equal to X2 of n.
x 2 of n which is nothing, but are a is equal to minus infinity to infinity x l of n minus i n for n is equal to 0 to n minus 1.
So, what are the two methods?
First we can do the circular convolution by taking the module of one of the signal or we can do the linear convolution of the signal and do the circular convolution at the output that is what it is shown.
So, we know that filtering of long data sequence how we are going to use our FFT.
So, as we have already discussed we have n is equal to 8 and 8 point FFT is given by this butterfly structure.
So, you have seen the thing.
So, if it is 16 you can extend it and 32 and so on.
So, it is easy to write n is equal to 8.
So, which we can use it.
So, how we are going to take care of the long data sequence that we want to filter it.
We say all n input samples are required simultaneously by the FFT operation.
So, complexity of n in FFT is what we have taken n log 2 n basically.
and if we use a symmetry property it will be n by 2 log 2 n. So, if n is too large as for long data sequences then there is a significant delay in processing that is precludes our real time processing that is we are going to have a time constraint on the thing because we do not know the length of the signal which is going to come continuously in real time.
So, how we are going to take care of this we cannot have as long as.
we want.
So, then what we do is we give the input signal here, we get it from the data acquisition delay what we are going to consider and then we will be adding our data processing delay also.
This is acquisition as well as processing, then we will be giving the signal out.
This is our real time processing what it is going to happen.
So, we will see the thing.
So, for the first case today what we will consider is the overlap.
method.
So, the next class we will come consider the overlap save method.
So, what is it?
Overlap add method.
This is going to deal with some of the signal processing principle what it is written here.
So, what is it?
We are going to have the linear convolution of a discrete time signal of length l what we are going to restrict and a discrete type signal of length m where what we are going to get the output is l plus m minus 1.
So, that is we are using the additivity property here x 1 of n plus x 2 of n convolved with our h of n is going to give us x 1 of n convolved with h of n plus x 2 of n convolved with h of n. So, that is what we are looking at it.
So, now we will see the thing.
So, what we have is input x of n is divided into non overlapping blocks basically.
and x m of n each of length l what will be considering in this.
And then each input blocks x m of n is individually filter as it is received to produce the output block y m of n. So, you will be seeing as a picture really here.
So, you are considering l is equal to 1 first that is the length in this case is n is equal to 4 what it has been taken.
So, this is the first length.
which is going to be convolved with h of n. So, the other length what we will be considering is l is equal to 4 sorry l is equal to 2, 3 and then 4.
So, in this whatever x of n signal so, we have 4 l basically.
Now, what we have done the thing so, we have separated according to the length.
So, I have 4 values in this we will do the convolution of it and the next one.
is convolved with H of n is convolved with X 2 of n then later on as you can see it we are adding with the previous one.
So, the next one is getting added with the X 3 of n. So, you will be seeing that these are the 4 samples which is in X 3 of n which is getting convolved and then you will be going on till you finish your input or if it is continuously coming this is the process which is going to be repeated for.
So, what is the filtering stage?
So, we make use of that is N DFT and N IDFT where N is the length of our this thing DFT or FFT length which is going to be L plus M minus 1.
And then we are going to do the zero padding of X of n and H of n so that are of length.
L what we call it, M is less than N is required in this case.
So, the actual implementation of the DFT IDFT will use the as we know that for fast Fourier transform what will be using it and then inverse fast Fourier transfer for computational simplicity.
So, how we are going to use the DFT for linear convolution.
So, first we are going to take XM of N.
which has the length 0 to L minus 1 and H of n is the other length which has the support n is equal to 0 to M minus 1.
So, we set that is in this case one of them is the signal H of n if it is the filter case we will be seeing that if it is a FIR filter we will be having the b coefficients the basically or H of n can represent the coefficients of the filter.
So, this is one length the other one is L length input length.
length, then we set n is greater than or equal to L plus m minus 1 that is the length of linear convolution result and 0 pad are x m n and then h n to have support for n is equal to 0 to n minus 1.
So, in the lab class we have seen that how we can do the 0 padding even two problems what we have taken how by 0 padding we can make it same length.
and then do the FFT on the two signals.
So, then what we are going to do it?
So, we are going to take first N DFT of X of M to give X M of k, k is varying between 0 to N minus 1 in this case.
And then the next one is take N DFT of H of N to give us H of k which is k also will be between 0 and minus 1.
Then we know that in the frequency domain when we have two DFTs it is only the multiplication between the.
2 signals that is y of y m of k is nothing, but x m of k into h of k for k is to 0 to n minus 1.
So, once we have done the multiplication we know that the result is available then we can take the IDFT, n IDFT of y m of k to give our y m of n. So, you must be wondering why we have to do all these things why not sigma.
So, in the last class we have seen that with the 512 points DFT computation cost and then FFT computation cost and what the frequency will be achieving although we are doing this four times basically or three times we call it because NDFT 2 of it and NIDFT cost is same basically and in between we have to do the complex multiplication in spite of the thing our computation time or the.
frequency of operation is higher than the normal DFT and even which is equivalent to our linear convolution.
So, now, we will see how we are going to do this linear convolution by other DFT.
So, length of linear convolution result is equal to length of DFT what we are going to get it.
So, this is our 4 samples.
So, we are repeating the things same 4 samples on both the sides left and then right hand side and we have assumed.
there is no overlap and then we have assumed support length is 4 which is n is equal to 4 and we can see that here x of n what we have is the 4 length and then the repetition on the r x tilde of n. So, now, we will see how we are going to overlap at addition stage.
So, from the additivity property since our x of n is equal to x1 of n plus x2 of n plus x3 of n you can go on.
So, which is nothing, but m is equal to 1 to infinity xm of n. So, this is what we have the convolution.
So, we will be using x of n convolved with h of n which is nothing, but x1 of n plus etcetera total going to be convolved with h of n or because of the our additivity property.
So, we can do them.
So, that is x m of n convolved with h of n, m is varying between 1 to infinity and then what we call it as summation of all of them individually done x m of n. So, we will be adding all y's basically that is n is equal to 1 to infinity y of y m of n will be giving us the complete overlap add output.
So, as we can see the thing here.
So, this is the length what we have it we are going to convolve with H of n and will be generating the linear convolution.
So, we know that it is going to give us L plus M minus 1 length here.
So, that whatever this extra M minus 1 samples that is we call it as which is going to be in connection.
we will be discarding them ok or we can take it to the next one and then use that is add to the next block basically.
So, this is first y 1 of n and then these two are going to be added to the next block and then we will be making it as l is equal to 4 length here as you can see the thing.
So, two samples will be coming from there these two are from m minus 1 which is 2 will be from.
this block what will be coming and then we will be using that to compute our here also y 2 of n and then later on it is y 3 of n. So, you will be adding these two samples as you can see that they are getting repeated in successive that is the m minus 1 samples are repeated in the next blocks for our computation.
So, we call y of n is nothing, but x of n convolved with our h of n.
So, thus support overlap amongst YM blocks must be accounted for that is what the one has to keep it in mind.
So, how the thing is going to happen we have this figure shows in I think that was little small.
So, you will be understanding the thing this is my complete input.
So, we have bifurcated into L chunks of them as you can see it.
We call them as X1 and X2 of n.
So, you are seeing from this m minus 1 what will be adding as 0s in this case and here also will be adding m minus 1 0s.
So, you will be seeing that you are adding m minus 1 0s with x1 of n, x2 of n and then x3 of n. Then what will be our output?
This is y1 of n and add this m minus 1 0s to this one.
that is you will be appending on the y 2 of n and then we have on the other side also m minus 1 0s.
So, this one is going to be added m minus 1 0s with y 3 of n and so on what will be having the output.
So, we have overlap add method how it is going to work what is shown in here algorithm what it has to be written.
So, what is it?
First break the input signal x of n into non-overlapping blacks of x m of n of length l. And then we are going to do the 0 pad h of n to be of length n is equal to l plus m minus 1.
And then we take n DFT of h of n to give our h of n basically k is equal to 0 to n minus 1. h of k here.
for k is equal to 0 to n minus 1.
So, for each block M we are going to 0 pad x m n to be of length n is equal to same thing l plus m minus 1 and then we are going to take n d f t of x m of n to give x m of k here for k is equal to 0 to n minus 1.
So, multiply y m k.
with x m of k what we have got it here with that of h of k. This should be h here, h m of n to give our h m of k. Then these are the two signals what we have taken the DFT and then we will be multiplying it and then take n I DFT of y m of k what we have got it to give y m of n for n will be because n was DFT n will be varying between 0 to.
n minus 1.
So, then the fifth step is form y of n by overlapping the last m minus 1 samples of y of m y m of n with the first m minus 1 samples of y m plus 1 n and adding the result.
So, this is how we will be doing it.
We will take up an example and then show that how we have done the overlap add method.
Thank you and in the next class we will cover overlap save method.
So, both of them should give us the same results.
Thank you.
Back to real time digital signal processing course.
So you can see that we are going to discuss the fourth part of IR filters today.
So, why FIR has not taken so much of time, why IR is taking you will be seeing in a while although we have already seen that quantization how it is going to affect.
So, in today's class we will work out and then see how the center frequency is going to move from with the coefficient quantization from one value to the other one.
So, as a recap so, we have been seeing the theory of IR filters and how to design them and then how the cascade.
filter section is going to aid us to implement in DSP processor.
Just to comment on it so, we know that cascade section is nothing, but it is a multiplication.
So, in DSP processor we have seen in the number system that when we do multiplication of 2 numbers the overflow is not going to happen.
Only if we have to do the addition we have to take care of overflow and then underflow.
So, the parallel section is equivalent to.
So, that is the reason why we will not use parallel structure in case of IR filter design for this hardware units.
So, usually we go with the cascade realization although both cascade and then parallel section have the same effect on the design.
According to the thing so, we will see that how we will be seeing.
So, what happens what is our transfer function is going to look like.
So, we are going to design a bandpass IR filter to be used in our digital clock recovery for a 4.8 kilo bits per second modem what we are using it which is characterized by the following transfer function.
So, you have been given your impulse response h of z is equal to 1 by 1 plus a 1 into z minus 1 plus a 2 into z minus 2.
So, it should be triggering in your mind that this is just a second order design what we are doing it.
So, in this case you have been given the values of a 1 and then a 2, a 1 is given as minus 1.957558.
And, a 2 is given as 0.995813.
So, you this your a 1 and a 2 can be designed from using MATLAB or this value has been computed and then you have been given in this equation.
So, assuming in this case because we are using in the clock recovery sampling frequency of what we are telling is 153.6 kilohertz.
to assess the effects of quantizing the coefficients what we are going to do to 8 bits that also you have to keep it in mind.
So, if you want to increase it to 16 bits you can do it and then verify what will be the centre frequency which is going to remain that is what one of the assignment what I will be putting it for you.
So, then we have to say that how the pole positions is going to affect our this thing centre frequency.
So, we will do that.
So, as we know that we have the equation how to calculate our p 1 and then p 2 value.
So, p 1 is my this thing pole position of the first one which is given r at an angle of theta and then p 2 is given at an angle r at an angle of minus theta because we are designing the complex conjugate poles in this case.
So, we had the equation that r is equal to a to the a 2.
to the power of half and then theta is given by your cos inverse minus a1 by 2r.
So, in this case how do we compute r?
So, we have been given the value of a2 as you can see a2 is given as 0.995813 which we are going to take it as square root of it because that will give me a2 value.
So, we are going to get 0.99795 what I will be.
getting it here.
So, that is r squared is a2.
So, r will be square root of a2 what you are going to have.
So, theta is going to be cos inverse a1 divided by minus a1 by 2r.
So, we know that a1 is negative.
So, that is the reason why you will be seeing positive here this is 1.957558 divided by 2r.
2r is going to be whatever what you have computed here.
So, will be.
into that which gives me in terms of degrees as 11.25 degrees fine.
So, this corresponds to a centre frequency of 4.799 kilo hertz.
So, what do we mean by that?
So, we know that this is my unit circle.
So, this is my centre.
So, we are calculating r here.
So, this is r at an angle of what we call it as zirc.
So, 11.25 degrees you have the pole ok, this is 11.25 degrees.
So, when I calculate center frequency that what we are going to do is this is my sampling frequency what it has been given and I know its degrees 11.25 degrees divided by 360 degree which is going to give me the center frequency.
So, for this it is at 4.799 kilo Hertz is the center frequency.
it is in the original state what we will call it.
Now, what you have been given in the problem is we have to quantize the coefficients to 8 bits that is what our constraint as one of the coefficients is greater than unity.
So, you will be seeing that a1 is minus 1.957558.
So, we need at least one bit to represent my coefficient in the integer format.
So, what will be the representation here?
So, we can in the normal case we say that it is Q15 format is 1.15 format for 16 bits number.
Here you have been given 8 bits basically.
So, normally if we allocate all the 7 bits, 1 is the sign bit and rest of the 7 bits then I will be talking about 1.75 or 1.7 format, but since my integer value is greater than 1.
So, I need 1 bit for my integer.
So, what happens to this?
will be representing it as 2.6 format.
This is the format what I need to represent this value.
Then what happens?
I have 6 bits for my fractional representation which I have to convert it.
So, my coefficient from a1 it is going to be a1 dash what I will be putting it minus 1.957555 into 2 power 6 which is equivalent to I will be rounding off or truncating one of the thing what you can do it.
So, which comes out as minus 1.2 minus 125.
So, if you represent in binary this is the value what you will be representing it.
So, coming to a2 dash.
So, which is given as minus 0.995913.
So, into 2 power 6 which comes out as 63.
So, it may come out as 63.5 or 63.6 exact value you can check the thing.
So, why we are representing this also in 63 I will hold on for a while we will come to that.
This is your binary representation basically fine.
So, now we will go back and then recalculate what are the values we have got it ok.
So, my maximum value what is it 125 for a 1 what I have represented in with 8 bits, then we said that it is 2 power 6 is nothing, but 64.
So, I can re divide the value and calculate what I am going to get it.
So, it becomes 1.953125.
So, what was the original this thing 957558.
So, you will be seeing that there is a quantization which is.
already happened.
Even A2 you can see that we are doing 63 by 64 which comes down to 0.984375.
So, what was the original one was 0.995913.
So, now, with this modified calculate your centre frequency apply the same equations as the previous one we call that as r dash and theta dash what we will be calculating.
So, you are seeing that from 11.54 degrees it has come down to 10.17.
So, if you want to round it off to 2 digits it is going to be that degree.
So, now calculate is your f naught that is the centre frequency.
This is what you will be getting it 10.17 divided by 360 into 153.6 into 10 power 3 because it is in kilohertz.
So, you can see that this is going to be 4.3399 kilohertz.
So, what was our original thing?
It was 4.799 kilohertz.
So, you will be seeing that.
your centre frequency has moved what we call it as centre frequency in this case is where I am dropping down.
This is we usually call it as my cutoff frequency fc ok.
So, you will be seeing that your think from 4.799 it has got moved to 4.3399.
So, you will be seeing that.
your thing has moved to left.
So, you are allowing more whatever we call it as in the stop band region.
So, that if there are going to be some aliasing.
So, it may creep into the thing.
So, this is the effect of moving quantization basically.
So, now I said I can take R is equal to 1 ok. What happens in that case?
So, we recalculate So, we have calculated and only we are giving the final thing.
So, you will be seeing that what happens to your theta dash it becomes 12.43 degrees and f naught becomes 5.303 kilohertz actually in this case fine.
So, what happens?
This is f c, this is I call it as f c dash and this I can call it as f c double dash.
So, this will be coming to.
5.303 kilo Hertz here if it is represented in kilo Hertz fine.
So, my fc double dash.
So, you will be seeing that more frequency will be coming into your input and then you will have a problem.
Here you are going to reduce the thing if there are any frequency component present in this thing is going to be cut off whereas, here more frequency has come in.
So, you will be having the aliasing effect.
So, that is the reason why.
We choose r is equal to 63 in this case.
So, which is almost nearer to our 4.799 compared to going beyond the frequency.
So, this shows that how your number of bits is going to affect.
So, now, you can calculate n is equal to 16.
So, what is the frequency?
How much difference you can get it?
You can calculate and then give the result ok.
Continuing with the thing.
How the next one is what is the word length requirement for stability and desired frequency response what we have to say.
So, our stability discussions will be restricted to second order filter sections because each individually if they are stable then we say the complete IR filter is stable.
Since these are the basic building blocks of any filter and consider our second order section characterized by the familiar equation what you are seeing it here.
That is h of z is given by b naught plus b 1 z minus 1 plus b 2 z minus 2 which represents our 0s divided by 1 plus a 1 z minus 1 plus a 2 into z minus 2.
So, a 1 a 2 are pole positions.
So, in the equation what you will be getting is y of n is k is equal to 0 to 2.
So, b k into x of n minus k this is our 0 representation minus.
are pole position that is feed this is the feed forward section and this is the feed backward section.
So, we know that poles are the roots of the denominator are located at what we call it as p 1 is equal to half minus a 1 plus a 1 squared minus 4 a 2 to the power of half or square root of a 1 squared minus a 2 and p 2 will be the complex conjugate.
So, of p 1 what will be representing it.
So, what happens in this case?
A digital we will take up an example, a digital filter required to that is satisfy the following frequency response specifications, determine a suitable transfer function for the filter and then determine a suitable coefficient word length to maintain stability and satisfy the frequency response specification.
So, you will be taking obtain and plot the frequency response of the unquantized filter Those of quantized filters corresponding to this part basically, how you will be number of bits what you will be considering.
So, what is the specification what we have?
Pass band region is given by 20.5 to 23.5 kilohertz and then stop band is given.
So, you will be seeing this is a band pass filter basically.
So, how it is represented?
This is the way I represent it.
And then this is given as 20.5 to 23.5 kilohertz.
Till pi by 2 it is going to be your stop band region in this case 25 to 50 kilohertz.
And then ripple what you want is less than or equal to 0.25 dB and then stop band attenuation what I want is greater than 45 dB.
So, as you know that it is better to design this filter using MATLAB and then get the values of your coefficients basically.
So, when you do that this is from the book I have taken the example.
So, you can refer to the book and then see CD of the book is going to give you this example.
This is basically from if Iker what I have taken the thing real digital signal processing book.
So, in this case what happens it generates as in the lab we will be seeing it that how many sections it is going to create.
So, here there are 4 second order sections which has been created and then using their and then poles you will be representing your impulse response like this h 1, h 2, h 3 and the h 4.
So, you will be seeing that this is in a cascade form basically.
There will be 4 sections what I am going to have.
This is my h 1 of z, h 2 of z and then this is h 4 of z.
So, these are the values what you will get it.
So, you have to take each second order section and then see whether there is going to be overflow or underflow or what is the number of bits what you needed.
So, that you are going to have the stable filter as you can see in this case.
So, you will be varying your number of bits that is 2 to 2 comma 3 like that you can keep on changing and then you can go up to 29 bits.
So, that is what the theory gives basically.
So, we will work out for H1 of z.
So, what is the number of b bits we will assume because even in the previous example we had taken 8 bits.
We will see whether it is going to give us a stable filter.
So, you will be seeing that A1 will be because all the coefficients are less than 1.
Now, what I can represent this as a 1.7 format.
That is why you will be seeing multiplication by 2 power 7 is happening and then we are doing the rounding that is the reason why we are adding 0.5 to that.
So, the value is going to be minus 22.8104 after that we will be truncating the value.
So, which is going to give us minus 22, same thing we will calculate a 2.
So, it will be giving us 124.1736.
So, you will be truncating here which is going to give us 124.
So, the fractional notation the coefficients are nothing, but minus 22 divided by 128.
So, this is in decimal value.
So, when I represent it in fraction, so it will be giving out as minus 0.1718.
So, you have seen I think something triggering in your mind.
So, the coefficient quantization has already happened with 8 bits, 1 point 0.1742, 0.171 what it has got reduced in this case.
So, A2 will be becoming 0.96875.
So, original was 0.9662.
So, you have seen that it has got because we have taken a round off it has got 0.96875.
little bit increased compared to the original one.
So, with this you can go back and then calculate your r and theta value and see that what we are going to get is 84.99 degrees what we are getting it.
So, what it says is the all quantized coefficients and polar coordinates were computed using an analysis program.
And, if for any coefficient word length the pole radial distance of a filter section is equal to or greater than unity, then there is potential instability that is what the literature gives.
And then it was found that all the filter sections as few as b is equal to 5 bits are required to maintain our stability.
So, in general if the pole of an unquantized second order section is at radius less than So, is more used in this case ok.
So, to see that B coefficient of second order section where each quantized to various word lengths.
So, you have to use your MATLAB code to do these things and then you can vary your word length 5 to 16 bits and then how they are going to be represented is given in the table here.
So, this is my poles.
that is a coefficients and this represent 0s that is b coefficients for 5 bits what we want is ideal is this one and then with 16 bits how almost closer what we are as you can see that most of the 16 bit is closer to the original one what we say it.
So, this is how we will be calculating and then fixing our number of bits that is the something should be triggering in our your mind all DSP processor most of them are 16 defined.
And then we have to this is one of the this thing quantization of our coefficients how it is going to vary the thing.
Next is we have to take care of overflow errors and their effects based on it what we have to decide on it.
So, we know that in two's complement arithmetic the addition of two large numbers of a similar sign may produce an overflow.
If it is beyond our representation we are going to have a overflow.
So, that it exceeds the permissible word length and then very large negative number if you are adding them negative numbers you may have a underflow in that.
So, these are the two things what you have to look at it, what is that we will see in the figure what is the thing happened.
So, the value is getting added here from here to here it has gone to the positive value we will assume.
And, then what happens?
So, when my number of bits are not sufficient immediately drops down to the negative value.
And, then again it start building up once it reach the peak value it is going to drop down.
So, this is how it will be oscillating between minus 1 and then 1 if this overflow or underflow is not taken care of.
So, what it says is.
Large scale overflow occurs at the outputs of the adders and may be prevented by scaling the inputs to the adders in such a way that outputs are kept low, but this is at the expense of reduced signal to noise ratio.
Because you are bringing down your amplitude of the signal then my signal to noise rate ratio is going to have a effect on it.
So, that is how it is important to select scale factors to prevent overflow while at same time maintaining my largest possible signal to noise ratio.
So, coming to the thing you will be seeing that overflow illustration is shown in this figure.
So, you have b naught, b 1, b 2 are the forward coefficients and then a 1 and a 2 are the feedback coefficients.
So, those both minus a 1 and then a 2 and what is the scaling factor we will be providing it.
So, this section if I am correct taking it up it is going to be scaled by 1 by s 1 at There are different places where you can do the scaling whether at the input or at the output or if you are providing any of these sections you have to integrate into all the arms basically to take care of that you have scaled everything fine.
So, as you will be seeing using the MATLAB when you are doing it the scale factor is given in the beginning itself.
So, that has to be used and then.
your filter has to be designed.
So, what is the principle of scaling?
So, first we will consider the canonic section because this is the one most widely used in all hardware implementation that is what we are seeing it.
As I said that it is scaled by 1 by S1 and when we want to get back of our Yn either I can scale up here or provide at these legs ok.
So, if I take the scaling factor inside as I was mentioning in the original thing this is going to be b0 by s1 and b1 by s1 and then b2 by s1.
When we are loading our coefficients itself if we want we can scale them if they are power of 2 if they are not then you will be having little computation.
involvement in designing your FIR sorry IAR filter.
So, you will be seeing that in the end what you can do is I can scale the output by S1 value ok.
So, you will be seeing that what are the principles to use the scaling.
So, most of you would have heard of what we have norms basically it can be L1 norm, L2 norm or L3 norm.
L infinity are the 3 norms what we have in literature.
So, what is that first we will see the L1 norm we call it as scaling by as S1.
So, here it says k is equal to 0 to infinity.
So, I am going to take the frequency response of my input and take the magnitude of it and then calculate the summation of all of them.
So, as it says f of K is the impulse response from input to the output of the first adder that is W of n in our figure here.
This is what I will be taking the impulse response of that.
And then in the second method often we usually call it as L2 norm, the scale factor is calculated this way.
So, if you want you can call it as S2 here or you we can have it as S1 is the scaling factor what notation what we are using it.
So, in this case.
You will take the impulse response, but you will be taking the square root of the value what you have sum sum value what you have calculated.
So, that is what it says scale factor may be obtained using contour integration via the relationship.
The last one L infinity norm what you are going to do is k is equal to 0 to infinity what I have to calculate f of k impulse response.
So, which is given as 1 pi.
2 pi j this is the L2 norm what we are doing with the contour integration as you can see it integral of f of z into f z minus 1 this is a complex conjugate what I have taken the thing dz by z where your f of z is that z transform of your f of k impulse response and this is represents our contour integral around the unit circle magnitude of z is equal to 1 basically.
So, evaluating this is much easier.
So, if you want you can go to the book and then refer to the steps involved in deriving this equation final equation in terms of your poles basically what it is calculated.
So, you will be calculating the contour integral of your poles in conjugate form dz by z.
So, if you do the simplification of it what then simplest one you will be getting it is 1 minus a to square minus a1 square into 1 minus a a2 divided by 1 plus a2.
So, this is how one can manually calculate our L2 norm using this.
So, in method 3 we calculate peak amplitude of the frequency response between the input and then W of n that is we will be taking the Fourier transform and then the peak amplitude whatever it has it.
So, we will be giving that as our scaling factor.
So, these are the underlying methods what we have it.
So, you can read the theory compact way of expressing the scale factor what we call it as S1 is our L1 norm what we have it with P. So, you will be seeing that we this is represented as norm and the method what we are going to have it is L1 norm, L2 norm are in L infinity norm.
And then how the scaling factors are going to get themselves aligned or compare what we will be seeing it.
So, L2 norm is the minimum and then next comes the L infinity and then L1 is the maximum what you would have scaled.
So, the value of L2 is less than your L infinity which is less than L1.
So, we will take up an example and then see how we are going to calculate this.
So, in the book it says that the figure whatever in 13.19 is been used.
And then we have this is our second order section for the example.
Then what is the thing is going to happen?
So either using flow diagram what you can flow analysis you can use the thing or you can use the book if you are using the thing CD which is the companion which is going to have it.
So, you will be getting these codes for this program and then you can run it.
So, you can evaluate all the equations.
in your book and then get the scale factors for 3 methods which it is computed and then you will be seeing it.
So, for the L1 norm it is 3.7112 and for L2 norm it is 1.7352 and then L infinity 3.5863 what you will be getting it.
So, one of the thing what we can compute we know that we have the equation to calculate our L2 norm.
So, which is given as S 1 squared is equal to 1 by this your a 1 and then a 2 what you will be substituting and calculate.
So, when you calculate it S 1 is coming as 1.7350.
So, which is closer to whatever the software has calculated the thing.
So, this is how you can do that.
So, the thing is given as your b naught b 1 b 2 and then this is the diagram what you have it for the example there and then see go and then look at them.
So, if you are realizing the scaling factor for cascade realization.
So, you will be seeing that each one has to be calculated and then how you will be rescaling back in the in between what you can see it one of the norms what you can use that fine.
So, this is how you will be selecting it.
So, one of the ways either you can have the division done when you are storing your after multiplication before summation you can scale them and then do the addition that way you will be.
avoiding your overflow instead of adding them and if there is a overflow and then dividing it later.
So, you can provide the scaling factor at this itself.
So, this shows for the sixth order I R filter how you will be doing the scaling part of it and then the final one you will be multiplying only by S3 whatever scaling you have done.
So, you will be accounting for S3 and then you will be sending the output y of n. So, this is what the S2 and S3 for the figures you can So, these are the cascade section H1, H2, H3 using MATLAB you can calculate them and then you can get the thing.
So, if you use your FWS program, so the solution you will be seeing that L1, L2, L infinity for the 3 sections what it is calculated.
This given in the thing L2 is going to give you the minimum this thing scaling factor and then the maximum is L1, L infinity lies in between.
The simplest method to calculate is L2.
So, if your application is going to overflow and then you are going to get results malfunctioning then better to go with one of these norms L1 or L infinity which is going to suit your application.
So, just the last slide to wind up our IR filter.
So, we will be seeing the comparison between our FIR and IR filter.
Few of the parameters what you can see the thing, one or two I will specify and rest of it you can go through.
So, that is sensitivity to filter coefficient quantization.
So, it can be as high it says in Motorola they use the 24 bit coefficients to for high fidelity audio function in their processor.
Otherwise all TI or analog devices they use 16 bit for their number representation.
So, in the case of we know that IFR filter it is very low and it says 16 bit coefficients are safely represented or computed.
using that.
And then probability or overflow it can be very high in this case, which is going to be very low and coming with our linear phase, we do not have IR filter direct method to implement it, but nowadays over the IR filter you can try to impose the linear phase.
So, using software techniques, so you can go through the MATLAB functions.
So, otherwise they do not provide the linearity of the phase, whereas it is guaranteed.
And rest of the thing what you will be seeing it, one of the example will be supporting supports adaptive filtering what it says.
So, I have both of them support adaptive filter.
So, we will be considering it in the next after few classes later.
So, coming to the end of it which finishes our filter design.
So, we will be taking our DFT and then FFT in the next class.
So, thank you for listening to this lecture and then happy learning through this media.
Thank you.
We come back to real time digital signal processing course.
So we have discussed about DFT in the last class.
Today we will try to cover.
So, to have a recap we discussed about discrete Fourier transform in the last class and then how to use that for circular convolution.
To give a flavor of it so, we will see the resolution what we discussed how the interval R resolution in the frequency domain is going to get affected whether it gets affected by padding 0's or not what we will look at it.
So, what we have here is how to check the.
frequency domain resolution.
So, we call f as the resolution which is approximated as 1 divided by n times t. We call this as hertz, t is a sampling period and then n is the number of DFT points what we will be taking it.
So, which we can give it as delta f as the resolution named with f resolution then we will be having n into delta f resolution.
So, this is the time period between two samples.
So, which is nothing but 1 by t which is nothing but FSR hertz.
So, what does it say frequency resolution is determined only by the length of the observation interval that is what we call it as n here whereas, the frequency interval is determined by the length of the sampling interval.
So, increasing the sampling rate.
It means that expand the frequency interval and increase observation time which will help our improving the frequency resolution.
So, zero padding does not alter the frequency resolution.
So, because resolution is going to be determined by the length of the observation interval that is whatever n what we have chosen and zero padding does not increase this length.
So, to show this so one can run MATLAB.
equation to see that how it is going to affect the resolution.
So, we will take two complex signals with close frequencies that one is with 10 hertz and one F 2 with 12 hertz sample with the sampling interval t is equal to 0.02.
So, it is going to be approximately 50 hertz.
So, consider various data length n is equal to 10, 15, 30 and then 100.
and we will pad these n with rest of the values as 0.
So, that it becomes 512 points and then run it in MATLAB.
As you can see for n is equal to 10.
So, which is what is the frequency we are going to have f 2 minus f 1 is what we have is 2 hertz.
So, what is our resolution it is 1 by n t.
which is equivalent to 5 hertz.
So, hence these two signals are not bifurcated as you can see only one is shown.
So, as this thing what it is showing 10 times this basically as a 10 hertz thing.
So, you are seeing it as 100 here in this.
So, coming to the next one when we substitute n is equal to 15 in your algorithm and then run.
Still, if this is not resolved why because our 1 by n t is equal to 3.3 hertz.
So, that is the 2 hertz is less than the interval between the 2 samples.
So, still you represent your 10 and then 12 as approximately 10 hertz itself and coming with n is equal to 30.
So, partly as we can see it is resolved.
So, we are going to see 2 peaks in our.
DFT domain with n 30 samples and then rest of them are 0 padded to make it 512 points.
So, it is what is it our resolution 1 by n t which is equal to 1.7 hertz.
So, you will be which is 2 hertz is greater than this.
So, hence you will be seeing 2 waveforms peaks here which is appearing.
So, when we go to n is equal to 100.
So, you will be clearly seeing them 2 peaks ok.
So, it is dropping down to 0 and then again raising.
So, this will be at 10 hertz and this will be at 12 hertz.
So, what is the resolution here we have it 1 by n t is 0.5 hertz.
So, as you can see that whatever we claimed in the previous slide that is 0 padding is not going to alter the frequency resolution.
That is what shown in the next slide.
So, coming with the next why we have to go for FFT.
So, initially we will take up radix 2 FFT.
So, we will see that how we are going to derive our fast Fourier transform algorithm for our DFT.
As we discussed in the last class the computation of DFT is order of n squared actually that is complex multiplication and addition.
So, we will be seeing that how we can reduce it.
using butterfly structure.
So, we are representing two butterfly ways of representing it.
One is in the decimation in time what we will be looking at it.
So, your twiddle factors W n k is going to be fed here and whereas, in the decimation in frequency it is at the output what you will be feeding it in.
So, both are the same concept and then what is the output here.
So, we know that.
A will have real component plus the imaginary component what we are feeding A is equal to and then B value also will be providing real and imaginary that is inputs are complex in nature.
So, what will be the output we will see in a while which we call it as A dash here.
So, we will be seeing that our twiddle factors W n k is nothing, but e power minus j 2 pi k by n.
So, which is expanded in cos and sin you will be seeing it cos 2 pi k by n minus j sin 2 pi k by n ok.
So, output a dash what we call it when we expand this a with real and then imaginary and b also with real and imaginary and w and k with cos and sin function.
So, this is what we will be getting it that is a real plus b real into cos x plus b i imaginary part into sin x.
plus j times this is the imaginary part, this is the real part and this is the imaginary part of it.
So, you will be seeing that same way even the b dash is going to be represented with real and then imaginary part separately.
So, from this you will be seeing that how many multiplications that is what we have real multiplication and addition what you can count from it.
So, I will be having 1, 2, 3 and then 4 multiplications.
And, then you will be seeing that 1, 2, 3 and then sorry for the real part 2 additions and imaginary part 2 additions taking into account my subtraction also.
So, this is how what you can separate and then B dash also we will be having the same amount.
So, what we say is one complex multiplication leads to 4 real multiplications.
and 2 additions what we are going to have it fine.
So, if we apply the symmetry property.
So, then we will see how we are going to make our twiddle factors look like.
So, W n into n k is given as we know that it is e power minus j to pi n n k divided by n. So, nothing but cos and sin what we have taken the thing.
So, how we represent W 8 0.
So, to show that our butterfly structure we will be taking n is equal to 8.
So, this will be e power minus j 2 pi by 8 into 0 which is nothing, but cos 0 minus j sin 0.
So, we know that sin 0 is 0.
So, cos 0 is plus 1.
So, we will be getting 1 and then w 0 1.
So, what it is going to be cos pi by 4 minus j sin pi by 4.
And, then w a 2 will be represented as this and then it is nothing, but cos pi by 2 minus j sin pi by 2.
So, and then w a 3 what we have is e power minus j 2 pi by 8 into 3 which is nothing, but cos 3 pi by 4 minus j sin 3 pi by 4.
So, how many coefficients we have calculated n by 2 in this case for n is equal to 8.
So, the rest of the thing that is 0 to 3 you can compute, rest of them what you can do is you can calculate it as w 8 4 is nothing, but w 8 0 plus 4.
So, which is nothing, but minus w 8 0 which will be minus 1.
So, you will be using the symmetry property here to get the rest of the coefficients.
Same way w 8 5 and w 8 6 are the same.
calculated and then rw87 remains same ok.
So, to see that how the coefficients are calculated both cos and sin coefficients for n is equal to 8 has been plotted in this case.
So, we know that sin starts from 0 and then how pi by 4 here and then pi by 2 and then next is pi by 2 pi by 3 and then.
how we will be going with values.
And then cos we know that it starts from 1 basically and then how rest of the thing pi by 4 and then pi by 2 what it you are seeing it in this case.
So, these are the 8 coefficients what we will be having it for are 8 point DFT that is discrete Fourier transform which will be deriving it for our fast Fourier time fast Fourier transform basically.
So, we will see first decimation in time.
So, we said there are 2 ways of doing it one is decimation in time the other one is decimation in frequency.
So, first we will take the time part of it.
So, how we are going to bivocate that?
So, x of k is equal to we can take even parts and then the odd parts separately.
So, that is what we name.
So, two summations what will be splitting it into.
So, which is equivalent to or r is equal to 0 to n by 2 minus 1 x of 2r here n is replaced with.
r basically for e1 it is going to be 2r for r part of it is going to be 2r plus 1.
So, this is n by 2 minus 1 and here also it is going to be n by 2 minus 1 and we have substituted r is equal to 2r.
So, this will be w n 2r k and here what we will be having w n 2r plus 1 into k. So, now we will see that.
by combining it that is 2 we are taking it out inside in this equation and r k goes here we have separated it out into w n 2 to the power of r k the other one term is w n k basically.
So, it which is not dependent on r. So, we can take it as a constant then take it outside in this equation.
So, now, we will see what is going to happen with our w n 2 which is nothing but e power minus 2.
2 pi by n which is when you split the thing it is going to be e power minus j 2 pi n by 2.
So, we will name this twiddle factor as w n by 2 fine.
So, when we substitute that so, we will be ending up with x of 2 r w n by 2 r k and w n k the other one is x of 2 r plus 1 w n by 2 r k.
g of k plus w k h of k. So, these are the two terms what we will get it when we split k 2 0 to n by 2 and the other part is n by 2 plus k 2 values what we will be representing it.
So, now, continuing with the thing DIT part of it.
So, we are naming g of k is thus we will give it as g r and w n by 2 to r k and then G of we are going to split this into 2 parts again even and then odd part G of k. So, then we give a new notation that is L actually.
So, this will be 0 to n by 4 minus 1 earlier it was n by 2.
So, we are bifurcating dividing by 2.
So, it is going to be n by 4 minus 1 and then this is going to be G of 2 L into W n by 2 into 2 L k this will be 2 L plus 1 W n by 2 into 2 L plus 1 k. So, same way if we represent the thing g of k now.
So, we can have it as earlier splitting.
So, we will be putting it as W n by 4 L k you have to recall that we named it as W n by 2 R k earlier now it will be L k bottom multiplied by 2 it is going to be n by 4 and then this is W n by 2 into to the power of k and again 2L plus 1 into W n by 4 into L k. So, same way we can split our h of k. So, because we had both g k and then h k here.
So, the first we have bifurcated g k into 2 parts h k we have to bifurcate.
So, when we do that it will be ending up in h of 2L even and then odd part of it n by 4 into L k and then this becomes.
As you can see this is this was W n k then when we split the thing.
So, it will be becoming n by 2 here into k this is the constant what we will have it twiddle factor and this is our normal one.
So, then what happens?
So, how we are going to define are all these coefficients W n by 2 k is nothing, but e power minus j 2 pi k n by 2 which is nothing, but W n 2 k.
And, same way W n by 2 0 is nothing, but W n 0 W n by 2 1 is now is equivalent to W n squared and W n by 2 squared will be equal to W n by 4 which is nothing, but W minus W n 0 and W n by 2 whole cube is nothing, but W n to the power of 6 which is nothing, but minus W n squared.
So, you are seeing that.
This g of k is this n by 4 point DFT and then h of k the odd part of it is shown here and further we will be getting our g 0, g 1, g 2, g 3.
So, you are seeing this is input is x of 0 and then here x of 4 and then x of 2 and then x of 6 for the even part where you are bifurcating g k into.
E1 and then Rd in this case.
So, coming for n is equal to 8 now we will split the thing.
So, what we have is this is my n by 4 point DFT what you have it on the left hand side and then we will be combining our weights in this case and then this is the final output.
So, how we will be feeding it?
So, we had for the two of it.
So, the other h k is the into 2 stages as you can see x of n and x of 5 and then the other one is x of 3 and x of 7.
So, we will be having combining the thing this is our output x 0 to x 7.
So, now what we will do is we have all our inputs here.
So, this we will see n by 4 point is nothing, but only single butterfly in this case.
So, we will replace this with a single butterfly and then put the.
weights here.
So, we know that W n 0 is equal to 1.
So, we can avoid the multiplication here and then we have minus 1 basically that is how did we get the minus 1 here.
So, you can you have to go back and then look into the thing.
So, that is W 8 4 which is equal to minus W 8 0 which is nothing, but minus 1.
So, you will be seeing all of them will have the butterfly at the bottom minus 1 here.
So, what we have is W n k here W n this is n by 2 what we have the thing.
So, when we this needs n log 2 n complex multiplications and complex additions.
When I have the twiddle factors it is in this way that is we are representing y m minus first stage in this manner.
So, now after splitting the thing that is W.
nr n by 2 is nothing but w n to the power of n by 2 into w nr.
So, which is nothing but minus w nr.
So, I can provide the what is it?
So, this is equivalent to minus 1 now.
So, this is minus 1 here and I can shift my w n k to here in the input of one of the input then what happens?
So, our computation is going to reduce to half.
So, then we will be needing n by 2 log 2 n complex multiplications and n log 2 n complex additions.
So, this shows for n is equal to 8 the complete butterfly structures.
In the second stage you will be seeing that we need two coefficients because the other one I have taken it as 1 equal to 1 and here also what you will be needing it is two coefficients.
Whereas, in the last stage what we have is 4 coefficients what is represented, but w 8 0 is going to be 1.
So, we need 3 coefficients in this case.
That way some of the multiplication complex multiplications you can avoid.
So, we will see that the computation complexity in a while.
So, now, we have compared when we discussed about DFT versus FFT.
Now, after doing the FFT splitting of it.
So, we will be seeing that how we have reduced it.
So, we know that we need in DFT n squared complex multiplications and whereas, in FFT.
with the shifting our twiddle factor to the input stage.
So, we have achieved n by 2 log 2 and complex multiplications.
So, with respect to that we know that when n is of the order of power of 2.
So, what will be the computations number of multiplications required by DFT and number of multiplications required by FFT and only with respect to this we will be comparing our efficiency.
So, it goes from 64 is to 12.
683 as the power of computation we have to do increases by base compared to base 2 ok 2 to the power of n. So, as it is increasing so our efficiency is also going to increase.
So, now one of the thing what we have seen is when we are doing this bifurcation what has happened to our here it is going to show us clearly.
So, what.
I have is first is x of 0, next one what I want is x of 4, next I want x of 2 and then x of 6.
So, we have done the bit reversal in this case.
So, as you will be seeing in the equation here.
So, what we want is decimal number 0 to 7 what we have it when n is equal to 8 binary equivalent is as you will be seeing 0 0 to 8.
1 1 1, but input in the order what we want is 0, next is 4 what we wanted which is equal to 1 0 0 and then 0 1 0 and the next is 1 1 0 which is equivalent to 6 so on in the outside part.
So, as we said that in DSP hardware we use the data address generator to do that.
I think if you have to recall your architecture I had given how to do this.
addition in hardware.
As we know n is equal to in this case 8.
So, n by 2 is equal to 4.
So, we know that the first one we are starting with 0 0, then we add 1 0 0.
So, that is from left to right what we will be adding it.
So, which gives me first digit is 0, next one is 4.
Now, I add 1 0 0.
So, I said we will be adding it in this way 1 plus 1 is 0, we will be carrying 1 to here 0 1 0 which will give me 2.
So, you can go on doing that till the end.
So, this is the data address generator which will be incorporating our bit reversal as the input or FFT computation.
So, now, we will see the how complex it is, how many groups we have and then how many butterflies per group what we needed.
So, that is we said input signal must be properly reordered using a bit reversal that is what we wanted in the input.
So, you can say that this is a two point DFT which we can represent it as just a butterfly when it is a two stage point DFT.
So, the next one is combine these two points DFTs from each stage.
We will be having the next stage.
And, then combine these two point DFTs and then finally, we will be combining 4 points here from 8 stage to get my 8 bit output.
So, when we represent n is equal to 8 as you can see the thing this is the first stage, this is the second stage what we have it, this is the third stage.
So, now, we call this thing as if we want to have we can do in place computation.
What do I mean by in place computation?
That means, my these are the inputs I can overwrite with these values with respect to this because I do not need these values in the later stages.
That is why we call it as in place computation.
So, that I need not have to store my input more than 8 bits.
And then next is how many stages we have to do?
We say n is equal to 8.
We have seen that we need 3 stages that is log 2 n. So, which is going to be 3 and stage 1.
So, we know that all the twiddle factors are 1, all are w 8 0.
So, which is 1 in this case and last stage that twiddle factors are in sequential order.
As we can see that here it is w 8 0 and w 8 0.
to what we need it.
Here what we need is W80 1 2 and then 3 that is what the twiddle factors in the last stage is going to be in order.
Now, we will see that some of the parameters with respect to our butterfly structures.
Number of groups how many I am going to have it.
So, here you can see that we call each one as group.
So, each butterfly basically.
So, in the first stage we have n by 2.
As we have taken n is equal to 8, 8 by 2 will be 4.
So, you will be seeing 1, 2, 3, 4 groups are there in this case.
Now, in the next stage I am going to have n by 4 which is nothing but 2 in this case n is equal to 8 you will be seeing this is one group this is the other group.
And in the last stage we will have one group.
So, 8 by 8 is 1.
So, this is you are having only one group in the stage 3 in this case.
Now, we will see how many butterflies per group are going to be there.
In the first stage we have one butterfly.
So, in all the groups we have only one butterfly.
Coming to stage 2, so as you can see this is these are the two groups I have two butterflies in this group and here also we have two butterflies.
When I come to the next stage, stage 3, then we are going to have n how many butterflies?
4 butterflies in the group here.
So, you will be seeing that this is 1 butterfly, second, third and then fourth butterfly.
So, that is what it is going to be and number of stages are more than what we will say in the stage log 2 n we will have n by 2 butterflies.
So, something should be striking if it is n is equal to 16 then it is going to be 8 butterflies in the last stage.
ok. And then what is it?
We call it as dual node spacing.
So, between the 2 nodes what is the spacing I am going to have it?
Here 1 because x 0 and x 4 these are the 2 nodes the spacing is only 1 between them.
When I come to stage 2 we will be seeing that the spacing is going to be 2 nodes.
So, I am taking 1 from here next one is coming from this.
So, there will be 2 node difference what I will be giving it as input with this.
Same way you can calculate everywhere and in the stage 3 I will be having this thing dual node spacing is going to be 4.
I think it should be something striking equivalent your butterflies per group and then node spacing is also same ok.
These 2 columns almost repeated.
So, you will be seeing that this is the first input, the next input the from the fourth one.
So, if I taken this 1, 2, 3, 0, 1, 2, 3 and then the fourth one from here what I will be taking it.
So, there will be spacing of 4 nodes for this.
Now comes the twiddle factor exponents how we are going to put it in each node.
So, we will be having n by 2 into k in this case in the stage.
1 k will be equal to 0.
So, that means to say I will be having 8 W n k's which are all 1 ok.
So, that is the reason why we do not have any we can remove this W 8 0 equal to 1.
So, 8 of them are there.
So, we which is equivalent to 1 in this case.
So, the next one in W n k what we have put it k is equal to 0 that is why it becomes W 8 0 and it which is equivalent to 1.
So, in the second stage.
what we are going to have is n by 4 into k, k will be going between 0 and 1.
So, you will be seeing that this is w 8 0 and then k will be 1 then it is going to be w 8 into 2 in this case.
So, the last stage what it will have our stage 3 in this case is going to be our last stage n by 2 into k 0 1 and then 2 are the values.
So, w 8 0, w 8 1, w 8 2 and w 8 3.
So, we will be having 4 of them here and when we have more than that what will be the thing k will be going between 0 to n by 2 minus 1.
So, you will be seeing here n by 2 is 4, 4 minus 1 is 3.
So, that is why we have k is equal to 0, 1, 2 when n is equal to 8.
So, coming with this thing as we said we can have the computation either in the time domain or in the frequency domain.
So, that is we call it as decimation in frequency.
So, we say that output signal must be properly reordered using a bit reversal algorithm.
That means to say input is in order and output will be in the bit reversal order in then the DIF case.
So, here also it is in place computation compared with your DIT decimation in time and here also number of stages is going to be locked to n.
and what we say stage 1 all the twigal factors are in sequential order and last stage all the twigal factors are going to be 1 in this case.
So, you will be seeing that in the decimation in frequency is equivalent to reverse of your decimation in time.
So, how the number of stages and other things it looks like you will be seeing it.
Number of groups in this case is going to be 1 for n is equal to 8 what it is shown.
And, then number of stage number of groups in stage 2 is going to be 2 and then last stage in this case is 4.
So, it is equivalent to log 2 in stages the stage thing will have n by 2 number of groups.
And, then you will be seeing the butterflies per group will be n by 2, n by 4 and n by 2 and last one will have 1 basically per group.
And, then even your dual node is equivalent to the previous.
case basically this is the one.
Now, only the thing is twiddle factor exponent.
So, you will be seeing that n in this case there it was a k was the variable here it is going to be n, n will be going between 0 to n by 2 minus 1 will be your twiddle factor first stage and in the second stage it is 0 to n by 4 minus 1 and so on what you will have it in the last stage you will be having n is equal to 0 and n by 2 twiddle factors which becomes equivalent to.
1 in this case also as you can see it ok.
So, now we will look at the finite word length effects in FFT.
Thank you.
So, we have seen how to get our FFT using butterfly.
So, in the next class we will look at the finite word length effects in FFT.
How it will be affecting our outputs and what is the care we have to take it.
Thank you.
Namaskara, welcome back to real time digital signal processing course.
So we will discuss today.
To recap in the last class we have covered about overlap save method, both overlap previous to that we had covered overlap add method for continuous input signal, how we can calculate our FFT and then we had seen lab also.
Coming to in today's class we will discuss about correlation.
So, what is the definition of correlation or why do we need it we will look at it.
So, basically a process of comparing two data sequences to obtain a measure of similarity between them.
So, most of you must be knowing that you will be trying to correlate one person with other either in terms of their habits or their look or their appearance that is what you will be looking at.
In this case we will be looking with our signals whatever we are going to get the thing.
So, one of it is.
in the application of voice recognition in audio signal processing.
So, which requires comparison of different speech waveforms.
So, you are want to recognize somebody's voice ok and then you have stored originally and then marked it this is the original person's voice and some of the people their voice is recorded or from the same person.
Then you want to see that whether whatever stored is going to match with that particular person's voice.
So, this is one of the application we need the correlation.
Next in the case of image classification in image processing which requires comparison of different image data.
As I was telling so, you might have taken the image somewhere else and then you want to have a see that the current image whether there is any correlation or.
So, the other application one of the mostly used what we will call it in day to day life is object detection and location in basically sonar and radar systems.
So, which require comparison of the transmitted signal and the signal reflected from the target objects.
So, it you want to all of you know now drone is becoming.
mostly popular.
So, if you want to identify if one of the drone is going to cross our border or whatever maybe the thing.
So, you want to identify it is a foe and then you want to destroy it.
So, lot of work is happening the same way in the sonar area is one of the sea area.
So, submarines and other things.
So, they will be reflecting through signals through radars basically and then they reflected by which comes back you have to process it.
and then see that what correlation it has with the template what we have it.
And even you would be in case of aeroplanes basically.
So, you want to see that what kind of aeroplane which is running whether it is military or civil so, that also reflection you will be catching through the radar and then you will be finding out.
So, you know that correlation is used.
So, the fundamental measure of similarity between the two sequences we call it x of and y of n is the sum of the products of the corresponding base of data values that is sigma x of n into y of n what we represented.
Then what we are going to say so, we say if the is it positively correlated when we are going to say this if there is some kind of.
proportionality relationship between x of n and y of n with positive or negative values generally occurring concurrently in both sequences, then some of the products will be a positive value.
Because even both of them are negative we know that the product is going to give us positive and both of them are positive then it will be giving the positive value.
So, then we will be saying that as a positive correlation, when we call that as negative.
If there is some kind of inverse proportionality relationship between x of n and y of n with positive values in one sequence generally accompanied by negative values in the other sequence then we know that sum of products will be a negative value indicating that is negative correlation between the two sequences.
So, when we say there is no correlation between the two sequences, if the two sequences are independent with positive values and negative values equally.
likely to occur in both actually the sum of products will tend to towards 0.
So, we call it as due to self cancelling of the product terms in summation.
So, then we say that they are not correlated.
So, continuing with the thing so, we say if two sequences x of n and y of n the cross correlation function we call it as C x y of P is defined by this equation.
What do we say cxy of p is equal to limit n tending to infinity 1 by n small n is equal to 0 to n minus 1 x of n into n minus p. So, we say where plus or minus p represent the number of sampling points by which y of n has been delayed or advanced in time with respect to x of n and 1 by n is included as a normalization scaling factor to ensure that The cross correlation of two periodic sequences converge to the same result as more and more sample pairs from two sequences are included in the cross correlation operation.
So, that we are trying to avoid the overflow by scaling it ok.
So, how do we define the autocorrelation?
When y of n equal to x of n, we have a special case whereby the cross correlation function becomes the autocorrelation function.
The equation is given by Cxx of p is equal to limit n tending to infinity, the same scaling factor 1 by n, n will be going from 0 to n minus 1, x of n into y of n minus p in this case the maximum autocorrelation where we are going to get is when p is equal to 0.
Since two identical in phase signals are being compared and the autocorrelation value decreases as p is going to.
So, we will see how we are going to calculate our correlation as an example.
So, what we have it the same example for FFT what we have taken the thing here also we will be taking the same this thing x of n and then h of n. Here it is x of n is 2001 and h of n is given by 4321.
So, now we will write.
compute our cross correlation by writing the table.
So, n will be varying between minus 3, minus 2, minus 1 this is and then 0, 1, 2, 3 greater than equal to 7 we know that it is going to be 0.
Because we know that like linear convolution we call it as linear correlation here the length is going to be L plus M minus 1.
So, that is what we needed even the negative side.
So, x of n we are going to write it as this thing.
So, we know that in the negative region it is 0 and if nothing is mentioned we assume the starts from 0.
Sometimes if you want to say that it is starting from the negative side of it.
So, you may mark with an upper arrow here stating that this is our 0th location basically.
So, it is 2 0 0 1 and then elsewhere it is 0 what we have assumed P ok. And then we will be computing our correlation equation that is Cxh that is cross correlation with respect to P. So, first one is h of n plus 3 because P is equal to minus here basically minus 3 it is going to be n plus 3.
So, it will be 4 3 2 1 what we assume the thing here.
and then rest of them 0s.
So, when you do the multiplication here, so what you are going to get is when p is equal to minus 3.
So, you are doing the multiplication 2 into 1 is 2 rest of them are 0s and we have to scale it by n, capital N is 4 because both the sequences are of length 4 in this case.
by 4 is going to give us 0.5.
So, same way what you have to do is next is n plus 2.
So, you will be shifting H of n sequence right by 1 place and then you will be computing your cross correlation here.
Same way you do the thing when this thing x of n and H of n at 0 will be seeing that is p is equal to 0.
So, both will be coinciding with each other that is 2 0 0 1 and 4 3 2 1 and then you will be seeing that the correlation of value at this is peak it is 2.25.
So, then you will be moving away from the thing p is equal to you will be giving it as 1 2 and then 3 and then 4.
So, this is our output of.
linear cross correlation.
So, what is the difference with respect to our convolution?
So, here H of n is not folded in the correlation process.
So, we fold H of n in the case of convolution, here it goes as it is, it is not folded that is the difference between our convolution and then correlation.
So, coming with continuing with the correlation, So, what is it?
It is often desirable in practice to make the autocorrelation function values independent of the signal scaling by normalizing the autocorrelation function with respect to its maximum value at 0 phase.
So, that it need not have to depend on the thing.
So, what is that normalization results in an autocorrelation coefficient we call it as rho xx whose values always lie in a.
fixed range of plus or minus 1.
So, when we take the autocorrelation rho xx of p, it will be cxx of p divided by cxx of 0.
So, similarly normalizing the cross correlation function results in cross correlation coefficient rho xy which is given by rho xy of p is nothing, but our cxy of p divided by root of cxx of 0 at the 0.
So, autocorrelation value what you will be taking it here for one of the signal and then autocorrelation this thing coefficient c yy of the second signal.
So, and a square root you will be doing it which will normalize our this thing cross correlation function.
So, the note at this places our rho xy lies in the fixed range of plus or minus 1 with plus 1, 0 and minus 1.
indicating 100 percent positive correlation, when it is 0 it is no correlation and 100 percent negative correlation respectively if it falls in this values.
So, what does it say that our cross correlation magnitude of it should be less than or equal to square root of this function basically.
So as an example.
We will take the same sequence x of n and then h of n we have already calculated their cross correlation coefficient.
Now we will see the values of it that is autocorrelation Cxx of 0 is nothing but 1 by 4 into n is equal to 0 to 3 x of n squared what we will be doing it which is nothing but 1 by 4 into 2 square plus 0 square plus 0 square plus 1 square which is equal to 1.25.
autocorrelation of the h signal that is we have it 0 it is equivalent to 1 by 4 into same way n is equal to 0 to 3 h of n squared.
So, when you substitute these values you will be getting 7.5.
Now, we have computed cross correlation Cxh of p in the previous table as you can see it 0.511.5.
So, how we can normalize this using this equation.
So, what is the first value what we have is 0.5 divided by square root of r 1.25 into 7.5 will give us the value 0.16.
Same way for all the autocorrelation values you can calculate are normalizing the thing will give.
these values which have been put into table.
So, you can go and then compute for rest of them whether it is going to match or not fine.
So, now, just like our linear correlation and linear convolution.
So, we have the circular correlation equivalent to circular convolution.
So, how we are going to write our circular correlation in this case?
We call it as C x y of p is nothing but 1 by n, n will be varying between 0 to n minus 1.
x of n into y of n minus p. So, in this case p will also be varying between 0 to n minus 1.
So, when we compute the circular this thing correlation between these two sequences as we had done it with linear correlation.
So, what we have it x of n is we have 2 0 0 1 and h of n is given as 4 3 2 1 and then the capital N in this case is 4.
So, we will be going between 0 to 3 after that it is going to repeat.
So, here when we calculate it.
So, this is nothing but 2 into 4 plus 0 into 3 plus 0 into 2 plus 1 into 1 and then scaled by 4 what we are doing it capital N. Then you will be seeing that it is going to give us 2.25, the next one is 1 and then next one is 1.75 and then the last one in this case is going to be 2.5.
is something going to strike to you.
So, you can see that what was our earlier case.
So, it is 2.25 in the thing it is matching and you will be seeing only one is going to match like a linear convolution.
Here also circular convolution with linear convolution there is only one value which is the at 0 which is going to match rest of them are not going to match.
So, to get again our linear correlation how we are going to implement it.
So, this is one of the questions.
So, how did we do linear convolution from circular convolution by padding 0s.
Here also you can pad 0s and then compute linear correlation from the circular correlation.
So, this is going to be your assignment.
or take home I will call it as problem solving thing.
So, you can work it out and then come back and then tell me whether you have got the results correctly or not ok.
So, now, we will see some of the DFT property of our circular correlation just we did it for the convolution we will do it for correlation.
So, what is it say may be stated formally with this if.
Cxy of p is given by this equation.
Then we call it as correlation of xyr we will put it which is equivalent to 1 by n xr into yr conjugate.
So, the multiplication is going to be xr with yr conjugate and then scaled by 1 by n. So, here we say Cxyr xr and yr are the DFTs of Cxy.
P and x n and y n are the inputs and y r is the y r conjugate is the complex conjugate of r y r DFT of y small y n basically fine.
So, now, we will see how we are going to compute our correlation output.
So, just like we did for the DFT.
So, we will be using I will be putting it as D I F FFT.
So, this is the butterfly structure what we have it.
So, we have 1 by 4 is the here also because the length of the sequence is 4 what we have taken the thing.
So, 1 by n is 1 by 4 in this and these are the points what we will be getting it in basically inverse of DFT basically.
So, this is C0, C1 and sorry A0, A1, B0 and B1 and then we will be getting out our.
x of 0, x of 2, x of 1 and x of 3.
So, we have calculated our DFT of 2 0 0 1 in the previous class.
So, which gave us 3 2 plus j comma 1 comma 2 minus j are the DFT of this sequence.
So, I think we have not calculated DFT of H of n. So, you can calculate in the same way using DITFFT that is decimation in time for fast Fourier transform butterfly structure and compute the DFT of 4 3 2 1.
In this case we have assumed that we have calculated previously and using the values what we have it.
So, which gives us.
2 minus j 2 comma 2 comma 2 plus j 2.
So, these are the DFT of 4, 3, 2, 1.
Now, we will calculate the circular correlation C x, y, r what we have to calculate.
So, 1 by n into we have to do x r into y r conjugate.
So, if we substitute the thing, so this is our x r multiplication with.
Yr this is the one conjugate what we have to take the thing.
So, how we are going to represent this?
So, this is 10 2 minus j2 2 and then 2 plus j2.
So, when you take the conjugate of this, this becomes positive and this becomes negative and then calculate this values.
So, you will be seeing that it is going to be 7.5.
0.5 plus j1.5 and then 0.5 minus j1.5.
So, this is our value for Cxy R. Now, how we will be calculating our Cxy 0 as you can see the thing.
So, you will be putting a0 plus a1 which is nothing but 1 by 4 Cx.
y0 plus cxy2.
So, these are the values what we have it and then plus 1 by 4 cxy1 plus 6y3, here we have these are the values what we have it 7.5 plus 0.5 and then plus 1 by 4 into 0.5 plus j1.5.
So, plus 0.5 minus j1.5 for the second sequence.
So, which you can see that.
we are getting it as 2.25.
So, how we calculated the circular convolution using a DFT property.
So, we can calculate these values.
So, the next one is Cxy of 1.
So, you will be substituting these values and then calculate the thing.
So, you will be getting it as 1 in this case same with respect to the next two.
So, you will be seeing that the DFT using DFT.
The circular correlation values resemble as that of the direct circular correlation what we have calculated.
So, coming to the next topic we have to introduce little on random process.
So, we know that real world signals such as speech, music and noise are time varying and we know that they are random in nature.
The set of all possible outcomes in any given experiment is called the sample space S.
Why do we need random process?
So you are seeing that some of the applications what we will be seeing later on based on some of the speech and music already we have seen the thing how our noise is introduced in the music or in the speech how we are able to eliminate our noise if our noise is known in this case.
In some of the cases noise may not be known okay so we have to adapt to the.
So, which requires a random process.
So, the next topic we will be covering is adaptive filter.
So, we need this basic knowledge of random process only little bit of it whatever required for deriving our LMS algorithm will be covering it in this course.
So, those who want to have more they can take up as a course and then complete it.
So, this is the space for sample space what we have defined.
And we have to define the random variable x, how we are going to define it?
This is the function that maps all elements from sample space S into the points on the real line.
As an example, considering the outcome of our rolling fair die ok.
So, we have obtained the discrete random variable that can be any one of the discrete values from 1 through 6, all of us know that our fair die has 6 values.
when we roll it.
So, we do not know what we this is the outcome, but it should lie be 1 through 6.
So, the cumulative probability distribution function we call it as CDF of a random variable x is defined as the that basically you can see that there is a repetition here that is f of x is equal to probability of x less than or equal to.
capital X, where capital X is real number and Px less than or equal to x is the probability of x less than or equal to capital X.
So, we call it as probability density function of random variable x is going to be defined with that f of x is nothing but d by dx of f of x, if the derivative exists.
So, two important properties of probability density function is f of x are.
summarized as this way that is integration minus infinity to infinity f of x dx is equal to 1 and probability of x1 lies small x lies in x1 and x2 is given by our f of x2 minus f of x1.
So, which is nothing but we will be putting x1 to x2 f of x dx.
So, if x is a discrete random variable.
that can be any one of this discrete xi that is i is equal to 1, 2 etcetera.
As the result of an experiment we define the discrete probability function as Pi is equal to the P capital P of x equal to xi it belongs to this ok. As an example so we consider a random variable small x that has the following probability density function f of x is equal to 0 in this range x less than x1 or x greater than x2 in the region x1 to x2 which is equal to a.
So, that is we say it is uniformly distributed between x1 and x2 and constant value a can be computed as with this equation that is minus infinity to infinity f of x into dx which is equal to x1 to x2 what we are putting the thing a into d of x which is nothing, but a into when we expand our integration which is going to be with the values it is going to be a times x2 minus x1.
which is equal to 1 as this can be seen that.
So, the maximum value is 1 by x2 minus x1 and then we will be seeing that this is uniformly distributed between x1 and then x2.
So, a in this case is equal to 1 by x2 minus x1 what it has been taken.
So, that is the reason why we will be getting it as 1 here.
So, what is it if a random variable x is equally likely to be any value between 2 limits.
x1 and x2 and cannot assume any value outside that range.
It is uniformly distributed in the range that is x1 to x2.
So, that is as shown in the figure it is uniformly distributed in this region.
Then we call that is uniform density function is defined by this f of x is equal to 1 by x2 minus x1 in x is in the range x1 to x2 otherwise it is going to be 0 in the other places.
So, coming with some of the operations of random variables.
So, the statistics what we call it as one is the first is the mean what will be defining it that is nothing, but expected value of x which is given by integration minus infinity to infinity x into f of x into dx.
So, this is for the continuous time case is defined as this for the discrete time case it is a sigma or xipi.
So, we represent E dot denotes the expectation operation or ensemble averaging basically.
The mean mx defines the level about which the random process x is fluctuates or fluctuating.
So, you will be seeing that is linear operation the useful properties of the expectation operation are expected value of alpha is equal to alpha and expected value of A times alpha will be A into expected.
of x basically, where alpha is a constant what we assume it.
If expected value of x is equal to 0, x we call it as 0 mean random variable.
So, you will be using a matlab function if you see the thing, the mean calculation is given mx is equal to mean of x computes the mean mx of all the elements in the vector x using the matlab function.
So, as an example so we said that our fair die rolling of a fair die.
So, we said n times that is n can be up to infinity.
So, the what will be the probability of outcome from this.
So, you will be seeing that X i is we are taking 6 and then our probability is 1 by 6 in all the cases.
And in this case mean is calculated as m X is P i into X i.
So, 1 by 6 of this which is going to be 3.5.
And the variance.
The measure of spread about the mean and is defined as sigma x squared with equal to expected value of x minus mx whole squared.
So, which is by substituting our expected value minus infinity to infinity x minus mx whole squared into f of x into dx for the continuous time case and it is going to be sigma pi xi minus mx whole squared for the discrete time case.
So, these are the mean and then variance what we will be defining it, x minus mx is the deviation of x from the mean value mx.
The positive square root of the variance is called the standard deviation sigma x and MATLAB this thing function for the standard deviation calculation uses std function ok.
The various defined can be expressed as that is sigma x squared.
is equal to expected value of x minus x whole squared.
So, which is nothing but expected value of x squared minus 2 mx plus mx squared.
So, you are taking the expected value inside which is nothing but expected value of x squared minus 2 into mx into expected value of x and this is away from our x plus mx squared.
So, this is the value what we will be getting it that is this becomes 0.
So, it will be expected value of x squared plus mx squared.
So, we call this is the mean square value of x.
So, variance is the difference between the mean square value and the square root of the mean value.
So, this is the random variable definition some of it what we will be seeing it.
So, we see that if what is it a mean value is equal to 0 that is mx is equal to 0, then what happens to sigma x squared is nothing but expected value of x squared.
So, which we call it as Px which is the power of x basically.
Consider the uniform density function, the mean of the function can be computed by this mx is equal to expected value of x which is nothing but minus infinity to infinity x into f of x dx.
So, we have seen the uniform which is substituted at 1 by x2 minus x1.
So, your integration x1 to x2, x of dx.
which is nothing but x2 minus x1 divided by 2 what will be resulting in.
So, variance of the function is defined sigma x squared is equal to this is what we had it expected value of x squared minus x squared.
So, if we substitute the thing with expected value of x squared with that and then by simplifying so, we will be getting it as mx squared.
So, So, in general if x is the random variable uniformly distributed in the interval minus delta and delta.
So, then we will be having mx mean is equal to 0 and then standard deviation x squared is given by delta squared by 3 by substituting in this you can calculate with minus delta and delta substituting it here you will be getting delta squared by 3 as the value.
So, this completes our on correlation.
And, little bit on random process in the next class we will be taking it up adaptive filter.
So, how we are going to derive it.
Thank you.
Welcome back to real time digital signal processing course.
So, last class we discussed about overlap add method.
So, we will take up example in this class and then continue with overlap save method.
This is what we have discussed overlap add method for continuous signal.
So, how we can take care of doing FFT for it.
So, today we will take up an example and then see how it is going to work if you have still doubt.
So, this is the procedure what we are going to follow for overlap save add method.
This is the impulse response of the sequence that is we call it as H of n. So, H of n has m minus 0 to m length and then n is the length of the signal if we assume.
So, we will be adding n minus 1 zeros to this.
So, this is the what we call it as to make it power of 2 that is n length for our FFT.
So, we are going to pad zeros here.
So, then we will be considering all n length what we call it as one is the impulse response as well as the input signal as you can see it is more than n length.
So, this can be continuous.
So, here for example, we have taken 3 n length in this case.
So, we will be bifurcating into n length of sequences input sequence also.
Then what we do this is x of 0 to x of n minus 1.
we call that as x1 of n and pad this one with 0s and then the other n samples will be taking type x of n to x of 2n minus 1 and then pad with 0s and then the third and then so on what will be doing it.
So, in the n we will be adding 0s as you can see what I will be getting it when I convolve x1 of n with h of n basically we will be getting.
y1 of n. So, then what we have is 0s here the complete this is going to be added to the m minus 1 sequence output of y2 of n here and this is y2 of n. Next our m minus 1 will be getting added with the y3 of n in this case because only we are going to do 3 of it to make it clear for you, but it can happen continuously.
So, we add this.
And, then this is our y of n as you can see here there is a addition sign here this is getting added with the previous one and this is the last one which we will be discarding it.
So, our y of n will be of this length.
So, to make it clear so, we will take a example in a while.
So, how this overlap add method although we have discussed in the last class.
So, we will just see that whatever the previous thing I have explained how it is going to work.
So, this is padding n minus 1 0s to the end of the impulse response sequence h of n of length m to obtain a sequence m plus n minus 1 which is l length and perform l point FFT of the padded impulse response sequences and store the FFT output values.
Then we will be performing l point FFT on the selected data block where each data block consists of n input data block.
values and M minus 1 0s.
So, thing will have input data and M minus 1 0s to make it L point sequence which will be taking FFT of it.
Then multiply the stored FFT output sequences that is because we are doing the filtering basically.
So, take the FFT of the impulse response, take the FFT of the input sequence, then do the multiplication as we know in the frequency domain.
2 A 50 are going to be multiplied which is convolution in the time domain.
So, we will be obtaining in 1 by the A 50 output sequence and selected data block obtained from 2.
So, perform an L point I A 50.
So, we have got the result.
So, we will be taking inverse Fourier transform on the output and the product sequence obtained in 3 here what we will be doing the I A 50.
Then, what we will do is overlap the first m minus 1 FFT values obtained in this 4 with the last m minus 1 FFT values for the previous block and then perform addition to produce y of n output values.
And then we will be moving back to this stage because we need not have to as we discussed in the computation complexity FFT because once we have done the FFT of our impulse response we need not have to redo the thing only for the next set of input blocks we will be taking.
So, we will be moving to the next data block that is will be performing it in loop.
So, we will take up an example.
So, which will make it clearer to you.
So, in this case m point filter it is 3 bit what we have taken sorry 3 point length what we have taken the thing.
So, it is 3 to 1 is the impulse response and we will be using a overlap add method to determine the output sequence in response to the.
repeating input sequence the size what we have chosen is 2 0 minus 2 0 2 1 etcetera ok as it is shown.
So, now our m is the 3 and then our n what we are going to select as you can see the thing here 2 4 6 and 8.
So, x1 of n so, we will be first considering it with 0s.
at the what is it we call it as in the end of our sequence.
So, we are considering our end point as 6 in this case m is 3.
So, 6 plus 3 is 9 minus 1 will be l. So, which is equivalent to 8 in this case.
So, this is how we compute our.
L m and then n basically.
So, from here what we are going to do is are now x 2 of n is as you can see in the figure here.
So, we will be starting from here to here after padding with 0s.
So, in this case 0 minus 2 and then we are taking the rest of the signals here up to 0 here, then we pad again with 2 0s m minus 1 0s.
which is equivalent to 2 0s what we are adding it here.
And then next sequence what we will have it is minus 2 and 0 in this case and so on.
So, this is how we have calculated our l m and then n values.
So, coming with the thing how we are going to continue.
Now, we have x 1 of n x 2 of n. So, we will be convolving with our h of n which is padded with 5 0s.
So, as it is shown here.
So, and then we have to take the.
what we will be calling it as H of minus of k minus n values what we will be taking it.
So, what we have been given is 3 2 1 and then you will be doing the reversal of the sequence.
So, first these are the 5 0s then 1 2 3 what we will be taking it.
Then this is going to be convolved with X1 of n what we have chosen.
So, now our Y1 of n is going to be as it is seen.
So, we have it 3 into 2 which is going to be 6 ok.
So, some previous values what you can have it because you will be moving the sequence as it is shown it is going to be moved to the right.
In the next step what you will be getting 2 into 2 is 4.
So, then you will be getting 3 into minus 2.
So, which is going to be minus 6.
x and then here you are going to have 2 into 1.
So, this is what the value which is going to come here in the second clock cycle.
So, minus 6 plus 2 is going to be minus 4.
So, so on you will be till the all the values have been computed.
So, this is r y 1 of n. So, this is how you will be doing your circular convolution.
Then now x 2 of n is the sequence what we have it from the previous what we have taken the thing.
So, this is minus 2 minus 1 0.
2 and then 0 0 then 2 padded with 2 0s and then this will be going in the forward direction as you can see it here.
So, the first one will be 0 output.
So, when you move towards your right because as you know the circular convolution.
So, we will be repeating those values.
So, this is minus 2 into R 3 which is minus 6 and so on you can compute it.
So, the output of y 2 of n is given here.
Then, next is how we are going to use this overlap add method.
So, we know that convolution result by m minus 1 two values and adding yields the output sequence as shown below.
So, that is this is my y1 of n and next y2 of n is going to be aligned with these two that is what it says two values have to be overlapped from y2 of n and then we have to add these two and then our y3 of n because only we have.
2 and then 0 and then later on it is not defined.
So, we will be calling it as xx.
So, if we have some more values then I have to compute my y3 of n in the same way as y1 and then y2 take those values and then put it here.
Now, what will be the final sequence?
So, it is 6 4 minus 4 minus 4 4 7 and then 4 plus 0 is 4 minus 6 plus 1 is minus 5 and then these sequences will be repeating it.
And, then after that I am not bothered I can put it as x x x.
So, if you see your convolution what output you are going to get it whether it is equivalent to this or not one can look at it using the overlap add method.
To show that it is correct ok what we have to copy is copy this sequence and then copy your 3 2 1 and then do the normal convolution.
So, if you are interested it that is what we will put it as show with the think.
So, normal all of you know this convolution pattern.
So, this is what you have it is 2 0 minus 2 0 2 1 0 minus 2 minus 1 and then last 0.
So, this is what.
So, what we have is 3 0 3 2 1 are sequence.
I can put a line here 6 0 minus 6 0 6 3 0 minus 6 and then 1 what I have it 3 and then 0 last one.
So, here it is going to be 2 0 minus 4 0 4 2 0 minus 4 2 and then 0.
the last one will be 2 0 minus 2 0 2 1 0 minus 2 1 and then 0.
So, you know that this is the way what you will be adding up in normal linear convolution.
So, you can do that and then see whether you will be getting the whatever you have got the output correctly or not.
So, these 3 what I have to do the thing.
So, first one is 6, second one is 2, minus 6 plus 2 is minus 4 and then minus 4 and then 6 minus 2 is again minus 4.
So, then what we have it is 4 plus 3 is 7, 2 plus 2 is going to be 4.
So, I have minus 1 minus 5 and then minus 4 and you can compute the thing.
So, go back and then check whether our output what we have got it is correct or not here.
So, this is how will you can cross verify and then see whether your convolution output is using this overlap add method because this is a simple length of it what it has taken to work it out by hand.
So, that when you write your code in MATLAB or in C.
So, you can verify it and then for larger x of n sequence and then whatever filtering what you have to do it you can use that and then run it.
So, in the lab we will demonstrate that whether it is going to work or not.
This is one of the way of computing the long sequence using overlap add method.
So, the next one what we will see is overlap save method.
So, here it is this one is called also overlap discard method.
will please hold on a while, while we are there we have added the whatever m minus 1 0s we have added.
Here m minus 1 data we are going to discard it that is why either we can call it as overlap save or overlap discard method.
So, how this method is going to work?
Same as this we have impulse response.
So, we have h of 0 to h of m minus 1 is the m length impulse this thing sequences.
And then next we will be padding with n minus 1 zeros to make it a n length sequence.
Now we have n length input x of n what we are going to consider and the next all these are again just like previous overlap add method.
So, we have n length sequences what we have considered then what we are going to do.
So, for the first one we are going to add n minus 1 zeros.
to make it L length sequence.
And then for the next one we are going to have m minus 1 samples from the previous one what we will be adding for the current length of the sequence.
So, that is we call it as block 2, this is the first block, block 2 and then so on block 3 and then if we have other in this thing inputs it will be going on that way.
Then how it is going to work?
So, you can see what will be our output this is m minus 1 we will be discarding it.
And, then block 1 output after this thing multiplication will be working on y1 of n that is x of k into h of k is y1 of and then taking IFFT y1 of n is going to come.
And, here it is again we are going to discard m minus 1 in this sequence and then take the rest of the block 2 as y2 of n and the other m minus 1 we are going to discard this.
output and then take the rest of the y3 of n and we will be concatenating these 3 blocks y1, y2 and y3 this will be our output.
So, you would be wondering how this is going to work we will take the same example and run the case in a while ok.
So, what is the procedure for it that is for the overlap save method I have to pad same as overlap pad, pad n minus 1 0s to our filter length to make it.
length L by making n minus 1 zeros to m length impulse sequences to make it as L length.
Then do the L point FFT and then same thing with our input how we are going to select here.
So, selected data block where each data block begins with the last m minus 1 values in the previous data block except the first data block which begins with m minus 1 zeros.
That is what I showed you in the previous slide.
Now, do the multiplication of these two FFT and then take a by the FFT of this thing block with respect to this.
Then perform L point IFFT to the product sequence which is obtained in 3 and save the last n values of IFFT obtained from this place and then discard the first m minus 1 values of the IFFT.
So, then we will be moving back to calculate the next sequences.
So, we will see how it is going to work with the same example what we have taken.
So, the impulse response for the FIR filter order is m which is equal to 3, the values are same thing 3 to 1 and then input sequence is same what we have assumed in the previous case.
Now, you will be seeing that your m is 3 if the length of the FFT or IFFT operation L is selected based on this that is 2 power 3 which is equal to 8.
Then n becomes L minus m plus 1 which is nothing but 6.
This is how we arrived at 6 in the previous case also and the segmentation of the input sequence results in the data blocks shown in this case.
That is n what we have named it minus 2 minus 1 because we need m minus 1 0s which is going to be padded before the input sequence.
So, we will be naming it as minus 2 minus 1 and then the input starts from 0 onwards.
So, your input is 2 0 minus 2 and then up to here what we have it as x of this is a complete x of n and x 1 of n is going to be up to here that is padded with 2 0s and then we will be taking 6 sequences as you can see here 2 0 minus 2 0 2 and 1 are the sequences what it is been assumed.
Now what will be our x 2 of n?
We said.
x now m minus 1 previous samples from the x of n what we have to take it.
So, in this case we have ended x 1 of n here.
So, previous to that 2 samples means this 2 and 1 are going to be repeated in our x 2 of n and rest of the 6 samples are going to be from our x of n here.
So, you will be pushing it down same thing with the x 3 of n last 2 and then x 2 will be repeating it and then goes for further.
Now, we will see its operation.
First is we have taken x 1 of n. So, we are doing the circular convolution here.
This is our x 1 of n and after that as you can see it is repeated for the next length also.
And our impulse response h of minus k minus minus of k minus n is given by this.
We have padded here also with 5 0s.
And, then you have taken the reverse the sequence which is going to be 1 2 3.
Start the computation here.
So, what is it?
Initially you will be seeing that this is 2 into 1 plus 2 into 1 which is going to give us 4 and then shift by 1 bit and then start computing it.
So, the next will be 1 and so on compute till here.
Then next is x2 of n. So, we said that x2 of n.
The sample what we had was from the previous one what it was repeated, you will be seeing that 2 and then 1 here and then you will be having the input what it has been taken from the input sequence.
So, now, same thing with h of minus k minus n. So, you will be reversing it and then taking it and then you will be doing the convolution of the 2 sequences.
So, you will be seeing that the resultant y 2 of n is 8 7 4 minus 3 minus 7 minus 4 and 5 and then 4.
Now, the next step is we have to calculate y 3 y 1 of n is given y 2 of n and y 3 of n last 2 we can ignore them that is what it will be.
So, you are putting under y 1 y 2.
So, we are going to discard these 2 values after the thing.
doing inverse FFT and then this is what it will be resulting is 6 4 minus 4 minus 4 and then you are going to discard these 2 values from y 2 of n and then put 4 7 from here and then continue with whatever data you are going to get from y 2 of n after discarding these 2 samples.
So, you are seeing that both overlap save and then overlap method.
So, works same as with our regular linear convolution.
So, we are getting the same results.
So, this is the way how overlap save method works.
So, you will be seeing that how the discard output blocks is going to happen with respect to y1, y2, y3 is given in this case.
So, y is 1, 0, y1 and then up to m minus 2 what you will be discarding them.
m minus 1 points and then you will be considering only this points and then these things ok, you will be discarding.
So, this is equivalent to our regular that is linear convolution with x of n with h of n. So, this is what the desired output and first m minus 1 points of each output block are discarded and the remaining l points of each block are appended to form the y of n. So, this covers are both overlap add and then save method to compute A 50 for a long length sequence.
So, one can ask why we have to have a overlap.
So, without overlap I have not taken the example in this case one can work it out using MATLAB.
So, what is the thing is going to happen.
So, you will have the discontinuity as you know that.
There will be if it is a speech signal if time permits will show you in the next class demo of it without overlapping how the signal looks like ok.
So, now, what are the applications of DFT?
So, the first one as I have told in the previous class that it is spectrum analysis.
So, what do we mean by that?
That is x of k is nothing but.
our magnitude of x of k into this is the phase part of it.
So, we will be taking the magnitude spectrum is given by that is magnitude of x of k is nothing, but a real of x of k whole square plus imaginary of x of k whole square under square root what you will be computing it.
So, this we have already seen in MATLAB as well as in CCS what will be our magnitude spectrum is going to be.
And next is the phase spectrum one wants to have it.
So, which is going to be tan inverse imaginary part of X of k divided by real part of X of k. So, in the example in the last class we computed for DFT what will be the angle and we plotted manually both the phase and then magnitude spectrum.
So, now, one more application as we call it of the DFT is first convolution.
So, as we computed in the last class what will be the computation time for FFT calculation and then how this can be implemented to do a fast convolution.
That is x of n is we take the FFT which is x of k and then impulse response are b coefficients in FIR filter.
We can take the FFT of it pre computed we will do that and then do the multiplication.
So, we have considered.
the complete computation time and we have to do IFFT and then get the Y of n. So, compared to the direct DFT or direct convolution.
So, how we were able to achieve almost 5 times the computation speed compared to the normal one that was shown in the last class.
So, then to check the thing how to calculate.
although we have done it in the last class, we will see how to plot our magnitude spectra with an example.
So, the example is x of n is given as 0.5 volts in this range 0 less than or equal to n less than or equal to 3 and then x of n is going to be 0 in other places.
Then compute the DFT for lengths of 8 and then 16 and plot the resulting magnitude spectrum sampling frequency in telco.
So, the thing is what we have is if you calculate manually you can do this and then plot it.
So, the magnitude spectrum you will be seeing that the n is equal to 0 will be 2 and then which comes to 1 0 and then 0.5 and then you will be seeing 0.5 and then you have 1 and then 2 this is with respect to.
n is equal to 8.
So, the same thing if you do with n is equal to 16 that is what we checked it increasing the that is magnitude spectrum for DFT how it is going to look like.
So, you will be seeing that few of the samples are in between filled between are 0 to 1.
In this case because it is twice compared to 8 kilohertz 8 point it is 16 point.
So, adding one more point in between these 2 signals.
So, you will be seeing that between these 2 as you can see that this point at 3 has been added.
So, at here 1 and this 3 and then you will be seeing all odd values have got added with respect to n is equal to 16.
So, you will be seeing when you draw a line in the thing.
So, this may be much what is it we call it as a smoother one.
to predict your computation using FFT.
So, now we will see how we can do the spectrum analysis.
So, two important parameters in spectrum evaluation are one is the bandwidth resolution, the other one is the frequency resolution.
So, the bandwidth resolution sets the signal sampling frequency, whereas our frequency resolution sets the record length and FFT length.
So, as an example it is required to use FFT to compute the spectrum of voice signal with a bandwidth of 5 kilohertz.
Determine the minimum record length if the frequency resolution required to be at least 10 hertz.
So, that means, from sample to sample what we want to have it as 10 hertz.
Then what is it?
A sampling frequency has to be greater than or equal to twice our bandwidth.
So, which restrict our sampling frequency as 10 kilohertz.
Then we will see that what will be our record length n what we have to calculate.
This should be greater than or equal to or Fs by F naught.
F naught is a spacing what it has been given is 10 hertz.
So, that means, to say that 1 kilohertz 10 kilohertz divided by 10 is going to give us 1000 samples basically.
So, to do our FFT computation we know that nearest power of 2 what we have to assume it for 1000 it is going to be 1024 that is 2 to the power of 10 is going to be 1024 is the nearest.
FFT computation what we have to do it for this signal, order to produce the required frequency resolution fine.
So, then we will see that in the previous case.
So, now, you will be seeing that instead of 10 hertz.
So, you can go back and then check what will be the frequency resolution, because we are trying to fix the record length based on it the frequency resolution little bit get modified it may come to 9.9 or.
hertz you can check it up fine.
Next is how to compute our power spectral density.
So, we know that power density spectrum or periodogram we call it originally introduced to determine our hidden periodicities in data.
So, gives the distribution of average power over various frequencies for a signal with indefinite length and is defined as.
P r r is given by the magnitude of X r r to the power of r divided by n. So, we know that X r is our DFT of X of n and n is the window width.
If X of n is a non stationary random signal then the DFT of X of n for each window period will differ.
And the average of a set of our periodogram is used as an estimate of the power density spectrum.
which is given by P r r r of of.
So, we are averaging over m windows 1 by m times.
So, P x m of r m is equal to 0 to m minus 1, where the estimated power density spectrum P r r r over the thing what it is represented is given as the average of the periodograms obtained from m windows.
The winded sequence is given by example, if you take it 0.5 volts, 2 volts, minus 0.5 volts and minus 2.
This is our x of n. We will see the how we will be calculating it.
So, you have been given values as minus 0.52, minus 0.5 and minus 2.
So, now, we will see that if we because 4 point.
So, we will apply the decimation in time FFT butterfly diagram is shown here.
So, if we input the thing so, and then compute our x naught.
So, we have worked out this example.
So, if you want to see the steps have been given here.
So, the first x naught is 0 and then the second one is 1 minus j 4.
So, third again is 0 and then we know that x 3 is going to be conjugate of our x 1 basically.
So, which is going to be 1 plus j 4 or you can compute using our butterfly diagram.
So, then how we are going to compute our power spectral density.
So, you will be seeing that x naught square whole square divided by here it is m is 4.
So, divided by 4 and then you will be seeing this way.
Then what happens to the thing it is 0, 4.250 and then 4.25.
So, this is the distribution in the thing to find out the energy and power of the sequence.
So, we know that passivals relationship what we are going to apply.
So, for the energy sequence.
So, which is given by E is equal to R is equal to 0 to 3 in this case for the example.
So, this is Px of R. So, when you calculate 0 plus add them up.
So, we will be seeing that it is going to consume 8.5 joules in an 1 ohm resistor.
So, that is if you are passing this on a 1 ohm resistor it will consume 8.5 joules.
And the average power if you want to calculate of the sequence.
So, you will be calculating energy divided by n basically.
So, it is going to be 2.125 watts of power what this system is going to consume.
So, this ends our overlap add and then save method and how to compute our power spectral density and then energy of a sequence.
So, in the next class we will take up correlation.
Thank you.
Welcome back to real time digital signal processing lab.
So today we will discuss about DFT and FFT.
whatever we have covered in theory.
So, we will see first in MATLAB, then we will go to the DSP processor board and then see how we are going to run our code today.
So, first we will consider the MATLAB thing.
So, this example as I was mentioning about the filters.
So, this is from the book Welch Wright and then Morrow.
So, you will be seeing that real time digital signal crossing book published in 2005.
There was an M file which shows that how the windows can be generated.
And, then the filter responses for different kind of windows what we can see it.
So, we will be applying one of the window for our DFT or FFT to remove the noise and then see that how they will be represented in the frequency domain.
So, here number of inputs what it is chosen is 128 and then alpha for KZ window is chosen as 3 and then number of FFT points chosen as 1024 into 8.
And then the sampling frequency in this case chosen as 48000.
And then you will be representing that is line type control for the plot and then you will be setting the font size in the plot of MATLAB.
So, first one will be calculating barlet window with the end points and then hamming window, rectangular window and then the kz window.
So, we have to pass the alpha parameters which can be variable.
So, you can select them as we have seen in.
filter design toolbox.
So, you can generate this then you will be computing their frequency response we call it as frequency Z basically.
So, you will be calculating for the that is h 3 what you have seen the thing w 3 by sum of w 3 what you will be putting it and then the sampling frequency what you will generate and then.
the frequency response for H 2 is shown that with this parameters and you will be outputting the figures actually.
So, you will be plotting W 3 that is subplot what will be having it and then font size line width what it is shown and all the 4 figures what it will be plotted.
So, with different colors and then later on.
You will be seeing that subplot what you are going to calculate that is P3 what it is chosen and then you will be finding these are the plot parameters one can go through you will be getting help file in MATLAB and then you will be all these are the subplot.
So, you will be seeing that you will be calculating a hamming window what it is going to be used and then.
its frequency after passing your data through that what you will be seeing it.
So, we will run and then see how we are going to get the output.
So, you can see the thing you will be seeing the first the figure we will look at it.
So, you will be seeing that this is a rectangular window and you will be seeing with the pink as a case of window with alpha is equal to 3 what it has been selected.
and then hamming window and this is the barlet window what you are seeing it is just like a triangular and then this is a rectangular and then the other two represent your smooth response.
So, the second figure we will see what has happened.
So, you will be seeing that in this you have passed through the rectangular window and then you are seeing the frequency response of after passing through the rectangular window.
And, then you will be seeing using the hamming window.
So, how the output is going to be represented?
So, you will be seeing that this is our main lobe, this is a low pass filter basically and then these are the side lobes.
So, you will be seeing that rectangular window you will be seeing it is has a main lobe is very narrow compared to your hamming window or any other window what you can take the thing.
So, you will be seeing the ripple somewhere.
in minus 14 dB or something like that what they have come down.
And then finally, it will be settling down to 21 dB also.
Whereas, in the case of your hamming window, this is a smooth response what you are having with your input signal.
So, the main lobe is little bit increased and then you will be seeing your side lobes have come down approximately what we can take it as minus 40 or 41 dB.
So, this shows that how our filter helps in having the main lobe and then side lobe required for your application what you can select one of the windows basically designing with windows.
So, we will close this and then we will go to the DFT basically.
So, here what we have is.
Usually, we ask the students to run DFT, FFT and then overlap add and save method.
So, we will demonstrate today up to this thing ok. We will go with the DFT, FFT editor because I can split the windows or editor can be in one of the thing.
So, here we will maximize on the editor so that you can see the codes what it has been written.
So, initially we use the clear all.
So, you should be calling back the theory.
So, we did.
the circular convolution using DFT properties.
So, we will be using in this case FFT to run our circular convolution.
One of the way of doing it is I can put a break point because the continuous code is running.
So, I will be setting the break point here.
So, that we will be seeing one after the other.
So, first one is a circular convolution.
using FFT as you can see that x has the value 1, 2, 3, 4 and then h is 1, 0, 1, 1.
So, this example we manually worked it out.
Now, we will see MATLAB how it is going to compute.
So, we will be first what we are doing convolution usually direct convolution as we have done it earlier.
Now, using FFT how we are going to do the circular convolution we look at it.
So, first what we do is xk is our FFT of x and then h k is FFT of h what we will be taking it.
And in the frequency domain we know that y k is going to be represented by direct multiplication of h k into x k. So, that is r as you can see y k is equal to x k into h k or h k into x k. Then what we will be doing is I can take the inverse FFT of the y k.
And compute and display circular convolution result.
So, then accordingly we can do the linear convolution.
So, how it is going to what are the values we are going to get it through a linear convolution is given by this equation.
Now, what is it L y linear y output what we will be getting it.
So, the convolve is the command prompt in MATLAB.
So, you can one can use it x comma h. So, it will be computing and display linear convolution results.
So, we will run this code since I have put the breakpoint till here what it will be running.
So, you can check the thing results it will be displayed on the command window.
So, I have to bring it down.
So, you can see that as the convolution of circular convolution of 1 2 3 4 and 1 0 1 1 what we got the result was 6 9 8 7 in the theory.
So, you are seeing using the MATLAB it was asked for you to verify with MATLAB whether you are going to get the same thing.
And, then the linear convolution what you can see is it is 1 2 4 7 5 7 4 what we got it.
So, that will be seeing that is direct convolution what it has been done.
So, using the convolution whether we can do the linear convolution that is what the example we worked it out.
So, here you will be seeing that linear convolution by 0 padding in the MATLAB code what we had has been written.
So, you will be 1 2 3 4 and you will be we have added the 1 2 4 0s.
So, this is 0s 1 2 4.
So, it will be generating 1, 2, 3, 4, 4 zeros followed by and then the same way with H z also 4 zeros what it has been added.
Now, you will be doing the DFT of or FFT computation basically of R X z and then H z, then we multiply in the frequency domain both of it ok.
So, why we can take the IFFT of IFT and then.
will be getting the results.
So, just to show that I can put the break point and then see that what our output is going to be.
So, we will continue the running.
So, we will see that the results are displayed here.
So, you can see that what was the thing the previous one we had 1 2 4 7 5 7 4 and then y is the what we have got the output with linear convolution and using FFT.
So, you will be seeing that it is 1.0, 2.0 and then so on.
The last one is minus 0 because we added one extra 0 in the thing because l plus m minus 1 as we know about it.
So, it has to be 7.
So, till there what you will have it rest of them are 0s by doing the 0 padding.
So, we will go back to the next this thing.
So, I can maximize when I want to show you the results.
So, we will reduce it and then go back.
Now, what is it?
Calculate the amplitude spectrum of sine wave using F50 and then display it.
So, here are this thing is number of samples that is 256, we call it as sampling rate and then sine wave frequency what chosen is 50 basically hertz and number of points chosen is 120.
So, this up to 128 points 0 to n minus 1.
So, you will be calculating sine of 2 pi.
f by f s into n. So, that is how we will be getting our x n samples in input sample.
Then we can calculate x of k that is f f t of x of n comma n number of points.
And then we will be plotting the absolute value of x k because we know that it is a complex conjugate what we will be getting it.
Only the amplitude what I want to have the thing.
So, we will be taking the absolute of x of k which gives us the plot the amplitude spectrum alone.
And, then this is going to give us the magnitude spectrum.
So, for the axis is going to represent 1 to 64 show only up to points fs by 2.
So, in this case what we have is 128 points which represents up to 1 to 2 pi or fs values.
So, you will be labeling.
So, what we will do is we will put a breakpoint again.
So, I have to go down and then the select a breakpoint here.
So, we will set enable the breakpoint here.
So, you will be seeing where next computation is going to happen we will have the breakpoint.
So, we can continue this is to avoid multiple files.
all the codes have been incorporated in one.
So, you will be seeing that this is the for up to 64 samples what you have it.
So, what we have is f is equal to 50.
So, you will be seeing the magnitude whatever you are going to get the thing and then the frequency index you will be seeing that it is at approximately.
So, what you are having the frequency at k is equal to 25.
So, can you compute and then look at it whether you are getting the frequency as 50 hertz.
How it is going to be?
So, you have to multiply it by 2 which you will be getting it as 50 hertz ok.
So, now the next one is.
compute and display amplitude spectra at 2 sine waves.
So, how we are going to do this?
We hold on for a while.
So, we will set the break point here also.
So, you know that next break point is set.
So, what we are going to do here?
So, again our sampling frequency we have chosen as 256 sampling rate and sine wave frequency is 50 hertz and number of points what we have chosen is 128.
And we will be calculating sine of the thing 50 hertz sine wave.
So, we will be doing the FFT of this one and then calculate our this thing magnitude.
So, this is what we did the thing.
So, the next one is we will see that amplitude spectra 2 sine waves what is going to happen.
So, we will put up the next break point it has already selected.
So, it is the same thing.
So, what you have is the first frequency is 50, f1 is 61 frequency of first sine wave and then second sine wave what it has been chosen.
And you will be calculating xn is sin 2 pi f by fs into n and then x1 of n will be 2 star pi f1 by fs into n. So, generate 61 hertz generate 50 hertz.
Then take xk is equal to fft of the first.
input signal and x1 k is of f of t of x1 comma n basically second sine wave and then calculate their magnitude spectrum first sine wave and the second sine wave magnitude spectrum and then plot them with n values which is varying between 0 to 127.
So, you will be only representing 1 to 64.
run this you will be seeing that how the two of them look like.
So, you are seeing this is a multiple as you can see this is you will be seeing at 50 hertz and this should be at 31.
So, you can see that approximately x is there 30 little bit movement will give select 31.
So, So, So, So, that is what your y magnitude is 40.7109 what you will be seeing it and you will be seeing this if I put the thing x is 25 and then y is 64.
So, you will be seeing that approximately you will be getting between 60 to 61 what you are seeing the thing which is 61 hertz sine wave generated.
Whereas, your peak is at 25 for your 50 hertz signal as because we are representing with 64 samples in the thing pi by 2 what we have done the thing ok.
So, this is how we are frequency spectrum and other things work.
So, the next one is we are going to see that overlap of two spectral lines due to frequency separation is less than frequency resolution.
So, how we have defined our frequency resolution?
It is fs by n what we have taken the thing.
So, you have 256 here again n is 128 and fn in this case sampling frequencies sorry the frequency that has to be passed first sine wave is 60 the next one is 61.
So, compared to the previous one so, we have 1 hertz difference.
So, we will see the resolution how it is going to be represented.
Then we will be calculating x in and then x to n.
generate 60 hertz and then 61 hertz as usual previous.
Then add them up and take the F f t of x in that is mix these two sine waves and take the DFT computation find the magnitude response and then plot.
So, we will be checking the break point again.
So, we will see.
sorry almost they are overlapping you are unable to see even the expansion of it.
So, you can reduce the thing.
So, approximately it shows at 30 R combined frequency response.
So, your resolution what you are going to see is very this thing small in this case.
So, we may have to increase number of samples.
So, what we can do is I can sample at this thing what we will call it as 1024 we can modify this sorry 1024 and whether number of points whether I can increase it to 256 we will see the thing.
And, then we will rerun the code again.
Actually, it has gone off to further ok. We will clear all the breakpoints and now we will put the breakpoint here.
And, the next rig point will be in the next place.
She had your dark suit in greasy wash water all year.
So, one second clear all will help.
break the thing.
So, that we can restart it because it has gone into the end.
So, we will come back and then run that portion.
So, I have to put the break point now where we are calculating here f is we had given it as enable the break point here and then again we will enable the break point here.
So, it has come to this.
So, you can see that it the previous one what we are seeing it as the output.
So, now, I have to run it again because it is pointing to here, we will continue the thing.
So, now, you will be seeing that.
all the sorry it is been mapped to only 64 points.
So, it will be little shifted you have to multiply still you will be seeing that the peak has gone up to 200 and odd.
So, whether we can expand it.
So, you will be seeing that 60 and 61 almost has got merged in this that is what we call it as frequency resolution which we are unable to look into the thing.
So, now, what is it?
How we are going to compare a rectangular and k-zer windows for spectral analysis?
So, the next example.
So, here the sampling frequency is 256 and we have n is equal to 128 points that is what it says sampling rate and then signal length and then the frequency selected it is 61 that is sine wave what we are going to generate it and then beta value in this case is selected as 8.96.
And, then the we are going to use instead of alpha we will be selecting beta in this case, w and k 0 n comma beta we will be applying it.
And then we are going to do the normalize the gain against again as rectangular window.
And then rectangular windowed spectrum what we will be calculating absolute of that.
And the other one is we will be calculating kz windowed spectrum.
from that that is normal g into absolute of x l k and then we will try to plot the thing.
So, here we will put again the break point.
So, that will not spill over ok.
So, we will run and then see what will be the frequency and then magnitude what we will be getting it.
So, you can see that.
So, what is the first one what we have it here is absolute of x k. So, that means, to say which is the window you are going to have it rectangular window here.
And then this is my rectangular window and this is the k z window what it is representing.
So, with the beta.
So, we will be having the response of the k-zer window as this way.
So, we you will be seeing that the almost equivalent to rectangular window the main lobe what you will be selecting it.
So, you will be seeing your frequency will be approximately 61 hertz both of them are passing with both rectangular and then.
So, we will see how to find the power spectral density of 2 sine waves embedded in our random noise.
So, you can generate a random noise that is initialized random signal generator.
So, and then your sampling frequency what you have chosen as 1 kilohertz and then you will be having generate fs by 10 is you will be seeing that 100 samples.
of the every one point what you will be selecting it and you have been given what is it amplitude of 2 sine waves that is 1 and then 2 which is 150 and 140 frequencies of sine waves.
And then amplitude of the first sine wave is 1 second sine wave is 2.
So, generate xn with a sine 2 star pi f star t plus.
0.1 times the random value what you will be adding with your signal.
Then you will be calculating your spectrum and periodogram ok.
So, that is what the next assignment or lab portion of it will again enable the break points here.
So, we will run it and then you will be seeing the spectral density here.
So, that is what your power spectral density.
So, what we had was two frequencies 150 and then 140.
So, you will be seeing that this is approximately 140 and this is approximately 150 4 or something approximate what you have the thing.
And you will be seeing that.
how your side loops are buried in your noise what you are seeing it fine.
So, the next one is whether we can play and compute a spectrogram of speech file in this case.
So, next we will put the this thing.
In this case.
So, you have a speech file sampled at 8 kilohertz you can record it using MATLAB and number of bits chosen is 16 bits in this case and sound is play the speech signal and then you can find its spectrogram using the function spectrogram ok.
So, we will see that first and then we look at it.
Hopefully, you have heard the thing.
This is the speech spectrogram what you will be seeing it.
So, you will be seeing that your power of frequency 0 dB per hertz what it is shown.
So, these are the 50 hertz and this is frequency in kilohertz what it is marked.
So, most of the speech signal as we say that it is going to be up to 3.1 kilohertz.
So, that is the reason why the or maximum 4 kilohertz that is why the sampling frequency is chosen as.
8 kilohertz and time duration in seconds this is the 3 second.
So, this is how you can generate your sign distinct speed signal and see its spectrogram.
So, now, what we will do is we will overlap add techniques for fast convolution what we are going to use it.
So, this theory will be covering it in the how to do this fast convolution will be covered in the theory.
And, then how to implement FIR filter that attenuate this whatever 1 kilohertz sine wave tonal noise speech file.
So, what is it?
So, you will be using the same speech file and then sampling rate is chosen as 8 kilohertz.
So, first we will be playing the original speech signal, then pure that is what speech is played.
Then what you are going to do is you are going to generate a 1 kilohertz sine wave which is called.
So, what is the omega 2 star pi into f by f s frequency of sine wave.
So, you have done the thing and you will be merging with your speech signal that is what we call it as corrupt switch by 1 kilohertz sine wave.
And then you can hear that corrupt voice and then you we can display the spectrum of noisy speech and then later on we will be applying window technique.
that is pass band filter 900 to 1100, fs by 2 is 4000 in this case what we have given and apply FIR 1 filter with stop band that design in FIR filter to stop the frequency this is a band stop filters what it is not band pass it is a band stop 900 to 1100.
So, we want to eliminate 1000 hertz so that is why it is stop band filter what it is designed.
And then you will be passing this coefficient b coefficient through your FFT filter that is FIR filtering using overlap add method is being used here.
So, that it is a continuous signal input signal what you have it.
So, you would not be able to take the complete FFT.
So, part by part what it will be done, done actually in the overlap method add method is being used.
So, we have the overlap save method also one of them can be used here overlap add method is going to be demonstrated.
So, you will be displaying the spectrogram of the filter speech.
this is a noisy signal.
So, we will go back and then press the this thing.
She had your dark suit in greasy wash water all year.
Although you faintly see the 1 kilohertz, but still in the speech you are unable to hear the sine wave.
So, this is a filtered output what you have got it.
So, this shows that how our discrete Fourier transform is computed using.
FFT method to implement for different applications.
It can be circular convolution, linear convolution or you want to eliminate your noise from the speech using the filtering technique.
So, we can do it in the frequency domain.
Thank you.
Welcome back to real time digital signal processing lab.
So, we will see that how our adaptive filter is going to run.
Yesterday one of the wave file was missing.
in the previous class.
So, today it has been put into the system.
So, we will see that how it is going to run with different people writing their own code and then testing their algorithm ok.
So, the adaptive filter what it is shown in this matlab file.
So, you will be seeing that this also GUI.
Yesterday we were trying to run the LMS algorithm.
So, the voice.
then the tone dot waver together basically that is what we call it as here it is included in the combined stereo basically.
So, you will be seeing that there is a mistake in the stereo spelling.
So, that is what you have to do the thing and then we can run it.
So, when we are running it independently then we have to open this.
Now, we will see that How using the adaptive filter directly including we call this as the adapt now you will be seeing that code is written in this way GUI code basically.
So, that you can change your input file and then mu and other parameters you need not have to go back to the system to change it.
So, you will be seeing that it is getting as yesterday I said.
in the last class sorry that is two tones what it is taking it one and then two one is the input the other one is tone and then you will be combining it and then sending it that is we have left channel and then right channel for stereo.
So, both are taken together.
So, then how our algorithm is going to work with mu and definition that is LMS algorithm.
alpha mu value what it is taken because it contains both NLMS and LMS algorithm.
So, you will be selecting alpha for NLMS and only mu for our LMS algorithm.
So, these are the inputs because you can see they are getting in handles me you can vary those values.
So, this is the complete code what it has it.
as it is given the thing it is going to code for adaptive filter dot figure creates a new adaptive filter and raises the existing single tone.
So, you will be seeing the property GUI what it is going to run it.
So, we will run and then see how it is going to work on this file ok.
So, you have seen that in the previous class that all the algorithms were together.
Here, you can select the wave file.
So, this is a combined stereo what I will be selecting it from this place and then the n is given 61 order mu is selected as 0.1.
So, what I will do is I will change the thing to 31 order and then 0.1 for 0.01 for my adaptive mu what I will be delaying it.
So, we will run the LMS algorithm first on this, run it.
So, if I want to see the unfiltered output, it is F 50 and then output what you are seeing it.
So, filtered output always if I run the filtered output.
So, you will be hearing it clear speech which is coming out of it ok.
So, now what we will do is we will change the order to 61 and then our mu value to 0.1 and then see what is the thing is going to happen.
I will run the LMS algorithm it is a clear speech.
So, you are seeing how your output is coming.
So, change of the order of the filter and then the mu value which is set to 0.1 step size.
So, you will be seeing how output is going to behave.
So, now we will see with respect to NLMS algorithm same thing what I will keep it and then alpha what selected is 0.9.
So, we will run the algorithm.
Remember the force will be with you always.
always, remember the force will be with you always.
So, if it is unfiltered output here also we will check the thing to make sure that our input contains both the that is noise plus our speech signal.
Remember the force will be with you always.
correct.
This is the way how you can design your adaptive filter.
Now, what we will do is we will take up as you can see there are different assignments.
So, we have done the demo also the same way.
So, this was LMS algorithm was given as a mini project to all of them.
So, they designed their own way in programming.
concept what they have taken because usually we do not allow for copying.
So, you have seen two different.
So, we will have multiple students developing their own algorithm.
Now we will see that one of the student think how our echo is going to work ok.
So, we have seen the thing echo generation.
So, what is the echo how we have given the equation.
So, I will show you the equation here.
So, you will be seeing that you are going to read your audio sampling frequency is set at 8000 and then echo duration what you will be setting from the your handles.
You can set the thing minimum how you will not have the echo path and then if you set the duration little more then how you will be seeing the echo path.
And then this is the delay so that is given by echo duration multiplied by your sampling frequency divided by 1 kilohertz basically.
So 1000 what you have taken the thing.
So in this case delay 1 is this is the time duration what you will take it.
So our out of i will be input of i what you will be taking it and you will be calculating the delay plus 1 to length of it.
So you will be adding with input of i.
your echo weight into output of I minus delay.
So, this is how you will be adding to your input the as you have called out of I is input itself.
So, this is the input delay what we are going to give it whereas, in the reverberation it is the output which is come whatever out of I you have calculated will be going as delay ok.
So, the will run thus.
and see how it is going to respond to our data.
So, here also you will be seeing that you have been given echo duration millisecond default first we will run the thing and then we can modify and then see it.
This is 300 millisecond what the delay is there and then echo weight is between 0 and 1 what we have to give it.
So, here it is taken 50 percent that is 0.5 what it is and then we have to select the wave file for running it.
So, we will see that.
This is the voice signal what we will take it.
So then we will run and then please see that whether you are going to hear the echo.
Remember the force will be with you always.
So you have heard the echo coming.
So what is the FFT of it?
So this is how the FFT of your echo path what you will be seeing both your input and then So, we will change the duration we will make it 30 millisecond.
So, in the theory we said that 40 millisecond are path what it is going to take for the telephone line to come back.
So, here we will make it and then we will make it as 0.1 also in this case and we will see whether we are going to hear the delay or not.
So, this shows that If the delay is lesser, you will not be hearing the echo in your telephone lines or voice over IP or if you want to generate it ok.
So, this is how it works.
So, we will increase it to little more and see how the echo can be perceived ok. And I will give wait for it is 0.5 and see it.
Remember, remember, so you have heard that.
Remember which is occurring so many times.
So, you can consider echo can be used for your reverberation.
So, it is not once it is multiple times what it is coming fine.
This is one of the example.
So, we will see from next is our scrambler basically.
So, you have to hold your breath for this example.
In the next example, I will show you I will go with this example later because.
they have not given a reset command to reset the thing sometimes it goes continuously fine.
So, we will go to the other this thing this is the MATLAB code.
So, I have to go to the particular thing.
So, you will be seeing that this is echo scrambler and equalizer all together in this case.
In the previous case we saw only one running it.
So, here everything is combined.
So, we will run the thing one more student thing how it is going to work.
Here you will be seeing that all the three should be coming.
So, there will be a case statement to take care of it which one you are going to select.
Based on it you will be running you will be seeing that scrambler which is going to run or it can be your echo the first one will be running echo the next one will be scrambler and then the last one will be equalizer.
We will be seeing.
that also how it is going to work ok.
So, you are seeing the codes here, this is scramble and then this scramble both is going to happen, you can select one of it and then you will be getting the plot also how it is going to look like and you are this thing audio file what you can read the thing.
Here it is echo strength you are calling with alpha in this case and then.
you will be computing your delay i minus d is the delay.
So, which with the wait function will getting added with your input and this is what it is going to generate your echo.
So, we will run this code I may have to as it is going out of the thing.
So, we will just reduce the delay.
thing to 100 that is size basically scale the thing so that I will be able to show you the demo part of it.
So, we will run it.
So, now, you will be seeing the complete GUI otherwise some of it is getting suppressed.
So, what we will see first we will check the echo basically you can here it is given in seconds there in the previous example from the other student it was in millisecond here you can define it as in seconds, but it is.
As you can see 0.1 to 0.6 what you can go with it.
So, we will choose same as that one and then I have to load the input wave file.
So, here we will be putting the same speech file in this case and then first we will play the input wave file.
Remember the force will be with you always.
So, one can select any wave file.
So, usually we give this and then even noise getting added, corruptive signals are given to the students to run the thing.
So, now we will generate the echo from this case.
Remember, remember the force will be with you, will be with you always, always.
So, as you can see here you do not have the option to select the delay.
So, only single echo has been generated.
In the previous case even the echo duration you are had the provision to do it, here only what weight what you are giving it.
So, if I give the weight little lesser.
0.1 ok and then generator echo.
Remember the force will be with you always.
So, you will not be hearing any echo.
So, as and when my weight is going to increase delay path is defined then I will be getting the delay.
Now, we will see the same thing how the scrambler is going to work.
It is the same input file what I will be giving it and then we can.
the frequency what I have to choose it.
So, as we discussed in the theory.
So, we had selected 3000 hertz as the thing we can, but here you have the variable thing.
So, first we will check 1000 and then do the scrambling.
So, you will be hearing a scrambled voice.
.
So, you heard the scrambled and do this de scrambling.
Remember the force will be very powerful.
So, you can see the plot how does it look like.
This is the scrambled signal unable to make out much difference in this case and then the descrambled output which is almost equivalent to your input.
So, we will change the duration that is filter frequency basically.
So, we will choose it as 2000 and then do the scrambling.
So, you can hear that is there is some this thing speech you can make out and then this .
We will choose 2500 hertz 3000 anyway ok.
So, then we will scramble it and then here how much you can hear or it is completely scrambled.
Since, you have heard the thing earlier, so you would be able to make out what is that disc rambling.
Remember, the force will be with you always.
Next, equalizer, so what is an equalizer?
If you have a nowadays anyway music system nobody is buying the thing.
So, although headphones and other things what you buy for noise cancellation and you know boss is the best manufacturer of your all the you we call it as audio equipments.
So, here the equalizer you can select which one you want to retain and which one you want to suppress it.
So, as you will be seeing here it is a 4 channel equalizer.
So, some of them go with.
10 channel equalizer.
So, that you are narrow band only those frequencies which you want to highlight it you can do the thing.
When all of them are in the center you know that it is a balanced system what you will be getting it.
So, some of them design a 3 channel equalizer with the frequencies.
In this case what is that it is 0 to 500 hertz is a low pass filter what it has been designed.
So, that anything above 500 hertz by making it 0.
Whether I can cancel it we will see the thing whether they have given the 0 option or not I am not sure of the thing.
So, we will verify it.
So, the next one is band pass filter.
What is the frequency after passing 500 hertz?
Next 500 hertz to 1300 hertz what we can use it to do are this thing frequencies that can be passed.
So, if I suppress the low pass filter and then only using this.
some of it is going to be highlighted and some of them will be suppressed.
And then the next band pass filter is 1300 to 2500 hertz.
So, this is what are this thing two band pass filters in different two frequencies from here to here what you have the thing.
So, they will be passing the signal between these two frequencies from them one can be 0 the other can be uploaded.
The last one band pass filter what it is been used is 2500 to 4000 hertz.
The sampling rate here it is assumed is.
8000 total fs by 2 that is up to pi value what you are giving your frequencies to pass through.
So, what we will do is here because we have to hear the speech file does not have all the frequencies usually all your bands and other things you will be having in the higher frequencies.
So, we will see that how it is going to work for a music in this case so, because usually the.
regular are August semester ends in December this student has chosen a merry Christmas as music signal to run the thing.
So, we will play and then see what is the output will be getting it.
So, I have loaded the thing I can play the input way file.
It is a part of it not the complete because it will take little time nobody will have patience to listen to the thing.
So, we will play the thing with respect to.
the thing because I think it might not have got cleared.
So, we will load the file again speech file, we will set minimum value for all of them we will make it at least little higher.
Remember the force will be with you always.
We will change the input file, we will load the music.
So, now we will reduce these two, if you had noticed some of the thing.
As you have seen the thing.
only it is getting passed with this ok.
So, I will include one more frequency and then we will play the thing.
Still some of the things are missing.
So, we can make it 0 here and then play only one frequency is getting passed.
So, you the clarity is gone ok.
So, we will make it all of them this way you can as I mentioned in the introductory class that you can keep playing like this writing your own code what you want to generate it.
So, as this example shows that this is from the MATLAB file what we are running it.
So, you want to design your own hardware.
So, you can do that.
So, you can see that.
And, then we will be seeing the demo in the next class using our DSP processor.
So, as you have seen it is a programmable device DSP processor, we will be using it for demoing all these experiments in the hardware.
Thank you.
So, last class we discussed about the DSP architecture 1.
So, today we will see what how we are going to continue the architecture part.
So, as a recap to refresh you what we discussed in the last class.
So, we discussed about the multiplier, how to design a parallel brawn multiplier and how to design a shifter, barrel shifter what we discussed and then how to design our arithmetic logic unit what we have considered.
In this class we will discuss about memory and then what are the addressing modes compared to our.
regular microprocessor what we need it and then why we need the bit reversal and pipelining and then parallelism of aspects of DSP processor.
So, coming to the memory architecture.
So, you see pyramid here.
So, registers are the closest to the CPU.
So, and then what we have is L1 cache, L2 cache and then you will be seeing the main memory and then flash memories and then.
for more storage magnetic disc, optical disc and then tape comes in the last part of it.
All of us know that these are almost extinct from the present a situation.
So, seeing the left hand side of it.
So, you will be seeing that speed is the highest in this case and it is going to slow down when as we go down in this pyramid.
Whereas, in the case of size and then axis time as we will be seeing it size is very small in this.
access time for these registers are the smallest one whereas for the magnetic tape is the last one sizes as we know a lot of it what we can store it and then access time is going to increase.
So, continuing with the memory architecture so how it is going to be stored in our DSP processor or how it is designed what we will be seeing it.
So, you will be seeing that CPU will be incorporated with the registers.
And then you will be seeing the cache for level 1, 2 and then 3.
So, these are the direct CPU access what we are going to have it.
And then even some of the temporary storages access what you will be seeing it.
That is physical RAM virtual memory.
And the other ones are it is going to be indirect access to CPU.
So, they do not have any direct bus connectivity in the thing.
Whereas, we have to use the external bus too.
access these memories basically.
So, you will be seeing some of them are going to have a overlapping spectrum basically.
So, these are the assisted memory management what we call them.
So, coming these we call it as secondary storage devices and then we have the input sources here.
So, you will be seeing that these are the permanent storage areas.
and these are the temporary storage for the processor.
So, coming to some of the addressing modes you would have learnt in your 8085 or 8086 course.
So, we have to provide immediate addressing mode, register, direct, indirect, special addressing modes we will be seeing it as circular and bit reversed.
Addressing modes are the typical to DSP processors.
So, when you come to immediate addressing mode.
All of us know that when I want to add directly some value from the memory, we will be giving it as add hash immediate address what we will be giving it or immediate value.
So, this value is going to be added to our accumulator and the result is going to be stored in the accumulator that is what it says.
Hash immediate is the value represented by immediate fixed number.
So, usually if we have to have the filter coefficient, so if we know a prior then we can.
give this as a immediate value and then as normal notation A is the accumulator in this.
Coming to register addressing mode, we say operand is always in processor register, we call it as REG and capability to reference data through its register, we call it as add register means the value whatever stored in the register is going to be added with the accumulator and result in accumulator.
So, this REG are the processor register.
which provides the operands for our addition.
So, coming to the next one we have to have a direct addressing mode, we have to take a data directly from the memory location we call it as MEM.
So, it is going to be reference data by giving its memory location directly.
So, we say add memory.
So, we are giving the address of it whatever the value stored in it that is MEM is going to be added with our accumulator and result is MEM.
the accumulator.
This is the specified memory location MAM.
And in the indirect addressing mode we have to say that operand accessed using pointer add register because all of our operations are continuous that is sigma what we call it the from 0 to n minus 1 times what we want to multiply and add for that we should have a pointer so that I can access one after the other.
So, operand memory location is the variable in this case and operand address is given by the value of register.
in this case.
So, you will be specifying add star gives the from where the memory location where it is available the data address register.
So, the value provided by this whatever pointer it is address register is pointing to the value is taken from that memory and then it is added with the accumulator and result is an accumulator back.
So, that is what it says add register loaded with register location before use.
And, coming to special addressing modes as I am telling these are the ones which classifies digital signal processor apart from normal processors.
The first one is the circular addressing mode.
So, here circular buffer allows continuous stream of incoming data samples.
So, once the end of buffer is reached samples are wrapped around and added to the beginning again.
So, this is.
required for real time implementation in DSP processor.
So, we know that the input is coming continuously.
The other addressing mode what we need is the bit reversed addressing all of you have taken the digital signal processing course will be knowing it that for the FFT algorithm if I am using the radix II FFT I need the input in the reversed format.
So, first we will see what is the circular addressing mode.
So, in this case this is the reference index the value what I have taken here is 8 basically that means, to say that there are 8 values what we can store.
If I put the circular address, so I will call it as what we have bifurcated into 8 the circle into 8 parts.
So, I will be seeing that this is the 0 and then this is 1, 2, 3.
4, 5, 6 and 7.
So, these are the values what I needed to store them and when the 8th sample comes what we are going to do it.
So, we have taken as it is seen here.
So, we are taking 8 mod 8 is going to be 0.
So, the 8th sample whichever is coming in the real time which overwrites this 0th location as the 8th sample.
So, what is going to happen to the 9th sample?
So, we will be overwriting on 1.
9.
This is what it is shown with the mod values how we will be storing it only in the 7 location.
So, why we need the circular addressing?
All of us know that we are working for the real time signal which is coming continuously if I start storing in the memory it is going to overflow.
So, I will not have any memory to store the thing.
So, how much I need it will consider it when I take up the filters class basically.
So, in this case we have taken only 8 values are sufficient for us.
Then once the next sample comes eighth one.
So, we will be discarding thus the first whichever is the last sample and then we will be overwriting on it.
So, that way we will be saving my memory in overflowing.
So, coming to the next is why do we need bit reversal addressing just now I said the thing how we are going to do that or how it is going to be represented.
So, if it we know that this is the input index what I wanted, but output I want it in this order.
So, as we know that if we do it in software it will take multiple clock cycles instead of that can we do this bit reversal in the hardware.
So, as you can see in the right hand side.
So, from 0 the length of the number of samples what I want capital N is equal to here also 8.
So, we take it as 8 by 2 which is 4.
So, number 4 in binary is 100.
So, we add 100 to 000.
So, you will be seeing there is no difference in this addition to whatever we consider example for fixed point addition.
So, we get next number is 0 4 as you can see this is the 4.
Now, next I have to add the same this 100 to this number.
How I am going to add instead of adding from right to left for generating this bit reversal this adder is going to do left to right.
So, when I add 1 plus 1 I will get 0 and I will have a carry here which will be taken to the next stage.
So, it becomes 0 1 0.
So, which is nothing but 2 that is what it is listed in the table here.
So, how we get the next one?
So, I add 1 0 0.
So, this is a normal.
So, it will be 1 1 0 which is 6.
So, like this we continue.
and then these are the numbers what it has to be input to my FFT algorithm to show that why we need the bit reversal it is shown in this figure.
So, what we have is x of 0 is the input and x of 4, x of 2, x of 6, x of 1, x of 5 and then x of 3 and then x of 7.
So, the output is going to be in order.
So, always input is in the bit reversed.
output will be in order.
So, if I give input in order output is going to be in bit reversed order what I will be getting it.
So, this is what the thing the detail of butterfly structure what we call it for 8 point FFT.
So, which has 3 stages the detail of the design and then how we are going to implement it in real time we will discuss when I take up FFT lecture.
So, coming to the thing next is what we have to worry about the speed issues.
So, in this case what we call it is why I need the speed part of it.
I know that TP is my processing type for the any processor and then I have to allow for some I O operations we know that we have to get input and then even the output has to go out.
So, which we call it as T O is the time.
So, this should be less than or equal to the sampling time of.
what we will call it as T s of the processor.
So, when we talk about in terms of frequency I can call it as 1 by f p plus 1 by f naught should be less than or equal to 1 by f s. So, the this is going to decide my what should be my input clock rate what I can feed it into my processor or how I am going to select the processor.
If you are designing your own processor this has to be considered depending on the application.
Here we are considering only the algorithm in this case that is processing time of one of the algorithm.
If it has multiple thing you have to take the longest one which is going to take depending on it what your clock frequency has to be designed.
So, if this is not going to be met then can I use pipelining and then parallelism.
So, that is we will be seeing in this case high speed instruction operations also one is in the data what we will be considering it as pipelining and parallelism.
How about in the instruction?
So, I can have a high speed instruction operations.
as in the 6x processors we have 32 bit 8 instructions I can fetch it simultaneously.
So, this is one of the speed at which I can get instruction in the DSP processor.
So, coming to hardware architecture.
So, we said that we have a design dedicated hardware supports multiplication scaling loops and then repeats.
Something here I want to tell that.
what is how we are going to avoid the loop why we need the repeats.
Most of the cases instead of loops we want to have the repeats.
What we call it as in the DSP processor as 0 overhead loop.
So, what is this?
If I define my variable with hash assign or anything which we will discuss in the lab thing how it has to be done.
If I declare that some value I know that what is the loop is going to run actually.
So, if I call it as 40.
And, then I will be repeating the instruction 40 times.
So, I need not have to spend that whether decrement everything is going to happen in the background and then I need not have to spend any time on the loop to come back.
So, for loop can be avoided this way.
So, the other ones we said we have use using the special addressing modes.
So, for these fast DSP applications.
The other architecture in the last class we said that we are going to use the Harvard architecture which is going to improve our execution time compared to Von Neumann architecture and even on chip memories.
aid speed of program execution considerably.
So, that is the reason why I was telling in the last class that why my intermediate result has to be in the register or stored in the accumulator.
So, that will not be spending because of your memory structure access in the external memory is going to cost me your number of clock cycles which I want to avoid so that I can increase my speed of operation.
This is how we will be designing our architecture.
Now if this is not possible.
Can we have the parallelism built into this?
That is, is there any data dependency in my algorithm I am going to check?
If there are no dependencies, then I can have multiple function units.
So, which may operate in parallel to increase my throughput.
So, then I need multiple memories and we need different ALUs for these operations and even the data and addressing computations have to be done.
differently for these ones.
As an example whatever DSK board we have using in this course DSK6713 has two parallel sites that is we call it as A and B which have four functional units on both the sides that means to say two CPUs are going to run in parallel.
So, the advantage of using this parallelism is algorithms can perform more than one operation at a time.
that how we can increase the speed.
The disadvantage of this is we need a complex hardware required to control units because which side you are working and then how we are going to transfer the data from one side to the other.
And some of the issues like you will be branching or call and then pop operations most of these DSP process does not have call and then return because we do not know where which side of the processor they will be working.
will be controlling through the branch operations those who are interested can go into hex coding and other things.
If time permits I will be presenting one of the example in the lab.
So, how we can decide what is the thing happening in both the sides of the CPU.
Otherwise most of the examples will be in C code and then how we will be extracting the parallelism is going to depend on how we will be configuring our compiler.
Next, is disadvantage of this is as we are mentioning it and then we have to make sure that instructions data can be fetched simultaneously.
Otherwise, one of them is going to slow down.
So, we will landing in the that whatever we are thinking that we will be getting twice that of that 1 clock cycle.
So, we may not achieve.
So, one of them delays the thing.
Coming to pipelining.
So, All of us know that a water pipe is an example I can take it.
We know that when the water flows when you are installed your pipe for the water line.
So, it is empty.
Once you open the tap it takes some time for you to get the water in your tap.
That is the delay what it is going to be or one more example is going to be car assembly what you can take it.
It is units are working at different parts of a car.
And once everything is done so finally, it will come for the assembly.
So, that is what it says separate unit performs each stage at the same time usually working on different stage of data.
So, advantage of this pipelining is the repetition of instruction after initial setup will produce output every clock cycle.
This one we call it as latency.
So, the first output will depend on how many clock cycles it takes to complete it after that we will be getting it.
output every clock cycle.
The disadvantage part of it is pipeline latency first one is that because we have to wait for first car assembly or first water to get it in the tap, the pipe has to be filled in this whereas, in the car assembly the complete unit has to finish it then it has to come out that is the longest delay what we have to wait what we will call it just like in multiplier we said that what was the longest path delay.
And then in the break instruction up into equally timed units if it is so then we will be arriving at the same time.
As I was just now mentioning collar branching may cause delays if because depends on what is the length of pipe what we have taken it.
So, I want to clean it up then even the water pipe I have to completely empty the pipe and then start different water if it is become dirty or whatever may be.
Even in the car assembly I have done one car design and then it is process is going on if there is one car which fails or something like that then everything has to be stopped.
and then restart the car building.
So, these are the delays disadvantage one has to take into account.
So, depending on this how many stages of pipeline what we can provide what will be looked at.
So, with discussion and everything all DSP process most of them use 5 stage pipeline.
So, the first stage is going to be instruction fetch we represent it as INSTR.
So, what happened at T0 time slot the first instruction is fetched in the stage 1.
result is out actually, but if it is going to take more clock cycle then our result may be little bit delayed ok.
So, just we will see how we can implement this parallelism and pipelining using an example.
So, although I have not discussed my FIR filter still I am taking this is an example ATAP FIR filter or you can assume it as it is a convolution summation what we will be doing it.
So, y of n is given by the equation k is equal to 0 to 7 h of k into x of n minus k. I was telling in the previous class why I am going to consider x of n minus k instead of h of k. One of the example I gave it as my memory basically what I will be using for h of k is the program memory which is going to be stored much earlier in the memory.
So, whereas, x of n minus k because I want to implement the circular buffer.
So, this gives me that whatever the latest after k whatever sample comes I can be rewriting in the same memory location.
So, that is how we use this equation to implement our convolution output or we call that also FIR filter.
So, you will be seeing that normal notation what your people will be using it h of k into 0.
convolved with x of n minus k. So, when I expand this, this is the equation and further the summation is going to be expanded.
So, then you will be seeing the sum y of n is given by your h of 0 into x of n and then h of 1 into x of n minus 1 and so on h of 7 into x of n minus 7.
So, this can be completed sorry implemented in many ways depending on number of multipliers and accumulators available.
So, we will see what is the thing is going to happen.
So, that is input needed in registers as we know.
This should be x of n to x of n minus 7 is continuously available for us and then when we are going to get the output that is we call it as time to produce y of n, time to process the input block.
So, we say that this is my input and y of n is given by this equation.
So, the new input x of n plus 1 can be processed after y of n is produced.
That is y of n plus 1 will be.
with respect to x of n plus 1 input what it is coming.
So, how is this shown in this as I mentioned in the one of the slide that it takes T b here it is shown with capital T there I showed it as small t. Time units to process your register block then for a continuous input stream the throughput is 1 output sample per T b time units.
So, a new input time is placed.
into the register block every tb time units.
A shift in the register block every tb time units is needed to accommodate a new input sample.
This is the theory how it is going to be done is shown in this block diagram.
So, time is 0.
So, I have all the inputs x of n to x of n minus 7 in the register.
When next clock cycle tb that is the delay of my computation time basically our this block takes tb unit.
then I will be getting the new sample.
So, x of n plus 1 to x of n minus 6 here in this case x of n minus 7 is the last data which is going to be thrown out.
So, in the second clock cycle we will be seeing that you will be throwing out even x of n minus 6 so on whenever new data comes into your buffer.
So, the thing is we said that sampling period we have assumed is T s which should be greater than my T b.
Then, what happens because my sampling frequency is much higher than my computation time, then whatever data sample comes basically I need to store them because input is coming at a much faster rate.
So, which I have to store it so that I would not miss any of the sample.
At the same time if my sampling period is less than the computation time, then what is going to happen processor may become idle because I have finished my computation I have to wait for my data to come in.
So, my processor is idling at that time.
So, how we can reduce this TB with appropriate parallelism and then pipelining what we will see in the next few slides.
So, first one what is it if I am using only single multiplier and accumulator then what is the thing I am going to how I am going to do this filtering basically.
So, I have x of n here n minus 1 usually we will be assigning it as 0 all of them initially and this is a 80 clock.
sample delay because I have seen that it is going to take 8 clock cycle for the new data to come in.
So, which are fed through the multiplexer and then this is my MAC unit because I have a single MAC I have to do all these 8 operations and then how I am going to feed in my coefficients basically.
H 0 to H 7 is through other multiplexer which is appropriately fed whenever this data is going to be there I will be doing the multiplication accumulation in a single block in this case what is the example we have considered.
And then once a complete thing is done after t what we say this 8 clock cycles my y of n is a valid output although it is coming every clock cycle, but we say at the 8 clock cycle I will be getting the correct output and from there onwards every clock cycle I will get the output.
So, here you can say t is the time taken to compute one product term and add it to accumulator and then new input sample can be processed over 80 time units.
So, our block computation time is 80.
80 in this.
So, I can take the new sample after 80 time units.
So, continuing with the thing at time t is equal to 0, we will be doing the initialization and accumulator is also made 0.
So, this is how the previous slide itself what it shows in this case.
So, in the next clock cycle what happens at t is equal to capital T, the accumulator which was initially 0.
Now, the first sample.
H of 0 is taken from here this multiplexer and then your X of n is taken the first sample from this side from through this multiplexer to your MAC.
So, they get multiplied here and then added with the previous value in the accumulator.
So, what happens at 2 t?
So, you will be seeing that whatever data here X of n gets moved to here fine.
So, this X of n minus 1 in the next clock cycle becomes.
and then you have to multiply with your h of 1.
So, that is how the samples have been chosen by these multiplexer which are fed to MAC unit.
So, then you will be getting the output.
So, this is the second clock cycle h of 0 into x of n in the previous one.
Now, h of 1 into x of n minus 1 is going to happen.
So, what happens in the next clock cycle?
So, we are skipping few of them we can put it as dot dot dot that is how we will be going with the thing t is equal to 3 t to.
at the last 80 what is the thing is going to happen what it is shown here.
So, the last sample your x of n minus 1 and then h of 7 is going to be taken into account from the multiplexer which is getting multiplied and all the previous samples you will be seeing it which has come will be added with multiplied value as you are seeing in the accumulator.
So, that is what we said was.
To do 8 bit of multiplication it takes 8 clock cycles.
Can I improve upon it by doing the parallel implementation?
So, how I can do it?
I will show in this case 2 MAC units I am going to provide.
Then I will be having as you are seeing the hardware is increasing here.
There are 4 multiplexer and 2 MAC units.
And you will be seeing that because they are working in parallel they do not have any dependency basically.
Whatever data they have stored it they will be working on it and then you will be seeing that 4 of them are connected to one of the MAC unit and 4 samples are connected to the other MAC unit.
So, they can work in parallel and then we have to last sample what we have to do is we have to add them from both the cases.
Then only I will be getting Y of n. Approximately we say that Tb is equal to 4T.
So, although this one addition we have not accounted for there will be we assume it as delta T 4T plus delta T which is ignorable that is what we said, but for large cases it may have to be considered.
So, we say that my computation is twice that of with single MAC.
So, you will be also multiple cores in your CPU you will be seeing it what you want is 8 core or 7 core what you will be telling I want to have 7 times what I have to get it why you would not get that result you can see from this visually saying that I would not be getting it twice what I wanted.
So, we will see that instead of 2 MAC units I will use.
For each multiplication I know what should be my filter length.
Most of you know that in FPGAs multiple DSP blocks are there and even GPUs for that matter you have multiple multiplication and then add units are there in the GPUs that is how you will be getting your speed up using GPUs compared to your CPUs.
So, here I have used 8 Macs in this case.
So, 0 will be for the first adder.
it is going to be pushed in and then rest of the thing can be fed from the previous stages ok.
So, there will be as we worked out in the previous class accumulator it will be taking n plus 1 clock cycle from this you will be seeing it for this the previous one what you will be getting it in the next clock cycle you can add it and then send it out.
So, you will be having every t units I can get the input clock in this case.
So, all of them are working in parallel.
And then we will be adding them up and then y of n will be my output.
So, we say 8 multipliers and 8 accumulators what we have used it.
T is equal to time taken to compute one product term and then add it to accumulator.
And new input sample can be processed every T time units.
We call it as 8 times faster.
That is why you will be seeing a exclamatory mark whether I am going to achieve this or not.
As I have mentioned.
will be overheads and other things.
So, we may not get so much speed in this case.
So, one has to bear with whatever we are going to get the thing with additional overheads.
Happy learning and then thank you for listening to this lecture.
Welcome back to real time digital signal processing lab actually.
So, today we will see on code composer studio.
and on the board how we are going to run some of the examples what we have looked in MATLAB.
So, the first one I will display is echo generation.
Here it can be either I can take voice or mic input.
So, we will see how to do the mic input.
Later on if we have time we will give the even the line input what we call it.
So, whatever the speech I am going to talk about it.
So, you will be hearing it multiple times.
So, that is what our echo generation is.
So, here the buffer size chosen is 4000 and gain for the thing is given 0.8.
So, we can vary the gain so that the intensity is going to be reduced.
So, we will be taking the input sample from the mykin and then we will be calling the codec both left and right channel what we will be putting it back.
So, how we are going to do the thing?
So, we will be having the input and then output getting delayed with respect to gain whatever has been given.
So, we can buffer length also you can change and then see the repetition how it can be reduced or it can be increased.
So, this is after that you will be incrementing your eye sample and then you will be outputting it in the codec.
So, you will be initializing from the main function here.
that is mic input what we will be taking it and then running it.
So, we will see that how the demo is going to run.
We will because it is recompiled as I have been mentioning in the previous classes.
So, if it is done it will be much faster.
So, we will run the thing.
Hello.
Hello.
Welcome back to real time digital signal processing course.
So, you can observe how long it is taking for the echo to come back also.
So, you will be observing that even if I stop running the debugger mode, still the code is running in the board.
So, I will reset it.
So, you have observed that this is from the mykin.
So, if we change the delay of it that is buffer size we can make it as 2000 and then our gain will try to reduce it to 0.4 or so and then we will save them and then we will recompile and see how it is going to behave.
We will observe it once again.
by running it.
Hello, welcome back to real time digital signal processing course.
So, you can see that how the echo has got reduced.
Earlier it was multiple once what it was coming because we had a low intensity of the signal that is we said 0.8 and then now it is 0.4 and then only 2000 of the samples what we are repeating it.
So, this you can go and then play around whatever way you want to do it.
So, if you want to run using the line input, then I had to give the sample from there, I had to comment on this.
So, we will see running this code, I had to because I forgot to save the thing it is asking me whether to save it to this.
So, I can give ok, then it will start compiling and then debugging the thing.
So, in the meantime we will try to select one of the, we will select a clean voice here, either it can be 16 kilohertz or clean voice, I will 8 kilohertz.
So, I will choose this as the voice which I want to run it and then we will see how we are going to get the echo from this.
So, the input signal is coming in, as you can see here.
there is a mistake in the code that is the reason why you are not getting the output.
So, what it is selected is line input has to run at 48 kilohertz, but the speed signal what I have is at 8 kilohertz.
So, we will change the input sampling rate that is ADC codec what we are going to select the thing to 8 kilohertz and then we will see whether it is going to run again.
So, I have to over rebuild the code.
This is how you can interchange between the line input and then.
mic input.
So, if you want to see your own voice how it is echoing for playing or whatever may be the thing you can give it through the mic input.
And then a line input see that your sampling rate is properly chosen because all speech voices in this case 8000.
So, if you are selecting any of the music which is sampled at 48 kilohertz or 44.1 kilohertz you can select that and then give it as an input.
So, this is one of the thing we demonstrated in the MATLAB.
So, you have seen in the board also how it is running.
So, we will see the scrambler here, but in the I will be closing this and then we will see the scrambler that is dot c in this case.
So, what it has is it is going to include the sign 160 dot h.
And, you have the filter coefficient which is 64 order, we will look at the thing and what we have is basically all are interrupt driven here.
So, the x of 1 will be getting the input from whatever you are playing 1 that is 160 hertz sine basically sample.
And, then you will be combining with your that is.
input, whatever input speed signal I am going to give it.
So, either it can be from the mic or same thing what we can select here I have chosen at present mic I can include with it or I can give it as a line input also both we will see the thing here how it is going to happen and then what is the thing is going to happen.
So, y 1 in this case is sin 160 sample that means to say that.
Whatever the input samples are coming, you are mixing with the sine function that is you are adding it basically.
Then how you are going to do the thing?
So, your X2 sample is generated with this Y1 that is get new input into delay line basically.
Then this one you would be filtering it that is Yn2 plus will be your HFI.
So, the order of the filter what you have chosen and then multiplied by your input signal X2 of Y.
So, then what is the thing this again X2 of Y because we have to move it.
So, we will be delaying it.
Here one FIR filter is happening the other place here it is FIR filter what we are doing the thing with both the signals.
That means, to say that after mixing it.
So, we will be passing it through the filter even the input signal is restricted to or the length whatever low pass filter length.
So, that we are not passing more frequency in the thing after adding with it we are passing it through again filter.
So, that will be cutting off anything above 3 kilohertz in this case.
So, then we will be outputting Y n to our left sample in this case it is going through the DAC.
So, what you can do one of the thing is you can repeat this so that again you will be using this as an input scrambled signal is given to the other board if you want to use it or you can give this as an input and then run this algorithm again then you will be getting the unscrambled output.
So, we will see now scrambling how it is going to happen.
Next we will be putting it as a mic in.
So, I will be doing the.
debugging is going to happen.
So, it has to, it is already compiled.
So, we have to go and then load the code on to the board.
So, it is done.
So, we will see the output what is you are going to get out of it.
So, you are hearing one tone that is signed tone.
Hello, hello, hello.
Hello, hello, so you are, hello, it got mixed up.
To give a better feel of the thing, what I will do is, I will run the speech signal.
Anyway, it is, as you can see, it is running continuously here, my speech signal.
So, I will take this as input and then we will combine and then see how it is going to look like.
So, I will call this instead of mic, I will be giving it as line.
So, we will compile it.
We will run the code again.
So, your speech has scrambled so we are seen in the theory that scrambling is going to keep our original voice whatever we want to convey to the other the one who is interested in not to all the people so that at the receiving end so you know with what this thing sample you have done the scrambling so they do the de-scrambling with the same method they can get back the original signal.
So, I will leave this as a exercise for you to put the code here to run to get back your own voice or your speech signal.
So, if you want you can record using MATLAB your own speech and then give it as an input to this and then see how your speech get distorted.
So, that nobody can make out that who is speaking.
Okay.
then at the receiving end you can get back the thing so this is the other example what it was pending so the next one is what I will do is here it is YC or BR basically what we have it so we will see the source file this is sorry in the previous one I told you I will show you the filter coefficients so you will be seeing this is a sine wave the generation basically psi 160 which is generated from MATLAB and then you are keeping it as a dot H file The other one is your coefficients what you have generated using MATLAB again.
So, you will be seeing that automatically using a function you can use the DSKFIR 67.m in the MATLAB file and then it generates the coefficient order n is equal to 65 here as you can see that and this is the coefficients what it has been generated.
Either you can use the FDA toolbox or.
use this code to generate from the book basically.
So, now, we will see what is our YCR, BR.
So, we said in the image processing.
So, I can convert RGB into my chrominance Y and chrominance CR and then BR and then intensity as Y illumination basically what we are going to have the thing.
Here, what it is going to do is as you will see this is from the book code basically that is real time digital signal processing to show you that how the this is actually this book supports 5505 board basically.
So, the code how it can be why if it is written in C code how you can reuse in other boards also with little modification what I want to show the thing.
So, in the DCT part of it as we said it was assembly code which was lying there.
So, one has to modify because that was meant for this board and then to make it a 6x board you have to modify all the assembly instructions.
So, you are doing input files are binary formatted.
So, that is files and output file is a BMP file what it is generating.
So, only 8 bit data made mode is going to be supported in this.
then minimum processing unit is 2 pixels in the same row what it is going to do so it will be using some of the dot H file here also this is the you what you have is Y C B C R to RGB dot H what you have generated and then kept so you will be seeing that these are the include files so in the previous one we had put all the required files in now the same folder.
Here you will be seeing that multiple folders are there.
One is you will be keeping only the source files in this case and then the include files are coming in this and you will be having the data in different place what you will be storing it.
So, you will be seeing the butterfly structure.
If you want you can this is getting stored back actually you can rename them and then you will be getting the data in this.
So, whatever the reference butterfly you can.
take it and then compare with both of them.
So, you will be seeing that this is the dot h file.
So, what you have it.
So, input pointer to y element.
So, and then CBCR and then this will be pointing to RGB basically.
So, the width of the image what you will be defining it and then you will be creating the BMP header file with these are the parameters.
So, this is an initialized 16 bit and then header file what you will have it width and then height has been given.
So, you have when you store this image and then you read in the MATLAB.
So, you have to take care of these things to read them and then decifer the image and then you have to plot it there.
So, this is types basically what it has been defined.
So, So, if it is not defined it will be defining it.
So, some of them boolean and then what are the integer format and unsigned int what you are will be calling it character and other things.
So, long what it is defined with uninitialized int 32 bit and short will be usually uninitialized int 16 and you can have unsigned character is going to be 8 bit what the definition.
So, you will be seeing that long again will be int 32 and short will be int 16 and character ints.
So, you have to first define and then use them in your code.
So, coming to the code we will see the this thing what we have I will close the rest of it.
So, you will be now what is it your image width chosen is 160 image height is 120 and then you will be calculating some offset.
So, number of rows what you will be calculating is image height divided by 15 what you will have it.
And, then you will be defining some data hash pragma specifies where your variable data has to lie.
So, here you call it as data section and it is named as RGB and then you will be getting as image buffer 1 whatever we are reading it here.
And the other one definition is it is the alignment as it was told that 2 pixels what you will be doing it.
So, it is aligned for.
2 bytes basically and then you will be defining some of the thing and your main variables what it is declared here.
So, you will be opening the file actually that is data file you have got it that is butterfly 160 into 20 into 8 dot data for reading purpose.
So, this is the original as you reference butterfly what you have it.
So, you will be reading that butterfly the input.
And, then if it is unable to open you have the error reflecting.
So, then again you will be using this is your elimination what you have read the thing y component next you will be reading your CB and then CR for reading purpose.
Again you will be opening the file and then you will be reading the other data.
So, then you have to write it back.
So, for this again what is it CR, one is Y the other one is CB and CR.
These are the three data what you will be reading from your input file separately and then open writing file that is order written is that is what it says it is B6 and then B, B is 6.
what you will be writing it.
So, this is bgb dot rgb what sorry bgr dot rgb means the file which is going to be open for writing into the thing.
So, you will be specifying rest of the sizes in this case and allocating your memory, so that you can release it later.
So, dynamic allocation of memory what it is happening here.
And, then you will be doing the data one block at a time what you are going to take it.
So, you will do the conversion.
So, you are reading from the thing and then do the conversion and then for both your C B C R what you have to do the thing.
And later on you will go back and then write it into initially temporary file and then you will be.
writing it out.
So, then once everything is done so, you have to free all the memories so that it can be used.
So, you will be using or releasing them.
So, then if you want you are allocating a memory to your temporary buffer.
So, that is the image width into 3 because RGB what you want to have the thing.
So, this is the RGB file read you will be doing it.
And, then you will be creating the BMP file here, create BMP file and then write into the thing all temporary data whatever you have the thing.
So, you will be writing into your output file.
So, we will see how it is going to run.
So, you will be getting the printf statement continuously.
So, we will run the code.
So, it is doing YCBCR to RGB conversion and writing it into dot BMP.
So, it in between you can give the printf statement.
So, how you are proceeding otherwise it may take little longer time to see the thing.
So, 8 by 8 bit what it is getting operated on as you can see the thing.
Working on the row now it is working on the BMP that is writing is happening here.
So, now, it says that it is completed.
So, one thing as I have been mentioning the things since I have did not give breakpoint.
or so what happens is it is unable to find the last line that is what it says I cannot find a source file at whatever exit dot c it is unable to find the thing.
So, it gives an warning in the end.
So, but we have completed running the complete code.
So, we can if you want to see the thing.
So, we can go and then tools.
So, what we have sorry.
So, what is one second, if you have declared them as global variable, then you would be able to monitor the output basically.
So, here you will be seeing that it is declared as global, I can see RGB.
So, you can go to tools, either I can put the graph.
It will be a variable or I can view the memory basically, memory browser I can do it and then give my this thing, what is it the thing I will be giving it as RGB here, the variable.
It is declared as int 16.
So, the style because it is declared as int 16, 16 but signed in tile give it so you will be seeing that RGB is the star this is the place where your data will start and these are the values what you're storing it in RGB format okay this is how it is stored and the other one what we can look at is so if you want to see the offset what is it you can go and then see that also So, the rest of them are not declared global.
So, if you want to look at the memory of it, so declare them global, so that you can see their values.
Otherwise, internal to the function, so you would not be able to look at it.
This is one of the ways of looking at it.
Now what you can do is, it is written the, I can close it.
After this, you would not be able to see the memory.
After running it, what you can go and do that.
So, what it has created is this bgr dot.
RGB file has got created.
So, this file what you have to do is take it to MATLAB and then read it with proper formatting given to the thing.
So, this completes the one more equalizer what we have it.
So, what you can do that also you can take it as an example to run the thing.
So, you will be seeing that.
So, this is a graphic equalizer.
So, it has low pass filter, high pass filter and then the band pass filter what it has been built across.
And then your buffers have been given and then amplitude for that and it is also interrupt driven.
So, you will be getting in low pass filter what you will be passing it through and then your band pass filter and then high pass filter and then band pass filter.
So, if you have generated a gel file, so you can select just how we selected in MATLAB different filters passing through the thing.
So, in this case the complete thing passes out.
So, you will be initializing the line input here and then you can generate a music whatever you have the thing and then with proper adjustment of this your band pass filter and whether you want to include all of them as you can see here it is getting.
multiplied with output from the filters all of them added.
So, you will be outputting it.
So, we will here what is we are going to get it.
So, you have to guess the thing I will be giving the speech signal.
So, if you want to give it music you can give it and then look at it.
I think my speech signal is still running.
So, I can we can test what equalizer it is because all of them have mixed together.
So, you will be hearing the sound there.
So, what you have to do is, you have to modify your gain in this and select whether you want only the low pass filter and then you can eliminate.
So, gel file has to be created for this and then.
You can select only low pass filter then because we know that up to 8 kilohertz what I can run this code and you will be seeing that the increase whatever the volume what you have given multiplied by 32000 what you have it.
So, I can select audio file and run it at high input the thing at high this thing sampled signal.
and run this code and then you can check it.
So, you can experiment with this audio equalizer by only passing through the only low pass filter and rest of it you can comment it out.
So, thank you.
So, this I will leave it as an assignment for you to venture.
Thank you for hearing to this lab.
Welcome back and then any queries or anything you can ask me.
Thank you.
Welcome back to real time digital signal processing course.
So, we will discuss today DSP architecture.
So, just to give a recap what we did in the last class.
So, we discussed about the number system.
So, hopefully you enjoyed that course it is fixed and then floating point number system what we discussed in the last class.
So, in this class we will be seeing DSP architecture.
So, how this is going to cater to whatever number system we have discussed.
So, coming to the problem what I have posed in the last class.
So, you are supposed to add.
2 numbers in the floating point format.
So, the thing was given is exponent was 4 mantissa 5 and bias 7.
So, when your this were the 2 numbers what it was given.
So, you know the first bit is sign bit and 4 bits because you have been given 4 as exponent, 4 bits will be representing exponent in this and rest of them are going to be your mantissa.
And then same thing with the other number.
Now, we will see that how we can represent this number in the exponential format.
So, if I see the thing it is going to be 0.0010 into 2 power 10 and then the next number has a exponent value 9, 1001 is 9.
So, it is multiplied by 2 power 9.
So, in this case usually what we do is the smaller exponent we are going to adjust it to the larger one.
So, that both the exponent become equal then only we can add the two numbers in the floating point number system.
We will adjust the exponent to the same exponent.
So, we shift this number by one right bit and then increase the exponent to 2 power 10 as it is seen here and then we do the addition and keeping the same exponent.
So, coming to fraction part it is equivalent as we see the thing it is 1 into 2 power minus 3 what we have it and 1 into 2 power minus 4 and 1 into 2 power minus 5 which is going to give me the value as 0.21875.
As we discussed in the last class we will be doing 1 plus f. So, it the fractional value will be 1 plus f is equal to 1.21875 and then we said exponent is the biased 1.
So, bias is given as 7 in this case.
So, it will be 10 minus 7 which is going to be 2 power 3 and if we do the multiplication by 8.
So, the resultant is 9.75.
So, this was the first assignment problem what I had given the thing.
The second one was fixed point multiplication.
So, the numbers were given as minus 0.75 and minus 0.375.
So, I told you to not to use that the result is going to be positive.
So, still we will work out both the methods and see how the result is going to be same in both of them.
So, first is we know that minus 0.75 in binary is represented as 1.110 which is nothing, but 0.5 plus 0.25 is going to give me 0.75 and then minus 0.375 is this number.
So, since I know it is the positive value what I am going to get it.
So, I can take both as positive numbers and then do the multiplication.
So, the resultant as you are seeing it here it is 0.010010.
So, because I said input and output has to be in the 4 bit format and we said we will be discarding the LSB bits in this case these 3 bits are going to be discarded.
So, the result is 0.010.
So, we will be getting it as 0.25.
So, originally what we are supposed to get is 0.2815 completely taken into account even in the decimal if you multiplied 0.75.
0.375 you should get it as 0.28125.
So, what we say is this 2 power minus 5 LSB bit has got discarded.
So, we will see how to do a 2's complement multiplication.
So, we said that in 2's complement minus 0.75 is this number.
First I take 0.75 and take the 2's complement of that number and this is the number same with respect to 0.35.
2's complement of that number is this.
So, in the second method we will be doing the multiplication in the 2's complement.
So, the 1.010 into 1.1101.
So, in this case one has to consider that when you are multiplying with 1.
So, you have to extend the digits by 1.
So, the we call it as sign bit extension in this case.
So, although it is 1010 later on we will be putting it 1 when multiplying with 0 we need not have to bother it is going to be 0.
Again multiplying 1 so we have done the sign extension with 1 and the last one because this is the sign bit what we are going to multiply with this number.
So, we have to take the 2's complement of this number and then put it there.
So, we know that 2's complement for 1010 is 0.110.
with 0, 0, 0, 1, 1, 0 then we add we are getting the same result as the previous method and here also we will be considering it as 0.010 which is equivalent to 0.25 which is not equivalent to 0.28125 what we are supposed to get.
So, this is the truncation what we are supposed to have in multiplication of fixed point numbers here also the 2 power minus 5 bit whatever 1 has got.
So, with this we will see how the architecture is going to get fine tuned for these numbers handling in that.
As an example we will consider how one novice wants to prepare a salad in our kitchen.
So, what are the things required we have said refrigerator, counter, cutting board and recipe first of all required what are the corners of the cutting board are kept free for partially chopped ones to add.
rest of the thing.
So, in the next slide we will see that how the bowl is taken and then mixed everything.
Once all the veggies have been considered and then mixed.
So, you can keep it back in your fridge or you can use it for consumption.
This is how the procedure is going to follow.
So, we always think in a simple term, but here you will be seeing each step has been recorded, how long it is going to say it take.
So, the same way we are considering our DSP application also in this manner and see how the architecture has been developed.
So, all of us know that regular processor has this architecture basically we have a motherboard here and then we have the ROM and then we have the processor chip in this.
Then through the bus all the peripheral units have been connected.
So, what are the peripheral the registers memory and secondary storage are all going to work together and we have the port ports for taking the input and then putting it on the output also.
So, coming to the basic architecture of the DSP.
So, we say it is a specialized microprocessor for the purpose of real time DSP computing.
So, the applications what are they in the commonly used in digital signal processing is.
So, they are mathematically intensive that is common algorithms require many multiply and accumulation.
And then we know that algorithm is run in real time.
That is current data must be processed before next data arise in the clock cycle what we call it every clock cycle I am going to get the data.
So, before the next data comes I should have finished my computation and algorithms are under development and hence DSP system should be flexible to support the changes if the algorithm is going to be changed or whatever may be the thing and we have to implement them in real time.
So, coming to the continuing with the architecture what all the other things what we needed.
So, one is arithmetic operations like any other general purpose processor add, subtract and multiply is one extra what we will be adding it and other support has to be logic operations like AND, XOR, ROR not.
And we need extra is the MAC operations because we need multiply and accumulate and some of the earlier processors had both multiply and accumulate.
Nowadays multiply unit is separate and then accumulator is separate, but we can run them in parallel so that I can get the MAC operations in one clock cycle.
The next one is we have to do scaling of the signal before and after hold on a while why we need it we will come to that discussion in a while.
So, coming to the next one what all the other things from the memory point of view we need a RAM on chip memories for samples because we are telling real time signals are coming in.
So, we have to have the RAM to collect it and next one is the ROM that is on chip program memory.
for storing our program and then we will see that with modification we can store our filter coefficients also in the ROM.
The next one is on chip registers for storing intermediate results because we know that memory access is going to slow down our operations.
So, we want to have it everything is faster.
So, we say that we can store the intermediate results in registers which are much closer to our architecture.
Basically, we will say it as a DSP chip.
So, the building blocks for our digital signal processing computations are multiplier, shifter and MAC units their capabilities and the last one not the least one we will say it as ALU that is Arithmetic Logic Units.
So, first we will take up multiplier how it can be designed.
So, one is we are looking at because we have lot of multiplication and accumulation.
So, speed is one of the criteria.
This is going to be decided by the architecture.
So, we have to have a trade off between hardware complexity and power dissipation.
As the hardware increases our power is going to be increased also.
So, we want to keep it lower power consumption and then we want to have more complexity in the hardware.
So, we have to match between the two of them.
The next one is accuracy.
So, this is going to be decided by number of bits.
As we discussed in the last class, it is going to be the format can be floating point a fixed point.
So, we know that for the floating point number of bits are going to be more.
So, our hardware is going to increase, but at the same time accuracy will be more.
So, what is the tradeoff between the two one has to look at it.
The next one is whether we can cater our architecture to large dynamic range.
So, this again is going to be decided by format representation.
at floating point numbers have large dynamic range whereas, fixed point will be having the low dynamic range, but they equal floating point numbers in precision.
So, it depends on what kind of application one is choosing depending on it one has to match all these things and then choose a correct DSP processor or design your own DSP processor using FPGA.
how we can increase the parallel or array multipliers what we call it.
Just now we did the fixed point multiplication.
So, you saw that the multiplication is basically a successive addition.
So, if we considered n bits we will take n clock cycles and then n plus 1 clock cycle will be required to do our successive addition.
So, whether we can improve on this.
So, for that we will be going with parallel or array multipliers because VLSI technology provides hardware capabilities for accommodating these multipliers.
And we want in process 1 clock cycle we have to complete the multiplication of 2 binary numbers that is what our aim is our goal is ok.
So, how we can do that with little bit of bit expansion we will see it.
So, we will be considering the multiplication and.
to unsigned fixed point numbers in this case a is m bit and then b will be n bit number what it has been chosen and then it can be represented in the summation form like this a will be ranging between 0 to 2 power m minus 1 and a will be belonging to either 0 or 1 same way with b operand also.
So, we say that we need r bits where r is going to be greater than maximum of m comma n to represent the product which is p is equal to a into b.
We know that we need more than maximum of one of the bits m and n are not equal need not have to be equivalent in this case that is what we are considering it.
So, we are taking the maximum of it, but it should be greater than that.
So, we will see how much greater we need it in a while.
So, that is what the question is posed also that is what should be the number of bits that is r has to be.
We will say first consider the minimum number of bits required P or B R bits we will say.
R bit will be in the range 0 to 2 power R minus 1.
Therefore, R P will be in the range between these two.
We will see first P minimum when A bits are all 0s and B bits are 0s then the minimum is going to be product will be 0.
When will be the maximum?
When all A bits are 1s and B bits are 1s which is we call it as maximum.
So, then we know that there are m and n bits.
So, it will be 2 power m minus 1 into 2 power n minus 1.
So, when we expand this multiplication.
So, we will be we are resulted with 2 power n plus 1 n plus m minus 2 power n minus 2 power m plus 1 is the number of bits what we needed.
So, we will see that how P max can be represented.
So, we have represented this and what the term is going to say is.
So, this terms can be represented as minus 1 that is it should be less than or equal to 2 power n plus m minus 1 for positive n and m and approximately if n and m are very large we can approximate this P max to 2 power n plus m. So, therefore, we say that the maximum number of bits required to represent the product is less than 2 power n plus m.
So, we say this as a tight bond then what will be R. So, we take the log of it log 2 P max which is nothing, but log 2 of 2 power n plus m which is going to be m plus n is the number of bits maximum bits what we need it for this it may be less than that that is what we have put for large n and m. So, how to do that we will take an example in this case I have taken n is equal to m is equal to 4 both of them are same.
So, then We need R is equal to M plus N in the maximum that is 8 bits.
Do we need that?
We will see with the expansion of our multiplication A and B are represented with 4 bits.
A and here 4 bits and B and when you expand this summation basically multiplication and summation you do the thing this is the result what we will be getting it.
So, when we further multiply both of them so these are the products what will be getting it.
So, from here to here are the products which have to be summation has to happen for them.
Then when we represent these with products as P0.
So, we will be putting their powers what are they because it is in terms of powers what it has been segregated.
So, we will be needing P0, P1, P2.
P7 is the maximum what we need it.
So, 0 to 7 which is the maximum.
gives me 8 bits.
So, this is what we say p 7 to power minus 7 to power 7 minus m what will be putting the number.
So, we will see why we need p 7 also we will see the thing.
So, we have to compensate for carry over bits what we will say that.
So, we have represent p 0 to p 1, p 2, p 6 how the summation is going to happen.
So, the first one is only the multiplication later on we have multiply and accumulate.
And, then this is a half adder what we needed for the P1 product, but from P2 onwards we need full adder as you are seeing it we are adding these numbers and with the previous carry.
And then same thing with the P6 and then P7 represent only the carry that is coming out of after adding in the last stage.
So, we will see the architecture how does it look like.
So, most of the DSP processor use a Braun multiplier.
So, you can see that 4 by 4 Braun multiplier how it is represented.
So, this is your full carry.
So, I have a operand and previous carry in is going to be input with this and the second operand is coming from this side and the result is going to be sum and then carry out is going to be generated from full order is shown in this way.
So, we say that I need because we have taken m is equal to n is equal to 4.
So, these are the structures what I need it.
from the multiplication and addition these are the adders.
So, as you can see that this is the multiplier what we are representing, but we need AND gates to do multiplication of these numbers whatever you are seeing that is the additional hardware what it requires.
And then in the first stage you will be having no carry in is going to be there.
So, you will be pump we are using all full adders.
So, that is why the carry in is going to be 0 in this case this is one apparent.
and then the other operand.
The first one we said P 0 is A naught into B naught which comes out directly.
After that what we will be doing is our addition what it is going to follow with these numbers.
And we say that the last stage in this multiplier what we have to do is we have to do a ripple carrier adder what we are supposed to use it that means, to say this adder has to give its carry out to this and from here to here and then from here what the P 7 bit is going to be.
So, coming to the Braun multiplier we say the speed that is longest path delay as we are seen the thing in this case is all these additions and then the last stage ripple carrier adder delay also one has to add it which gives the longest path delay.
So, what is it through the gates and then adders we say this will be within one processor clock cycle.
So, my in internal clock rate may be much faster than the outer clock.
So, that see that all these are done in one clock cycle.
And we say that there should be additional hardware before and after brawn multiplier required to take care of sign numbers because we took it as unsigned number.
So, as we did sign multiplication if one of the number is both of them are negative then we have seen that we have to do the two's complement this is the hardware which is required for the.
before we do the multiplication of the number for the sign numbers.
Coming to the array multiplier or parallel multiplier, what is the bus width required?
So, we need two buses of n bits to directly give the parallely give the input to our multiplier.
And we know that x into y the product we said maximum length is n plus n which is going to be if I am taken both are n.
actually bits for the two inputs then 2 n will be the maximum bits what I need it output of the multiplier.
So, that can be Z it depends on the application that is what it says.
So, program bus can be reused for our multiplication instruction is when it fetch after fetching the instruction and that is most of the cases coefficients what will be taking it.
So, which can be pre.
stored in the ROM and then we can fetch it from the program bus.
So, bus for x can be used for z once we have done use the input.
So, I can use the same bus for my z that is discarding the lower n bits from z or storing two consecutive memory locations.
So, as we know that if we want to store two n bits output in the memory it is going to take twice that of the.
memory requirement.
And then computation loading when we have to load 2 in I would not be able to load them in one shot I have to do them in 2 clock cycles.
So, which is going to slow down.
So, most of the DSP processor what we do is we only store the higher bits as we discarded in our example also lower bits high bits n bit whatever is defined is going to be stored in R.
memory through Z bus.
So, the next one is after the multiplier we need the shifter.
So, first is why do we need the shifter?
One is it is to scale down or scale up to operands and results to avoid errors resulting from our overflows and reflows during the computations.
So, as we saw in the previous case in the example we scaled down all our numbers.
So, And, then used it for our multiplication that is converted into fractional from integers to fractional numbers.
So, that fractional multiplication is not going to overflow.
So, we have we need that scaled down in there and then once the result is there we may have to scale it up back to the previous whatever scaled down value and then give the output.
So, this avoids our overflows and reflows.
So, overflows all of you must be knowing that.
the value is much more androflu is it goes below or whatever maximum negative value what it has been provided.
So, when computing the sum of n numbers.
So, each is going to be represented by n bits the overall sum will have we know that n plus log 2 n bits.
So, we have to say why this is.
So, each number is represented by n bits we said and sum of n numbers you have seen that sigma i is equal to 0 to n minus 1 then the maximum width is going to be n into 2 power n minus 1.
So, therefore, our r whatever for the bits that is required for my product we will be putting it as log 2 P max approximate it as log 2 n into 2 power n. So, which is nothing but log 2 2 power n plus log 2 n. So, we know that log 2 2 power n is nothing but.
n plus log 2 n is the representation what we are going to have it.
So, depending on this we will say when is scaling required.
So, we said to avoid overflow either at the input or before addition that is scaling by log 2 n bits.
So, that is what we said that maximum what we can represent here.
So, depending on that we may have to scale the number by log 2 n bits.
So, after summation to get back the original results we will be doing the scale up by log 2 in bits.
So, this is a trade of between overflow and then accuracy one has to consider.
So, we will see that how we can do the shifting in this case why we need scale up or down.
So, as an example n is equal to 4 bits and then capital N number of additions what we are going to have it also 4 basically.
we have chosen unsigned fixed point integers case.
So, then our summation is going to be x 1 is represented with 4 bits and then x 3 x 4, 4 variables are there we are adding it up.
As an example these are the values what we have taken their binary representation shown in the square bracket.
So, when we sum up we are going to get it as 21 is the result.
So, the maximum because we are representing it 4 bits what I can represent maximum value is 15 that is 2 power 4 minus 1.
So, which is much greater than.
this 15, 21.
So, then we have to do the scaling.
So, in this case because we have assumed n is equal to also 4 numbers what we have it.
So, log 2 capital N is 4.
So, we have divide by that is scaling by 2.
So, that is scaling by 1 right shift is basically equivalent to dividing by 2.
So, we will be scaling all inputs by 2.
We will see the same numbers when we do the scaling what you will be getting is x 1 hat.
So, that is not equivalent to x 1.
So, when it is going to be 4 when I do multiply by 2 here I will get 8 not 9 same thing whatever shown in the red are the approximated value to the original one.
So, if they are divisible by 2 you know that we will be getting back the number otherwise we will be having the approximation.
Then we will see what is the summation I am going to get it when I add these numbers which is going to be 9.
So, to get back result we have to scale up the number by 2 which is going to be 18.
which is not equivalent to 21.
So, these are the errors one has to consider.
If it is not tolerable then we may have to go for the floating point number representation.
Otherwise if it is within whatever are errors usually we call it as signal to noise ratio.
So, if it is in that we can accept this and go ahead with these processor architecture.
So, when can we use the scaling?
That is what we said conducting of floating point additions when we need to align our exponent that is what it says where each operand should be normalized to the same exponent prior to addition I need the scaling.
And one of the operands can be shifted to the required number of bit positions to equalize the exponents that is what we did in our example.
So, how we can accommodate this shifting?
So, we know that.
But sequential shifting is going to cost us n clock cycles if we need n bit shift.
So we have a barrel shifter that is normal shifting any microprocessor that is what it says 1 clock cycle for every single bit shift.
So what the latency will be multiple clock cycles due to many shifts ok.
Whereas the barrel shifters allow shifting of multiple bit positions within 1 clock cycle reducing the latency for our real time DSP computations.
So what we have.
I have a shifter here input is going to be n bits and output will also will be maintaining n bits and we will be telling the these are the two control bits one is whether we want to do a shift left or shift right and then how many number of bit positions I want to shift it is given as the control inputs.
So, we will see how barrel shifter works we have taken example as a 4 bit shift right barrel shifter has been designed here.
So, you will be seeing these are the a 0, a 1, a 2, a 3 are the bit inputs and then outputs are going to be b 0, b 1, b 2, b 3.
So, what are the input bits it will be going into this what we will be seeing in a while.
And we have switches s 0, s 1, s 2 and s 3 and we say that switch closed on control signal is on and then only one switch can be.
operated at a time.
So, we will see how this write operation is going to help us.
So, the first is 4 bit write shift barrel shifter what we are considering it and logic circuit takes a fraction of a clock cycle to execute this.
And majority of delay is in decoding the control lines and setting up the path from input lines to the output lines.
These are causing the delay otherwise we will be getting the output in a fraction of a second or clock cycle we will say.
So, my input first is a 3, a 2, a 1, a 0 are the thing and we will see this which positions actually first is 0 that is represented with S 0.
and output is b 0 b 1 b 2 b 3.
Since I am only a 0 is being used I am not doing any shift operation.
So, the input whatever you have given will be going into these output lines as it is.
When switch 1 is operated I have to do a shift right operation by 1.
So, in this case whatever the MS b value is going to be pushed into the last place basically.
So, we will be shifting a 0 out of it.
it becomes a 1 a 2 a 3 a 3.
So, when s 2 is on then 2 shift what I needed.
So, a 0 a 1 is going to be shifted out and the result will be a 3 a 3 a 3 and then a 2 which are going into this output b 0 to b 3.
So, when I want the maximum shift.
So, you will be seeing that all the a 0 to a 2 are shifted out and then the result will have bits are going to be only a 3 in this.
So, as an example how the switching is going to be done is shown in this.
So, what is the result I want a 2, a 3, a 3, a 3 on the my b 0s.
So, you will be seeing that S 2 switch is closed wherever you have seen the S 2 switch you have it is marked highlighted here.
So, these are the ones which is going to these lines are going to be connected.
So, when you connect this one what happens?
So, you will be seeing this red line correct.
your a 2 is going to be pushed into b 0 and then your a 3 is going to be pushed into b 1 and then a 3 will be pushed into b 2 also and a 3 as it is it will be in b 3.
So, you will be getting the output as a 2 a 3 a 3 a 3 that is what we wanted since a switch is closed this is how the barrel shifter works.
So, one can try.
how the left shift operation is going to happen.
So, you hope you have done a little bit on microprocessor 885 or something like that there are two ways of shifting left.
So, either you can push the 0 into the first LSB bit or you can push the carry into your or last MSB into your LSB bit.
So, you can try how you can implement using the barrel shifter.
Now, we say that multiply and accumulate what we needed, how it is going to be represented in 6713.
So, we will be we said we want a MAC operation, but the later versions all 6 6 processors have only multiplier and accumulator separately which will be done in parallel.
So, common DSP applications we said filters and then Fourier fast Fourier transform what we want to implement.
2 of it and then rest of the things you can consider.
So, what is their equation what it is shown here.
So, here y of n is x of n minus k that is my input and this is my filter coefficients.
So, you would have seen that some of the equation it looks like your convolution equation.
So, either x of n into h of n minus k would have been comfortable but we use here input for X of n minus k and then H of k why I will consider it when we take up the architecture further I need circular convolution what I need it.
So, we will be taking it up in the next class and then see why I need that.
So, the next one I know that the X of k is my Fourier output and X of is in input X of n and then e power minus j to pi n k by n and this also I need multiplication and accumulation I can consider sine and then cos function separately and then do it parallelly.
So, we will see when I take up FFT how we will be doing the.
operations in our DSP processor.
So, coming to MAC operations we said in parallel what it is going to happen.
So, what are the things we needed?
So, if n products to be accumulated we know that we need n minus 1 multiplies can overlap with the accumulation basically.
That is during the first multiply accumulator is going to be idling in the next clock onwards we can do the thing parallelly and the last clock cycle because I one value is left out to be added.
So, this will be adding the last product.
So, to compute MAC for n products we say that we need n plus 1 instruction execution cycles are going to be required.
If n is much greater than 1 it is almost equivalent to 1 and then we say that MAC operation per instruction cycle what I will be getting it instead of n plus 1.
So, you will be seeing that either adder or subtractor we have not discussed the subtractor we will be using the adder itself for our subtraction because we are doing it in the two complements.
So, I do not need a separate subtractor only the one of the thing what we have to say is I want to do the subtraction.
So, that it will be happening in the two's complement.
So, are 2 n what is the input and then for the addition and you are seeing the sorry first multiplier is n bit 2 n bits are coming I will be doing the multiplication and product register will hold the 2 n bits which are fed as input to our adder and then which is coming in here as 2 n and whatever accumulator is storing in the thing which is fed back.
So, which is going to be added.
in the accumulator and then the output will be coming out of it.
Then we will final round will be making 2 n to n when we are storing back in the memory.
So, just to see that how the each instruction is going to take we will see that what is the time required for MAC operation.
So, we say that if I want to do 1024 products to be computed using a MAC unit and if the MAC execution time we have given it as 15 nanosecond.
the hardware takes.
So, we have to say what is the total time required to compute the operation.
So, we said 1024 MAC what we needed.
So, we need basically n plus 1 which is nothing, but 1025 execution cycles what we needed.
So, the total time required what we are putting is 1025 into because each operation is taking 10 15 nanosecond which is nothing, but 15 into 10 power minus 9, 1 nanosecond is equal to 10 power minus 9 second.
So, which comes 51.25 microseconds which is required to do this computation.
So, you can see which is very small it depends on the clock speed of your processor.
Coming to we said we need this scaling we have taken care of in the multiplication by considering only fractional numbers.
So, that the result of the multiplier is not going to overflow, but we have a constrained in the adder.
So, how overflow and underflow can be taken care in the MAC operations.
So, our addition or subtraction cause of overflow or underflow.
To take care of this most of the DSP processor have 40 bits for as a accumulator.
We call it as long addition what we can have it.
So, then 40 bits are going to be used.
If it is a 16 bit 2 operands the maximum can be 32 plus 1 carry bit, but we say we can accommodate the overflow of.
to 2 power 8 bits in this case.
So, the barrel shifter at input and output to normalize the values what we needed and the other one is the saturation logic.
We know that when there is a saturation happens if the maximum value is more than the whatever the processor can represent it goes as a negative value.
So, we want to restrict to that the maximum value.
So, the largest and then what we say is overflow accumulator has to stop.
So, in that case for 16 bit processor the maximum value what we can represent a sign number what we are considering it is going to be 0x7FFF in hex which is nothing but 32767 and the minimum number what I can represent is 0x800 minus 32768.
So, these are the values what has to be output if it is below this value or above this value.
So, this is taken care of in the hardware.
So, we have the least negative value and then the most positive value and you are taking the sign bit MSB and then you are going to consider whether it is going to exceed one of it you are doing the exclusive var.
So, you will be setting overflow or underflow bit is set then you will see that the maximum value is going or minimum value is going to be stored in the accumulator which is going to be output.
So, this is our arithmetic logic unit apart from addition it has to take care of our the increment decrement negate or other operations and then shift multiply and additional features in the like other processes we should have a status flags for sign 0 or carrier overflow and then overflow management via saturation logic can be incorporated and register files for.
storing the intermediate results.
So, coming to the bus architecture, it depends on the cost speed and size of DSP process basically width of the bus and memory.
So, we have two architecture lot of normal CPUs use one human architecture whereas, DSP processor use the Harvard architecture.
So, in this case both address and data bus are as you will be seeing that program and data reside in the same memory.
and single bus to access both your address as well as data.
So, which is going to slow down the program execution whereas, in this case so, we will be having program memory separate and then data memory separate.
So, I can access the program from the program memory and then data from the data memory.
As we know that there are two operands what I needed for my multiplication and accumulation.
So, the coefficients which are already designed and fixed I can store it in my program memory.
And once the program fetch operand opcode has been fetched I can release this bus and then get the data from here.
So, that is what it says separate program and data memory faster execution that is what it says how to fetch two operands.
So, in summary of this class we discussed little bit on Von Neumann and then Harvard architecture how we can design parallel multiplier and then how we can do the shifting parallel shifting using barrel shifter.
and then the bus architecture we saw it.
So, whether we have to have 2 n bus or n bus.
In the next class we will discuss about memory, how we will be incorporating a pipeline and parallel architecture using our hardware.
So, thank you.
So, we will meet in the next class.
Welcome back to real time digital signal processing lab.
So today we will see DCT.
So how we are going to implement discrete cosine transform with quantization.
So how much we can see the view or image.
then look at it so the first we will see the MATLAB so you will be seeing that these are the students who are developed it as you can see this shows as an assignment 7 basically here we will be considering the histogram equalization that is when we feel that the image is little black so we want to do the histogram equalization to give the perception a little bit clear The other one is the noise what it has.
So, by using the gamma correction it is going to improve upon it.
And the other one is whatever demo I will be showing is with respect to DCT.
So, we will run this code actually and then see how we are going to get the images out.
So, we will go to this folder.
So, you will be seeing this is a GUI developed.
So, as you can see the thing.
It has DCT histogram equalization and gamma correction.
So, we can load the image as an input.
So, we will see that load an image.
So, the first what we will do is load our first image as a baby image ok.
So, you will be seeing this is the image what it has got loaded ok.
So, we will do the DCT.
So, you will be seeing that the knob can vary from here to here.
Only the thing is in this case the slider values have not been given in steps of you have to go back to the code and see how what will be the steps of the slider is going to move ok.
So, now, we will run the DCT in this is the compression whatever it is shown with the slider.
So, we will run it.
So, this compression has not much change the output.
So, you will be seeing the histogram of the original image and histogram of the.
So, almost they look alike.
So, now, what we will do is we will increase the slider little bit and then I will be doing the DCT.
So, now, what you have seeing is only the complete thing has gone to black.
So, the compression what we have taken is almost more than 70 percent what we can see.
a little bit reduce and then do the DCT of it.
So, we have got back the thing.
So, this way you will know that what how much compression you can achieve with respect to this.
Now, if I want to do the histogram equalization.
So, we will load a different image to see that whether we are going to look at that difference or not.
So, we load the Einstein image.
So, you will be seeing this.
So, I can do the I can do DCT or histogram equalization.
So, we will run the histogram equalization.
So, you have seen that the original histogram is centered between this thing what is it black and then some of the grey values here ok. And then little part of it is here and after that we have 0, but I want to have the uniform distribution of the thing.
So, we do the equalization.
So, you can see how the image has got.
So, we can load the other image and then see whether it is going to give us a better histogram equalization.
So, we will run the histogram equalization for this.
So, you will be seeing that whatever that the background which were a little darker now you will be seeing that they have been exposed.
So, by doing the histogram equalization.
So, if you want to see background properly then you can do the histogram equalization.
and then run it.
Now, we will see how the gamma correction is going to happen.
So, now, this is what the gamma correction.
So, if I will increase the gamma part of it and then we will run the gamma correction.
So, you will be seeing that what happened is that you will not be seeing not much output.
So, by the this thing elimination of lot of noise what happened is we have lost the thing.
So, depends on what the gamma value is going to be.
So, here you are seeing that it is little darker at the background and then this is little bit prominent what you will be seeing.
This is how your gamma correction is going to happen and this are the histogram how when you do the gamma correction.
So, this way you can play around and then see what will be your output you can get the thing with different images.
So, now, we will see the other way of doing it this is from the same batch one more student how he has implemented we will look at it.
So, we will run the code again.
So, it is from a different flow folder.
So, we will be changing it and you will be seeing that this is the GUI what it has got ok.
Here also you have to select a image file.
So, these are the.
images are stored in a different file.
So, you will be seeing different images basically from black and white and color images what you have it.
So, we will see that you know the personality of this person.
So, we will do the DCT compression one second because the aspect ratio is more you are unable to see the figure here.
I will change the thing for the viewing thing and then come back from the settings.
So, we will change it to 100 and then we will run this code ok.
So, now you would be I will be aligning the thing.
So, we will select the image.
So, the images what you have seeing the thing this is the input image.
I am going to do first DCT compression.
See here as you can see the compression factor is varying between 0 to 1 in this case.
So, if I change it.
So, we will do the what is the compression factor what we shown in the class that it has taken it as 4.8832 is the compression.
So, do the DCT compression.
So, you are not seeing much changes in the thing again I will increase the thing.
do the DCT compression.
So, you are not identifying much of it.
So, in this case it is between 0 and 1 what they have selected.
So, this is sorry the output was taking little time to come.
So, even with 20 compression factors.
So, you will be seeing not much difference between the this is the input image, this is the output image.
So, I can reduce it, we will do the DCT compression.
ok, not much difference.
Now, we will see that what is the thing is going to happen, we will load a different image I can go to the images.
So, you will see that this image basically how is going to.
So, we will do the gamma correction for it.
Now, it has loaded the thing.
So, you are seeing that the plane is not much visible.
So, we will do the gamma correction.
As you can see that the background has also become little brighter and then even the plane is completely visible and then you are seeing the whatever luggage carriers what you know of actually which are there and even the whatever the petrol fueling thing is also visible.
So, I can do that.
So, if I want to do the compression I can look at the compression how it is going to look like.
with our original image.
So, not much to the original image.
So, you will be seeing that not much changes has happened.
So, in this case gamma correction has helped us to get more clearer one.
So, we will see.
By doing the histogram equalization we will select an image file again to show that their functions are working properly.
Since it is running in loop it will take little time to come read the thing.
So, this we will see that this is a low light this thing.
So, we will use this still it has not loaded the image.
So, you are seeing it this has a low lighting conditions as you can see, we will do the histogram equalization for it, still it is processing.
So, now, you can see that whatever the lighter.
So, you are seeing the reflection completely in this thing water in front of it.
And, this is become much brighter.
So, this way you can have a different ways of doing your DCT compression and then your gamma correction and then histogram equalization by making a different image processing applications you can incorporate.
So, in this as an application what I will do is our audio file.
So, I said we have not covered the what I will call it as interpolation and decimation.
So, our audio application one can use it at different sampling frequencies.
In this case we show that input is 44.1 kilohertz input.
How we can convert it into a 48 kilohertz is this.
demo is going to show you.
So, this way you can incorporate and what are the filters will be choosing it, it is going to be FIR filter what it has been chosen of different length and then we will have three stages in this case to run the algorithm.
So, one is decimation, the other one is interpolation what we are going to have it in the second stage and the last stage is going to do again decimation.
So, to get our So, you may not feel the audio file, but from looking at their responses we will see that how it is going to look like.
.
.
So, you are .
So, seeing that how the changes is going to happen that is 3 stage output what you are hearing the sine wave from 44 kilohertz to 48 kilohertz which got modified ok.
So, did you notice any differences between the two?
So, that is what the thing is going to be.
So, if you want to expand here so, we will see that.
So, you can do this zoom in.
So, to see the frequencies what it has got.
So, from this is input that is 44.1 kilohertz to 48 kilohertz what it has got transmitted.
How it 3 stages what it has done the thing that you will be seeing in this figure.
So, the original you will be seeing it in red and then.
What is it?
You will be seeing it is getting pushed to little bit black and then little green and then the final is your blue.
So, you will be seeing here this is original, this is stage 1 what it has got little bit shifted and then later on this and later on this is the final.
So, instead of because it is not possible to shift from 44.1 kilohertz it is an odd number to.
So, we do what we call it as multiple times so that the output will be visible that is what the MATLAB what is shown the same experiment is available even in the code composer studio.
So, we will take up now the code composer studio.
We will start our code composer studio.
What is happening is as you are seeing it, so it is creating it has little bit crashed I think so when shutting down.
So we will open a new this thing.
I will call it as V9 because recently I have closed it.
So we will launch a new.
workspace.
All the files whatever demos have been shown.
So, I have put it in CCS 9 as you can see the things.
So, I have to pull out these files now into the new workspace.
And, then I have to load them let it come up.
So, we were discussing about the DCT and then I have the other and we will see little on echo today on the DSP processor.
Some of the equalizer and other things are giving little error in the thing.
So, till I settle solve the problem once it is done in the next class we will be taking the demo of it.
So, what I will do is I will copy these directories to here.
Hopefully one shot it should work.
Let us see if everything is copied otherwise we may have to copy the include files and then libraries.
If it ask you to install you can sometimes it gives an error.
So, it is better to.
not to install the new one whatever you have installed the original let it be there.
So, we will open the thing, we will open the from the project from the directory.
So, we will put the thing, I will be opening this folders hopefully.
If you want to create a new project you can go and then create it since all that already these projects have been running.
So, what I will be doing is you will be getting started and everything in your code composer studio.
So, you can have a look at them.
So, we will first run the DCT let because I had to because it is a new workspace I had to do compilation first and this is the C file in the mean time let the compilation happen we will see what is it.
So, this is what you are hopefully you are able to read the thing I am reducing this also.
So, this is the code what we have it.
So, here you are defining 64 by 64 image.
So, you will be considering 64 by 8 to the power of 2 what you will be looking at it.
Because, you are going to give image file dot h file has to be input as this or you have to read from the file.
As you know in the hardware it is going to be in a continuous memory what you will be storing it.
We may not be able to read 8 by 8 image correctly.
So, you will be storing it as dot h file.
So, if you see that image file dot h you will be looking at.
So, it is a continuous.
So, you will be seeing that it is a 64 by 64 the image has been taken from the MATLAB and then dot h file values have been created and then you will be storing it in the continuous format like this which you will be inputting it into your CCS ok.
So, this thing is going to run in your.
what we will call it as even simulator you can run the thing.
So, if you want you can have the leno.h also what you can look at it.
So, and then it can be image file up to 128 by 128 what it has supported.
Otherwise, we have the input directly from the camera you can feed it in and then do the compression and then take it out also.
So, both.
DCT and IDCT have been incorporated in this code basically and the compression factor what is this factor array compression ratio is chosen as 4 here.
So, if you want you can change the compression ratio here and then you will be seeing that whatever chromium and other things is 8 what you have taken it ok. And you will be allocating the memory and then you will be performing the DCT using this equation as you can see that it is direct DCT has been implemented.
So, less than n so, you will be seeing that there will be a 4 for loops here.
So, that is why order of n power 4 it is going to be.
So, if you want to reduce it so, you can go and then use a butterfly structure to implement the thing.
So, you will be seeing that calculating you are doing the compression here.
whatever CR value what you have chosen the thing and then.
So, you will be doing row wise and then column wise and then once you have stored this you have made the rest of them 0s whatever is less than what you are selecting the thing the values DCT matrix you are making them 0s ok. And then you will be storing it.
and then do the idct.
So, this is what the output is going to be.
So, matrix u comma v will be your idct.
So, you will be seeing from this thing a main function is here.
So, you will be seeing that total by compression ratio what you have set the thing and then compression ratio parameter what you have set it here square root of CR and you will be sealing that basically.
So, not to have the We will call it as decimal values are avoided only integer what you will be selecting the thing to the higher what you have sealed the thing.
So, you will be seeing that some of the assignment.
So, you are putting it as a test block.
So, your input image block wise what you are operating 8 by 8 blocks i comma j what you will be working on.
This is the DCT you are passing the test DCT or image.
And, then block whatever the you have selected test block and then you will be giving x and y dimensions.
Then once you have done that DCT which uses the compression also, then I you will be doing IDCT.
As you can see there are.
So, first we have to make clean and then run the project.
ok. As I have mentioned in the first class we have to go to properties.
So, when we have this the latest version support ELF file format, but what we want is the legacy cof file generation in the new one.
So, I have to apply and then close hopefully we will not get any errors let us see the thing.
That is the reason why it was cribbing that no this thing what is it make option is available.
When you get this error it is better to go for sometimes even the warnings you may have to see that if it has to be eliminated you have to eliminate warnings.
So, in this case what it says is.
declared in the thing and then it is not used.
So, that is fine.
So, what we will do is we will build the thing ok, because I have started the new project thing.
So, what I have is I do not have the target configuration.
So, I have to specify which I will be using it.
So, it is going to load the target configuration and it will ask me which one you want to have it, I have to wait for it to give me that.
The first time it is going to take little longer time ok. Usually whatever demos all these days I was doing it.
So, it was prebuilt so, that I need not have to waste time on the thing.
Today because one of the workspace it is having a problem.
So, I had to recreate it.
So, it is running for the first time, it is going to take a little time on the thing.
It is asking me to update it.
So, we will not do any updation here.
So, when we rerun the thing second time it is going to be.
much faster ok. One more thing what I can do is I can stop the debugging and then go back and then give it a I will call it as new because it was asking me for the target configuration file I will give it as configuration.
So, we will try to finish it.
So, it will ask me which one I am going to use it here.
So, what I have is as I I told you in the beginning.
So, I have a XDS110 debug USB debug what I have connected here and then it is going to be LCDK6748 board what I am using it.
So, this is the target configuration what I will be giving it and then I will save this one and then I can do the test the connection whether it is getting connected or not.
So, you will be looking at it software log files and other things.
So, it is connected to the board or not what it is testing.
Some of this scan test what it says is it is failed anyway finally, it says scan has succeeded ok.
So, that is how the board whatever you are going to connect it you can look at them.
So, we will recompile the thing.
So, and then see whether it will go it is as you can see the debugger is going and loading on to the board.
Some of the whatever you have configured.
Your memory you can.
You have assigned Kellogg basically.
So, you can release them later on you will be freeing the memory once you come out of the loop.
As you can see you will be freeing them in the end.
All the blocks what you have assigned nothing they are going to be freed.
you will be seeing that everything has got loaded onto the board and your pointer is at the main here.
So, now, you have got icon to run and then if you want to break you can do the thing.
So, what we will do is we will put a break point here so that and run the code.
So, it has finished it.
So, you will be seeing that whatever the modification values are dimension of y, x and then i and j, k, k is gone up to 64 and then what we will see is because it is in this case although image analyzer is there it is giving little problem in this version.
So, what we have to do is we have to view the memory basically.
So, whether it has got So, we will go to the memory browser and then I can give output image is the where it is getting stored as you can see coming from the test adct, the value is going to be stored here.
So, you will be seeing that it is a floating point number.
So, you will be seeing that here it is stored in your data memory basically 1D what it shows and this is output image all the values what it has stored.
So, if you want you can write this memory back into a file and then you have to read it properly.
So, this is a floating point number what it has stored.
So, you can see that the values have come.
So, some of the values if you want to see the.
with respect to the original value.
So, you will be seeing that reconstructed we will look at it.
It is 804100 what we have it.
So, I can give it as input file we can dot h file what we can open.
Some values what you will be seeing is 100 or So, we have to check our memory ok.
So, once we close the thing the output file is not going to be available.
So, what you have to do is you can copy it and then paste it and then look at it.
So, the other one.
will see here also there will be a problem with the thing because this is from the book of you will be converting from YCBCR to RGB ok.
So, this is the DCT S dot C what it is gives ok.
from the code book what it has been selected.
So, I have to have the here also I have to call my CCXML.
So, what I can do is I can copy this one to here.
So, that I need not have to again put the thing and we have to see its properties again you will.
Here it is chosen as legacy cof file here.
So, I need not have to worry and then you will be when you are doing the thing the family I will be selecting it as C6000 and you will be seeing it as LCDK6748.
And then the compiler version for this board is although there are higher versions of it, it is better to use a TI v7.4.4 in this case.
So, we will just do that I am directly gone to do the debugging because.
It is asking me there is an error.
Oh, ok.
Here what happened was this code book gives 55 version.
I have this one DCT has been written in assembly.
So assembly with respect to 6, 7 and then 5, 5 are different.
Most of this as you know now why assembly coding is particular to one of the board.
So, we will modify this DCT to what we will call it as to the 6 7 processor and then we will see in the next class how we are going to implement this using assembly programming little bit of it what I will give a little flavor only multiplication what we can do it and then we can look at the rest of it if you are interested in assembly programming you can learn it and then implement it.
Thank you.
Welcome back to real time digital signal processing course.
So today we will be covering adaptive echo cancellation.
So, in the last class we discussed about how do we do the prediction and we saw scrambling why do we need it to protect our own voice or audio files from misuse of it.
So, we can do the scrambling and then send it to people who are only connected with our network.
The other one is echo generation so, most of the time we know that it is an hobby.
So, how to generate the echo first we have seen the thing today we will be seeing how to do the cancellation of echo.
So, most of the places what we visit which has the capability of echoing that is we will have stones and other things which sometimes if it our voices reflect then we will be enjoying that when you go when all of us go for a picnic or other places.
So, in this case.
Synthetic echo generation what we saw in the last class.
So, we will continue how to because this is one of the welcome for a hobbyist, but in some of the cases we will see in a while that how it is going to hinder our output.
So, we will be looking at it how to do the cancellation.
So, first is we will see the line echoes basically.
So, in this case what we have is.
This is the line indication that is most of you may ask that is what you will be getting the cartoon network saying that it is what is it antic whatever phone lines or telephones what we show it to the kids because they are used to mobile basically, but still some of the places only in the cities it may be not there, but in.
what we will call it as villages still all of us know that in those people are also using most places mobile phones, but still telephone communication is one of the part of for past life and then some places it is still there ok.
So, what is it what we call it as line or network ok.
So, it echo is caused by impedance mismatches at various point of interest what we will call it.
So, we are seeing this is a telephone where it is connected and then the.
This is from the sender side and this is the receiver if we call it.
So, these are the paths what it has to take it.
So, at different places you may have a echo basically.
So, we say this effects are they are going to depend on their loudness, spectral disk and time delay.
So, these are the ones which will be causing echo.
So, if there is no delay then we say that we are not hearing any echo from the transmission part of it.
What it says is longer delay requires a higher degree of echo attenuation and time delay between the original speech and then the echo is short then echo may not be noticeable.
So, we will be seeing in the lab.
So, how we are going to run the thing.
What is it?
This is a simplified telecommunication network which is being illustrated.
So, what are it contains basically.
So, this is the local telephone is connected to the central office by it.
2 wire line in which both directions of the transmission are carried on a single pair of wires.
So, as you can see here it is connected with 2 wire basically.
So, the connection between 2 central offices they use 4 wire facility which physically segregates the transmission from the 2 wire facilities and this is because long distance transmission requires.
repeated amplification that is a one way function.
So, you will be seeing that this is a of office 1 you call it office 2 basically you will be seeing 2 lines going from here and then other 2 lines to 4 lines what is going.
So, this is how it is connected and when you are putting it to the receiver.
So, you receiver telephone.
So, you will be seeing again from the office it will be 2 wire connection what we will be having it.
So, what happens in the thing is a hybrid located in the central office makes the conversion between the 2 wire and 4 wire facilities.
So, this is used for most homes and then small offices.
Otherwise, what we are going to have is basically exchanges switches through which you can be connected.
So, as an example for this.
We know that internet protocol trunk applications that use IP packets to relay a circuit switch network traffic.
The round trip delay can easily exceed 40 milliseconds.
So the you can see this is how it is connected.
So what you have is we call from here to here is your round trip delay.
So which can cause 40 millisecond.
This is a voice over IP example using a gateway in which the voice is converted from the time division multiplex circuits to your IP packets.
So, you have an encoder.
So, you will be having the RTP packets basically and use the IP cloud and then you will be either transmitted this way or you can pass it through the jitter buffer.
And, finally you will be decoding it and this is the hybrid circuit what you will have it as you are seeing the telephone is here.
From there you can do the encoding and then you will be sending the RP packet here to the cloud and then it this is going to have a jitter buffer and then you can decode it.
So, this is how what happens although this is the receiver what you are intended to send the thing, but there will be a round trip delay which is coming back.
to the person who is calling.
So, this is how the what you will call it as echo comes back from here to here whatever you have spoken sometimes as I pointed out in the last class.
So, that you will be hearing yourself.
So, that delay includes speech compression and decompression that is why you have both encoder and decoder there and jitter compensation.
So, what you call as jitter.
It may be a little bit of noise or it may be little delayed that is what we call it as jitter ok. And the network delay, so we have to include the network delay also.
So, the standard used for this voice over IP is G.729, we call it as ITUT standard for speech coding standard is widely used for voice over IP application.
So, why it is being used?
Because of it good performance.
And, it is 15 millisecond low algorithm delay what it has it that is round trip delay where we said it is 40 millisecond whereas, in the G dot 79 it is 10 millisecond low logarithm algorithm delay what we have it to compute the thing.
So, when a 10 millisecond frame real time protocol what we call it as RTP packet and 10 millisecond jitter compensation are used the round trip delay of this G dot 729 speech coder based system will be at least.
twice that of 15 plus 10 which is equal to 50 millisecond.
So, that is 10 millisecond is our jitter and then we have algorithm delay of 15 millisecond because it has to go and then come back as you can see encoder and decoder is here.
Here also we have the encoder and decoder that is why it is twice what it is getting multiplied.
So, which comes to about 50 millisecond without counting the IP network delay here IP cloud what you are using it.
you have not counted and as well the processing delay is ignored.
So, if such a long delay is this is the reason why our adaptive echo cancellation is required for voice over IP applications, if one or both ends are connected by our TDM that is time division multiplex circuit.
So, for this reason one has to use the echo canceller as you can see that.
that is what it shows that round trip delay can exceed 40 millisecond.
This is with respect to G.729 shown that it is going to have a 50 millisecond round trip delay fine.
So, how we are going to design the adaptive echo canceller what it is shown here.
Using echo cancellation the echo canceller is located in 4 wire section basically that is the reason why all the.
stations they use the 4 wire section of the network near the origin of echo sources.
So, you have the telephone this is near end and then the principle of adaptive echo cancellation is what shown in the diagram here.
So, we will see how it is going to work to overcome the line echo problem in full duple communication I think you must be knowing half duple is going to be only one way communication full duple is.
you will be getting back your signal that that is known as our full duple.
It is necessary to cancel the echoes in both directions of the trunk basically.
So, only one echo canceller located at the left end of network is it is what it is shown here basically.
For showing a telephone and two airline is indicate that this side is defined as the near end.
While the other side is referred to as the far end.
So, this you are calling it as far end and you will be having the near end the circuit what you are having is the hybrid circuit.
So, which you will be giving a compensation for the echo.
So, we will see how principles of echo cancellation will be looking at it.
So, what is it?
Echo cancellation the function of the hybrid is whatever we have put the H here.
the hybrid circuit is shown in this case which is expanded.
So, where the foreign signal this is what your foreign signal X of n passing through the your echo path that is P of z is your echo path results in an undesired echo R of n. So, when it is passing through so it will be P of z will be causing this thing echo.
which is known as R n. So, near end signal U of n what you have considered and noise is defined with V of n. So, based on the principle of adaptive system in this case identification the adaptive filter W of z here models the echo path P of z.
What is the echo path is going to be modeled and So, what happens using the foreign speech X of n as an excitation signal.
So, for this it is modeling P of z based on R X of n and what happens the output signal Y of n generated by this W of z we have Y of n here will be subtracted from the primary signal D of n. So, this is this becomes our.
desired signal and subtracting it will be calculating the error will try to minimize that error.
After the adaptive filter identifies our echo path its output y of n echo replica what we call it approximates the echo thus the error y of n contains the near end speech noise and then residual echo.
We may not be able to completely suppress the thing, but little bit of it is there most of it is going to be.
suppressed basically.
So, what we call it as tail delay, what is that delay?
So, we will be seeing the impulse response of this P of n of an echo path is what it is shown here.
The time span or the hybrid is usually about 4 millisecond which is called the dispersive delay.
So, you will be seeing that this is approximately 4 millisecond which is going to be dispersive delay, because the 4-way circuit is located between the echo canceller and the hybrid.
The impulse response of the echo path has a flat delay as you can see it here it there is a flat delay.
Then you will be getting the dispersive delay.
The impulse response of the echo path has a flat delay.
The flat delay depends on the transmission delay caused by the distance between the echo canceller and then the hybrid.
And also depends on the filtering delay associated with the frequency or time division multiplex equipment.
The sum of the flat delay and the dispersive delay is called tail delay.
So, the complete thing including flat delay plus dispersive delay is known as the time delay which is shown in this figure.
So, how we are going to estimate the echo?
So, that is echo path what we have is a P of z, we say it is a linear time invariant and with infinite impulse response that is IAR.
filter what will be defining it which is given by P of n is equal to P of n which is n is going from 0 to infinity.
The primary signal d of n in that case can be expressed as which is given by R of n plus U of n plus V of n which is given by this equation.
So, we call it as V of n as the additive noise which is uncorrelated with the near end speech.
u of n and the echo is r of n. So, this is the when you substitute the thing P of l x of n minus l plus u of n plus v of n. So, what will be the adaptive FIR filter w of z is going to be estimated as echo basically y of n is given by we have seen that l is equal to 0 to l minus 1 is the length of the filter, w, l are the weights of the filter.
And, then x of n minus l is the input to the filter.
So, that is what l is our length and error signal in this case can be expressed as e of n is equal to d of n minus y of n which is given by after substituting from this d of n, u of n plus v of n plus this summation l is equal to 0 to l minus 1, p of l minus w l of.
n into x of n minus l plus l is equal to 0 to infinity p of l into x of n minus l. So, this is how the substitution is going to happen d of n and then y of n. So, when you put the terms in proper way.
So, how we are going to do the echo cancellation?
So, due to the changing power of speed signals.
The normalized LMS algorithm is commonly used for adaptive echo cancellation for all these applications ok.
Assuming that the disturbances what we call it as V of n and the near end speech U of n are uncorrelated with the foreign speech X of n then W of z is going to converge to P of z that is W L of n is approximated as.
p of L and L is varying between 0 to L minus 1.
So, the adaptive filter W of z adapts its weights W L of n to mimic the first L samples of the impulse response of the echo path.
So, as it is shown in the figure this is our hybrid.
So, that is what it is tried this W z is getting adapted ok.
The residual after W of z has converged can be expressed as this is convert then you will be putting our error of n is approximated as L is equal to capital L to infinity P of L x of n minus L plus u of n plus v of n. So, where the first term on the right hand side is called the residual echo.
This what we call it as residual echo which is carried and then our signal and then the noise what we said that will be there.
at the fore end.
So, how to estimate the performance basically.
So, effectiveness of our audio echo canceller is usually measured by the echo return loss, enhancement that is E R L E which is defined as that is based to the log what we will be taking it 10 log expected value of our desired signal squared D squared of n divided by expected value of the error square function E square of n. So, for a given application how we are going to consider it?
Here really depends on the step size m that is mu what we consider it the filter length l signal to noise ratio and the nature of the signal in terms of power and spectral contents.
A larger step size results in faster initial convergence, but final ERLA will be smaller due to the excess minimum mean square error and quantization errors.
And if the filter length is long enough to cover the echo tail or tail delay what it is known as.
So, further increases L will reduce the ERLA.
So, ERLA achieved by an adaptive echo canceller is limited by.
many practical factors, the detailed requirements for adaptive echo cancellers are defined by the standard ITUT that is telecommunication standard, recommendation for G.165 and then G.168 ok, including the maximum residual echo level that is separation effect on the hybrid, the convergence time, the initial setup time and the degradation in a double talk.
So, one has to will look at the what is that double dock in the next slide ok.
So, in the past adaptive echo cancellers what was happening implemented using customized devices in order to handle the heavy computation for real time applications.
So, we know that software delay is going to be much more.
So, hence there was a hardware which was designed to do this cancellation in real time applications to reduce the delay.
So, what was the thing disadvantages of VLSI implementation are long development time, high development cost, lack of flexibility to meet new application specific requirements and inability to be upgraded for more advanced algorithms.
So, when you design hardware VLSI implementation it is very large system integration.
So, if the volume is too high then you can go for the VLSI.
implementation.
So, what are the drawbacks of it?
One is because development time one has to design your circuit from a transistor level.
So, which is going to take longer time that is what it says long development delay and high development cost because once it becomes a long development.
So, you know that the person has to be paid and other things.
So, the cost is going to be very high and then what is the.
Other disadvantage, lack of flexibility.
So, if I want to modify any circuit, so then I have to go for redesigning.
So, I would not be able to do that design within the time constraints.
So, these two will be going up again if I had to redo the design.
With little modification it is not possible to accommodate it.
That is what it says any new application is coming.
So, we may not be able to.
use the same circuit it has to be completely modified.
And what is it the other thing is you cannot upgrade the system.
So, most of you must be knowing that you will be upgrading your memories if you know DDR3 and then now DDR4 which is coming in earlier DDR1, 2 ok.
So, whenever those systems were there so, if you want to upgrade it you had a limitation of memory for those systems.
For the other one you have to.
completely change your CPU.
So, what you will be doing now also it is so fast they become obsolete ok.
So, for the advanced algorithms whatever nowadays being used.
So, you will be not be upgrading the whatever you have designed in hardware.
So, these are the drawbacks.
So, what is the solution what they gave is recently adaptive echo canceller design and development have been based on.
programmable digital signal processors.
So most of the even your mobile has a DSP.
So which is programmable so hence you will be avoiding you will be getting once in a while upgrade your software correct.
So whenever you upgrade the software even the hardware must be able to run those softwares.
So if it is not going to do that then you may not be able to upgrade your software.
or any of the hardware system for that matter.
So, that is how from the custom design it has gone to the programmable device what you can look at it now signal process.
So, what are the practical considerations we call it as pre whitening of signals in this case that is the convergence time of adaptive FIR filter using LMS algorithm we have discussed is proportional to the spectral ratio.
that is L max is equal to L min.
So, since speed signal is highly correlated with a non-flat spectrum, the convergent speed is generally going to be slow.
So, the de-correlation that is what we call it as whitening of the input speed signal can be used to improve the convergence speed.
So, this is one of the application practical consideration one has to.
So, the other practical consideration what it is shown in the figure here.
Typical pre whitening structure for input signals where the whitening and then adaptation are processed in the background.
The same whitening filter what you call it as FW of Z what it is given here is used for the both foreign signal X of n and the near end signal your D of n.
So, you will be using for both far n is R x of n and then d of n is R near n. So, you will be using the same this thing filter for both of it.
So, the whiten signals are used to update the background adaptive filter W of z.
So, from here you will be based on it what you will be updating your weight functions of your filter.
For improving the convergence rate.
The foreground echo cancellation uses the original far end and near end signals thus the resulting signal E of n will not be affected by the pre whitening process.
So, the function of the non-linear processor what it calls will be used for this effectiveness.
So, this is how you will be putting the thing although if it this thing what it says is it is.
So, original foreign and foreground echo cancellation is not going to be affected with your what you call it as whitening part of it that is pre whitening.
So, how you are going to estimate the delay that is what the next slide shows that is fixed filter what we have is Fw of z can be obtained using a reversed statistical or temporal function.
average spectrum values.
So, the example is anti tile filter used to lift up the high frequency component since the power of most speed signals is concentrated in the low frequency region.
So, the whitening filter can be updated based on the foreign signal X of n which is similar to the adaptive channel equalization.
So, initial part of the impulse response of our echo path that is flat delay in the.
figure what you will be seeing it represents the transmission delay between the echo canceller and the hybrid.
So, this is what the delay which is getting represented thus that is what represented with z minus delta and your input is getting delayed by x of n minus delta in this case.
So, delta is the number of flat delay samples and by estimating the length of the flat delay.
And, using delay unit z minus delta the echo canceller W of z can be shortened by delta samples since it covers only the dispersive delay part of it.
So, this technique effectively improves the convergence speed and reduces the excess mean square error and computational requirements.
So, however, there are three major difficulties in realizing this technique in real applications.
that is the existence of multiple echoes the difficulty in estimating the flat delay.
So, if it is a single delay you can estimate it and then do the cancellation otherwise if like example we considered as reverberation if we have multiple echoes then your flat delay and the delay variation during a call it is little bit difficult to cancel it.
So, how you are going to estimate your delay.
So, one is using the cross correlation function between the foreign signal x of n and the near end signal d of n can be used to estimate the delay.
So, what is the we have derived this normalized cross correlation function is given by rho of k which is equal to Rx d of k divided by what is it this is autocorrelation value of X that is input signal and this is the desired signal autocorrelation value under the square root of it.
So, what it defines is Rxd is the cross correlation function and Rxxk and Rdd of k are the autocorrelations.
So, it can be estimated with typical values of length between 128 to 256 for an 8 kilohertz sampling rate.
So, this is our sampling rate.
that is narrow band frequency what it has been considered in this case.
So, what are the double talk effects?
So, you would be seeing your own echo is coming and someone else also there will be a cross talk is going to happen.
So, how you are going to look into this?
Designing adaptive echo cancellers for practical application is how to handle the double talk problem.
So, which occurs when the.
far end and near end talkers are speaking.
So simultaneously it is going to happen ok.
So during the double talk periods what you will call that is sign basically D and contains both the near end speech U of n and then the undesired echo R of n. So that is what it is shown.
So you have the hybrid as well as this is the far end what you have the NLP in this case ok.
So how you will be detecting and then control algorithm what you will be providing it.
So thus the error signal.
or E of n contains the residual echo, the uncorrelated noise V of n and then near end speech U of n. So, for adaptive system identification that is D of n must be generated solely from its excitation input signal X of n. So, in order to correctly identify the characteristics of R, P of z for the hybrid.
So, you will be generating from the X of n. So, to do the thing.
So, we will consider in the next class equalizer and then some of the speech coding techniques available in the literature.
So, thank you for this hearing and then happy learning.
Welcome back to real time digital signal processing lab.
So today we will see how you can use your own mobile either it is Android platform or or iPhone you can run your some of the real time signal processing experiments on it.
So this has been developed by using Java from Arizona State University say they call it as what I am using today for the recording is JDSP basically.
So they have for the Android AJDSP.
So you can use that or in the normal thing they have the JDSP basically Java based DSP which has been developed so you can use them.
So what I am using as I said you are seeing the screen that we have the do net.
So here manuals have been given so you can go and then check with them.
So here we will do some experiments whatever we had done the thing.
So we will see that how signal generator is going to generate some signals.
So whether we want the sinusoid signal rectangular.
or a triangular or delta exponential any of the functions what you can select from this.
So here we will select the sinusoid.
So I will be doing the save actually and the gain is given as 1 and pulse width is 20 and we have not taken any time shift for this and frequency in pi radians that is 0.2 pi radians what it has been selected.
So default what it is there I am taking it.
So we are adding a block as you can see it is a block level design what you will be doing it.
Next, what we will do is I will see what kind of sine wave I am going to get it.
So, we will do a plot.
So, it ask our add plot.
So, I have added the thing.
So, now the connectivity is going to be between output of the sine generation and then the plot.
So, we will click on it.
So, I want to see the magnitude of it.
So, you are seeing the sine wave how it is looking like.
So, you can have it as linear or in dB if you want to see the thing continuous or discontinuous what you want to see you can do it.
So, linear sine wave what I am displaying it here.
So, number of samples there if you want you can increase also.
So, what we will do is if you click on the thing, so it will ask me to delete it, so I can delete this.
So, now what we will do is I will select one more sign generator.
So, here also I am clicking on the sinusoid save.
In this case what I will do is I can select the values what I want.
So, we will select it as point.
3 in this case and then save it and then the pulse width if you want you can increase the thing.
So, we will make it as 30 and then save it and then add them.
So, I have a 2 sine waves what I have it.
Now, what I can do is I can take a sum of this and see how my output is going to look like.
So, I will you have a adder.
So, we will select the add this thing and then put it here and connect these two and output I can put it on to the plot.
So, now, we will see what is the magnitude of it.
So, you are seeing this is your output basically what you are getting from the two of it.
So, if I want I can add one more sine wave or what I can do is I can do the filtering.
So, I will disconnect.
So, we will move it a little on the left hand side of it so that I have a place for me to put the I can do the FFT magnitude also.
So, first we can see FFT it is FFT size is 256.
So, I can add it here.
So, what I get FFT magnitude and I can do the plot.
So, once I click on the thing.
So, we will see the magnitude plot.
So, you are seeing.
different plots for the frequencies whatever you can see this is going to give you approximately 0.2 pi.
So, and then here sorry this is your this thing 0.2 pi and then multiple what you are generating 0.6 to 0.3 is not a multiple of 0.2.
So, that is the reason why what you will be seeing here approximately 0.94 what the repetition is happening.
So, now what we can do is we can create a filter in between and then see that.
So, first I have to define the filter coefficient.
So, here it is going to give me a 0 is always 1 and then if I do not give any part of the thing only b coefficients what I am going to specify.
So, it is going to create me.
So, I will give the moving average basically I can say V1 and then V2 I can give it as a 0.5.
We will see what is the thing is going to happen with the filter coefficients and then we will put the filter basically.
So, we will add the filter here and coefficients are given from here.
And, then input is from here and then what we will do is we will connect this to FFT here.
So, now, we will see what is the plot I am going to get it magnitude plot.
So, you can see that it has it is a moving average.
So, you have seen that the peaks have been amplified.
So, if I want I can change my this thing pulse width I will keep it as 20 here.
Or same as the previous one.
I will increase it to this one to 0.4.
I can update the thing and see what is the plot I am going to get magnitude plot.
So, you will be seeing that different kinds of it what it is generated.
So, like this you can create your own this thing either FIR filter or IAR filter whatever filter operations you want to do the thing.
So, what I will do is delete all means the work space is going to be deleted there is no way you can save these work spaces in these.
So, now what we will see some of the examples, what we have it here that is all of you know what is a midi basically.
So, if I click on the thing, so you will be looking at the your piano basically.
So, if you want to play and then see what is the music tone it is going to generate.
So, we will only work on the black one.
So, you will be seeing different.
tones also coming along with it.
So, and you will be seeing what are the frequencies as in our lab using the sign generation we created a Sarigamapadhanisa.
So, you will be seeing same kind of it what it is generated here ok.
So, this is one of the example and if you want to see the in between the magnitude what it will be giving up to pi what you have it.
So, you if you click on the thing, so what is the peak value what you will be seeing it 0.04 pi what it is for the first white one.
And so, next one you can see that what is the displacement you have between the thing ok and for this what is the peak you will be getting it point approximately 0.05 ok.
So, this is at these distance 1 twelfth of the distance basically in the piano what they frequency what it will be getting.
aligned basically.
So, this is one of the examples.
So, we will delete this also.
Now, other examples.
So, all of you know that are D2MF.
So, if I click on the thing.
So, you will be seeing the numbers as in your phone telephone basically.
So, I can click one of them 1, 2, 3 or whatever may be the thing.
So, and then even the hash function what we have it.
So, this is what different frequencies what you will be getting generated.
So, if you want to see what are the things generated.
So, what we will do is we will put FFT here.
So, add the thing with the DTMF and then we will do the plot basically.
So, the magnitude plot what you will be seeing because we know that.
it has two frequencies, one is the horizontal frequency, the other one is the vertical frequencies for the D2MF.
So, you will be seeing this is approximately 0.53 and then this is 0.93.
So, for one these are the two frequencies what it generated.
So, if I click on now 8 ok.
So, I will go back and you can check the magnitude what it has got created.
So, you will be seeing that it is.
x-axis 0.63 what you will be seeing the thing the other one is 1.04.
So, you can go to the DTMF.
So, each digit what are the frequencies that get generated.
So, you can map it into that.
So, this is how you can play along using your mobile also that is what I wanted to bring in.
So, next is using the PZ placement that is your pole 0 placement you can generate your coefficient and then use it for your.
So, this is a demo what you have it.
So, if I want to add a 0, I can add a 0 or if I want to add pole I can do it or you can reset.
So, this is the demo.
So, I will put it as 0 what I have to add it.
So, I am going to put it my 0 in this position.
So, you are seeing what is the magnitude response I am getting it and then now this is the frequency that is phase what it is at the bottom what it is showing.
Now, add a pole to this.
So, what we will do is what kind of frequency you want to have it.
So, I can put it in this way also.
So, what is the thing approximately what I am getting is a high pass filter in this case.
So, by adjusting your zeros and then poles you can fine tune.
So, I can add one more 0 and then I can place it here and then add a pole here.
I will be fine tuning it.
So, you will be seeing that what is my cut off what how it is varying.
So, I want to fine tune the thing.
So, you can place the poles and zeros in whatever way you want.
So, if you want to delete if you have not satisfied with whatever the response what it is showing.
So, we can move them.
So, or if you want to put the zeros outside.
So, you will be seeing that what is the phase response is going to happen.
and then how it is getting moved.
So, this is how you can play around by placing your poles and zeros using this PZ demo.
So, the next one what we have is a little bit on sound record and then player.
So, what the manual says is you can play from one of the unit and then you can get it in the other unit through your Wi-Fi or whatever way it is connected.
So, if you want to see the frequency response demo, so you will be seeing the demo here.
So, if I want to have a low pass filter to be built in, so this is how it shows that what are the components A and B it is a IR filter what it has designed it.
So, these are the values what it has taken to get this response.
So, if I want to design an high pass filter, so this is my poles.
And, these are my zeros what it is coming in my system ok. And same way you can define the band pass filter.
So, these are the what you will be seeing poles and then zeros which is getting done.
So, this is one of the thing.
So, like this you have a sound player.
So, if I want to do the convolution demo I can take the thing convolution demo or you can do your own convolution.
So, the demo will whether I want discrete convolution or linear convolution what you have seen the thing.
So, if I click on the thing.
continuous convolution if I want to do it or discrete convolution.
So, we want to have a discrete convolution.
So, it will ask me signal 1 is rectangular and signal 2 is also rectangular what it has been default what it is chosen.
So, we will see what is the output we are going to have it.
So, you will be seeing that this is the output y what you will be getting your convolved signal.
So, if you want to do this thing different one we will take a triangular.
1 and the other one also we will take a triangular and then save it update the thing.
So, you will be seeing the output is what you will be getting 2 triangular how you will be representing the output y basically.
So, one is I can choose it as rectangular and then save the thing update it.
So, you will be seeing that wherever you have the thing convolute signal what it shows.
So, this way you can play around with the thing and then see.
whether your DSP concept is clear or not.
So, the next one is if you want to design FIR design you can you do use it or if you want to design IR filter you can design the thing, but the coefficients have to be given from the FIR coefficient values will be given from this block basically.
If you want to design a window you can do the window design frequency response you can get the thing.
filter coefficients had to be fed into your filter design block basically.
So, we will take up FIR filter design.
So, I have asked for this thing.
It has chosen in this case hamming window, order is 8 and then the design is low pass and cutoff frequencies it is taken it as 0.2.
So, we will update the same thing.
So, these are the coefficients what you have it for the 8th order filter.
So, now, what we can do is I can generate this thing signal generator I can use it.
So, we will give it as we will see the rectangular what is the output we are going to get it.
So, I will add this.
So, I have to select the filter.
I will be selecting the filter input from here to here and coefficients what I have taken from here.
So, now, because I have to see what I have got the thing.
So, what we will put is FFT block in this case.
So, I will add a FFT and then I need a plot.
So, I will connect that.
So, now, we will see what is the output magnitude what I am going to get.
So, we have designed the low pass filter and then cut off frequency what it has chosen is 0.2.
So, sine wave if you want to ok.
So, one more plot what you want to see it ok what is the signal generated one with FFT what we can plot it after the filter we can plot the thing.
So, for that what it has is a junction what it calls.
So, I can put a junction here.
So, from here.
I will be taking input to this.
So, from here I will be taking one of the input to here.
So, I can directly plot the other one let us I will put a FFT there also.
So, from here I will be giving to this and then I want to have one more plot I can select it and then I will be putting.
I will be connecting.
So, now, we will see what is this I will see the magnitude response of this and then after filtering so, what I will going to get is this one.
So, there is no difference between the thing.
So, what we will do is our signal generator directly instead of putting a FFT.
So, if you hold it for a thing you can delete the thing I can directly give it to the plot.
So, you will be seeing that magnitude of it.
So, this is a flat response what you have it correct.
So, when I pass it through the filter because I am passing through the low pass filter the rectangular wave.
So, you will be seeing that this is what the output is going to be ok.
So, after filtering so, I can you can keep playing with the thing one or two more demos what I will be showing you the thing.
So, if you want to do up sampling or down sampling I have shown you one of the example and then if I want to do the inverse FFT both FFT and then IFT I can do the thing.
So, if you want to pick up the peak you can do that and then if you want to signal to noise ratio you can do it.
So, the other one is if you want to see the spectrogram of your signal what you can do it.
So, there is one provision for long signal generator.
So, if you click on it and then you if you do the thing what it says is it is a male speaker and then the gain what they have is 1 and frame size 256.
frames are there and then overlap there is no overlap between the frames and then you will be seeing that current frame is there are 32 frames in it.
So, I can go with the thing.
So, you are seeing that where your voice is going to come.
So, you will be picking up the peak of it.
So, you can use that one for your usage in any of the thing.
So, you will be seeing that one of the example you have is a linear predictive coding what you can use it.
So, we have a little demo on the thing there is a LMS demo is also there for your adaptive filter.
So, whatever the quantization and then pole 0 to LSF what you have the thing.
So, we will take the LMS demo.
So, if I click on the thing.
So, you are seeing that initially original filter is value has this.
and then the estimated filter what you have is this one.
So, by doing the next this is a default what it has taken.
So, if you give the next step, so you will be seeing that it is getting adjusted to these values whatever you had the thing.
Step size you can choose between the thing.
So, we will give it as point 1 is our step size.
it was 0.05 earlier now it is 0.1.
So, you are seeing that it is going into the negative.
So, what is the thing happening?
It is not reaching the 1.0.
So, they are varying much away from the thing.
So, by varying your step size smaller the step size you will be seeing that it is getting adapted and then by making little more.
you can see that it is oscillating between positive and negative side of the thing.
So, this is how what you can look into the thing and then the there is a quantization set up to what this is a demo basically.
So, what it has got created.
So, you will be seeing that what it has is a long signal generator and then this is a LPC 1 coder basically.
and then quantizer what it has in it and then there is a filter and it will be going for the player.
So, you can see the play sound in your this thing it will be coming out I think sound because it is taking my recording.
So, here you would not be able to hear this sound.
So, you will be seeing the long signal here it has been chosen as male speaker.
So, if you want to see a different speakers are there whether you want to have a music.
you can play with it or a female speaker or noise or sign 1 2 and then you can have a music and noise combined and then you can pass it through your adaptive filter and then see that your noise is eliminated using your filtering and then you will be getting only the music back So these are the play things what we what one has okay So the other one is quantization if you want to see the thing So, we will LPC quantization.
So, what it will happen is signal to noise ratio what it is going to give you as the output.
So, here it is a long signal generator, same thing what you have is a male speaker and it has 32 frames which will be continuously played.
So, and then from the junction one is signal to noise ratio what you are calculating, the other one is you have pass it through the linear predictive coding LPC coding.
And, then you have the quantization two level quantization what you are doing the thing and then you are doing the filtering from that and giving to signal to noise ratio.
What we will do is we will see the thing here that is in dB what it is going to give you.
So, if you the whatever the male voice getting played is going to be showing its signal to noise ratio.
So, if I play the thing so, you will be seeing continuously changing with it.
So, that is from the sound recorder.
what you can connect with the signal to noise ratio and then see what is your signal to noise ratio is coming.
So, one is the direct signal what you have taken the other one is noise what you have whatever the output of LPC coding what you have got it the difference between the thing that dB what it is showing here.
So, this is how you can use this help files are there in this when you.
So, if you want you can go to the information.
So, you will be having the IGDSP video demo one can look at it and then you have the DSP with book with simulations this has to be bought basically.
So, you can web page is also available.
So, if you go to the demo.
So, you will be seeing the so, it will show you how to go about using it with the.
demo.
What are the things available and how is it signal generator how you can do it whatever demo have seen the thing.
So, you can go with this demo and then use in your own design basically.
So, hopefully you will be enjoying this course.
So, with this thank you very much for listening to me.
So, you can go.
And, then play around with your mobile phone with the block level simulations also.
Thank you.
Welcome back to real time digital signal processing course.
Today we are going to discuss what are the few things that we can do it in laboratory.
So, first lab course is going to be demonstrated today.
In the present laboratory we will be using DSK6713 board from TI.
So, in this case we will see how to go with the Code Composer Studio and then the first part of it how to download the software.
So, the below link gives you how you can download the Code Composer Studio version 5 and are the downloads.
So, this will try to install in Windows version, this is the release version of Code Composer Studio 5.5 in C drive.
So, you have to have a permission to download it, if there is any issue you can come back to me.
So, I will be giving the license because we have the user licenses here.
So, you can use that.
So, first we will see that after installation.
what are the features of this DSK6713 or we call it as TMS320C6713.
So, we have a 32 bit instruction cycle processor, typically it runs at 225 megahertz and it can go up to 300 megahertz clock frequency.
And then what is the MIPS or what we will call it as Million Instructions Per Second or Mega Floating Point Operations what this board can do is shown here.
So, 2400 MIPS and then 1800 mega flops instructions processing what it has the capability.
So, this has 4 ALUs and 2 32 bit MAC functional units and we have 4 KB level 1 program cache and then 4 KB level data cache basically and then 256 KB level 2 data cache and it supports external memory interface up to 512 MB addressable external memory space what is provided in this board.
And we have two I2C ports, two MAC BSP that is serial port interface and two 32 bit timers in this board.
Coming to the block diagram of the DSK6413.
So we have the core 6713 CPU is shown here.
So, which has instruction fetch, instruction dispatch and then instruction decode.
So after that we have the data path for two functional units what we have it.
We call it one as path A, the other one is path B.
So it has A registers which are connected to these functional blocks and B registers.
file are connected to this functional block and this is some of the functional units.
So, when we take up in the class about the architecture of the processor, I will be discussing about these functional blocks.
Coming to how it is going to be controlled, you can see control registers are there, we have controlled some logic and then test what we can do the thing and in circuit emulation and then interrupt.
control is also available.
So, these are the external which can be connected and you can see that whatever cache memory which is a two way set associative 4 k bytes L 1 0 is available.
And then we have the clock generator here and then power down logic is available and then you will be seeing that for this is the data cache what you have seen L 1 D and then here this is the program cache.
So, L 1 P cache which is a direct map.
but this also has a 4 K bytes total basically.
And this is the interfaces what we can see this is the L2 memory interface and this is the L which can go up to 4 wave whatever it supports and then L2 memory which can go up to 492 K bytes of data which you can interface.
The other one is we know that whenever direct memory access has to be done we need the DMA.
So we have the external DMA controller here which is 16 channel what is available and some of the interfaces for the memory interface and then MAC BSP what it has and then it has a MAC ASP and then there are two MAC BSPs board support logic application specific logic interfaces.
is MAC ASP and then I2C what we saw there were two and then there are two timers.
So, using the timer we can interface the external world and this is the GPIO which is going to be connected to the board and then we can have a host port interface also using the USB.
So, this is gives the overall picture of the board basically.
So, we have the DSP processor here.
TMS320C6713DSP and then we have the SD RAM.
So, we can see flash memory is also available and some CPLDs and if we want to have the memory expansion we can go here actually some of the memory expansion and then we have the point external interface for this unit also.
And then for the peripheral expansion also what we can do it here.
And then you will be seeing some of the things this is the mic in for real time application I can use my input as speech through mic in or audio stereo what I can put it in the line in basically from any external device with audio and then some noise if you can feed in from the line in.
And then there are dual output basically here which is line out and then headphone.
So both are stereo basically so any from any one of it what we can.
take the output.
If a line out is taken and then it can be interfaced with a 1 volt board as a line in we can have the loop back system.
Or if I want to hear what is my after processing in the processor what output I am going to get.
So, I can connect the headphone or speaker out basically.
So, we have little bit of JTAG emulation.
So, which provides a to do the debugging friendly basically.
And then we have some power jack is what it is going to be connected which is a 5 volts power supply and this is the USB port which is going to be interfaced with our laptop or desktop any of the system.
And there are some DIP switches through which you can configure if you want to control your input and output and some LEDs immediately if you want to say whether your board is working or not you can do that.
and there is a software reset switch available here and then there is a configuration switch how this has to boot basically what you can configure with the switches.
And we have the external JTAG interface also.
So, which can be used for more debugging and then go deep into the in-circuit debugging part of it.
So, this what they call it as hurricane header what is.
So, coming to the functional block diagram, you saw the board diagram with all the components there.
From the functional block diagram what you will be seeing this is a chip and then you have the CPLD logic and some flash memory and then SD RAM and then these are the memory expansion unit what we have it.
We call this as external memory and then we have the peripheral this thing interfaces here.
expansion for host port interface what we can use the thing.
So using Mac BSPs one of them is going to be selected either your codec or peripheral expansion one can use the thing.
So with the peripheral expansion so we can add on camera unit, daughter card and other things to give extra features to the port.
And we have as I said in the theory class we will be using the AAC23 codec in this board.
And, other higher versions will be using AAC 3 1 versions and as we saw in the board these are the inputs, two inputs and then two outputs what is available.
And then we have the JTAG interface using the USB will be connecting and voltage regulator.
So, here it is going to be 5 volts what will be operating.
Some of the boards 5 5 series will be operating at 3 volts suboptimal voltage.
to run the board.
So, we will see little bit on AC23 codec interfaces how it can be done.
So, we will be using the MAC BSP 0 to input to this codec chip and then output ADC output is going to be taken out through MAC BSP 1 interface to the DSP board.
And then whatever the format it has to be defined we are going to provide it here.
And then as we can see that I can given as a mykin.
or stereo we will be seeing input or stereo output or I can connect the headset for it.
And then we have different configuration here.
So, we will be seeing in later classes how we will be interfacing these things.
So, coming to development kit features in this case.
So, we say that this is a Texas Instrument TMS320C6713DSP.
operating at 225 megahertz.
So, it has a AC23C stereo codec and then we have 6MB synchronous DRAM this is complete to the board what we are using it or whatever features I have mentioned it will be referring to the board.
Here we can go up to this memory if it is we in the full fledged board basically this would this is a.
development kit what we will be using it which is a subset of this features.
And we have 512 KB non volatile flash memory which is 256 KB usable in default configuration.
And we have 4 user accessible LEDs and DIP switches which can be configured for depending on our application.
And we have the software board configuration through registers implemented in complex programmable logic device that is the CPLD.
And, we have the configurable boot options.
Once the system is booted it can run on its own once the power is given.
So, it can continuously take the input and then it will be providing the output.
Only for loading your program and then debugging purposes we should have the interface with one of the hardware either laptop or desktops.
And then we have the standard expansion connectors for data card usage if it has to be connected.
and we have JTAG emulation through onboard JTAG emulator with USB host interface or external emulator.
And as it was said that it works on 5 volts power supply in this development kit.
So, coming to the programming language and little on the number system detail of it will be taking it up in the theory class.
So the type was DSK6713 supports.
ANSI C basically not complete C is available.
So based on that we have the characters and signed character are going to be 8 bits and the representation is the ASCII format and minimum is minus 128 and then maximum what it can go up to is 127.
And we can define unsigned character which is going to be 8 bits.
This also in the ASCII representation we have the representation.
and the minimum from 0 to 255 what it can take the range.
Coming to the integer sign basically sorry this is short which is 16 bits.
So which is represented as 2's complement.
So which will be having the range from minus 32768 to 32767 and unsigned short is going to be 16 bits but it is going to be binary so it will vary from 0 to 655.
3 3.
Coming to integer and then signed integer it is represented as 32 bits and then the representation is going to be 2's complement.
So, the range what you can see which can take in the board is so much for 32 bit.
Coming to unsigned int it can take 32 bits binary it will be from 0 to the 2 power minus 32 minus 1 is the value what it is represented here.
And then even it supports long and signed long, here it is going to be restricted to 40 bits.
So you will be seeing that usually long and then signed long has to be 64 bit, but only 40 bits is supported in DSK6713 board.
So if you want to use 64 bits then we have to provide long long and signed long long.
So which is represented as two complement and then the range what you will be seeing.
2 power minus 40 to 2 power 40 minus 1 and in this case 2 power minus 64 to 2 power 64 minus 1 on the positive range.
And the this thing unsigned you can have long long which is going to be 64 bits which can be binary.
So, 0 to 2 power 64 minus 1 will be the value in this case.
And then enumeration what we can have so which is also this thing 2's complement.
And, since this is DSK6713 is a floating point board this is going to support float 32 bits and double is going to be 64 bits.
So, the format what it is going to take is IEEE 32 bit format and for 64 bit is IEEE 64 bit format and then the range is going to be as specified here.
And then along double also what it supports it is 64 bits and IEEE 64 bit standard what it will be using and the range what it is shown here.
And like any other processes you should have a pointers, references, pointer to data members.
So which everything is going to be 32 bits in this which is a binary format and 0 to as you will be seeing it is in hex is 0 x all f f f basically ok.
So, we will now go to some of the example will show one I will be showing sine wave generation using the sine function.
on the board and then the dot product will be working on the simulator.
Both can run on the board, but to show that those who are unable to get hold of the DSK board some of the examples whatever shown here can be run using the simulator.
So, as an example for dot product what we have is we have taken one of the x of n is 1, 2, 3, 4 values and then the other one is 0, 2, 4, 6 as we know that the dot product of these two numbers is going to be given by this formula.
So, the total what we are supposed to get is 40 and then sine wave since we have discussed in the theory class that what will be the case if there is aliasing happens if proper sampling frequency is not selected that also will be showing you that what is the result of it.
So, we will go to the board to run our examples.
So, I will try to open the code composite studio as you can see there are two versions of it in my system.
So, this is a code composer studio 5.
So, you will be seeing the icon is going to be represented this way and if it is higher versions more than 6 or something like that now 11 version is also available.
So, it will be having this, but for this interface you have to have a board connected to that.
So, to show that the simulator is going to run only the simulator is provided up to version 5.
So, we will click on the code composer studio.
So, it will show you what is the workspace you want to select.
So, wherever your workspace either in C drive or D drive or whatever multiple drives you have it, you can use that directory.
In this case what I have used is so, D colon C6713 what I have given the name and then we will try to open this workspace.
If it is not there, if you are restarting it, you can browse where you want to create this directory and then give.
So, it will take a little time to open it.
So, if any of this thing up tradition is going to happen.
So, it will be showing that what are the files available for you to upgrade.
So, better not go for the up tradition because sometimes compilers gets corrupted.
So, you cancel them and then it shows welcome to code composer studio v5.
So, if you want to create a new project.
So, we can open here.
So, I will show from the scratch although I have two of them.
So, I will show you new project we will open it.
So, it will show you what is the requirement of the thing project name what I have to give.
Since I have already have the dot product what I will give is dot product 1 I will give it so that I will be creating a new one.
So, then it what I want output type is a executable which is default and then the processor families you will have different processor families.
It depends on how you have installed your code composer studio.
Since I have board for with ARM and then 5 4x series also boards we have in the lab and 55x boards are also there I have given option of these.
So, if you do not want anything you can give only C6000 option.
In your case and then go with it.
So, in this case I will be selecting platform is C6000 because 6713 is the board what I will be using it.
And then I have to select what kind of this thing type of filter if you want to have the thing or directly you can select it as DSK6713.
Now here what I have to do is whether I want to have that simulator or the emulator.
If I am connecting the board then I have to select that spectrum digital EZDSP on board USB emulator if I am connecting the board.
So, if I am running in the simulator mode then I will be selecting simulator.
So, first we are doing the dot product as I said promise that I will be showing you in the simulator mode.
So, I will be selecting the simulator in this case and then we can do finish.
So, you will be seeing on the left hand side what we the new project has got created.
So, and then you will be seeing that.
There is a C basic minimum has been come in here.
So, that is return of your main is integer what you are calling it.
So, void and then return 0 what it is going to be the default with the braces what you will be seeing it.
So, now, there is a little this thing what it ask for is the target configuration.
So, when I go to this one and then.
click on this board.
So, here you will be seeing that there will be little emulator what it will be coming.
So, what I want is the little endian.
So, one thing what we say is a little endian means that in the memory lower bits are stored first and then higher bits are stored later on.
So, when it comes to big endian then it is going to be higher bits first and then lower bits later.
Some interfaces may need that higher endian, but most of us need we are comfortable with lower bits first and then higher bits later.
So, we will be using the little endian in this case.
and then it will be asking default they started with the 62x that is why it will be showing 62x as a thing and some gel file wherever it has downloaded it is showing me emulator here.
But I want to have a simulator connected to this.
So, what I will do is I can first thing is I can remove this CCXML file.
And, then create my own new one.
So, we will see that how to create my configuration file.
I can give delete and then delete it and then now I will go to right click on this dot product one and then I will say new what I want is the target configuration file.
So, I will say yes to this and then I will click on the new configuration file.
So, you will be seeing that it is a Texas instrument simulator what it is giving me the thing.
So, now, what I will do is I have to come back to my main dot c and then put the dot product.
So, since I have already created the dot product.
So, we are calling it as a short, x count is 4 numbers what I showed in the this thing slide and then y count is going to be this and then we will.
what we will do is to save the time we will cut and paste this in our new directory.
So, I will be replacing this also main also because everything is given there.
So, this is a default main and we are initializing result is 0 and then result is what we calling as a function dot product of x comma y comma count and then finally, we can print a result.
because this is a integer what we have taken the thing short is 16 bit as already format what I have specified it.
So, I will be printing the result value in the integer format.
So, then the function dot product as you can see the thing.
So, you will be initializing i value and sum is 0 then depending on the count in this case count is going to be.
for what it is defined.
So, it will be less than count.
So, we will be incrementing it and then you are doing the product of A of i and B of i and it will be returning sum to the main this thing function.
So, what we will do now is you are seeing so many blocks on the thing.
So, this is where your project explorer is going to lie and then this is where your C code is going to be seen.
If you are writing in C and if you want to somebody wants to do assembly we can do that also, but the extension is going to be dot asm.
Here as you are seeing it is main dot C.
So, we can interface assembly and then see programming if time permits we will be seeing one example of that also in the end.
So, now, what I have is a console and then if there is any error what it will be coming and this is a GUI basically a code composer studio.
So, you have different options in this case.
So, we will be making use of one by one.
In this case what it shows is either there are icons to do build debug and then now.
compile the thing or I can go to the project option and then I can say that build automatically what it is shown ok.
So, I can use this or this one to see whether I have any errors in my code basically.
So, what it says is it is telling me there is an error in the case ok.
So, I can click on it to show me that.
So, that is.
undefined main dot c what it is showing me here.
Here as you can see count is undefined.
So, we will define the count here.
I can call this also short is equal to 4 what I will give the thing and then let us see by.
compiling again.
So, if you have not given control s. So, when you are trying to compile it will ask you whether to save the thing.
So, as you can see the thing.
I forgot to include these two in the beginning.
So, because for printing I need to have these two function defined.
So, we will be defining the count here itself.
So, I can remove the count from here this place and then now we will try to compile the thing.
So, as you can see the error is gone now, but still I have a warning.
So, what we will be seeing sometimes these warnings becomes critical in the board.
in the simulator it does not matter, but we have to take care of this warning also.
So, what it does is it is showing is stack is not defined and then some system memory has to be defined for heap operations.
So, what we can do is click right click on the thing and then go to the properties and then we will be getting the properties for this.
So, here we have the compiler option because it is the linker option.
So, what we will be doing is basic options what we have to take it.
So, you will be seeing that stack whatever the size has to be defined here.
So, I will give it as 512 as the stack size and then you will be seeing the dynamic and memory allocation that is basically heap size.
So, you can give it as 512 in this case also and then.
do ok and then do the recompilation.
So, you can see that there are no warnings also.
Now, what I can do is I can go to build and then I can build the working set whatever doing the current working set or I can I will be giving the or build this as you can see in the thing dot product.
So, you will be seeing that this is the active directory.
So, I can give active debug also or there is an icon.
So, that is debug this one because this is the current one I can do debug.
So, I have to select the simulator.
So, one way of doing it is I can copy whatever I have set the thing into this and then paste the configuration file and then I can go for debug.
See here because it takes little time to set the simulator what you have to do the thing.
So, what I will put is how to set a breakpoint because when I run the thing I do not want it to go beyond my control.
So, what I do is if I double click on whichever line I have it.
So, it will be generating a break point here.
So, now either I can go and run in different I can load the project and then I can resume from wherever I have stopped it or I can terminate or I can reset the software reset what I can provide from the code composer studio or I can restart or I can do step function in running or step over that particular function and then go to the next one.
or if you have done assembly programming.
So, you I can go into the assembly thing also ok.
So, here what I will give is the there is an icon to show that.
So, I can click on it.
So, it will be running as you will be seeing that from the start of the thing it has run up to the wherever I have put the break point.
So, now, you will be seeing that the sum value is 40.
So, this is how the product has been calculated.
I can stop debugging this and then what I will be showing one more example on the board.
So, you will be seeing that sign generation using the what I will do is I will close all of them because it may be getting confusion for you people.
So, I will click on the main dot c here.
So, you will be I will be using the mat dot h and then we are defining the sampling frequency initially we will define it as 8000.
And, then pi value has to be defined here it is not some of them are not explicit.
So, we have to provide it to the system and then we will be defining the float as my output.
So, the length of it I have given it as 256 depending on your sampling frequency and then sample period how many sample periods you have to generate you can specify it.
And then we are starting the main.
So, the frequency of interest in this case what I have given is 1000 Hertz.
So, what is it?
So, I will be incrementing.
So, as I said I will be using the sine function down actually.
So, we are defining 2 star pi into frequency divided by in my sampling frequency what I will be giving as frequency of interest and this is the sampling frequency.
So, in this case 1000 by 8000 what it is going to be 1 by 8 will be the value of this and theta will be incrementing it is going to go in steps plus equal to.
And, then if it goes beyond 2 pi will be resetting it to 2 pi basically.
And then output of i what we are going to calculate.
So, amplitude to increase its amplitude I said and will be finding the sine theta.
So, we have different ways of sine generation.
So, we are using the built in function which is defined in mat dot h sine function basically.
And then we will be calculating this.
So, now, what I will do is since it is already pre compiled.
So, you can see that it is compiled and here you will be seeing a little change in the thing I will show you the configuration thing here.
So, you will be seeing that it will be using the emulator basically that is DSK spectrum digital DSK board what it is going to use.
So, we will do the compilation.
You will be seeing that when it is loading onto the board you saw that green one running.
So, that the complete code and then go it will be placed on the DSP processor basically and then it is ready for running.
So, you will be seeing the pointer here.
So, here also to save the thing I have given the break pointer.
So, that we can have the control of it.
So, it will not be going back.
to original place or it may go anywhere else also.
So, we have run the thing.
So, you will be seeing that whatever the values that has modified the previous value what it was and then after the initialization you will be seeing that.
Some of them are in hex actually and some of them are in the here you are seeing the integer value the same thing where the location they have been stored these.
variables have been shown.
Now, what we will do is one of the other function what we will be looking at it because if I come out of it this tools is not going to be visible.
Either I can have a memory map file or I can see whatever values stored in the thing I can save the memory or before running it I want to load into memory some values I can do that or with some pattern I want to fill the memory I can do that.
And then real time operating system what we can use the thing and system analysis toolbox is also there somewhere if I want to use the hardware trace analyzer we can see that and now I am interested because I have generated a sine wave.
So, how does it look like either a sine wave or not what I want to check the thing ok.
So, since I have this is graph what I am function what it is available in the code composer studio.
So, we will be using that and here because I have taken it as a floating point.
So, I will be defining my this thing in data type as 32 bit floating point depending on whatever you want to define it you can do that.
So, now sampling rate is I have used is 8000.
And, then the start address what I want is I want to see the output here.
If you want to see any variable you can give the name of it, it will be showing you what it looks like.
So, you see that the sine wave has been generated here.
Now, I want to know at what frequency the sine wave has got generated.
So, what I can do is again I can go to tools and then here now graph I have a FFT map.
So, I can see the magnitude here.
So, we will be taking the theory also, but sometimes to see that what frequency I can use a built in function also.
So, here I will be putting it as 256 and then this is 32 bit floating point what we have it and then the sampling frequency at present is 8000 and then start address is output what I want to see ok.
So, and then here also if you want to have a more frame size you can choose the thing FFT order chosen in this case is 5 which is 2 power 5 is 32 is the frame size.
So, if I want to increase it to 8 it will be becoming 256 you can.
check the thing and window function what it is using at present is a rectangular window.
So, if you want to modify this functions you can do that ok.
So, you will be seeing that what we generated frequency was 1000 hertz.
So, you will be seeing the peak coming at 1000 hertz.
So, if you want to see you can move this cursor here and then exactly point to the center of it and you will be giving getting the exact value of the frequency what you have generated.
So, now, I will show you what is the thing is going to happen to our reconstruction because this has reconstructed if I change the sampling frequency.
For a simple case I will take it as 800 hertz is a sampling frequency what I am choosing whereas, my highest frequency component is 1000.
So, you may be guessing what is the output I am supposed to get.
So, hold on for a while and then we will see whether our theory and then practical goes hand in hand.
So, this is again I am recompiling and then loading directly onto the processor I am going to run the thing ok.
So, now we will see that go back to the tools again I will go to the graph.
So, I will see the single time graph again both are fit what we will be getting it.
So, this is a 32 bit floating point what I have the thing and then now the sampling frequency what I have used is 800 ok and start address for me again I want to see my output.
what is the thing I will be getting it out.
So, you will be seeing the compared to the previous one how the input frequency has been created.
Now, we will see it is FFT magnitude what output it has created ok. Coming to the graph we will do FFT magnitude again here it is 256 and then this is 32 bit floating point.
then sampling rate is 800 and then this is output.
So, if I want to change the thing I can make it 6 ok.
So, you will be seeing that it becomes 64.
Now, you will see that is it matching with theory I am supposed to get reconstructed signal as 200 hertz.
So, you are getting 1000 minus 800.
So, you are seeing that it is aliased version of the 1000 hertz is going to be 200 hertz.
So, this is how you can play around with your simulator or connecting the board even this code runs in the simulator one can check it and then you can get acquainted with the simulator or the board.
So, that more and more labs are going to be run based on it.
So, if you are comfortable in running few of the experiments it becomes easy for you to.
fiddle around with so many other real time interfaces and other things which we will be taking it in the next laboratory session.
Thank you.
Namaste, welcome back to real time digital signal processing course.
Today, we will discuss about graphic equalizer.
So, we had seen the demo, but again we will be demoing after completing the theory.
So, that previous class we saw that how to do echo cancellation and even generation in the previous class what we had seen the thing, why we have to cancel the echoes.
So, if it is required as a hobby you can generate the echoes and if you are not want the echoes which are generated by different sources, so you can do the cancellation.
So today what we will see is the graphic equalizer.
So, why do we need equalizers?
So, we know that we use in home sound systems, vehicle sound systems also, in musical instruments, amplifiers and processors, even in studios and even live concerts.
including our public address systems and then you can go on listing where we will be using the equalizers.
So, it is used to boost or cut certain parts of the audio frequency spectrum.
So, we changes the way the original audio sounds.
So, equalizers can be classified into four categories, one is tone control, the other one is graphic.
So, console and then parametric.
So, it is the graphic equalizer is a tool for independently adjusting the gain of multiple frequency regions in an audio signal.
So, the common graphic equalizer design can provide up to about 30 controls for manipulating the frequency response of each audio channel and structurally a graphic equalizer is set of filters.
So, if we are designing in the digital domain.
Each with a fixed center frequency and bandwidth.
The only user control is the command gain what it is provided or the amount of boost or cut in each frequency band which is often controlled with vertical sliders.
So, it is a very popular device for sound enhancement although it is more restricted than a parametric equalizer.
Available music players such as those available in mobile phones.
because, most of us use the thing usually have several preset settings for the graphic equalizer for different music styles such as pop, rock and then jazz.
So, one can investigate what are the things you needed for your music players.
So, continuing with the thing, so this can be implemented using either a cascade of equalizing filters or a parallel bank of bandpass filters.
So, we have discussed about the filters.
One of them you can consider in the cascade form or in the parallel form.
Bands in the graphic equalizers are two common designs are octave and one third octave graphic equalizers what we have it.
So, an octave is a musical interval which is defined by doubling in frequency.
So, octave graphic equalizer will have the ratio that is we call it as R is equal to 2 between.
each band.
So, in one third octave design, so each octave contains 3 bands which implies that R3 is equal to 2, R is given as 1.26.
So, starting at 1000 hertz that is 1 kilohertz and octave spacing would have geometric mean frequencies at 2 kilohertz.
4 kilohertz 8 and so on.
And in one third octave spacing would have filters centered at 1260 hertz 1587 hertz 2000 hertz and etcetera.
To call you back we generated musical notes Saragamapada Nisa.
So, if you remember that complete thing what we call it as one octave.
So, we started with the base frequency 240 hertz there and we went up to 480 hertz and different base what you can select.
I think music lovers will be knowing C C sharp and whatever their tone is going to be you can set at it and then you can go on adjusting your frequencies.
So, the number of bands is going to be determined by the spacing and the requirement to cover the entire audible spectrum what it is going to be considered.
So, what we call it is active graphic equalizers usually have.
10 bands ranging from about 31 hertz at the lowest to 16 kilohertz at the highest.
So, the third octave design usually have 30 bands ranging from 25 hertz to 20 kilohertz.
So, you will be seeing that how the difference of frequencies or bands what you have to select in your design part of it.
So, to show that octave frequency bands.
So, you can go to net and then you can see.
So, search for the thing you will be getting it.
Here whatever preferred octave frequency bands according to the ISO standard what it has been listed.
So, you will be seeing that lower frequency f 1 hertz is 22 to 11360 that is 11.36 kilo hertz what it is going.
So, in the geometric mean frequency that is u fc which is the cutoff frequency, centre frequency what we call it.
So, which varies between 31.5 hertz to 16 kilohertz in this and the upper frequency one can have is from 44 hertz to 22.72 kilohertz.
So, this is the table shows and then that is for complete one octave and if you say for one third octave frequency bands the ISO standard is given as this.
So, what you have is F1 and then you will be seeing little variation with the thing it varies from 22.4 to 562 what you can see it and your centre frequency is somewhere from 25 hertz to 630 hertz what it goes.
So, what it says is bold font represents the centre frequencies in this case.
So, because we said it is 30 bands what it has.
So, this is represented in one column.
So, in the next column you will be seeing the upper frequencies what it has it and then from the 500 and this thing 62 it goes from to 708 and then you will be seeing up to 17.78 kilohertz.
So, you totally you have 30 bands in it and these are the center frequencies what you will be providing for them and these are the upper frequencies.
So, for these frequencies these are the center.
and these are the upper frequency and for this set you will be seeing this as the center frequency and then upper frequency.
So, this is how synthetically you can generate your equalizers.
So, how to go about designing it?
So, in this case first we will consider the cascade part of it.
So, you want you can go to the theory and then see how the design is going to be done.
In this case we will consider we are going to give this is the input audio what it is going to be.
and this is the overall G 0 gain for the audio what we can give it.
And then for each band here it is 3 band or M bands what you are going to decide it can be 1 octave or 1 third octave what you can select.
So, if it is 1 octave it is 10 equalizes what you will have it and 1 third you know that 30 what you need it equalizes basically.
And for each one the gains can be varying from G 1.
G2 to Gm basically.
So, what it says is m is varying between 1 to m is the filter index receives as input the output of the previous band filter and finally, the last band we call it as H m of z produces the equalized output signal.
So, this is what how you provide to octave basically.
So, the band filters are biquad filters.
I think it should be something is ringing in your mind.
So, when we use the biquad basically in IAR filters.
So, as you will be seeing that it is a biquad section what we have chosen this is the input and this is plus and minus this is the feed backward path and this is the feed forward path.
So, if you want to have a B0 you can give the thing most of the time it is going to be 1 that is why it has been removed.
This is a b i of m because number of stages is going b 1 comma m, m will be varying between 1 to capital M. So, so many stages what you can do concatenation basically that is cascading what you can do.
This is a b 2 coefficient comma m and this is a 2 comma m and then this is a 1 comma m ok.
So, you will be seeing this is our output after adding it.
And, then because we know that our feedback coefficients are negative that is the reason why what you have put it as negative in this and these two getting added and then after that it is going to be subtracted.
So, if you remember the equation, so what we have it is I will write here y of n is equal to b naught into x of n plus b1 into x of n.
n minus 1 plus p 2 into x of n minus 2 and minus y 1 of n minus 1 minus y 2 of n minus 2.
Sorry, this is a 1 and this is a 2, a 2 into y of n minus 1 y of n minus 2.
So, this is the equation what we have it for the bike path section.
So, a 1 and a 2 are the bike the coefficients for the poles basically and then b 0 b 1 b 2 are the 0s.
So, this is what are biquad equations.
So, which is written in this way and then z minus 1 will be in the z domain the delay which is provided for x and then our y what we see it right.
So, what we can do is one filter is used for per band what it says.
So, that m is equal to 10 such.
Filters are needed for a standard 10 octave graphic equalizer.
So, each modified what filter which is named with ARFINIDIS band filter has its own linear gain gm what we call it and center frequency fc comma m for each this thing what it is defined.
So, now, coming to the thing first it is necessary to select the center frequencies fc comma m.
which are here set to the recommended octave center frequencies.
What it is given with previous slide what you have seen the thing that is these are the center frequencies mean frequencies what we have it for the 10 band same thing what it is going to be considered here in the case.
So, next one is 62.5 and then 125 hertz and then so on up to 16 kilohertz.
So, 10 band center frequencies what it has been.
So, now, we will see what are the magnitude response of an octave graphic equalizer.
So, you will be seeing that the thick line what it shows is the cascade structure.
So, you are seeing the this is the input and this is the output and this colored curves what it shows is 2 shelving and 8 band filters what it has been considered here.
So, you will be seeing that this is a low-pass filter after that what you have is a band pass filters.
So, each one represents the center frequency of each one of them.
So, we have it 1, 2, 3, 4, 5, 6, 7, 8, 9 and then 10.
So, you have what is it shows is 8 band filter with what we say Q is 1.41 of the cascade structure.
So, what it says is red circles command gains all at.
10 dB as we can see that all of them are at 10 dB and this is the frequency in hertz what we are going.
So, that is whatever in the previous one we had said that 31.5, 62.50.
So, you will be seeing they are the central frequencies what it has been chosen along the x axis and y axis will give us the magnitude of it.
So, the cascaded what it shows.
in the thick line here.
Now, how we can design the same thing in parallel that is what this figure shows.
So, we will be having the overall gain g naught here and then each one will have its own impulse response h 1 of z and they will be this thing multiplied with their gains in parallel and then you will be seeing that each one is getting added and then.
what will be getting get out.
So, what it says is here all bandpass filters receive the same input signal and the output is obtained as a sum of individual filter outputs that they are weighted by the command gains.
So, one has to think now whether we want to have the cascade graphic equalizer as it is shown here or the parallel.
think of it because we have seen even in IR filter design we said for our hardware because we are using DSP processor or if you want to implement in FPGA.
So, we said that multiplication overflow is taken care of whereas, the addition we are going to have a overflow in it.
So, we have to check every time if there is output is overflowing then we have to check.
scale them and then we will be taking care of all the overflows.
So, it is better to go with cascade section in hardware than the parallel structure although we have both the things.
So, if you are able to take care of whatever the overflow which is going to come from the addition in the input itself, then we can use the parallel section because we know that this is much faster compared to our cascade section.
So, what I will put it as this is parallelism what I can use it here, there I had to use the pipelining in between I had to put a what I will say is a buffer basically or a delay unit.
So, that each one will be pipeline structure what I can use.
So, you will be recollecting your pipelining and parallelism what we used in the theory here and then can go for.
implementation of it.
So, the next is we will take up as an example one can design a 3-pand equalizer.
So, it depends on some of that books gives that we can go with the 3-pand is enough that is what you will be having tone control was designed with frequencies of that is 200 hertz that is low shelf what you will be considering it and 1 kilohertz mid peak.
And, then here Q is taken as equal to 1 and 5 kilohertz what it says is this is the high shelf.
So, with this also you can design your graphic equalizer.
So, you will be seeing that what is it.
So, the dB what it is shown from here that is minus 12 to 12 dB what we you will be selecting it on different spaces.
And then this is your FC is your cutoff frequency.
And, then you are you call it as low filter shelving what you will have it and here cut off frequency fc gain g in dB what you will be providing it to the system.
And then the next one this is a low pass filter as we know and here it is a band pass filter that is middle frequency what we can call it as peak that is cut off frequency fc bandwidth fd gain g in dB what you will be taking it.
So, this is our.
cutoff frequency and this is the frequency range FD that is pass band region what you will be selecting it.
And the next one so on what you can design and next is the you are this thing multiple middle frequencies what you can see and then their peak and here your cutoff frequencies what you will be specifying with their gain as well as your band pass of this structure what it is shown here FD.
And, in the last what you will have is does a high pass filter.
So, which is H f which is given with cutoff frequency as usual f c and it is high filter shelving the last stage and cutoff frequency is f c and its gain is g in dB what it is given.
So, whatever dB you want to select you can select them and Y n is your output.
So, how we can decide design the thing all of us know that.
Audio file is given in the time domain.
So, x of t is our input which is coming from the it can be from the mic or audio system.
So, then we have to convert it into digital domain that is we will be using ADC depending on number of bits what we wanted we can select our ADC.
And after converting it into digital domain we will be getting x of n as our input.
which will be passing it through the equalizer and y of n is our output then what is it.
So, if I want to convert this back to that is our time domain then I have to use the DAC then y of t will be the output.
But I do not want to use this ADC and DAC, but I want to see that whatever I have stored it whether I can provide the equalizing filters designed for this equalizer filter 1, 2 and then M if it is whatever band you will be selecting it.
So, that is what the cascade section what you are seeing it which goes into your equalizer.
So, now, you will be seeing that in the market a 3 band equalizer is shown this way.
So, what is it you have a low frequency knob which you can adjust it.
it.
And then this is the mid frequency what you have it or middle one.
So, different one what you can select here one of it low or high whatever FD bandwidth what you want to have it.
And this is the high frequency what you will be selecting it.
So, you were seeing this is our low pass filter and this is what it is shown is the inverse of it.
So, that is band stop what you are seeing it and whatever frequencies you want to pass it.
So, you can put it as a band pass filter.
and then the other one is the high frequency filter what you are having it.
And some of the frequencies how you can adjust it what it is shown in this blue color.
So, this is the commercial which I have taken it from the net and then I am showing you how it can be designed.
So, this is completes our adaptive filter and that applications filter applications what we have considered.
for band pass filter, low pass filter and high pass filter how it can be used in scrambling, echo generation and cancelling and then in the equalizers.
So, in the next class we will be discussing about the speech coding techniques that is available in the literature and we will be considering one of the example how we can design both in MATLAB and then in code composer studio.
So, thank you.
So, happy learning for this material and then we will meet in the next class.
Thank you.
Welcome back to real time digital signal processing lab basically.
So we were discussing about the adaptive filters in the last class.
So, today we will see how we can use MATLAB first to generate different kinds of adaptive filters for different applications.
So, this is what we discussed two of the adaptive filters in the last class and today we will see first how we can use the adaptive system identification.
So, here it is a fourth order system was created using the unknown system.
in the MATLAB program and using the adaptive system identification program a seventh order system was initialized to 0 initially and the algorithm was performed.
So, in under 200 iterations the coefficients were determined with an overall error of 4.7269 to the power of 10 power minus 8 what it shows and the estimated coefficients values what we will be seeing it here.
So, we will go back to the MATLAB and then see whether we are going to get this results.
We will see the system identification.
So, this is one of the available codes to show the application.
So, you can use the book codes to do the thing.
This is written by Thomas Drumright.
It is you can see it is in 97 what it is written and still it can be used.
So, what the program does is it initializes input vector to 0 and then you have the mu is set to 0.1 that is convergence factor and then the length that is taken as 8 that is filter length and then the data value that is iteration number of iterations what it is selected is 200 and then input is a random number that is input white noise what it has been selected.
And, then mean square error is set to 0 and these are the initial input and initial coefficient filter coefficients basically the length of it what you will be take making it 0 w. And, you will be start calculating the that is unknown system which is given as unsystemed dot m in this case.
So, here you will be seeing this is the system coefficients what it is defined.
And, what the your system this thing identification has to converge to this.
So, W will be starting weight vector will be 0 and output will also be 0.
So, then you will be going on and then this is the desired signal what you have it and then error function you are trying to minimize that is the D minus Y, Y what you are considering with the X values.
and w is going to be updated as usual.
And then we will see that how it is going to converge to the required system and what is the value we will be getting it.
So, as you can see there will be little cut off if I increase the size of the font you will be losing some of the things on the top actually.
So, you will be seeing mean square error in between what it is high and then it is settling down to almost 200 it is almost it has become we can say it as nearer to 0.
So, that is what it shows for 200 iterations what it will be settling down and you will be seeing the values.
So, we said that you will be seeing that that this is the magnitude and this is the frequency response of the filter and you are seeing that whatever in the past band you are seeing this has a linear phase basically this is frequency versus phase what it has been plotted.
So, what we can do is we can close these two.
So, that we can go back and then see what was the initial value it was given and then how the estimated coefficients what we w that is system identification what you have done the thing.
So, it is given 1 minus 1.416, 5 minus 1.416 and then 1.
So, you will be seeing that this is what it has converged to.
So, you are able to identify what system you have given as input it is a band pass filter in this case.
So, the coefficient has merged with this.
Then going on to the next this thing this is the first application what we have seen it.
So, the next one what we will see is in the MATLAB how we can do the adaptive noise cancellation.
So, adaptive noise cancellation system was given an input of a noisy frequency varying that is sine wave after 1000 iteration you will be of the filter the noise is considerably reduced.
that is what it is written.
So, we will go back and then see noise cancellation in this case.
So, we will open this.
So, this is adaptive noise cancellation.
So, you will be seeing that mu is given as 0.01.
So, you can definitely expect that number of iterations is going to be more.
Here it is running up to 1000 iterations.
And then you have been given the input white noise is with 0.7 magnitude what it has been.
chosen and you will be generating the sine wave along with random noise and then we will see how the noise is going to get cancelled ok.
This is built in function sine wave generation and then you have your error function also which is going to be reduced.
So, the rest of the thing remains the same thing.
So, you will be displaying what is the error even the weight function you start from 0 and then you will be.
trying to adjust your weights based on your application.
So, we will run the thing.
So, you will be seeing that so many waveforms have got generated.
So, the figure 1 shows the in the time domain this is time and this is the noisy signal what we have it.
And we will see the next figure, this is figure 2, this is a time domain how does it look like a filter signal in the time domain.
So, the next one is what we have is figure 4 shows that this is the sine wave which was generated along with the noise basically.
So, this is in the frequency domain as you can see.
but naming has not been done here and this is the magnitude of it what you will be seeing on the y axis and x axis is in the frequency domain response.
And then the fifth one how the noise is introduced with the that is this is the noise signal in the frequency domain along with that is sine wave you have the noise present also.
So, now we will see.
Now, figure 6, you will be seeing that this is a frequency.
So, you are seeing that this shows I think this filter signal and this has got little bit exchange as you can see that here the noise is less after filtering.
So, the naming is little bit interchange that this is the noisy signal and then the filter signal is little less.
Sorry about it I done the mistake in y axis.
So, the next one is you will be seeing the error that is time versus mean square error.
So, you are seeing initially which was high and then which it has got considerably reduced.
So, this is how you would be doing the noise cancellation.
So, using adaptive filter.
So, the next one what we will see is.
After the noise cancellation, how your linear predictive coding is going to work ok. That is error signal from the linear predictive system basically what we have it.
That is system has a much smaller dynamic range in the frequency domain than does the original signal.
So, how this can be implemented what we look in using the.
MATLAB.
So, we will run the this thing.
What it has is you will be seeing that for the prediction the you will be seeing that convergence rate is very small and the filter length chosen is 100 in this case and the number of iterations as you can see it has gone up to 5000.
So, you will be seeing that the variation in iterations.
what it has been chosen from one application to the other application, it is increasing because it takes more time to predict the thing that is what it says.
This is a linear predictive coding what it is going to be.
It recursively calculated the coefficients of an unknown system.
The value mu's this thing specified the rate of convergence of the adaptive algorithm must be less than the smallest eigenvalues of the unknown transfer function for this adaptive filter to be.
properly conditioned.
So, for that you have to choose the lesser one and length is the order of the filter and then L i n is number of iterations to take place.
X is our input signal to the system, n 0, n 1 are the two independent noise sources in this case.
So, this is a sign which has this thing you are seeing that there are three sine waves what you are seeing in here.
with different frequencies what you have.
This is your signal S 1 what it has been given and then your N naught is the random noise white noise which is getting added with the signal.
Apply the adaptive algorithm what you will be doing it and x and w are initial input as well as the filter coefficients and you will be running the code for your this what is it multiple times.
So, you will be monitoring the mean square error what you will be setting it the J plus 1 will be set to the previous error.
And then your weight function is given with W z plus whatever the previous value with respect to updated.
This is how your W vector is getting updated and you will be seeing that these are the displays what you will be.
So, we will run and then see the algorithm how it is going to behave.
So, we will be seeing that what all the figures this is our input wave here also.
So, you will be seeing that S of t represents are in the time domain input wave that is time response of a noisy signal what we are considering it and then figure.
2 will be giving a filtered signal basically, how it is represented that is y of t in terms of time domain think.
And then figure 3 will represent time response of the error signal that is e of t what you are looking at random white noise how it is going to be.
And then next one is figure shows that how the error signal is reduced ok.
Somewhat at 100 it is coming down and then next one will be frequency response of an IC signal in the frequency domain what you are seeing it S of W what you are putting it with respect to weight vector what you are seeing the thing.
And then 6 will be whatever sign wave and then this is according to this we have done it.
So, you will be seeing that approximately we are able to achieve the this thing error signal how it is coming down and then your sine waves are what it is seen at the output it has adapted.
And this will be showing error along with the in the frequency domain how the error is much more compared to the previous one which has got.
out filtered out ok.
So, this is what after filtering and this is the before filtering how the noise was present in the input signal.
So, it is coding how LPC coding has been done to receive the our input basically correctly that is although there is a noise channel noise has been added as a white noise and the received signal is.
exactly what we have received.
And coming to the next application, so what we will be seeing with the MATLAB is adaptive inverse system.
So, that is demo will be showing the response of an unknown system and how the equalization can be done with the inverse system.
So, this is what the demo will look at it using.
So, we have the inverse system here.
So, we will run the thing that is calculated the coefficients of an unknown system, you specify the rate of convergence all the same thing.
So, what we have is here there is a unknown system to what it has been chosen for this application.
So, which has you will be seeing that this is the weight system coefficients what it is modified compared to the.
other unknown system dot m. So, this is the unknown system and then the output will be identifying the system basically it will be the inverse system how you can do the equalization to get the original system.
So, we will run the code sorry because that is a function which is called from here.
So, that is the reason why what you are getting the error it is telling that it does not have input arguments because I had to call this function from other source.
So, I would not be able to run it directly.
So, you will be seeing that will run from the inverse system.
So, here what it shows is we will get the detail of it and then come back to show the output here mu is chosen 0.005 and length of the filter chosen as 20 and the iteration is 5000 in this case.
So, you will be seeing that initial input vector what you have it and this is a Gaussian white noise what it has been added to our noisy signal and then you will be calculating your sine wave what you have it and the.
So, you will be adapting to your unknown system basically inverse of the system what I have to get it and then your weight vector as usual will be updated in this manner and then you will be performing your what is it frequency that is filtering what you will do it and this is the filter what it is being used you will be calling it is the response of the filter and then f is the frequency what it is being calculated you will be using the free Quincy Z with your weight vector W basically what it has and then 1 and then 512 what will be getting it and then you can do subplot and then it will be hold on and then rest of the thing what it will be giving you.
So, this is the filter one has to identify the thing.
So, you will be seeing the values what error you will be seeing that which is equal to 0.2848 what it has come down to.
And, you will be seeing that what is your answer for the thing what it has identified the unknown system that is inverse system.
So, this is the just hold on for a while I think or I will show from here you will be seeing that this is your inverse filter what it is working.
And, this is the response you will be seeing that of the original this thing.
filter what we have it and how you can that is equalize from the inverse system to the output level what you will be seeing and this is the noise which is getting added to your system this is in the frequency domain and this is also in the frequency domain how your error signal is going to that is noise is going to look at it.
So, from the noisy signal you can see that after your system.
has the what is it input basically what you have given the thing, the response of the system what you are looking at it.
So, you have identified from the noise also and then you are able to this was the original and you are able to correct it to the original and you are seeing your phase how does it look like.
Here in the original this is the phase of the system and in the recovered signal this is the phase of the.
signal.
So, this is how you will be applying your different applications that is adaptive filter in different fields of it.
So, that is the application of our adaptive filter.
So, now what we will look at it is we will go to equalizer what we discussed in the theory.
So, we one of the equalizer developed by our own student what we have seen in the last class.
We will see that how the MATLAB is has designed an equalizer.
So, we will see this is a my equalizer dot m anybody can download from the MATLAB website.
And then what all it is a new my equalizer or raises the existing single ton what it says.
And, H is the equalizer returns the handle to a new equalizer or the handle to the existing single turn and it will be calling this functions basically and this is a GUI ok.
So, it has other thing what you can see guide or whatever one of the thing what you can use it.
So, this was modified in 2008 which was available.
Some of when you download.
these things one has to be careful.
So, wherever wave read has been used in the latest MATLAB version it has been modified as audio read.
So, if you if it gives an error one has to modify it to audio read and then my play has to be changed based on the whatever 2020 B supports ok.
So, you will be using it to audio play instead of my play.
So, these are the modifications one has to do it.
So, we will run this file.
So, you are seeing that in this case by looking at it you must be able to identify how many control that is gain systems have been given.
It is a 5 band equalizer basically what you can see it.
and you are seeing that what they call it as C1, C2, C3, C4 and C5 are the 5 bands and what are the frequencies.
This is a low frequency and then this is band 4 to 8 kilohertz and this is 9 to 13 kilohertz what you can see and this is 13 to 17 kilohertz and this is the high frequency.
As you can see that the frequency is gone up to 44.1 kilohertz what it has been chosen for the audio and you have the 5 bands what it has been chosen.
So, we will see that we have all of them have been placed here knobs in the centre of it and this is the response what it is showing.
I think I may have to reduce the thing and then come back because all the control is at the bottom which I am unable to see the thing.
how we can do that.
So, by changing the resolution you will get back your what I will put it is the complete GUI will be shown otherwise some of it as you were seeing it the bottom portion was getting blocked.
So, now, we will see that load the whatever wave file which has come with the default what I will be taking it they call it as back 2 and then if you want to plot you can plot this is how the.
after equalization what you will be seeing it and we will vary and then see how it is going to look like ok.
So, we will play the thing now with the all of them are in equal positions ok. Only this is the length of it.
Now, what we will do is we will bring down the thing and then we will see plotting of it.
So, what you are seeing is almost low pass is what is it?
It is cut off ok.
The low frequency has come down to minus 16 dB.
So, this is the dB setting and these are all 0 dB.
So, if you want you can play and then here to this ok.
So, now, what we will do is whether we can go up to positive from 0 dB.
So, this is the 0 dB.
will increase the dB to 16 dB.
Now, we will try to plot it.
So, you are seeing that this is a low pass filter and rest of them this is at how much 16 dB as you can see the thing magnitude response.
So, it is low pass filter what it is happening rest of them are not that so we will try to play.
So, you can see how it became because more of low pass filter frequency is what it contains.
So, now, we will see the thing by increasing this to positive side.
So, we will plot the thing.
So, you are seeing that it is going in steps.
So, this I have given 10 dB, C to these frequencies whatever you are seeing it up to 20 kilohertz as I said 20.05 will give you 44.1 kilohertz is the sampling frequency.
pi by 2 whatever Fs by 2 what it is getting plotted.
So, you are seeing this is 16 dB and this is 10 dB.
So, hopefully it will not be so loud let us see.
We will go increasing this also.
So, we will put it as 6 dB.
then you can plot so you will be seeing almost in steps what we are incrementing it here and you can play the thing okay so you can see this plot again we have increased the other one and we'll do the other one little more than this one And, see how the plot looks like this is what I said you can keep playing with the thing this is gone up to 2 dB now here.
So, it is not any more 0 dB for the high frequency and then we will play the thing.
So, you can have your own music and then.
keep seeing it how it can vary what are the components present in it which one you want to highlight and which one you want to suppress as you would be seeing nowadays that most of you in mobile.
So, you will be having your own what is it audio basically for the whatever music you would be playing it only orchestra will be there voice will be yours.
So, voice of the original person is going to be separate and then you can have.
your voice inbuilt in that orchestra most of them you will be seeing single solo they will be playing without instrument these people will be using the orchestra part of it and then voice will be this.
So, this is how you can play with your music that is what I wanted to show.
So, in the next class what we will do is continuing with our application of adaptive filter.
So, we will be seeing.
in code composer studio same adaptive filter with different application what we have seen in the matlab we will be seeing in our board also.
Thank you.
Welcome back to real time digital signal processing course.
So hope you have enjoyed the course.
Today we will look at the summary of the course.
We started the course with introduction.
So, we know in real world all the input is in analog domain.
So, that is what we have seen here is time domain signal what we are taking it and then we are going to do the sampling using our ADC basically.
So, ADC can be either 8 bit or 12 bit or depending on the latest one sigma delta ADCs we can go up to 16 bit.
ADC conversion.
Then we will be converting it into digital signal X of n. So, then we are going to do the quantization because we know number of bits what we want to represent it.
So, in our case we have taken it as 16 bit basically in all our processor applications.
So, we can convert it into 16 bit and then do the quantization with respect to that and then we have to do encoding of this quantized signal into.
the number representation.
So, that is how we will get the digital output, but this constraint what we said was in the real time signal processing.
So, if I take my clock as this way.
So, we know that this is my time period what we are discussing about it or t is equal to 1 by fs is my sampling frequency.
So, for different sampling frequency.
frequencies, what should be a real time constraint one has to look at it.
So, the bottom table what it gives is different applications what we have in the real world basically.
One is the speech coding or decoding, one can use the ITU standard basically G dot 729 or 723 and the which requires a sampling frequency of 8 kilohertz.
So, we must be able to complete both decoding or sampling.
encoding within this time period.
So, and the time second in that is what we give it as capital T is equal to 125 microsecond.
And in the case of wide band telecommunication speech coding which uses G 72 or 72.2.
So, we know that the sampling frequency is 16 kilohertz.
So, our fs has to be 16 kilohertz and we must be able to finish our computation time in 62.5 microsecond time period.
And when you go for the high fidelity audio compression like MPEG.
2 or your AAC standard or MP3 standards or DOLB.
So, you know that they have operated 48 kilohertz.
So, within 20.833 microsecond I must be able to finish my sampling quantization encoding and even the computation of my signals and even outputting which has to be carried out.
So, that is what our real time constraint what we have put it.
The other way of looking at is it depends on application what we are choosing.
So, here only 3 what it is listed.
So, we have umpteen number of applications.
So, we have to define our system requirements in this case and develop the algorithms and perform simulation.
And then if we are using the DSP processor which DSP chip we have to select it we have to select it.
or the devices.
So, if you are having your own design either you can do your design in VLSI or in FPGA.
So, most of the application we want to try it on a field programmable gate arrays and if we have a requirement of many numbers basically then we can go in for the VLSI design.
So, the other two legs what we will be taking is software development is going to happen and then hardware development.
So, nowadays it is going to be.
what we call it as hardware and software co-design together they have to go hand in hand so that both the things match simultaneously otherwise all of us know that hardware multiple units come out and then we may not be accessing most of it because software is the must most costlier to develop basically so then usually we combine these to do the system integration and then check if it is going to satisfy our requirement or we may have to go back and select different algorithms for this application.
Then once everything is finalized then we will be doing the testing and debugging.
So, once the product is ready you can give it in the market.
So, different architectures what we went through in this course.
So, the first one was all of us know Von Neumann architecture.
So, we have the processor and then memory is single memory.
So, both address and data resides in the same memory and then we will be using the address and database to access this.
So, for our DSP applications.
Most of the applications we said that it is of this nature that is y of n is equal to sigma.
So, x of n minus k into h of k. So, this is our most of the applications what we said we need multiplication and then addition simultaneously and then we have to access 2 inputs at a time and then we may have to write 1 output.
So, for that reason so, Von Neumann architecture is not.
So, we said Harvard architecture was developed for this purpose.
So, what is this?
It has separate program memory and then data memory and even address and then data bus for them is separate.
So, in spite of developing the thing.
So, will be instruction fetch we can get it from the program memory, but data still we have one data memory.
So, if we keep on adding the hardware architecture is going to increase.
So, what it was decided because most of the.
If we are talking about the filter then we know that filter is designed much earlier in real time we will be using only those filter coefficients to pass it through our input.
So, this one can be stored in our program memory and both the and then input data is going to come into the data memory and then we can access them simultaneously.
And, then we can one more multiplication what we said was will go with the Braun multiplier.
So, which is a much faster.
So, we said that these are the two inputs for 4 bit what we drew our Braun multiplier.
So, in this case we are going to have an AND gate before the data comes into our Braun multiplier.
So, as you will be seeing that the longest part delay in this is going to be as you have seeing that from this path to the final output.
So, to reduce this also we can have pipelining in between stages ok.
So, that we looked into pipeline architecture later on.
So, and we know that we need shifting operations because we said that the input is going to be represented that is.
So, my x of n is the input which is going to be in between 1 and minus 1 and then 1 this is the range what I will be considering it.
So, what we have to do is it has to be shifted on the go.
So, most of the shifting operation we can use the barrel shifter either we can do a left shifter right shift even the output is exceeding certain limit then we have to do shifting of the thing before we feeding it to the next stages.
So, we can use the hardware barrel shifter.
So, which is going to do the shifting operation in 1 clock cycle.
So, if I want to shift 5 bits basically in normal cases in the sequential it will take 4 5 clock cycles whereas, using the barrel shifter I can finish it in 1 clock cycle.
So, that is what we saw the thing.
Next, is coming to the memory architecture.
So, how we are going to have the memory because we as far as possible we want to have a latency of accessing our data writing into the memory or reading from the memory or storing has to be minimized.
But the architecture defines that we cannot have whatever our wish.
So, based on the things so what we have is we will be having along with the CPU some of the registers.
will be having it.
So, they are the fastest one as you can look at it that is what we discussed it and we will have some this thing L1 and L2 memory which are little away from the CPU, but they are much closer.
So, their access is minimized and then we have larger memories down the lane.
So, this triangle gives you how will the access time is going to be.
So, the least one you will be seeing that our keyboard mouse and other things here even some of the tape readers what we had it earlier and then we will be seeing that ROM and then our removal devices and other things will be.
much slower compared to this.
This is how the memory hierarchy we went through in the class.
So, then we said that for increasing the speed of our computation we can go with pipelining and parallel architecture.
So, our intention was to get one within one clock cycle we have to get the whatever the input clock or output should be available in the same clock cycle.
So, every clock cycle I want to have the output whatever my computation is going to be.
So, one of the way of looking at is we can have a instruction pipeline.
So, most of the DSP processors have.
5 stages of pipeline.
So, that when the first stage is instruction 1 what it is happening.
So, later on when instruction 1 moves to step 2 basically.
So, the next instruction can be fetched.
So, when instruction 1 is getting decoded in step 2.
So, in the next stage you are going to access your data basically.
That is instruction 1 moves to get the data in the third clock cycle and then you will be passing the decoding of instruction 2 is happening and then you are trying to fetch instruction 3.
And then in step 4 and 5, I can have the execution.
So, most of the time it is step 5 is our execution.
Execution can be from one clock cycle to multiple clock cycles it may take depending on the hardware what we are going to use it.
So, most of the DSP processor we know that.
that our add is going to be in one clock cycle what I can fetch the I can complete my execution whereas, my multiply mpy operation is going to take two clock cycles.
Whereas, my this thing what is it we have a load and then store architecture what we said it is going to take four clock cycles.
And, branches in all this discrete processor 6 7 what I have considered that is DSK 6 7 1 3 and then 6 7 4 8 LCDK board from the TI they take branching of 5 clock cycles.
So, these are the computation that is execution times what we need it in this.
So, these are basically a load and store architecture what we call it.
So, we know how much clock cycle each instruction is going to take.
Some of the instruction I will come in a while, we may not know how much clock cycles.
Then we call them as this thing complex instruction cycle.
You would have heard of risk and risk.
So, DSP processor most of the time 80 percent it is going to use is a RISC architecture and 20 percent for our circular buffering and then what we call it as FFT operation we have to bit reversal has to happen they use CISC architecture for that.
And this is pipelining what we call it and then in the parallel operation.
So, we said that our DSP processor has a.
2 functional units in them.
So, parallely I can do my operations that is this has 4 functional blocks within each side there are 2 sides and then 4 functional blocks in each side.
So, if I operate them in parallel.
So, 8 functions what I can operate in parallel and each is 32 bit.
So, we have a data width of 256 bits for this get the complete instruction in 1 clock cycle.
So, we said that when we do 2 this thing sides of it we can do them in parallel.
So, how the delay is going to be here if it was taking for 8 clock cycles here you will be seeing that within 40 what I can finish one side of it the other side and then finally, the output from both the sides I have to add them up and give my.
y of n output.
Although we say that 2 units are there I should be completing within half the clock cycle of the original one, but you will be seeing that there will be some delay.
So, we will not be getting exactly that the computation done in half the clock cycle.
So, the next one was our number system what we discussed that is we said that we can represent floating point and then.
fixed point number system.
So, all of you know about the floating point.
So, just I will put one of the slide with respect to that.
So, what was the fixed point signed integer representation we said the number can be represented between minus 2 to the power of n minus 1 to 2 to the power of n minus 1 and how it is going to represent it.
So, we are will be considering that is minus s dot 2 to the power of n minus 1 and we are not giving any bit for our binary point representation.
So, we will be considering b n minus 1 2 to the power of n minus 2 to the power b 0 to 2 power 0.
The most negative value what I can represent with this number system is minus 2 to the power of n minus 1.
So, in because we have considered.
n is equal to 16 bit in our processor.
So, it the most negative value what I can represent with representation is 0x800 in hex basically or we call it as minus 32768 is the value in decimal what I can represent.
And the most positive value in this format is 2 to the power of n minus 1 minus 1 what I can have although we put minus 1 to 1.
So, I would not be able to represent.
plus 1 in this format.
So, the maximum what I can represent is 0 x 7 f f in hex.
So, which comes out to be plus 3 2 7 6 7 is the maximum value what I can represent with this number system.
So, you are seeing that different format what we considered in our representation that is Q 15 format means that it is 0.15.
and the largest value as you can see the thing and the least negative value is minus 1 and the precision what I am going to get it with respect to this number system is the as it is given.
So, like that we can go last one is the integer representation that is a Q15.0 format or Q0 format what we call it.
So, in that case the number in decimal what I will be representing.
is 3 to 7 6 7 to minus 3 to 7 6 8.
So, the precision is going to be 1 between the 2 bits that is LSB bit and the next bit that what I will have precision is 1.
So, as we know that we need high precision for most of our speech or audio processing.
So, Q 15 format what will be using it in our application and we know that the multiplication is going to have what is it 30 bits it represents because both are in Q15 format both inputs that is 16 bit memory what I have taken the thing.
So, when I multiply it so, we will be getting 2 sign bits basically from both the thing depending on if both are positive these two will be positive.
So, if one is negative one is positive.
So, it is going to be both are going to be negative and then both are negative then we will be having positive.
in the sign bit representation.
So, we call this is a extension of the sign bit and we will be discarding this and then we will be taking the 15 bits that is MSB bits from our output and we will be storing it in the memory.
This we call it as truncation when I am doing it.
So, if I know that my most of the values are in this higher 16 bits.
And, then exponents are represented with the 8 bits we said it is a biased what I will be representing them with.
And, then the fractional is 23 bits and then we know that there is a binary point here for our fractional representation which does not require any bits for it.
And, what is the representation it is minus 1 to the power of s into 2 to the power of s.
E minus my exponent minus bias into 1 plus because we assume that there is a 1 value before our point and then I will be representing this 23 bits for the fractional representation.
So, we call this is a bias.
So, that is what happens to my negative numbers.
I can have exponent both positive and then E can be both positive and then negative.
So, how I will be representing it?
So, that is how we have the bias what we have given the thing.
So, what we have is this is minus 127 to plus 128 is the number what I can represent with 8 bits in sign format.
So, what we do is instead of this representation.
So, we shift this one to 0 here which is equivalent to minus 127 and this one will be shifting up to 256.
So, that is how we will be having exponent minus bias whatever x is 7 bit what I have given the thing.
So, which will be computing it and we went on to discuss about some of the problems both in fixed point multiplication addition and then the floating point addition and multiplication how we have considered it.
So, most of the architecture as we know that multiplication is going to be multiply the fractional bits in floating point and add the exponent basically.
to get the result.
So, but whereas, the addition if you are doing the addition of 2 numbers then you have to bring them into the same exponent and then add them up.
So, what we say is in 6713 is a floating point processor.
So, which takes approximately if it has to do maximum adjustment it will take 10 clock cycle to do addition.
As you can see in the fixed point processors, it takes only one or two clock cycles, so one clock cycle to do the addition and two clock cycle to do the multiplication.
So, whereas, 6713 is a floating point processor, 6748 is a dual processor that is I can do either fixed point operations or floating point operations.
Both can be incorporated in the thing if we are writing our code in.
assembly.
So, coming to the thing we said that why we need pipelining and parallelism although I have we considered it for a low power applications basically.
So, we know that a typical computation time what we said was this is my T p is my computation time and then T naught is for whatever I O operations what I have it together it should be less than or equal to T.
So, most of the applications we say TP has to be approximately what we call it as 40 percent only the time what I will be getting it.
So, the rest of the things goes in getting the data in and then adjusting it and then sending the data out.
So, some cases if you are completely knowing about this operation we can make it as 50 percent and 50 percent time what is allocated for your.
computation as well as your I O operations.
So, then we said this is the parallelism if there are no dependencies then I can use the parallelism.
And then if this thing we took an example of water pipe how the water is going to flow.
So, we will be seeing that the pipelining architecture is going to go in this way.
So, what are the pipelining hazards So, if the complete pipe is full ok what we call it if it is full and at the starting itself I get a branch basically.
So, if the code is not properly written if I have a branch lot of branching in between.
So, then what happens whatever which has come into the pipe which has to be flushed and then you at the branching place again you have to.
put your pipe and then you have to go with the instructions which are following it.
And if you it so happens that if again if it happens after one this thing you are going to branch it then you will be seeing that whatever you have designed for getting the speed you may not achieve it may work at a lesser speed than in the sequential code basically.
So, one has to take it such that.
the branches are avoided as far as possible or usually what we do in the assembly program is we do the delayed of it.
That is we will have the branch here, but we will be putting some of the instructions which can be operated because as I was mentioning it may take branching takes 5 clock cycles.
Before that if there are no dependencies if I can operate the those clock cycles.
So, I will be saving those.
5 clock cycles by the time the branch is going to happen.
So, that my flushing of the pipe is going to be reduced.
So, and then how we are going to write our code in basically.
So, most of the thing we said we will have it C programming, most of our applications what we discussed was both in MATLAB and then in the DSP processor only we concentrated on the C programming we did not have time to do assembly programming those who are interested you can go through the text books and then see.
and then work on the assembly programming.
So, we have the compiler there and we have the compiler options also for branching and other things how we can minimize optimization one can do it up to 3 optimizations you can have it.
So, they give it as O 1, O 2 and then O 3 basically.
So, for different loop optimization we can incorporate and then use it.
So, we generate the machine code here in our case we said it is a co file what we are going to generate it for our boards.
And then we will be linking with the libraries and then loading on to the board and then we will be doing the execution and data input data is going to be given from codec if it is we are considering the real time.
If it is non real time it can be stored in memory and then it can be used.
And then if we are working on the real time thing output goes out of the board or you can store it in the memory for further usage.
So, then we said that how we can use this pipelining and then parallelism for the low power.
So, for that we discussed about little on the cut set.
How we are going to have the pipelining architecture developed from the existing one.
So, we said that the longest path delay.
is the time taken to compute our output.
So, in this case it is going to take 4 unit of time.
So, what we are going to do is I am going to put a cut set.
So, we said that it is only in the feed forward path what we had the cut sets and then as it shows there is an error.
So, we have to put a delay line or a buffer what we are going to put it since you are cutting this line also.
So, you have to put a delay.
So, all the lines wherever you have cut the thing you will be having the delay.
So, that is how in the FIR filter this is what the example what we took it.
So, which was taking one multiplication and then two clock cycles for our addition.
So, how we can reduce one clock cycle for multiplication and one clock cycle for addition by putting the feed forward cut set here.
and introducing the delay.
So, what is the disadvantage of it is we will be adding the hardware to this structure and the first output is going to be delayed by 1 clock cycle in this case and later on we will be getting every 1 by I will put it as t multiply plus t naught I will be getting my output from this structure.
So, we said that can we.
avoid this cut set by doing modification to our structure itself we said that transpose the filter structure.
So, this is how we did the filter transpose structure that is input and output were reversed and even all the whatever you had the feed forward one you have reversed them.
So, by doing that so, we call this is a broadcast structure.
So, X of n is broadcast to all the legs basically.
And, you will be having the delay in it and then you will be multiplying in this case each this thing node you will be seeing the delay is one multiplication and one addition what you will be getting the output.
So, then we went on to say why pipelining there are restriction to the thing because as I have already said because of the pipeline hazard.
So, we may not have more than 3 to 4 cut set at the most of the time we will have only 2 to 3. .
that is a maximum not even the fourth one ok.
So, beyond that how we can want to have what is it speed or in the case of you are considering the computation time or from the power point of view both the pipeline or parallelism we is going to reduce this the power consumption.
So, you will be seeing that how we can convert from serial to parallel structure and then parallel to serial.
So, we said the critical path in this case is the communication.
If communication between the 2 units.
becomes much more than the computation it is better to go for parallel architecture.
So, that is the restriction.
So, what is the power basically this is the propagation delay what we have put it.
So, which is going to have the charge capacitors and are the input voltage is V naught and then this is directly proportional.
So, we are putting the constant k in the this thing here basically and then we have V t is the threshold above which are transistors are going to switch on.
As we know that most of the TTL transistors you know that 0.8 volts is the cut off point above that what you will be taking it as on and then below that is going to be off and then if they are operating at 5 volts.
So, the power consumption is as you can see it is directionally proportional to the capacitors that are being used in the computation.
And you will be seeing that it is the one which is proportional to square of your input voltage.
So, whether we can operate it sub optimal voltage because which is the dominant we will call it as the unit in our power consumption.
So, we will we can reduce our power.
quite considerably and it is directly proportional to frequency.
So, if I want to operate at higher frequencies we will be going with parallelism or pipelining, but if I want to operate at the same frequency, but at reduced power consumption then I can go with red optimal what is it input voltage what we can operate.
So, the equation what it was given for the sequential one is given by this.
equation that is C charge into V naught divided by k into V naught minus V t whole squared and then f is given by 1 by T sequential that is the frequency of operation.
So, how we reduce the power by pipelining that is M stages of pipeline what we will be considering it by substituting in equations.
So, this is what we do the left hand side and right hand side will be putting it.
along with the sequential what we are considering our pipeline 1.
And then we will be assuming beta is the value by which I can reduce my operating voltage.
So, we will be considering calculating this beta and then we went on to show that in the sequential 1 the whatever our P reference takes 12 units of time whereas, in the case of pipeline without reducing F0.
So, we can operate it.
2 times the p reference and the clock period is going to be reduced to 6 unit of time.
So, if we use the reduced voltage that was reduced to 0.364 times the p reference basically, but I am operating at the same frequency as the original one.
So, then we consider both parallel and pipeline how we are going to consider the power consumption assumption.
with respect to propagation delay we calculated.
So, we have the L t sequential will be equal to t parallel what we will be having it and then based on our pipeline as we can see that it is t sequential is equal to t pipeline what we will be calculating it.
So, the equations have been propagation delays have been given in this and we will be solving L and then m values and we can combine both.
So, what is it pipeline and parallelism to get L by M will be the operating voltage of our circuits.
So, later on we went on to define our filters.
So, we said the common filter what you can see this is original signal and then you have multiple components which got have added with it and whether we can do low pass filtering to get one of them and then or do the high pass filter to get the multiple of the thing or I can select one of them to do the band pass filter.
or I can do the notch filters.
So, that I will be eliminating these two and then I will be trying to get one of them from the thing.
This is what we discussed and then we went on to discuss about FIR filter.
How FIR filter can be used in the linear phase response only a normal FIR filter is not a linear phase.
How do we represent the magnitude and then phase of the signal is given here that is magnitude of h of omega into e power j phi omega, where our phi of omega is nothing, but minus omega into n naught.
When we are going to achieve this linear phases when the we consider the symmetric coefficients basically that is h of n is plus or minus h of m minus 1 minus n, n will be going from 0 to m minus 1, m is the order of the filter.
So, we discussed about how we can design our FIR filter in our digital domain using hamming, Hanning window, hamming window and then Blackman window with different responses depending on what you want the peak that is minus 20 log delta whatever the cutoff frequency what you want to have it, whether you need it 21 dB down the lane or minus 44 dB or up to 74 dB what Blackman can give.
And then we said that main lobe is.
Going to be the smallest one for rectangular window.
And then as you will be seeing that black man has the next lowest one and then it will be same for both Hanning and then Hamming.
So as one comments here energy neither can be created or demolished basically what we say.
So, how we are going to distribute the energies in the windowing thing.
So if you distribute more energy in the windowing.
what you will see that in the main lobe then the side lobes is going to be reduced basically you what you will have it or so the main lobe has what you say narrow basically then you will be seeing that peak side lobes what you will be having it and then you have to have one of them compromise on the thing.
So, the what are the design stages for our filters basically so we are going to start We will be specifying some of the performance and then we will be doing the filter coefficients calculation using the MATLAB what we said either it can be a FIR filter or IR filter and then we have to define our realization structure what we wanted.
So, whether we want the linear phase for FIR filter or IR filter cascading section and then we will be looking at the finite word length effects analysis and solution.
And later on we will be porting them on to the hardware and our software implementation and then we will be going with the testing.
So, any of the stage if we are not satisfied the thing.
So, you will be going back to change the either the structure or you can calculate your filter coefficients by doing little bit narrowing or widening the thing and then.
Or you have to go back to specify your thing modify that itself.
So, you will be doing all this redesign if none of them satisfy you may have to go back finally, to this and then come down.
And then we went on to say what are the errors that are creeping in our digital signal processing or using the digital signal processors.
So, one is the ADC quantization error and then we had the coefficient quantization error and we looked at it.
and then there is a overflow error from our signal processors and then finally, when we are representing at the output we will have the round off error.
So, we said in IR filter from the FIR filter we went on to design our IR filter.
So, we said direct 1 form and direct 2 form what are the advantages and disadvantages basically.
So, our storage is minimized in this and whereas, here it is twice in this case.
And the problem with respect to these two is here if there are positive and negative values.
So, because you have only one summation unit here.
So, it may get nullified whereas, in the direct form 2 cascade section.
So, both negative also is getting added and then here it is the positive addition what it is going to happen.
So, all of us know that multiplication is not going to cause overflow, but.
addition can causes overflowing this case.
So, this is one of the disadvantage what we have to bear with our direct to form.
And we went on to say that our coefficient as in case of FIR filter we can represent it in Q15 format, but in the case of IR filter it is not possible to represent it because the maximum and then minimum value what will be getting is minus 2 to 2.
So, that is what we went on to.
with this triangle basically.
So, we have to represent coefficients in Q13 format for all our IR filter applications.
And we said that the how you are going to combine your most of the time we have the complex conjugate poles basically and zeros will also be occurring.
How we can combine them that is the which is from the 0 which is farthest.
in the pole positions which is going to be combined with the nearest 0s in the nearest to the 0 basically and then so on what you will be applying it.
So, that when we disturbance in the thing it is going to be minimized.
So, this has one has to work it has been over the years one has worked out.
And we know that in IR filter we will be designing our.
filter in using the ah analog domain and we will be doing the transformation.
So, we know that most of them are Butterworth filter what we will use it or Chebyshev 1 and then 2 basically and then the elliptic filter what we can design using ah in the ah analog domain.
So, this has a we know that it has a narrowed steep of what we discussed it.
And, here is this thing what Chebyshev 1 has a little ripple and then flat response and then Chebyshev 2 is you will have a ripple in the pass band and then the flat response and elliptic will have both ripple in pass band and then stop band and then we know that this is the lowest order filter what we can design and we went on to design a sign generator in the oscillatory mode and the same oscillatory mode can be.
design for the quadrature oscillator both you will be getting sine and then cosine output basically that was the application.
And then we went on to say that how the scaling is one of the important one in the case of IR filter.
So, either we can have L1 norm or L2 norm or L infinity norm.
So, we said that for hand calculation and other things we can use our pole positions A1 A2 coefficients to calculate our L2 norm.
So, and then L infinity we will we have to calculate the Fourier transform and then maximum of the value what we have to take it and then went on to show that our L2 norm is the minimum what we can calculate which is less than L infinity which is less than L1 ok.
So, we say that f of k is the impulse response from the input output of first adder.
So, that is w of 1 what we take it that the magnitude of it and you have to do summation and then calculate your scaling factor in this.
So, later on we went on to discuss about adaptive filters, I thought filters I will complete it and then go to a my DFT and then FFT and then DCT we can combine the thing.
So, we discussed about autocorrelations little bit on cross correlation and we went on to see little bit on random variables how to calculate our mean and variance and then we said that why do we need the adaptive filters.
So, if we have the.
output and then the noise is known then you can design either FIR or IR filters where you do not know the noise you have to adapt it to the scenario.
So, then in that case it is better to go with adaptive filters.
So, this is the adaptive algorithm.
So, these are the digital filter which weights can be adjusted based on my error function.
If I know the desired signal, so my output is going to be subtracted and try to minimize on the error.
and then adjust my weights.
These are the equations what we considered and we went on to show that it needs 2L addition and then 2L plus 1 multiplications to do my adaptive filter.
So, the practical applications few of it what we discussed only I have listed 3 here.
So, that is one is adaptive system identification if I unknown system what I have it whether I can predict what is that system is using this.
structure basically and then computing my error function minimizing on it I will be trying to know what is this unknown system.
Later on we said that adaptive prediction what I can do it.
So, by delaying my input itself whether I can know what kind of this thing prediction I can do my system is going to be that is what I am looking at.
This is one of the.
advantage of using noise cancellation in most of the speech if you are not in the closed environment where noise is not creeping in then you will be seeing in the public address system and other things so you will be having two mics or this is the signal what you are taking the source and noise is coming from here so whether you can predict this noise what it can be and then feed it into the system and see whether this noise is going to be subtracted from wherever you have your speech plus noise which is going in as an input so that I can adaptively cancel the noise.
Most of the application as you can see that in the engine noise most of the time in the aeroplanes or in the cars which is going to be cancelled out.
So, the other filter applications what we see was in the scrambling.
So, if you want to scramble your speech and then protect it or your audio or whatever may be the thing.
So, we took an example of 3 kilohertz input signal low pass filter and then 3.3 kilohertz as my this thing sign generator what I have taken.
I will be adding them.
sorry I will be multiplying these two signals and use the low pass filter with 3 kilohertz.
This can be replaced with your input speech or audio if it is within the thing you have to take care of your filter design here and then output is going to be a scrambled one.
Same output I can feed it to the input and then do this operation I will be getting my clean speech so that way you will be protecting.
your own one way of what you will call it as safeguarding your voice basically.
The other one we said that echo we did the creation and then how we can cancel the echo which is getting created.
So, multiple of the it can be a single echo or it can be multiple of them if it is got reflected we said it is a reverberation.
So, how we can create them how you can cancel it that is what some of the using are FER and then IR filters what we saw the example.
Next one was using the graphic equalizer.
using different equalization techniques, different filters it can be low pass, band pass or high pass filters.
You can either allow your audio to pass through or only the instrument to pass through.
So, most of the application you can use it in normal life.
So, next we went on to discuss about the speech coding techniques whether we had the waveform coders or coders.
and you can see that what kind of applications they use which are the bands what it is going to be used.
And one of the example what we took was one of the students project to show that LPC coding how it can be done both analysis and synthesis and then reconstruct your voice at the receiving gate almost equivalent we will not say same, but at least it is going to match with whatever voice it was getting generated.
We went on to why we have to go for discrete Fourier transform.
So, in the time domain we know that some of the frequencies component that are present in our input signal may not be clearer better to go into the other domain other transform domain to see that whether we can look at what is the thing happening to the signal.
So, as we said if the sampling frequency is not met.
So, we will be seeing that there will be a overlap of the thing.
So, whatever the frequencies so, we will be accounting for the aliasing.
So, we intended to have some frequency at the output, but we are getting some other frequency then definitely we know that in the Fourier transform which frequency we are getting it how it has got aliased and then you can avoid it in the.
time domain for that or your sampling frequency what you have to increase more than twice of that whatever Shannon sampling theorem says.
So, we know that the equation what we have is with respect to it is a complex equation that is e power minus j both real and imaginary parts are there.
And we went on to say that our coefficients can be represented.
in this manner and then how in the unit circle how your coefficients that is weight factors are represented is shown with that.
Then we said we can calculate our application of our DFT was to find out the magnitude spectrum and then how the phase is going to look at it.
So, we went on in the DSK board also to implement the same thing and some comparison we did the thing DFT if it is order of n squared is our complex multiplication which can be reduced to n by 2 log 2.
n complex multiplication in the case of FFT and we showed we have shown that how it is going to be the ratio for different order of the input basically.
And then we went on to say that our decimation in time and decimation in frequency to develop our butterfly structure to get our FFT as it is shown and then we said that how.
our computation in hardware can be for the bit reversal.
So, if it is input is bit reversed output we said it is in bit reversed format what we are going to have it sorry in line output.
If input is bit reverse in line then output is going to be bit reversed.
So, how we are going to access it as we discussed in the hardware we can do the reverse addition to calculate our bit reversal.
of the value.
So, that we need not have to spend on the algorithm if you go and look at the book you will be getting what complex we you have to do the reversal of it which will be taking lot of time.
Whereas, in the hardware we did the reverse addition so that we can immediately get our output and then we went on to show that.
So, how many this thing butterflies are groups and how many twiddle factors are required at each step.
stage because we have log 2 end stages.
So, we went on to say what are the twiddle factors that are going to be present in each stages.
So, we went on to discuss about finite word length effects in FFT also.
So, we know that signal to noise ratio is given by this equation that is it is directly proportional to number of bits and inversely proportional to the order of your FFT what you are going to consider and then these are the errors what we considered in FFT also.
And, later on for a lengthy signal how we can work on using a overlap add and then overlap same method to implement the same using RFFT.
So, then we went on to discuss about discrete cosine transform that is little on image processing what we did the thing.
So, how the DC value is going to be maximum in case of discrete cosine transform.
And then where are the low frequencies present and medium and then high frequencies.
So, because of our human visual system so, we may not be able to view this high frequencies so, we can.
eliminated and then go for the compression basically.
And then went on to say that our JPEG uses this DCT or compression technique to implement it.
So, you will be seeing that different colors how it is represented in the RGB domain and we know that it needs maximum word length and then number of bits are much more required in this case.
So, how we can go from one domain to the other here also in the YUV format as you will be seeing that it is represented in only here and then illuminance what we will be having it in the Y.
And then what we said was the color space conversion.
will be doing it into that is illumination and then chrominance and then both CR and then BR what will be taking it.
And then we can do the subsampling in the chrominance subspace basically and apply the discrete cosine transform.
Later on go on to do the quantization.
So, we use different quantization matrix to see that how much information we can discard.
Later on we went on to do in the DCT run length coding and in the inverse DCT it is going to use the Hoffman coding to get back R.
value.
Later on we went on to use butterfly structure to show that the order of multiplicate for the 8 bit 8 by 8 bit 1D or DCT needs 64 multiplications and 63 additions which we can be reduced using the butterfly structures to 13 multiplication and then 27 additions.
So, that is one of the technique what we used it.
to show this.
So, you will be seeing cos and sin function what it is going to be used here.
So, to wind up we have lot of people to be acknowledged few of them what I have listed here.
One is a Professor L.Uman and the NPTEL coordinator for allowing me to take up this course and then a Professor T.V Prabhakar who is the one who initiated me to give this NPTEL course and then initial.
he looked into my all the course contents and other thing he said it is very good and then you can go ahead and then professor n j rov was the mentor i should ask once i have given everything i was supposed to give my lectures he sat with me and then said these are the things what you can do it so final tuning and everything done was done by professor n j rov and then i cannot forget to acknowledge all NPTEL office people that is Avinash, Dipali, Gurraj Maya, Kavitha, Naidu, Navin, Vidya and then Sushma if I have forgotten any other names these are the ones I could remember.
Sorry I try to acknowledge everyone and bearing with me my lunch hour recording and other things they had to forego or little bit fine tune their lunches and other things.
And then I am very grateful to my reviewers of the course because those are the ones they said.
your course content is too much you may not be able to finish it in 12 weeks.
So, better to fine tune it and then it has to be fine tuned and then it has taken the stage and first of all I have to tell that IIT Madras for giving me permission to do this course for NPTEL and Swayam government organization who is I think doing all the everything and putting all questions and everything.
And whatever the support required from MATLAB because they were the first one to contact me saying that what are the tool boxes you needed for the students to use it.
So, definitely I have to acknowledge them for continuously in touch with them what are the things I need it and then providing online MATLAB for all of you to do the thing.
Later on I took the permission of Code Composer Studio although it is there online and those students who want to use their.
kids DSK 6713 in their colleges they can use that and then I have used the LCDK 6748 board as I was mentioning both it is fixed point and then floating point board for all my real time applications.
And this is would not have happened to show all the exercises what I have shown without my students who took DSP system design and real time digital signal processing course with me so far.
And then some of the books I have referred few of them what I have listed it is list may little bit go more actually.
The first one is SANE and then core real time digital signal processing fundamentals implementation and applications from V-LAY that is 2013 version what I am using it.
And if occur for my fixed point implementation and scaling and other things what I have referred from this book.
And the DENALDRY you would have seen some of the examples I was running from this book.
which uses both OMAP L138 and then for the 6 LCDK 6748 is the subset of this experimenter kit from John Ville which is the 2021 version.
And one more what I have used pipelining and parallel processing chapter from Keshav K. Pari on VLSI digital signal processing book.
So if I have forgotten and first of all I have to thank Thank you all for taking this course and then it is going well and if I am little bit delayed in answering your questions please bear with me.
Thanks to one and all.
So, happy listening and then working with respect to all lab experiments.
Thank you.
Welcome back to real time signal processing.
So, today we will discuss about the number system.
Just to give a recap of the what we covered in the last class.
First, we did sampling theorem, some DSP hardware basics what we looked into.
So, in this class we will see number system, its needs and then benefits in programming.
Although you may think that it is a primary class section, but we will see that how it is beneficial for implementing it in hardware that is what we will be looking it today.
So, first we will see what are the number formats available.
So, we know in DSP signals are represented as discrete sets of numbers from the input stage along through intermediate stages to the output.
So, all the stages have to be in the discrete format and all the applications of DSP like filters, FFT coefficients to be represented also as numbers.
So, there are two formats popularly available in DSP processors.
one is the fixed point format, the other one is the floating point format.
Most of you might have used the floating point format, still we will see how to represent that in DSP process we will look into the thing.
So, coming to the fixed point format, so we know that it is the simplest scheme.
So, we represent the number as integer or fraction using fixed number of bits.
So, we know that an n bit fixed point signed integer.
as we mention it again it is a signed integer what I am representing.
So, the representation will be from minus 2 power n minus 1 to 2 power n minus 1 and we know x is the number what we are representing.
So, which is given by so, minus s dot here s represents the sign bit of the number if it is equal to 0 it is positive number and if it is minus 1.
it if it is equal to 1 it is a negative number.
So, the first number will be minus s into 2 power n minus 1 and then the next number will be its magnitude is b n minus 2 what we will take it into 2 power n minus 2 and so on.
In the last we have b 1 into 2 power 1 and then plus b naught into 2 power 0.
So, all of us know that.
what is the range this number format can take.
So, we will see the most negative value in this format is x is given by minus s into 2 power n minus 1 to b 0 into 2 power 0.
So, if we know the negative bit is equal to 1.
So, if we substitute s is equal to 1 it is minus 1 into 2 power n minus 1 and rest of the bit is going to be 0s.
So, this is equivalent to minus 2 power n minus 1.
So, which is represented in binary format as.
1 followed by all 0s.
And then if we use 16 bit representation for this number, then the binary format for most negative number is going to be 0x800 in hex.
And then the most positive value in this format what it can take is minus s into 2 power n minus 1.
So, this is a number what we have represented as earlier.
And then we know the sign bit is going to be 0 for positive numbers.
So, x is represented as 0 minus 0 into 2 power n minus 1.
And we consider all the rest of the bits later as 1.
Then it becomes the number representation is equivalent to 2 power n minus 1 minus 1.
So, in the binary format it is going to be 0 because it is a positive number and rest of the numbers magnitude is represented as 1 in all through in 16 bit format the maximum value is given as 0x78.
f f f in hex.
We know the number representation hexadecimal I think most of you would have covered the thing.
So, f is the maximum number which gives us the 15 as the value for it.
So, the next one so, we have to represent this number in the integer format.
So, we know that in when I n is equal to 4 the value what I can represent in integer format is minus 2 power n minus 1 less than or equal to x less than or equal to 2 power n minus 1 minus 1.
So, in this we have substituted n is equal to 4.
So, if we substitute in the next line.
So, we know that minus 2 to the power of 4 minus 1 to 2 power 4 minus 1 minus 1.
So, the range is going to be minus 2 power 3 to 2 power 3 minus 1 which is nothing, but minus 8 less than or equal to x less than or equal to 7.
So, in this case we know that x belongs to minus 8.
minus 7, minus 6, minus 5 so on and then the positive side it is 0, 1 to 6 what we and then the last one is 7 in this slide.
So, we will see that how to represent our number x is equal to minus 3.
So, that this is the integer format.
So, we said x is equal to minus 3 how we can represent.
So, we know that this is a negative number.
So, s will be equal to 1 and then we know that when I divide 3 by 2 I will be getting 1.
So, the digit what it will be is 1 into 2 power 1 plus 1 will give me plus 3 and then since we are using the 4 bit representation this bit is going to be 0.
So, the number what I can represent in binary is 1 which gives the negative value and 011 is.
So, coming to why we have to go for the fixed point fractional format, we will see it in a while.
First we will discuss what is this number system.
So, the n bit fixed point signed fraction representation, we say that the number x can be represented between minus 1 to 1 minus 2 to the power of minus n minus 1.
So, n is the number of bits what we will be using as normal notion.
So, if I represent this.
in the open format.
So, x will be minus s into 2 power 0 plus b minus 1 into 2 power minus 1, b minus 2 into 2 power minus 2 and so on.
And then the last number will be represented as b minus n minus 1 into 2 power minus n minus 1.
So, here again s represents sign of the number.
If it is equal to 0, it is positive and if it is equal to 1, it is a negative number.
So, we will see how a fractional format can be represented.
So, that is the most negative value how we did for the integer format.
So, we will see for the fractional format.
The most negative number, so will be represented as s is equal to minus 1 and then rest of them are going to be 0s.
So, which is going to be equivalent to minus 1.
and this is represented as our regular thing 1 all 0s which is 0x800 format.
And then what is the most negative value that can be represented in this format what we will see the thing.
So, we have s is equal to 0 and rest of the values are going to be 1.
So, it is represented as 1 minus 2 to the power of minus s.
n minus 1.
So, in the binary format we will be representing as 0, the point is whatever is not given any place bit value is given for the decimal value.
So, it will be 0 point all 1s or in the processor it will be taking it as 0 1 1 1 1, but the notation for as is equal to 1 minus 2 power minus n minus 1 will be the largest value what I can represent in this format.
So, we will see what will be the granularity of this, why we have to go for the point fractional format.
So, which is given as this way.
So, minus n to power 0 what I have it.
So, in the resolution in this case is going to be 2 power minus n minus 1 will be my granularity what I can have from this representation.
So, coming with the example.
So, we will see n is equal to 4 what are the numbers I can represent in the fractional format.
So, which is minus 1.
than or equal to 1 minus 2 power minus n minus 1.
So, we are substituting n is equal to 4 here.
So, which comes out as minus 1 to 1 minus 2 power minus 3 which is nothing, but x should be less than or equal to 7 by 8 that is what we have to represent.
Then what are the x values it will be taking from minus 1 to plus 7 by 8.
In what we call it as the smallest value will be minus 1.
then next will be minus 7 by 8 and so on minus 3 by 4 and then minus 5 by 8 you may be wondering why I have got minus 3 by 4 just check 7 into 2 is going to be 14, 14 by 16 what you will be doing it or you will be adding minus 7 by 8 plus minus 7 by 8 will be giving you this value when you simplify the value of it.
So, like this you will be going on representing till.
So, and then later on the positive side what you will be representing it as 1 by 8 and so on the last number will be 7 by 8.
As you can see that how many values you have represented in the negative side and then how many values are represented on the positive side.
As you will be seeing that it has 2, 4, 6 and 8.
So, that is what the values what you will represent it as on the negative side and positive side you will be seeing that.
it will be 7.
As we have we know that 2 power minus 4 minus 1 is going to be 1 minus this is going to be 7 in that case magnitude of it.
So, we will see that what is the smallest precision measurement I can have with n is equal to 4 which is nothing, but 1 by 8 which is coming from 1 by 2 power n minus 1 what we said it in the previous slide.
So, moving on.
So, how I can represent the number x is equal to 3 by 4.
So, we will see in the fractional format how we are going to represent it.
So, we know that minus s into 2 power 0 this is the representation what we are considering for the fractional format and then we have to substitute as 3 by 4 which is equal to 0 into 2 power 0 plus 1 into 2 power minus 1 which is nothing, but.
0.5 and then the next number is going to be plus 1 into 2 power minus 2 which is 0.25.
We all know that 3 by 4 in the fractional representation is 0.75.
So, 0.5 is given by this weight and then the next bit will be representing 0.25.
So, 0.5 plus 0.25 will be 0.75.
So, the binary representation is 0, 1, 1, 0.
Since it is a positive value, we have put it as 0 and then we have.
These two are the representation the last bit is going to be 0 ok. Coming with the fixed point format and then how we are representing it all of us know that even the integer representation is a fixed point number system, but where is the point actually you will be seeing that we usually discard this it comes at the end of the number.
So, the decimal point will be at the end of whatever number you have considered.
And then the same you will be seeing it in the fixed point format I have the sign bit and immediately there is this thing what we assume is a decimal point.
So, this since it does not have any bit allocation for it to say for my rest of the numbers we assume that it represented immediately after our sign bit.
So, the next numbers what we will be representing is b minus 1.
and till b minus n minus 1 whereas, in the case of integer you will be seeing that sign bit will be having the n minus 1 place and then later on it will be b n minus 1 will be its magnitude and so on till b naught.
So, coming to next what is the fixed point format.
So, why we have to use the fractional representation of numbers.
This is what we will see the thing all of us know that.
Any multiplication of integer numbers will result in overflow and may wrap around to result in bit error.
So, hold on for a while we will see that how it can happen.
So, for an n is equal to 4 the representation what we have is minus 8 x can be represent between minus 8 to 7.
So, consider the multiplication of 3 into minus 4.
So, the result has to be minus 12 all of us know.
So, you will wonder why I am talking about the primary class multiplication.
So, but as we can see that the range what I can represent is between minus 8 to 7.
So, minus 12 is outside the range ok.
So, the same thing if I represent in the fractional representation.
So, I assume n is equal to 4.
So, then what I will be having is the representation in this format.
So, how can I do that basically whether can I bring this one in this format.
So, that I will not be.
outside the range of it.
So, for that what we will do is we will how we can represent this 3 by 8 into x into minus half which is equal to minus 3 by 16.
So, what did we do can you check the thing here.
So, we have because n is equal to 4 format I have taken the thing.
So, the number what I can represent is 8 basically.
So, I have divided the 3 by number 3 by 8 the same thing what I did was minus 4 by 8 I have done it ok.
So, which is nothing, but minus half.
So, when I multiply these two number the result is going to be minus 3 by 16 which is nothing, but I can represent it in this format minus 1 by 16 minus 2 by 16 then what happens to the number in the binary format.
So, we result in.
We know that it should be a negative number.
So, initially what we will put it is plus value what we will be giving the thing 001, 1 by 16 what we have it and then the next one is 2 by 16 is 1 and 00.
So, which is equivalent because this is a positive number what I have represented I have not represented the negative value.
Here I will be considering the.
2's complement of this number.
When I take that 2's complement I will be the number what will be represented is 1.110100.
So, that is what it says is we will be having a 2's complement format.
So, what we say is it is outside possible precision what we say the thing.
So, in this case what we do is we will be discarding one of the 2's 0s here and then the lower values we can discard and then take only the 4 bits.
So, that is what we say the LSBs will be discarded instead of overflow error.
So, that is what the thing what is the trade off in this case?
Trade off is overflow error for rounding error what we have to consider.
What is the value represented can you tell me the thing in this case ok.
So, now So, we know that we have a tradeoff between overflow and then rounding error what it is coming in can I work on it to avoid these things.
So, we say how to increase range of number represented by integer format first we will consider it.
So, we can say that because my multiplication is going to cause me twice that of the number bits what I needed.
So, whether I can increase the number of bits n to 2 n. So, this will increase.
the range of numbers substantially.
So, for n is equal to 4 my representation is between minus 4 to 3 when I increase by 2 times this n then n becomes 8.
So, the range of numbers what I will be representing is minus 2 power 8 minus 1 less than or equal to 2 power 8 minus 1 minus 1.
So, which is equivalent to minus 128.
than or equal to x which is less than or equal to 127.
So, what will be the consequence of doubling the size of this number?
One is a storage has to double because I have to instead of 4 bit numbers I will be storing them as 8 bit.
This is a smaller example what we have taken.
So, this is not the scenario in real time.
So, real time most of the numbers will be 16 bit what we can represent in hardware.
most of the things.
I think all of you will be using the number format as int as 32 bit, long is 64 bit and then a long and then longer double precision what we will be using is 64 bit.
But you will be seeing that how the consequence is going to be in a while.
So, the storage is going to double.
So, my hardware has to increase.
So, what we are discussing is the real time signal processing.
So, real time capabilities is going to come down whether we can do that or not we will see when we take up some examples.
and then we may need double the size of axis using original data bus.
When we take up the architecture we will see that by increasing this how my bus width is going to increase and then how it can increase the hardware as well as how it can slow down.
And one more thing you have increased it to 2 n, but if I store this value and then use it with my 4 bit value next I will be getting it as 12 bit.
Can I go on increasing in this fashion forever?
It is going to be a what I will say is no end for it for this increasing of the numbers.
So, hence we have to restrict the thing.
So, that is the reason why what we use the fractional fixed point representation.
So, it is what we call it as equivalent to scaling and then usually the fractional number representation is going to be represented in Q format.
So, what is that Q represent is quantity of fractional bits I will be using in my implementation.
The number flowing following the Q indicates the number of bits that are used for the fractional representation.
As I represent as Q 15, I know it is a 16 bit DSP chip basically the resolution of the fractional will be 2 to the power of minus 15.
So, or it can be.
30.518 into e power minus 6 in decimal value what I can represent.
So, what are the things here?
Q 15 means I will be scaling the number by 15 that is 1 by 2 to the power of 15.
And then once again Q 15 means either I can scale by this division or I can do the shifting because all one shift right operation is going to be divided by 2.
So, I can shift right by 15 times.
So, that I will be resulting in the value of it.
So, how will be incorporating when I take up the architecture will be coming back to this number how I can do this shifting.
Otherwise each shifting will be costing as.
every clock cycle.
So, I need 15 clock cycles to shift if I have want to do 15 bit right shift, but we will be doing it in 1 clock cycle we will look into this in the architecture when I take it up.
So, now, as an example how we are going to represent 0.625 in memory.
The first one is we can use the truncation method 1 what we call it.
So, we will be calling it as an integer value.
So, which is nothing, but 0.2625 into 2 power 15 what I am multiplying it.
The resulting integer values 8601.6 in the truncation we will be truncating that whatever number coming out of the decimal point.
So, it will be represented as 8601.
So, you will be seeing in the 15 bit format this is how in the binary 15 bit binary format is this one.
And, in the second case we can do the rounding.
So, what we will be doing?
So, we will be adding 0.5 into the result what we are getting it.
So, then we will be discarding the normal way or whatever number comes out of the decimal point.
So, which will be 8602 here the binary representation what you will be seeing.
So, you have added 0.5.
So, the number has gone to plus 1 in this case.
So, it will be 10 the rest of the numbers remains same.
So, this is the positive number what we have represented.
So, whether you want to go for truncation or rounding which one is better.
So, we will see what happens with the truncation.
So, in this case the magnitude of the truncated number always less than or equal to the original value.
So, that is we will be seeing that it is consistently downward bias what I am going to have it.
Whereas, in the rounding what happens magnitude of rounded number could be smaller or.
greater than the original value.
So, then what happens to the thing error tends to be minimized that is positive and negative bias is what I am going to have it and popular technique is rounding to the nearest integer.
So, we will be seeing in hardware when I have to do rounding then I have to add 0.5 to the whatever the number what it is resulting in and then to the.
it to the nearest value.
So, there is additional addition is going to happen.
So, which will be costing us again extra clock cycle.
So, the simplest one will be a truncation, but if you are not able to get the required result, then you have to go for the rounding and then have the additional whatever clock cycle that is going to result from it.
So, as you can see INTO51.2.
So, we know that it is truncate or we call it as floor it is 251, it is not going to cause any damage to the number represented.
Whereas, if it is rounding also it will be resulting in the same value sorry rounding is you are adding 0.5.
So, it becomes 251.7.
So, which is going to be rounded to 252.
So, we call it as rounder it is going to be seal value what you will be considering in normal number representation or I can have a round nearest one more distinct function defined 251.2 which is going to be So, you will be seeing that truncation and round to nearest almost it is matching whereas, rounding has increased the value of the number ok.
So, we will see that general fixed point representation how we can do that is given by Coe and then Gann for 16 bit numbers.
So, if it is a unsigned integer and then how it is going to be represented in the signed integer format.
The smallest value for unsigned integer is 0.
And, then the largest value it is going to be 1111.
So, it is going to be 15.
And then unsigned fractional number what I will be having it is smallest is 0.
And then the largest value what I can have is 1111 which is 0.9375.
When I come to the signed representation, so the first.
value is 0.
So, all the 3.
So, this is plus 7 and then the least negative value is 1 0 0 which is minus 8.
And in the sign fractional the number representation we know that 0.1111 which is nothing, but plus 0.875 will be the maximum value and then least negative value 1.00 which is minus 1.
In this case we have taken number of bits equal to 4.
So, you can increase it to second bit sorry 16 bit and see what will be the minimum and then maximum value what you can represent with this you can look at it.
So, the minimum value will be 0 and then the maximum value will be 65536 in this case to power 16 what you will be having it to power 16 minus 1 will be the value and then in this case.
It is going to be 7 f f f positive number will be 32767 and negative number is going to be minus 32768 and same way you can calculate in the unsigned and then signed values.
So, coming to the general fixed point representation.
So, we will be seeing what are the dynamic range and precision of 16 bit numbers for different Q formats.
This also taken from Co and then Gan.
So, you will be seeing the first one.
As we said Q representation will give me how many bits are represent fractional bits represented.
to the right of it whatever represented.
Here if I give 0.15.
So, I know that all the 15 bits are represented as the this thing of fractional number the maximum that is largest positive value what I can represent is 0.999 what you will be going on and then representing it and then the least negative value is going to be 1 and precision what I want to have it is represented with.
this number ok.
Same thing if I want to allocate 1 bit to the integer here 0 bits I have included to the integer.
Here I want to include 1 bit to the integer and 14 bits are for the fractional number then my range largest value will be 1.999 to 2 that is least negative value I can have it is minus 2 and this is the precision what I will have.
And then but I do not want to represent any fractional number I want to have it as an integer then I will be.
calling it as Q 15.0 then I know that the 15 bits are represented as my fractional number.
The value what I will be representing is 32767 to minus 32768.
So, the precision in this case is going to be 1.00.
So, it depends on what precision you want to have for your application based on it you will be taking your number system.
You may be wondering why I have to discuss about this number system.
As you know that in the present scenario FPGA is mostly used for most of the applications because of low power.
So, whether when I am writing my own code all of you know that in C you will be representing it as hash define you will be doing it, int or float or double or whatever number, but when you are using in the hardware.
So, you have to be careful whether I can save my resources save my power.
So, that is what one has to look at it.
So, when you have to do that you have to play around your fixed point representation of the number.
So, that you know for what application you are using it, what is the dynamic range.
I have not discussed yet here in the dynamic range in this case.
So, we will be discussing it later and then what is the precision what I want to have it.
So, coming to few examples what we will take it.
How we are going to do all of you may be wondering why I have to do addition of 2 numbers.
So, here I am going to do it in binary.
So, you will be seeing the binary number is given in this way.
So, when I add these 2 numbers so, what is the thing is going to happen I will be getting So, you will be seeing that it will if you add the thing just to show you that how you will be adding it.
This will be from right to left what the addition is going to happen.
This is 0 when I add 1 plus 1 0 which will be carry and then you will be getting 1 here and then you will be adding this way further.
So, when you come to the last one you will see that this is 1 plus 1 is 0 and when I put 1 here so, it will be 1 plus 1 is going to be 0.
2 power minus 7 and then the last one will be your 2 power minus 10 minus 11 and then the 2 power minus 13.
So, when I add this number the value in decimal what I will be achieving is 0.40024.
So, this is how the addition is going to happen in our hardware and coming to the multiplication what is the thing is going to happen ok.
So, I have to multiply 0.5 and 0.25 in.
What I say is q 3 format.
So, that means, to say that I have 4 bits it is in the signed format what I am going to do the multiplication.
So, 1 bit for sign and 3 bits are going to be for my fraction.
So, 0.5 I know that 0.2 power minus 1 is 0.5.
So, the other 2 numbers are 0 0 and 0.25, 0.010 what I will be considering that this is 2 power minus 2 it is 1 by 4 which is 0.25.
So, I want to do this multiplication.
I have taken the simple so that I am not doing any truncation or rounding in this case.
So, which can be represented in binary format that value what I have taken the thing.
So, I will be multiplying 0.100 into 0.010.
So, will be bit by bit multiplication is going to happen.
So, you will be seeing that one after the other.
Then what is the how we are going to calculate the final value?
All of you know that it is going to be numbers have to be added that is what we have been taught in our primary also.
Then we will be adding it and then what we are going to do is because my format what I have input and output is in Q3 format only I can represent 4 bits the LSB bits I will be discarding which is shown in blue here all three zeros are going to be discarded result is going to be 0.001 which is nothing, but 0.125.
So, you will be seeing 0.5 multiplied by 0.25 will be resulting in 0.125 in decimal.
So, you will be seeing that how fast the calculator or your computer gives, but what goes on is this one in the inside your hardware.
So, how this can be done faster and other things we will see in the architecture.
So, now, what we say is what is this is point format and then size what we have to look at it.
So, which format will compromise between precision, overflow and then storage needs.
So, one method we said we can increase the number of bits, the other way of doing it the floating point number which will give me all this solution.
So, how it is going to give me the thing?
So, we will say that suitable for computations where large number of bits in fixed point format would be required to store intermediate and final results.
And the algorithms that need summation of large number of products in that case we will be using the floating point number.
So, if x is going to be represented in floating point format as x is equal to x.
Mx into e power x.
So, this we call it as mantissa and this we call it as exponent.
This is a non-standard format we will see the IEEE format what it is the standard has defined.
So, in this case when I do the multiplication of 2 floating point numbers we know that it is Mx into e power x and then y is given by My into e power y.
So, we know that we multiply the mantissa and then the add the exponents to get the result.
So, floating point unit should have a as you can see to do the multiplication and do the addition for the multiplier for the mantissa and an adder for your exponent.
This is the architecture definition what you are getting from the floating point.
So, the numbers of adders should be normalized before addition that is the exponent of the number should be same for adding it is not as simple as my multiplication.
So, when I come to IEEE format representation we call it as IEEE 754 which is defined in 1985 this thing format for single precision that is 32 bit floating point number is represented as x is equal to minus 1 to the power of s into 2 into e minus bias into 1 plus f. So, here s, e and f are all unsigned fixed point format, s will be representing your sign bit.
E will be representing exponent biased and then f is the significant in this case.
And we say that this is the implied binary point here also will not be allocating any bits to the decimal point.
So, you will be seeing that the significant is represented with 23 bits whereas, exponent is with 8 bits and sign bit is with 1 bit if it is 0.
it is going to be positive significant and if it is 1 negative significant.
So, you will be now wondering why exponent is biased because why I can exponent also can represent it in positive and negative.
So, I am not allocating any bit for the thing.
So, we will be doing the biasing so that to avoid this positive or negative number representation for the exponent.
So, we will see as an this thing example here which is nothing, but minus 1 to the power of s.
into 2 to the power of e minus bias into 1 plus f. So, we know that f is the magnitude fraction of the mantissa.
So, in determining the full mantissa value.
So, IEEE format specified that 1 is placed immediately before the implied binary point 1 dot format that is why you will be adding 1 to the whatever you have the fraction here.
So, e is the biased exponent.
So, the bias make sure that the exponent is signed to represent both the small and then large numbers.
So, two's complement complex for comparison.
So, the bias is set to be 127 that is largest positive number represented by 8 bits with which is equivalent to 2 power 8 minus 1.
So, s is the sign of the fractional part of the number.
So, as an example how we are going to represent we will see the thing.
Find the decimal equivalent of the floating point binary number with bias 2 power 3 minus 1 which is 7.
So, you will be seeing this is the number what you have been given in binary format.
So, we know that sign bit is 1 in this case and bias have been given as 7.
So, I will be using.
4 bits for my exponent.
So, which is 0 1 1 0 and rest of them are fractional bits.
So, which is nothing, but 3 0s triple 1 0 0.
So, when I represent it fraction part 0 into 2 power minus 1 and then all the 3 of them are 0s and the next number will be 1 into 2 power minus 4 and then you will be seeing 1 and rest of them 0s, which is nothing, but 0.109375 is f value and then experiment we will see the thing.
0 into 2 power 3 and then 1 into 2 power 2 and then 1 into 2 power 1 and 0 into 2 power 0 which is equivalent to 6.
So, when I put it in its format we know that sin is 1.
So, it is a negative number minus 1 into what we have is because f plus 1 what I have to do it.
So, it is 1.109375 into 2 power exponent minus bias, bias we have is 7, 6 minus 1 is 2 power minus 1.
So, this is divided by 2.
which is equivalent to minus 0.5546875 is the value what I can represent.
So, we will see little bit on the DSP architecture and we will be taking a detailed one in the next class.
So, what we have is as you can see here.
So, I have for the floating point DSK6713 processor what I have considered here.
So, you have the integer or floating point multiplier here and then I have a integer floating point.
ALU addition and then we have some extended precision registers and we have some address generator 0 and 1 in this and then we have some auxiliary registers and some control registers.
So, these are the compiler what you would be feeding in and this is the data bus which is data bus is 32 bit long and then the address bus is.
24 bit and then we have something we call it as program cache and this is the RAM what we have it which is 1 k into 32 bit each.
So, RAM block 1 what we have it 1 k into 32 bit here and then the ROM for storing our coefficients and everything which is 4 k into 32 bit and some of the peripherals what you will be seeing connected here through the peripheral bus.
Then we have the like any other microprocessor 8085 would have studied the thing I have the DMA controller which will be generating address generator and control registers.
So, directly I will be able to take from the memory and then load into the hardware.
So, coming to recap what we have done in this classes we discussed about the number system.
So, as in to see that.
whether you have understood or not the fixed and floating point.
So, I have given two assignments here, please work it out and then I will be showing you how we can compute this one.
One is first one is add these two numbers, here it is non IEEE standard format what I have given the thing, exponent is given as 4 and mantissa is 5 bits and bias is given as 7.
So, these are the two numbers one has to add.
So, please keep it in mind we did the multiplication it was very simple we have multiplied mantissa and then added the exponent.
In this case you will be seeing the exponents are different you have to bring it to one format I will see that which format you will choose it whether the.
higher one or the lower one and then we will discuss why which one is better to choose the thing in the next class.
The second assignment what I have given is minus 0.75 by minus 0.375.
So, we did the simple positive number multiplication.
So, I want it is going to be a trick to do multiplication of 2 negative numbers.
I know the result is going to be positive.
So, you can trick me by removing the minus sign, but I want you to keep this minus sign and then do in the 2's complement.
So, that using the 4 bit.
for both input and output and what will be the result whether it is going to be correct or not what I want to you to try it out.
So, that you can play with me in the number system in this fashion ok.
So, with that we will end this today's class.
So, in the next class we will be taking architecture of DSP that is we will be using DSP synonymally for signal processing as well as.
processor part 1 what will be taking up in the next class.
Because this number system will help us to see that what should be our architecture for designing it although I have shown you one DSP architecture we will see how we will be going about to build it.
So, those who are interested in building on their own DSP processor you can use FPGA to build it.
Thank you.
Welcome to real time signal processing course.
This is three credit course.
This is I am Dr. Jain Rithna, principal research scientist.
from electrical engineering department Indian Institute of Science.
So, I have been working in I A C from 1982.
So, this is my 40th year basically.
I have been teaching this DSP system design, real time systems, real time signal processing and sensor networks in I A C. The real time signal processing course is meant for college faculties, students and corporate people who wish to dirty their hands what I will put it that is dirtying their hands in real time signal processing.
So, the course covers following topics basics of signal processing, processor architecture.
Next we will be discussing about digital filters like IAR, FIR and adaptive filters.
Continuing with this we would like to know the spectrum of the real time signals using FFT and then DCT.
The complete course is centered around TI Texas Instruments DSK6713 board.
to generate synthetic music, remove noise from the signal knowing their spectrum and then how we can an unknown noise can be removed from the signals to improve the signal to noise ratio will be demonstrated.
The course also demonstrates how to generate echo synthetically, create reverberations etc.
So, come and then play with me with signals.
after learning the theory.
Thank you and welcome to this real time signal processing course.
Welcome back to Real-Time Digital Signal Processing Lab basically.
So last class we had a problem with the.
loading into the thing.
So, today I will show you how you if there is any problem how you can load it.
So, we are discussing about the adaptive filters in non real time.
So, these are the equations that is updation of the weights here and error calculation and then the output calculation is here and this is our LMS algorithm which will be running it in non real time.
So, these are the parameters what we have it that is.
2 cos 2 pi nf by fs is are this thing desired signal and the input is chosen as a sign of signal itself that is 2 pi n f by fs ok.
So, here f is equal to 1 kilohertz and sampling frequency chosen is 8 kilohertz.
So, adaptation rate of mu is going to be set with 0.01 and order of the filter is 21 and we know within 60 iterations.
So, the system will converge error is going to come down and then output will be equivalent to input.
So, this will be the desired plot what you can see it.
So, this is going to happen in non real time.
So, we can change the adaptation or convergence rate and then see how it is going to behave.
So, what we will do is we will go to the code composer studio.
As I said there was a problem in the previous class what we had it.
So, all the directories if you go into the thing I have loaded all the labs thing in ah in my D drive basically.
So, that is in ah CCS 9 what I have all the files basically running.
So, this is my working ah workspace basically for the code composer studio.
So, yesterday I was seeing this and then I was ah having a little problem.
So, what I did was so, go to the file if you are by mistake all the complete workspace is cleared you can go and then ah you will be opening the projects from the file system.
So, if you give this directory.
automatically all the files gets reinstated in the directory as you can see here I am having from the day 1 whatever demos I have been doing it is available here.
So, this is how you can get back all your directories and then you can run.
So, this is a non real time what the demo is going to be.
So, what we have in this is a main.c file what we have it.
as it is pointed out this is the desired signal what we want is to cause 2 pi into t into 1000 by fs, f we said it is 1 kilohertz.
So, the noise signal given as a sign that is 2 star pi t 1000 by fs.
So, this noise signal has to be eliminated and then we should be getting the desired size signal at the output.
So, we will see how we are going to get the thing.
So, this is desired and I have a y out and then.
error signal.
So, fine in this case the W as we said the weight function.
So, it is assigned to 0 initially even the x 0 will be getting the first noise signal here new noise sample and D will be our desired signal and Y is going to be 0 and the variable that is a filter output what we will be calculating Y plus that is whatever weight you have computed into X of i.
And error is computed as d minus i desired signal minus y output and you will be updating your weight w of i with w of i plus mu into error basically what you have computed here into input that is x of i.
So, in this case mu is assumed as 0.01 in this case that is what the initial.
So, you can change it to 0.02 next and then see the convergence will be faster and in MATLAB pi value automatically takes, but here in code composer studio in C file you have to define your pi value also.
So, it is defined up to 7 decimal places whatever length you want to define your pi you can define it.
And sampling frequency we said 8000 order of the filter is 21 and then are the number of iterations is chosen as 60.
So, we will be calculating the update the error function and the delay because x also has to be further this thing delay line has to be input line also has to be updated this is how we will be updating the delay line.
And, we will be putting last desired of t will be equal to d and then our y out will be y and then error function will be e. And then once it is done you can call it as done.
So, what we do is because as we said the return function the handle is written elsewhere it is not in this memory.
So, we will put a break point here and then since it has been tested.
So, we will what we will do is we will directly go for.
So, you will be seeing that if there are errors it will ask you whether with errors it has to go for the debug since no errors.
So, it will go for the debug.
So, now, I have as you can see the handle is in the main the flower bracket where it is flashing.
So, it is ready to run with the thing.
So, I have put the breakpoint as I said.
So, we will run this code and then you will see it is going to run up to printf.
So, that will not have any error.
So, you will be seeing that the sum of the values what it has got changed and where location if you want to check in the variables what we have the values here.
So, now what we will do is we have to plot that is what we have in the thing output what we have to see it.
So, what are the thing this is the desired signal what it should look like and this is the adapted signal and this is the error you will be seeing it is initially high and then it is coming down.
So, we will observe whether we have got these results.
go to tools and then we will put the graph single time.
What we want is iterations is 60 and all of them have been declared as float.
So, we will it is a single precision 32 bit floating point.
So, the first one will be calling it as desired.
So, you are seeing this is a cos what we have it.
So, now, again we will plot the other one single time.
So, this also 60.
Same thing it is a floating point what it has been chosen here floating point and start address is going to be I will call it as y out is what we want to have the thing.
So, I will give y out.
So, you will be seeing that initially it is low and then after that it will settles down.
So, now, we will see how the error is going to look like.
Again graph single time I will give this also 60 iterations and this also declared as float floating point and start address will be error function what I want to plot it.
So, you will be seeing that initially error is very high you are seeing it and then later on it is coming down.
So, it is 60 samples is enough to get your desired output that is what it is shown here it is there and then you are settling down.
So, it has whatever the desired signal.
So, what you are getting at the output.
So, you will be seeing this is the desired signal.
So, what we are trying to achieve initially we had the noise as sign.
So, which comes out as the cosine here.
So, that is the desired signal this is the output.
This is one of the demo what we had the thing.
So, we will stop here and what is the next demo we will be taking in our code composer studio.
So, this is adaptive filter for sinusoidal noise calculation.
So, here it is the adaptive noise, interrupt driven what we will be doing it.
So, what happens here is the same thing signal frequency is 2500 watt it is chosen with an added undesired sine wave signal noise frequency which is 1200 hertz.
So, one of the two inputs to our board basically here to the noise cancellation structure and then present the signal plus noise from the primary.
A cosine wave that is reference noise with a frequency of noise frequency that is what we have chosen 1200 hertz represent the reference noise signal and is the input to end coefficient adaptive FIR filter in this case.
We want to remove this as a noise and then it will be removing the noise from the signal and you will be hearing only one tone.
So, signal reference noise is strongly correlated with signal-signal noise, but not with the desired signal.
At each sampling instant the output of adaptive FIF filter is calculated and its n weights are updated and the contents of the delay line x are going to be shifted.
So, same way we will be calculating the error signal is overall desired output of the adaptive structure.
So, it consists of desired signal and additive noise from the primary sensor that is signal plus signal noise is included from which the adaptive filter output y n has been subtracted.
And, our input signal used in this examples are generated with the program and both the input signal plus noise and the output signal are output via the AIC 3106 codec on right and left channels respectively.
This is how what will be running the thing.
So, you will be putting the demo here.
So, what happens here is signal what we have it, the undesired 1200 hertz sinusoidal component of the output signal error is gradually is going to be reduced.
while the desired 2500 hertz signal is going to remain ok.
So, to faster rate of adaptation your beta or your mu can be changed.
It is too large the adaptation process may become unstable.
So, this is your signal and this is the reference noise what you will be generating it and putting it and you will be hearing that line out right and then left what you can hear the.
errors separately ok.
So, if you have a separation of left and right you can independently look at your CRO also and then see that.
So, what we will do is we will go for the demo.
What I need is the adaptive noise interrupt driven.
So, I have the thing already built in.
So, if I click on it becomes a active debug.
So, we will see that.
So, this is the interim driven what we have it.
So, we will be getting the data on the right and left channel and then you will be it uses the delay adaptation what you have it and in this case we will be using the GPU I will get input from left channel or right channel.
So, you can use the dip value 0 then.
it is going to output fixed out.
So, if it is otherwise if it is 1 it is going to put adaptive out ok.
So, what we will do is we will run the thing, we will compile it, debug it and then run.
I can close all these things.
So, I will run the thing initially you may not hear the both the sounds.
You are hearing the noise that is what the thing.
By changing the depth switch we can hear the clear sign away basically.
So, what I will do is I will show you by a graph basically what is the thing we have it out type will have adapt out hopefully it will plot it some will plot some 200 samples.
So, it is in this case it is showing your So, that is the error what it is coming out of our this thing audio signal ok. By dip switch I have not taken the thing you can experiment it by changing the GPIO dip switch.
So, you can hear the other sound.
So, the next one what we will continue with the thing is adaptive FIR filter for system identification.
of a fixed FIR filter as an unknown system.
So, what is it here also you have a dip switch basically, is to select either FIR out the output from the fixed unknown FIR filter or adaptive FIR out.
So, the output from this FIR filter what you will be getting it as a output.
Return to the right channel of line out on the kit and what you have to do is the error signal is always return to the.
left channel of line out.
So, that is what you will be one of the thing what you can select, but your left channel always error what it will be coming.
So, this is a unknown system you are trying to identify by adapting the weight for the FIR filter.
So, it uses a band pass filter that is 55 dot coefficient that is 55 coefficient FIR band stop filter centered at.
So, you can change the number of weights coefficients from 60 to 40 and verified slight degradation is going to happen in the identification process.
So, we will see the thing using CCS.
This is the system identification.
So, you have the system id interrupt dot c is the code what I will do is I will show you this code.
So, here the weight is that is w length is 256 and then the beta value or mu is 10 into e power minus 12 the learning rate has been selected and you will be getting the left sample.
I am unable to change the dip switch in this case, you can try it yourself and then see that you will be getting the output correctly.
So, the next one what we will have is the same thing there are different this thing what is it fixed FIR as an unknown system with weights of an adaptive filter initialized as FIR band pass filter in this case.
So, that is IDFIR init coefficients dot H what it will be using it and then what is coming out of the left sample ok.
This is the adaptive filter output left sample you are having the left sample and to the LDAC what it is going.
One thing I forgot to give the thing is it is going to read from the ADC.
And, then this is the DAC output.
So, what I have to provide is one of the sine wave what I have to provide it as an input.
So, for running this test signals it is given some of the test signals will be known some of the tones are there.
So, I can provide the sine 1000 this is a sound input to the system.
We will be seeing that it is continuously running.
So we will see whether the left sample has come or not in this case.
So, the input is coming.
So, because I am taking left sample and then I am outputting it whether it has adapted or not one has to look at it because there is a problem at the so, this is the noise what you have it.
So, you are outputting the noise in this case basically.
So, you will hear the noise anyway already you have heard it.
So, I am showing that what is the output happening ok.
So, the noise is coming out of the thing so once it is .
I will push this little down so that I can output my either filter output what we can output it.
This is how you will be changing the thing.
So, if I are out what I want to put the thing.
So we will do debug and then see whether I am getting the.
So, as you can see I have a phase j this thing error in the thing.
So, unless I solve this there is no point in line 27 what it says.
So, I have to come out of the debug mode I will go to the thing.
As you can see I have not removed it was 0 what it was taking.
So, there was a mismatch in the thing.
So, I have to correct the error and then recompile it.
So, when there is a error do not go and then load it on to the board.
As you can see that there is little error in the whatever the FIA filter what it is getting adapted to that is filter coefficients trying to remove this noise and then I should clean sine wave, but still there is an error.
So, this order is may not be sufficient for it.
So, you may have to go to higher order to remove the noise from the thing.
So, it is a little bit reduced, but it is still getting overlapped.
So, you have to fine tune and then work on it.
So, what is the next application what we will see using this thing in the board that is idea of fixed IAR as an unknown system in this case.
So, earlier we have seen it as FIR.
So, this is the pseudo random generation what you are doing it, IR filter through which you are passing and then looking into the thing.
So, here it is used as elliptic dot coefficient what it is going to be used for this purpose, the filter length that is because we know that it has to be one of the thing either I can use Chebyshev or Butterworth.
or elliptic.
Elliptic has the minimum what we have seen in the class is that it has both ripple in the pass band and then stop band.
So, which has a very minimum order for the thing.
So, we will go and then see whether we can work on this.
So, this is IAR.
So, I have adaptive IAR here.
So, we will make this is a active debug directory and then I will close the C file and open.
IAR adaptation.
So, you will be seeing that elliptic dot coefficient what it needs the thing when I open it.
So, you will be seeing that number of sections what it has is 3 that is numerator sections are 2 basically as you can see the thing and then denominator what you have it.
So, number of sections what we have it is that is second order this is the numerator the denominator of the first section and numerator and then denominator of the last section.
first section what we have it.
That is number of sections what it has is 3 b order is 2 sections what we have it that is fourth order filter first is the second order second stage is the second order section what we have it.
So, these are the b coefficients and these are the a coefficients what we have it.
So, when we run the thing we will build the thing.
what you are seeing the thing almost it is getting the noise it is not completely eliminated with fourth order what you are seeing it.
So you are using the update adaptive FAR filter coefficients in this case, delay line what you are doing it.
So still the noise is left out so it needs further training and then.
the order of the filter is very low in this case.
So, it is unable to adapt itself to the noise.
So, this example because I said it is audio wave file what we generated in the last class because it needs longer time to adapt itself.
So, it was taking longer time that is why I shown this demo in the last class.
So, this completes the adaptive.
filter up what I will say for different applications how we are going to run it using the board in real time.
So, whatever data how system ID identification it happened and how the noise is going to be cancelled and it can be non real time or real time what you can give the thing.
So, one more way of doing it is you can give separately the noise in one channel here it is mixed and then sent it as an.
input to the system.
So, one of them can be mic input the other one can be line input what you can give and then mix and then match.
So, that is what I was telling.
So, you can play around this board the way you want to give the input and then what you want to hear at the output.
So, thank you for listening to this lab.
Welcome back to real time digital signal processing lab.
So in the previous class we discussed about the Today, we will be seeing the demo of the linear predictive coding for speech synthesis.
So, welcome back and then we will see little bit of theory and then we will go for the demo both on MATLAB as well as in the board actually that is DSK board.
So, first the introduction because to give the feel of LPC what we discussed in the theory.
So, this is linear predictive coding is widely used in speech coding, synthesis, speaker recognition and for speech storage.
So, these methods provide extremely accurate estimates of speech parameters and does it efficiently.
So, the basic idea here is to closely approximate the speech sample as a linear combination of past samples.
So, as you can see in the equation.
So, what we have is S of n is the present sample for that this thing k is going 1 to p a k are the coefficients S of n minus k. So, for some values of p a k and then S will be predicting the thing.
So, coming to the architecture for both analysis and synthesis our speech is what is shown in the figure here.
So, we have the input speech we can select depending on which speech we want to have the thing and we have the digital filter that is FIR filter.
So, which is going to do the pre emphasis on the thing and this can be directly given as input to our moving average filter which is shown as lattice moving average filter.
So, one can go to the net and then check what is moving average filter.
So, as an input.
So, the other way is what you are going to give to overlap analysis window what it goes into the section.
So, next is it is passed through the hamming window.
So, this is the FIR filter what we are going to design and then we are going to check for the autocorrelation basically.
So, we have discussed the correlation.
So, here it is going to correlate with whether it is going to match with the present scenario.
and it uses the Levinson Durbin algorithm to predict the coefficients basically and this is given as input our lattice moving average filter.
So, we are going to do time varying analysis basically over the fiber net what it can be connected here we will be doing both analysis is this equation and synthesis is this part.
So, we will be incorporating both of it.
and then see the demo.
Otherwise in the normal case this will be becoming a channel and you will be sending it out and then at the synthesis part that is at the receiving part.
So, we have to depredict the thing that is we have to run the lattice filter this which is time varying moving average filter here.
So, analysis receiver what it is going to have and then the output is connected to.
our de-emphasis and then output is going to be predicted.
So, whatever input speech which is there which should be coming out.
So, what is the how it has been implemented little details have been given here.
So, first is because it is a speech which has to be segmented and taking the windows of it.
So, the speech signal is divided into overlapping segments for further computation.
So, the parameters used in this test scenario is window is the hamming window and window length chosen as 80 and window overlap is 40.
So, as you can see this is the speech signal which is a input signal and we will be considering the overlapping window.
So, you will be seeing that this is the window length and this is the hop length.
what it is called and this is the overlap length.
So, approximately you can take it as 50 percent of overlap what it has happened as you can see here it is given as 40.
So, that is what the overlap length what will be taken and these are the segments as you can see in this window length.
So, we will be cutting this pitch into smaller segments.
So, and so on and then till the.
end of the speech and processing is going to happen.
So, coming to the next is the autocorrelation.
So, what we have to do it on this windowed signal that is this is done to minimize the expected value of squared error between the predicted signal and the true signal value.
So, it is computed using equation as you know Rxx is the autocorrelation coefficient.
of k is given by m is equal to minus infinity to infinity x of m into x of m minus k. And the parameter for the autocorrelation function is the lag is taken as 9 in this case.
So, next is the Levinson Durbin algorithm for linear predictive coding what we have to use the thing.
So, the equations of the Levinson Durbin recursion basically it is a recursive algorithm.
which are used to compute the corresponding reflection coefficients and LPC parameters.
So, the equations you will be seeing that given by A2 as you will be seeing up to E. So, this is your expected value of 0 which is given by phi of 0 and K i is calculated with this equation.
So, for this thing is 1 less than or equal to i which is less than or equal to pi.
P ok. And then A i of i is given by this thing constant K i and then after substituting in the equation.
So, for j will be going between 1 to i minus 1 this is the recursion what will be doing it.
So, expected value of i is calculated with this equation.
And then the updation alpha j is given by alpha j p between.
J between 1 and then P that is the final solution what it is given.
So, when it matches.
So, the parameter is number of LPC coefficients chosen as 10 in this case.
So, coming to the analysis filter here it is FIR filter B is being used.
Uses the LPC coefficients as filter weights and this filtering removes formants from speech signal.
And, the remaining signal after the subtraction of filtered model signal is called residue.
So, what is it?
Y of n is equal to a naught into a naught plus a 1.
You may be wondering why a coefficients has been chosen.
Usually we choose a coefficients for poles and then b coefficients for 0s basically.
In this case you can see that a coefficients have been used for.
So, you will be having A naught plus as you can see this is Y naught is A naught plus A 1 into X of n minus 1 is the input plus A 2 into X of n minus 2 plus A 3 into X of n minus 3.
And in time domain is expressed in this fashion and in the Z domain as you can see H of Z is given by A naught plus A 1 into Z minus 1 plus A 2 into Z minus 2 plus A 3 into Z minus 3.
And, filter length chosen is 10.
So, you will be seeing x of n is the input these are the coefficients and then you are delaying the signal and you the other coefficients a 1 into x of n minus 1 or a 1 into z minus 1 what it is going to be coming from this length basically and you will be adding with your a naught and then you will be getting the y of n this is the filter structure what it shows that how it is getting calculated.
Now, in the synthesis part of it, it is the IR filter.
So, now, it must be triggering because the coefficients we have to keep the same a naught a 1 a 2 a 3.
So, here it is IR filter whereas, in the analysis we use the FIR filter.
Speed signal by reversing the analysis filter using the residue and LPC coefficients to recreate our formats.
So, we will be using the all-pole model.
of filter has the ability to describe most type of speech signals quite well.
So, whatever 0s in the analysis part now they become poles in the synthesis part as you will be seeing it here that is a reason why it was named as A coefficients.
So, you will be seeing that impulse response H of z is given by Y of z by X of z.
So, which is given by some constant.
G divided by 1 minus k is equal to 1 to p or a k p into z minus k. So, y of n is given as if we write in the time domain it is going to be G into z of n plus k is equal to 1 to p a k of p y of n minus k. So, these are the feedback path and even here it is parameter what is it filter order is chosen as 10.
equivalent to our analysis part.
So, coming to this the where all the LPC coding is going to be used applications what you will be seeing it in the speech compression example as GSM standard and then speech encryption in the voice codec also example is electronic music you can use the LPC coding and tonal analysis of musical instruments.
you can use and even in the speaker recognition.
So, these are the references to create the files what it has been used ok. Now, we will first see the demo in the MATLAB and then go to the hardware to check the thing.
So, first I will show you the LPC or this thing DSP because this student has chosen as the project to implement it in the course as I say students will be taking as a mini project or they can use it as an assignment.
So, what is it?
Frame size what it is chosen 40 as theory says frame length is 80 and LPC coefficient number is chosen as 10.
So, what is this part is going to do?
System object to read from an audio file and determine the files audio sampling rate.
So, when you are using it you may not know the thing.
So, what we will do is first we will read one of the file and then we will test it on the other two also.
So, this is a Kannada.
So, hold on what we are going to get through this.
It is a M4 this thing format students own voice is recorded and then it is stored in the MP4 format.
So, we will be taking input as we have to do the resample whatever the sampling rate may be the thing what we need is a 16 kilohertz.
So, input with 16 kilohertz and then sampling frequency what we want is resample.
for 16 kilohertz.
So, F s is going to be defined with 16 kilohertz here.
And then you will be starting and then some of the specific length of speech segment as 80 and then you have to do this zero padding to align on our this thing what is that length of it and then now you will be making some of the variables 0.
So, you will be creating a buffer system object and set its properties at that.
You get an output of twice the length of the frame size with an overlap length of frame size.
So, you what you want to have is although you are selecting 80 samples, 40 of them have to be overlapped.
So, that is why you will be choosing the buffer length twice that of it and then in that there will be 40 right side and 40 left side overlap will be there.
So, this is the signal buffer what you are defining with twice that length.
Next is each frame of a input signal is windowed using a Hamming window.
So, you will be calling DSP dot window which is given with Hamming window.
So, the 10th order autocorrelation coefficients are found using this equations.
So, you will be calling the function again DSP dot autocorrelator and then what is the maximum lag source.
property and then lag and LPAC your coefficient minus 1 and then scaling and biased or the input of this.
So, you will be this section what it does is calculates the reflection coefficients from the autocorrelation results using the LPC spectrum.
So, you will be calling the Levinson solver to get the coefficients as you are doing it.
So, then you will be creating an FIR digital filter.
used for our adaptive purpose.
In the analysis case also create two all pole digital filter system objects used for synthesis.
So, you have to create the filters both for analysis and then synthesis.
So, this is the analysis filter which is FIR filter which is declared and then you will be seeing that it is a moving average lattice filter which is being used and then you will be getting the coefficient.
here.
And in the synthesis filter it is all pole filter what you are designing it you will be giving the structure and then lattice all pole value basically that is auto regression what you will be setting it.
So, how you are going to play the thing it is going to be written audio writer.
So, you will be writing into the audio device or writer.
So, whatever the sample rate.
So, which is selected as FS in this case ok.
So, main code where LPC analysis and synthesis of the input audio signal using instantiations done whatever you have set it ok.
So, the loop stops when we reach the end of the input file.
So, which is detected by the audio file reader as a system object.
So, you will be seeing that frame size and then length of input minus 2 star.
frame size and then taking input in segmentation you will be taking it and then window each segment and then perform the autocorrelation here what you are doing it then calculate the Levinson Durbin algorithm in this place and then synthesis filter is IR filter basically what it is being used and then you will be writing in this thing and then you can play output audio.
So, writer what you are doing it and you will be after everything you have to close the thing.
So, you will be releasing the audio writer part of it.
So, we will as I said this is the first file what has been taken for reading and we will see the after synthesis sorry analysis and synthesis what output you would be getting it ok.
So, we will run the thing.
Were you able to hear it?
So the selected one is telling Namaskara.
So we can see once again running it.
Namaskara.
So, what we will see is we will run the other part of it.
So, we will open something what it has been stored wave file.
So, we will run this.
Good evening.
Did you hear the thing again I will play it.
Good evening.
So, this is one more.
As I said we can play with whatever your voice you want to have the thing.
So, we will see this one.
So, we can play the original and then see how it is going to look like.
So, now what I will do is this is from the MATLAB what we have.
So, I can show you how it is going to be from the original way file whatever is it and then what we were able to reconstruct.
So, it takes a little.
Time to play through the this thing.
This was the original.
So, what I will play here is from the this thing what is it analysis and then synthesis LPC coding what we have done the thing.
So, you would be seeing that there is a little.
difference with the original just you will hear the thing again.
But still it has a little meaning in the thing.
So, as you know LPC coding is 64 kilobits per second what we are going to have it.
So, the original voice in all the thing what you can hear it from this place.
play the other one original.
Good evening, good evening, good evening, good evening, good evening, good evening, good evening.
So, as you can see this is a female voice now we have to take mean score of opinion ok here.
So, what is it going to be?
So, you will be hearing this good evening how it is going to be it has got reconstructed through our LPC coding.
Good evening.
Good evening.
So, this is what what you heard ok.
So, there is a difference between the voice pitch and other things.
So, you have to move on to the other standards and other things and see whether we are going to get the correctly ok. That is what what you have to do it and then Matlab.
Namaskara.
This is the original voice.
So, you will be seeing that after you have already heard once again I am playing with the original and then the reconstructed.
Still it was able to do the thing with the some of the functions.
So, you can.
recreate much more.
So, before moving on to our demonstration in the code composer studio just I thought I will show you one of the application of our filter.
So, here it is usually we call it as a multirate signal processing which those who are interested can look into the thing when I want to convert my CD quality that is 44.1 kilohertz.
file to a midi quality what we call it as 48 kilohertz.
So, this is the input audio rate and then output audio we want it at 48 kilohertz.
So, how we are going to do it is going to be in stages what we will be reconstructing.
So, we will be having some filters in between when we are up sampling it and then we will be using the FFT that is audio and then FFT what it will be coming.
And then we will run and see this is one of the application of a filter.
So, here it is going to happen in three stages basically.
So, some of the filter you will be seeing it used here it is for decimation and then interpolation and then these are the two ones will be configuring to two the other one will be last one will be this one.
There will be three stages of it and we will see that each stage.
how it is going to run with the thing.
So, we will run this algorithm.
So, and then see.
So, what happened?
So, you will be seeing that if I make it maximize on the thing.
So, you will be seeing here these are the three stages through the filter what it has got passed.
So, from 44.1 what will be going to 48 kilo Hertz which is depicted with respect to this.
So, you will be seeing that initially it.
the red one was at 44.1 kilohertz.
Then based on our this thing both decimation and interpolation together will be converting in three stages to 48 kilohertz.
So, you will be seeing this is the black is the first stage and then green is what it is going to be second stage and this will be third stage what waveform it is going to look like.
So, as you heard from signal this is a sine wave ok.
There is no difference between your stages from one to the other one.
So, without compromising on any input data.
So, we can reconstruct from one frequency to the other frequency.
So, those who are interested so, this code will be up.
So, you can look into the thing and then see that if you want to do from one why do you why do you want to convert it into one frequency at this frequency because as you we are seeing it.
are speech is at 8 kilohertz and then from 8 kilohertz narrowband speech to wideband if I want to convert it from 8 to 16 kilohertz what I have to convert.
So, this requires multirate processing basically.
So, those who are interested as a beyond this course material you can go through and then get it.
So, we will stop the MATLAB demo here.
So, we will.
go into the code composer studio and then check the demo of LPC coding.
We will see how to proceed using the code composer studio.
So, this is the synthesis using LPC as it has been named and then we need some include files, Ivo files and some math library and then because we are going to use the codec in this case input and then output codec.
So, we need this AC3106 init dot h is our codec.
So, we will be including the hamming window as even in the FIR filter when I was demonstrating.
Usually we create using the MATLAB and all our filter coefficients and then keep it.
So, you can see here.
hamming dot h what I will open.
So, if this is the 80 order what it has been chosen ok ham 80 and these are the coefficients in fixed point format what you have taken.
So, fixed point format basically equivalent to what it represents in our board is integer format.
So, you will be seeing 80 coefficients what it has been stored here and which is used a scamming window coefficients basically this is the scaled version of it.
And here also again the overlap is defined with 40 length and then the frame length is defined with 80 that is twice that of it.
So, you can include this thing speech samples what it is being stored fine.
So, initially I have taken Kannada 2 dot hedge and we have the.
other H files.
So, we will see how does it look like because you will be seeing that total length is 19520.
So, this is the total length of the speech files what we have it and this is how what it has got stored with respect to what I will say is in the fixed point format.
So, you can see all of them are.
So, the first one.
So, after that what it is going to do?
So, we have to define some data section, when we want to have in particular data place will define as hash pragma that what we want this final output in the dot output.
So, that is store the output in external memory and we want the input to be.
also in the external memory then we will be putting it this way because it is length input and output are more.
So, the internal memory is less in the case.
So, we want to store it in external memory and you will be initializing basically.
So, to show that print is to debug basically in between if you are unable to get the output usually because this is a C code.
So, in between to debug it.
So, you give print commands and then see whether it is matching with MATLAB.
First usually all the codes are written in MATLAB and then tested that it is working because we prove it there sometimes we have the built in functions in MATLAB for all these things.
So, when we try it out and then it is working then usually sometimes we may not use the built in function we will write our own code.
So, that the code can be mapped into our code composer studio or any hardware for that matter even if you are designing your.
thing in FPGA usually in the MATLAB we test the thing.
So, algorithm or in using the python code one can write their own algorithm then will be going into or transfer it to our whatever hardware which supports the languages.
Usually in FPGA we use the Xilinx board basically there we use both.
VHDL as well as Verilog combinations to implement it even sometimes C will be front end and then back end will be VHDL coding what we will be doing it.
So, here also you will be seeing the front end in C I will as I promised one assembly program I will show you that how the coding length is going to reduce and then how you can predict what is the time it is going to take in later lab demonstration.
So, this is the interrupt driven.
So, usually here it is used is interrupt 4 actually and then you are getting some input sample and then you want to put it in some dummy like dummy file we say here dummy variable what it is going to be put and then we will be taking it out ok. And if the index is less than the total then you have to modify your input.
And then you will be making it 0 because your window length is less and then your input length is more.
So, you will be what I call it as circular buff of what you will be putting it and then taking into that area.
So, next is this is the segmentation function input into frames of size whatever length it has been specified.
So, from the start what it is going to do?
So, you will be allocating some memory basically and then you will be starting.
So, you will be bifurcating your input wave and then if you want to print it that signal loop and other things what you can print it so that it is entered into the loop ok. Then now comes the window function.
So, this multiplies the segment with hamming window.
So, you are seeing that here it is doing the hamming within the loop and then converting result from you can see Q format what it is shown.
So, because the multiplication is going to result with Q 30 format.
So, result has to be in the Q 15 format.
So, you are seeing that it is getting shifted by this thing 16 bits.
And, then here because we have two what we call it as sign bits that is why one left shift is going to happen and then later on 16 bits and then will be storing that in our this thing basically output which is going to show that whether it is coming or not ok.
So, then what it is going next one is your autocorrelation function which is being implemented in C as you can see.
So, this is X correlation.
what although it named as cross correlation.
So, you will be using same data so, that it can be for two different data set input or it can be the same input what you can provide.
So, you will be initializing your correlation 0 and then you will be looping till your frame length minus i.
So, that index does not spill over in this case.
So, you are doing the same basically what is it only to the size of your data.
And then you will be returning from this function and then next is the LPC function what it is defined here.
It uses the Levinson Durbin algorithm and then it is going to calculate your LPC coefficients from autocorrelated segment.
And you will be defining some of the variables and then allocating some memory here and then what are the loop functions.
You will be seeing that some of the K and E and then alpha what it is being defined in the equation.
which has to be incorporated and then you will be iterating with this thing i is equal to 1 to order as iteration is going to variable ok.
So, you will be seeing that whether it has entered into this for debugging purposes what you will be seeing in between printf statements.
Now this will be to the order you will be looping this is the start step 1 here.
So, you are calculating your sum.
and then k value and reference value and then you will be calculating your modifying your alpha and then you will be using it in your equation basically in the Levinson Durbin equation and you will be trying to minimize your error basically and then E of i and then you will be resetting your alpha value and other things and then you will be.
freeing all your memory here ok. And this is the residual function what it is being computed here FIR filter to calculate residual signal from windowed signal and LPC coefficients ok. Numerator size minus number of filter coefficients is equal to our number of LPC coefficients what it is getting generated.
So, this is the function what you will be writing it.
So, then You will be summing it up and then to check whether it is doing it correctly you will be printing it.
Then next for the synthesis you have to run your IR filter.
So, it is a all pull synthesize your speech from whatever you have done the analysis part of it and then you will be reconstructing it.
So, this is length here also IR filter length is 10 what it has been considered.
And then you will do your equation and then next is the buffering function.
So, you want to accumulate because only for 80 samples what you are doing it and then you are doing it in concatenation that is there is a overlap and other things.
So, you have to reconstruct your signal with removal of overlap basically.
So, you will be defragment and then.
put it in the concatenation using this function.
So, finally, you are all those are the functions which are defined and then main function what will be seeing it here ok.
So, all your outputs and then have been defined with 0 and then the loop what you will be giving it that is I trace for every speed segment length here it is 80 and overlap what we have taken is 40 and every overlapping speed segment is going to be windowed.
and do the autocorrelation later and calculate your LPC parameters and calculate the residual signal calculating using the FAR.
So, you will be doing the synthesis through IAR and output the accumulation based on overlap.
So, you will be seeing that these are the ones how you are going to free.
And since we are using 3106 here L138 we have to initialize the interrupt service routine.
So, we have to say what is the sampling rate we are providing it to the.
ADC, it is 16 kilohertz even DAC is at the same thing ok. And gains what usually it is going to be 0 dB what will be providing it.
And then input to this is going to be from LCDK line input.
So, even the output as here it supports both mic and then line input mic is we have a differential input whereas, line will have both left channel and then right channel input what we can take it.
So, that is how we will be working on one of the channel.
Or if you have two signals we can work on left and then right channel if it has been separately given and then we will be looping back.
So, now, what we will do is if you are doing it for the first time this code it will take little time basically.
So, since I have already compiled and then done the thing directly I can go and then do the debugging part of it.
So, you will be seeing that it has build has finished.
So, the memory map what you are seeing it how it is getting mapped into the boards memory.
And, then the code has to go and then load it on to the board.
So, you will be seeing that the pointer you will be seeing in the C code.
So, it has come to the main function where it is pointing to our program counter basically.
So, it is now ready for the debugging is happened.
So, I can.
this memory map.
So, you will be seeing so that your debug is going to be seen ok.
So, it has entered the main function here in the main.
So, which is what we call in its you can see the code both in C as well as mixed assembly I will show you in a while.
And this is where the entry point for the board basically C underscore int 00 this is the input what entry point.
it has reached the thing that is what it shows the thing.
And then these are the what it says is we have used the ECDIS 110 USB debug cable for connecting it to the board.
So, we will run and then I will you will be hearing the synthesized output from the board.
Now it's got a.
Now it's got a.
Now it's got a.
So, as you can hear that I am going to close my debugger as I did in the other example still the code is running on the board as you can hear it.
So, unless I reset it will be continuously running.
So, I can disconnect from the debugger as you heard the thing I can disconnect from my this thing system and it can run directly.
as an input and output this thing system unit.
So, we will see with other example how it is going to be depicted that is input voice signal.
Here I will take out from the this thing comment and then I will comment the other one.
So, it this it can be both in C and then C plus plus.
So, once I have done the modification I had to do this is going to do debug and then say any errors are present since I do not have any errors in the things.
So, what I will be doing is I can directly go into the debug mode.
So, it will debug and then as you can see there are warnings the section which was specified it says it has not taken the things.
So, some dot h files have to be given.
So, but still it is running so, we sometimes if it does not run some of the warnings you cannot ignore you have to check with the thing.
As you can see that it has become a male voice from the female voice.
So, the last one we will see whether you would be able to hear from the board or not.
I will be saving it and then I can give.
So, to give different this thing we can create a gel file and from there we can provide different sections so that while running itself I can modify it.
Otherwise I have to do debug and then.
the thing ok.
So, here it is you are able to at least hear the female voice, but for the good one of the voice almost getting I think swallowed or something it is coming out as a god in name ok. We have seen the LPC speech coding basically both in MATLAB and then.
in code composer studio using 6748 board.
So, we will see other examples of scrambler echo and equalizer in the code using code composer studio on the 6748 board in the next class.
Thank you.
Namaste, welcome back to real time digital signal processing course.
So, we are discussing about the speech coding, why do we need it.
So, today we are going to continue with the speech coding.
So, in the last class we discussed about the OCODERs and then how the GSM model look like and then today we will look at our this thing code excited linear predictor encoder.
So, how the graphical representation of kelp encoder is look like.
So, what we have is a speech input.
And, then here it is error weighting and then minimization.
So, that is whatever error which is going to be generated from this is going to be try to minimize this error from the thing.
And, this minimized error is fed into our excitation code book and the same error minimized error is going to be transmitted.
So, in this case.
And here is our this thing speech input from the linear predictive filter.
So, which is going to be subtracted from the thing and you will be generating the error.
So, which is going to be minimized ok.
So, the same input is going to go into our coefficient determination basically and then even the gain determination is going to happen from the speech input.
Then these are the LPC coefficients.
which will be going into our linear predictive filter and will be for this the input is going to come from the gain and this filter output is fed as the subtractive for our this to generate minimize our error.
Then our to the coding thing what we have this LPC coefficients goes as the input our mixer.
And, even the gain factor is given to this mixer and then all these three get mixed that is error here earlier only normal error was given here we are going to do the minimization of it that is fed into our mixer mix it and then this is our kelp output.
So, that is how code excited linear predictor is going to work.
So, coming with the this thing coders that is general kelp architecture looks like this.
So, what we will have is encoder is the one from the sender side.
So, we have the code book and we will be feeding in to this the perspital error is what is coming from the weighting filter and based on it you will be calculating your gain is your output.
And, then what we have is a fine structure that is the pitch what is calculated whether it is voiced or unvoiced.
So, we will be taking in the unvoiced case pitch and then we will be feeding it to the long delay correlation filter.
So, this is the pitch lag what the parameter which is coming out and from the code book you will be having the optimum code word what you will be generating and from the gain you will be putting it to the gain.
And, then the next one is our spectral envelope basically how we are going to look at it that is short delay correlation filter what we are going to provide the thing.
So, to get our LPC parameters.
So, these are the four that is even the code word and then the gain pitch lag and then LPC parameters are passed through this is our channel as you can see the thing.
transmission channel which goes through the channel.
So, the other one is we have the reference of the original speech and what is calculated.
So, we will be doing the subtraction of the thing.
So, we will have the objective error which is going to be fed into our waiting block and then we will be calculating the perpetual error and then we will be feeding it into our code book.
So, what happens at the decoder?
So, we have the optimum excitation which has come from the encoder.
So, we will be providing the gain basically whatever decided at the encoder also and we will be doing this pitch this one pitch synthesis filter what we are going to extract our pitch lag and we have the LPC synthesis filter there it was LPC analysis filter we will use the synthesis filter here.
And, then combining the thing so, we will be creating our output speech.
So, you may be wondering how these are the things is going to happen in the lab we will see that how these can be generated and then we will be as an application LPC coding will take it up and then how it creates the synthetic speech in the lab.
Now, what is it?
So, what it says is NATDMA IS 54 speech coder that is if we are using the sub band code book approach termed vector sum excited LPC that is we self see what it is going to be named in that case what is the thing is going to happen this is our I that is code book 1 and then this is a Y1 is the output.
So, what we have is the Y1 is goes as input and then comes out and then we are having a code book what is input to that is part of L2 L actually and this is our Y2 and then gain whatever you are putting into the think system these are the gains Y1 Y2 Y3 are the gains and then this is the code book 3.
So, you have the H parameter and beta is the gain for this.
So, these are the filter coefficients what it are going to be generated.
Then, you will be seeing that all the from the sub band you will be adding them up and then going to give it as LPC synthesis filter it is going to be passed and this are the output.
So, the filter coefficients which are been calculated will be going into our output for combination.
So, how we are going to evaluate the speech coders?
So, that these are the basis one is qualitative comparison what we are going to do it that is based on subjective procedures in ITU what it says is RECP 830 that is in the page 830 it has been specified.
So, based on it one has to do the qualitative comparison.
That is subjective is you will be putting various subjects basically.
To hear these voices and that as we said mean opinion score is going to be taken from each one and then say that how much has said that it is quality is good or bad or based on it what we have to calculate.
As we can see that mean opinion score how it is going to be graded if somebody gives excellent which has the value 5 and 4 for the good.
And, fair has 3 and 2 is poor and then 1 is bad.
This is the MOS one is going to have the thing based on it you would be subjecting different subjects to assess the quality of the speech based on this parameters.
So, the other one is major procedures that are going to be followed which are the ones that is absolute category rating.
That is subjects listen to samples and rank them on an absolute scale result is a mean opinion score.
That is in this case only they listen to the output and then qualitatively they compare the thing.
But here they have to do the absolute basically that is here the original and the synthetic speech what is being generated both of them they have to be able to.
absolutely compare and then give the mean opinion square sorry mean opinion score for that.
So, that is what it says is comparison of mean opinion score that is CMOS what it says.
So, it is much better has the value 3 better is 2 slightly better is 1 about the same is going to have 0 and slightly worse is minus 1 and worse you will be taking it as minus 2 and much worse is minus 3.
So, these are the scores basically.
So, what does it how the comparison category rating is going to be generated based on this that is subject listen to coded samples and original uncoded sample PCM or analog basically any one of them because we know that PCM is very good that two are compared on a relative scale.
So, result is a comparison mean opinion score which is based on this.
what the subjects will be giving.
So, these are the procedures one will be following in comparison or evaluating speech coders.
So, further how it is going to be evaluated.
So, based on mean opinion score for clear channel environment that we call it as no errors in the channel, result vary a little with language and speaker gender.
So, as we know the accents from one person to the other one it is going to vary.
So, based on it one has to do that analysis.
So, you can see that the standard what it is given whether PCM standard or CT2 or DECT or TDMA or GSM or Q-KELP quantized KELP what we call it and then this thing LPC coding.
So, quantized KELP you will be seeing that hybrid.
RALPC it can use or hybrid kelp what it can use and then LPC will be using the vocoder technology and we saw that the ITUG.729 is going to use hybrid kelp.
So, what are the bit rates for these standards basically.
So, we know that PCM is the waveform based.
So, which is going to have 64 kilobits per second.
So, what was the that is.
MO is value which is given is 4.3 for this.
Whereas, our adaptive which is going to use differential PCM which we said it is 32 kilobit per second.
So, the mean opinion score you can see is 4.1.
Whereas, it says DECT is the ADPCM what it is going to use at 32 kilobits per second.
So, this also has 4.1 whereas, our TDMA technology that is hybrid V cell PCM you can see that the bit rate is 8 kilobits per second.
So, which has MOS of 3.
So, whether you can as you will be seeing that the transmission rate is very low in this.
So, whether with this degradation you can accept this.
where in your application not much is required.
So, you can use it so that you can save on the channel basically.
Whereas, GSM as you can see which is the lowest what you can see 1.3 kilobits per second which is going to use our hybrid model that is REL PCM basically.
So, which gives the M O S score that mean opinion score of 3.54.
So, that is the thing GSM is much more popular and then quantized kelp you will be seeing hybrid basically kelp what it is going to use which is at 14.4 kilobits per second.
So, the mean opinion score you can see it is varying between 3.4 to 4.0.
So, it has a better quality and then hybrid kelp which runs at 9.6 kilobits per second.
which has at the minimum that is what it is shown at 3.4.
And our LPC which uses a vocoder speech coding techniques which has 2.4 kilobit per second.
So, the you can see very low mean opinion score what it has.
And G dot 729 which uses the hybrid kelp which is at 8 kilobits per second.
So, which has 3.9 score.
compared to our this thing what is it TDMA hybrid which has 3 at 8 kilobit per second.
So, depending on the thing so, you can select that is as you can see that even the gender is going to matter.
So, if it is a male voice and female voice so, we will see in the lab how it is going to vary and then you can decide on it what.
you want to select for your coding techniques.
So, continuing on the evaluation types of environments recommended for testing coder quality.
So, on what should be our environment on which you will be testing this quality.
It says clean channel no background noise.
So, you have to provide this so that you can evaluate it.
The other one is vehicle that is emulate car background noise.
So, if you are using the thing, so you will be seeing that you have to emulate the car background noise and then you have to hear these speeches for giving mean opinion score.
The other one is if you are considering the street then emulate pedestrian environment.
So, when the pedestrian is walking on the street.
what are the noises will be present.
So, you will be using that to get the evaluation from the subjects.
The other one what it says is HOT that is emulate background noise in office environment that is voice band interference what you are going to do that.
So, consider environment above for cases of what is it perfect channel no transmission errors random channel errors what you can consider.
And, bursty channel errors so, when you are want to check the channel errors which you have want to consider and then see what will be the mean opinion score given by the subjects.
So, you may consider repeated encoding or decoding that is you will be seeing that mobile to mobile call one you can have it and then say that what is the because you are putting it in the clean environment and then simmers that is emulating these things.
and then you are asking the person to give his mean opinion score you are not within the chamber.
So, you are outside.
So, then you will be having the finishing the thing you can ask them to give the score for that ok.
So, how you are going to do the codex selection?
So, you we know that for cellular need to consider basically quality, complexity, delay and compression rate.
So, these are the standards which are available ITU that is international for telecommunication standards.
G dot 711 is 64 kilobits per second.
So, in this case coding delay is going to be 0 and even the decoding delay is 0, but we say the complexity of this is low.
Whereas, G dot 729 which has 8 kilo bits per second and the delay is 15 millisecond and then decoding delay is 7.5 millisecond sorry coding delay is 15 milliseconds and decoding delay is 7.5 millisecond and the complexity of the code is medium in this case.
If you use G dot 723 the versions are A and B what you have it.
So, that is it can run at 6.4 this thing kilo bits per second or 5.3 kilo bits per second.
Then the coding delay is 35.5 millisecond and decoding delay is 18.75 millisecond and the complexity is high.
So, one has to accept which you want to have the this thing coding techniques you want to use in your work basically.
So, if you do not want to have any delay then you can use this G dot 7 11.
So, we know that what are the 3G standards specified that is two competing 3G standards.
Both standards use multimode kelp vocoders in them.
So, that is 3GPP that is CDMA 2000 and 3GPP UMTC what we have the thing.
So, here it is multimode rate set in this case.
Here it is AMR NB multirate what it will be using it.
So, here it is going to be variable bitrate O coder and source control of bitrate and channel coding treats all bits in this case equally.
Whereas, you will be seeing that it is the fixed rate O coder what it uses and voice activity detection is going to be discontinuous transmission network control of coder rate what we are going to consider.
and then Taylor's channel coding to speech coder what the standard uses in the 3G.
So, what is it because as you know that wherever silence is required.
So, we can use that and then you have we have to put that silence also in our speech basically.
So, if the silence is not required.
compressed we know that it will be taking more number of bits.
So, much of a conversation is silence what it says is according to the standard approximately 40 percent is going to be the silence zone.
So, we need not have to transmit that, but it has to be incorporated in the receiving end.
So, what it says is it is going to do voice activity detector VAD that is hardware to detect silence period quickly.
So, you are building the thing in the hardware.
So, we are going to use variable bit rate coders basically to reduce bit rate when silence.
So, I need not because I need not have to transmit this and say only that it is from this to this the silence zone.
So, how we are going to take care of the discontinuous transmission which is called DTX ok. Stop transmitting frames and second minimal number of frames to keep connection.
up.
And what the other one is comfort noise generator that is CNG that is synthesized background noise avoids did you hang up.
So, that is how you will be having the noise generator and a random noise or reproduce speakers ambient background to cancel it out.
So, for example, in the GSM codec and popular voice over IP which uses G dot 723.
1 codec has what is it all the 3 of them that is our voice activity detector and then discontinuous transmission and the comfort noise generator which have been combined and then supports the thing.
So, in the CDMA 1 and then CDMA 2000 codec use variable bit rate approach.
So, that is what we will be using it.
So, you can see that how the silence compression can be done.
This is what you are seeing the A 1 this is the speech signal what we have it.
So, you are seeing the here are voiced or unvoiced what we have it.
In between you will be seeing the silence zone.
Here also it is a maximum silence zone what you are incorporating after that it is the silence zone.
And then how this thing B 1 is going to look at it that is variable rate.
coding what you will be doing it.
So, you need not have to you can transmit as 0 here wherever the silence zone is there and you can see here also.
And then the other places what you can say that it is that is a variable rate basically that is b 1 which is number of bits are going to be very less for these places and then when there is a signal you will be using the high bit rate.
So, that you can get the value of the output.
So, that is how you will be having the variable rate there.
So, that you can avoid the silence zone with minimal bits and how the pulse is going to be generated that is kilobits per second.
So, you will be seeing that this is a peak after that because this is a silence zone as you can see maximum silence what we have it.
So, which.
goes down and then again you what you will be having it and then down.
So, this is fixed rate with what you have is this thing VAD and then DTX incorporated in the sample speed signal how it is going to go about it.
So, the next one is what we have is the voice coding that is basic voice coding approaches as we have seen that it can be waveform or vocoders or hybrid vocoders what you can use it.
So, how we are going to do evaluation of vocoder quality.
So, we have to see that code book based vocoders use in new technology and we know that in 3 GBP and then ITU recently standardized a that is AMR wide band KELP basically and then input in this case is 50 hertz to 7000 hertz.
So, we are moving from narrow band to wide band signal as you can see rather than 300 to 3400 this was the telephony standard.
and this is the new standard what we have it in 16 kilohertz range of current systems.
So, more natural quality speech that is slightly higher bit rate what we have to account for.
So, this covers our speech coding.
So, the application of speech coding what we will look in the next class.
Happy learning and thank you for listening to this lecture.
Welcome back to real time digital signal processing course.
So in the last class we are discussing about the discrete cosine transform.
So we will continue.
Today also on the discrete cosine transform.
So, in the DCT 3 we covered little on quantization and then how we are going to have the quantization matrix 2 that is eliminate the lower part of the coefficients that is AC coefficients in DCT matrix.
And later on how we did the run length coding and then in the process of recovering we will be using the Huffman coding.
These are the things what we considered in the last class.
So, today we will see how we are going to consider the DCT implementation in.
So, one of the application we said it is in JPEG applications.
So, that is in the analysis program that will be running on the that is our UW parallel computing labs cluster has the thing and then potential uses are in the in this lab what they use is for the application is in the agriculture that is webcam is go images can be analyzed for fruit.
that is ready to be harvested and workers can then save time by only going to areas that have fruit.
This is one of the examples or application what it is given in the web basically and the other application what they use it is in the parking.
So what is that?
It is webcams can be placed in a parking garage and their images can be used to identify areas with open spaces.
So this is one of the example in the parking lot you can identify if there is any empty space then you can go and park your vehicles there.
The other one is the web search what is that images can be found over the web that are similar to an input image and images can be analyzed then stored as keywords to be used in searches so all we usually type the basically for web searching and if you are interested in some part of the images if you have liked the thing so you want to see that similar ones then you can keep that as a reference and then you can find out how many of them are available.
As an example in some of the applications if you want to run your machine learning algorithm you need lot of images of that variety.
So, it is in that case it helps us to give up search for the typical those images.
So, as you can see in the agriculture.
So, that is how you are going to sort the image according to amount of red as compared to a baseline photo.
So, you will be seeing that whether you want to segregate them.
So, that is based on the red if it is intensity is more you want to have it as first and later on the next one and then which has the minimum.
So, this is one of it.
So, this will show that some of the ripe fruits if you want to go and then pluck it.
So, you can concentrate on these area to pluck them.
So, little whatever later on you know that how long it will take for this tree to get more ripened one.
And, then here you are not seeing any red in the thing.
So, you know that fruits are not ready in the thing.
So, you can predict also and then see only those places what you can go and then pluck it so that you will be saving some of the time of farmers.
So, the we know that this is how we have introduced our DCT that is discrete cosine transform.
So, we know that it is going to store the cosine waves.
them to a set of coefficients what we have given the values here.
And we know that JPEG uses an 8 by 8 DCT.
So this thing what we will call it as 8 by 8 reference image basically basis function what we call it.
So we will be having 8 by 8 basis function to find out our we will call it as coefficients.
So, visual band as a wave what it is shown here.
So, this is from Wikipedia source what you will you can go for more detailed one in that to see it.
So, now coming to the human vision.
So, what is it we said already in the previous class the better detect differences in light and dark than in color images.
As you have this is a RGB image.
So, we have a red green and then blue.
So, if you bifurcate them as luminance as we discussed in the last class.
So, you will be seeing that you are.
able to identify the person in that is Y component and then chrominance that is Cb and Cr they are little faded.
So what we said was we can do the compression in this domain.
So that is what it is given luminance and Cb and Cr are the chrominance values and can be sub sampled first basically.
So what is the sub sampling we are going to do it.
So we are going to keep the chrominance Y0, Y1, Y2, Y3 as it is that is.
And, then we can do 2 by 2 that is a chroma subsampling.
So, how we are going to do average is Cp and Cn value to save space basically.
Common sampling ratios are 2 by 1 in the horizontal or we can have 2 by 2 both horizontal and then vertical ok.
So, what we say is cheap cameras that is webcams mostly use this.
2 by 2 standard sub sampling basically.
So, these are the CBCR.
So, you will be sub sampling to either 2 by 1 or 2 by 2.
So, as it says webcams convert it into 2 by 2 for chip cameras.
So, what is that that is what it says is JPEG minimum coded unit.
So, this is the smallest amount of data that can be coded in a given JPEG.
So, how do you say that that is size is going to depend on sub sampling.
So, if we are doing 2 by 1.
then it is 16 pixel by 8 pixel what has to be stored.
So if you are considering 2 by 2 then it is going to be 16 pixel by 16 pixel what you will be taking it.
So this is a image taken from NASA what it is projected to show that how the subsampling can be done.
So to give you a JPEG the steps that are involved in summary.
So first what we do is a color space conversion.
So, from RGB we will be converting it into luminance, chrominance and the YC, BCR basically and then we will be doing this chrominance subsampling is going to happen.
Then later on we are going to do the DCT.
So, we know that just the DCT is not going to give us the reduced size of the image.
Later on we will go for the quantization.
So, as we said in the previous class quantization we can use P is equal to 1, 2 or 4 depending on how many values you want to store it.
So, that is decides the quantization, how much you want to have it.
One has to be careful that.
So, that is the quantization.
near the edges.
So, we may lose the information.
So, one has to look into that when you are doing the quantization.
Then once the quantization is done, so we will be in the DCT we will be going for the run length coding.
In the IDCT because we have to reconstruct the image.
So, we will go for the Huffman coding what we had discussed in the last classes.
And then the reverse process is going to happen that is whatever the quantized signal has to be re quantized and then IDCT what we will be doing it and then we will go for the chrominance subsampling in the reverse direction and then we will convert from YCRBR to RGB image and then we will be displaying it.
So this is how JPEG in summary looks like.
So now we will see that how we are going to implement this in hardware.
So to give again a flavor of what is DCT and IDCT the code has been given that is one dimensional what we are considering it.
So we have E of k into n is equal to 0 to n minus 1 X of n into cos.
2n plus 1 pi k divided by 2n, n is we can choose it as 8 by 8 or it will be the size of the image what we are considering.
So, if it is we are using it in the direct DCT form, k will be going 0 to n minus 1 that is our image size n by n what we have considered here.
So, in the reverse process IDCT we consider 2 by n.
instead of multiplying by root 2 by n in both the cases we consider only in the IDCT form 2 by n. So, this will be going from 0 to n minus 1.
So, it will be E of k into x of k what you have computed and cos 2 n plus 1 pi k divided by n and n will be varying between 0 to n minus 1 in this case.
And our constant E of k is given by 1 by root 2 if k is equal to 0 and it is going to be 1 for.
1 by root 2 into x of 1 so on 1 by root 2 into x of 3.
So, all the x 0 to x 3 has to be summed and then we have to multiply by root 2 to get x of 0.
To get x of 1 so we will expand the thing this equation by substituting n is equal to 0 to 3 in this case.
So, which is going to be x of 0 into cos pi by 8 and x of 1 into cos 2 pi by 8.
plus x of 2 into cos 3 pi by 8 plus x of 3 into cos 7 pi by 8.
So, we are substituting n is equal to 0 to 3 in this assuming r k is equal to 1.
So, now, what we call all these are cos functions what we have we call it as coefficients.
So, if you want you can expand x of 2 and x of 3 also to get 0 to 3 coefficients.
So, here this is x of 3 what you have to expand it and then write down those coefficients.
So, now coming to in the matrix form if we substitute these values as we have got it expanded 1.
So, we will see how it is going to look like.
So, my capital X of 0, X of 1, X of 2, X of 3 are written here and we know that the first coefficients is going to be 1 by root 2.
So, which is going to be multiplied by X of 0, X of 1, X of 2 into X of 3.
3 as a input and then the next second row is going to be pi by 8, 3 pi by 8, 5 pi by 8.
So, you will be adding 2 pi for all the things.
So, the last one will be cos 7 pi by 8.
So, you will be seeing in the third row it is going to start from 2 pi by 8 and then you are going to add this thing what is that 4 pi to this.
So, you get it as 6 4 is 10 pi and then 14 pi.
So, because that is multiplication what we have it 2 into 2 because x of 2 what we are doing it 2 into 2 is 4.
So, it will be plus 4 pi.
So, it is going to be 6 pi same as that.
Now, the next one is cos 3 pi by 8 and then you will be adding 6 pi to that.
So, 3 into 2 is 6.
So, it will be 9 pi by 8 and so on.
So, now, we because we know that we can simplify thus.
So, when you write the after simplification.
So, what we are going to get it.
So, in terms of negative what you will be representing because you will be doing 2 pi plus 4 pi.
So, which is nothing but minus cos 2 pi by 8.
So, by substituting all this these are the coefficients what we will get it.
So, we say whether it is symmetric or asymmetric rows what we are going to have it fine.
So, now coming further continuing with the matrix form.
So, we will represent we call this is a c 2 coefficients what we can represent for 1 by root 2.
So, the next one is pi by 8 is c 1 coefficient, 3 pi by 8 is c 3 coefficient.
Now we can represent this is minus c 3 and then.
this is minus c 1.
So, the next stage is going to be c 2 coefficients cos 2 pi by 8 and then minus c 2 minus c 2 and then c 2.
So, the same way the last row what we can represent it as c 3 minus c 1 c 1 and then minus c 3.
So, we will know that 4 point DCT needs 4 coefficients.
So, that is c 1 to c 3 n minus 1 coefficients.
that is what it is going to be used it is shown here n minus 1 is 3 coefficients that is c 1 c 2 c 3 what we need to represent our coefficients here ok.
So, the some of the new variables how we can modify the thing is.
So, what we have is here we know that it is c 2 this is x of 0 and we have rewritten the thing.
Now, what is our x of 0 we have to sum up.
all this and multiply by C2 and same way what we will be doing for X of 1 is it is X of 0 minus X of 3 into C1 plus X of 1 minus X of 2 into C3.
Because we will be combining this C1 and then this C1 and this C3 and this C3 so that our number of multiplication is going to reduce.
So it will be X0 minus X3 we will subtract this and multiply with one coefficient same way for the other thing.
So you will be seeing for X2 and X3 the same way you can combine them.
So, now what happens?
So, we will write it as from what we have is original we need because it is a 4 by 4 matrix we need 6 multiplication.
So, what we can reduce this one to 6 multiplications what you are seeing it that is 1, 2, 3, 4, 5 and then 6.
So, we have reduced from 16 multiplications to.
6 multiplications, but addition is going to remain the same.
So, now we will see intermediate products how we will be representing it.
We call it as X of 0 is given by P0 plus P1 into Rc2.
So, what is P0 which is going to be X0 plus X3 and then M0 that is because we are calculating the negative part of it X0 minus X3 and P1 will be X of 1 plus X of 2 and M1 is represented as X of 1 minus X of 2.
Then we will be reordering thus we will be seeing X of 0 is given by this equation X of 1, X of 2, X of 3 in terms of P0 M0.
P1 and M1 is given by this equation.
So, how we are going to represent in the butterfly form?
So, we know that X0 and then X3 is going to be minus, first one is X0, we are going to take this one X3 to this X0 plus X3 is my P0 output and the later on X0 minus X3 will be my M0.
Same way we will put it for X1 and then X2.
So, that is x1 plus x2 will be P1 and x1 minus x2 will be my M1 here.
So, what is happened here?
We have the reversed input order just like our DFT.
So, we are having x0, x3, x1 and then x2 right.
So, coming to the second stage what is the thing is going to happen?
So, we have P0 and M0 and P1 and then M1.
So, next stage is we have X0 is P0 plus P1 into C2.
So, we will be multiplying with C2 coefficients in the last stage after adding with P0 M0 we will be getting X0.
So, the next one is what we have is X of 1 is M0 into C1 plus M1 into C3.
So, you have to have a M0 with C1 coefficient and then M1 with C3.
C3 coefficient.
So, this is what you will be C3 coefficient.
So, you multiply both of them add them you will be getting your x1.
Now, x2 is what p0 minus p1 into C2.
You are taking p0 here minus what you are going to do p1 multiplied by C2 will be given output as x2 and x3 we know that m0 into C3 minus m1 into C1.
So, what we have m0 into So, what we have is here it is multiplied by C3 here and then M1 is multiplied by C1.
So, after the this is a subtraction that is minus what we have it.
So, we will be getting x of 3 as the output.
This is how we can write our butterfly structure.
So, the final thing what we have 4 point DCT is given by this complete butterfly structure.
x0, x3, x1 and x2 are the inputs.
So, we will be getting actually input is going to be small x0, x3, x1 and then x2.
Output is going to be capital X0, X1, X2, X3 in line with our FFT what it is shown by combining these two butterflies.
So, intermediate you will be seeing that P0, M0, P1, M1 and this is the output you will be seeing there in order x0, x1, x2, x3 and in input has got reversed in this case.
So, now extending the same thing from 4 point to 8 point how we did with respect to DFT.
So, we will do it for 8 point DCT.
So, you will be seeing that input that is output is capital X0 to X7 input is small x0 to x7 what we have it in terms of coefficients you will be seeing that from a C2 because it is a.
n by 2 what we are going to have it that is 8 by 2 is 4.
So, the first row is going to be c 4 coefficients you will be having it.
After that you will have c 1, c 3, c 5, c 7, c 9, c 11, c 13 and then c 15.
So, you will be writing this way fine.
So, all the coefficients you can write it in this fashion and then later on as we see the symmetry thing what you will be looking into the thing.
So, we will be reorganizing my you will be seeing that my C10 is going to be minus C6.
So, how many coefficients I needed here can you guess it?
We said in 4.33 coefficients in 8 point we need only 7 coefficients.
So, that is C1 to C7 what we are supposed to have it.
So, we have to organize in that manner when we do that you can see the simplified matrix.
what it is given in this case.
And then you will be seeing that these are the outputs and multiplied with x 0 to x 7 in order.
So, how we are going to represent this in a matrix form.
So, one of the famous thing is what they call it as ACF and then BDEG coefficients form to put it in FPG.
So, you can use the butterfly structure last will I will be showing it otherwise most of the FPGA implementation use this format that is we call it as instead of x0 output will be y0, y2, y4, y6.
So, this is our DCT or E1 coefficients what we are going to combine with the coefficients ACF ok.
So, that is what for the E1 and you will be adding x0 plus x7.
x1 plus x6 and x2 plus x5 and then x3 plus x4 and these are the odd coefficients bottom.
So you can put them in bottom y1 y3 y5 and then y7.
So they need BDEG coefficients to compute and the input of this will be x0 minus x7 and x1 minus x6 so on and this one.
So now to compute with these coefficients back okay IDCT.
So, how you will be using in the that is y0 to y0, y1, y2, y3 what you will be calculating it.
So, you will be using the ACF coefficient in the top portion, but you will be seeing that input is going to be that is bit reversed that is x0, x2, x4, x6 not completely bit reversed in this case even anyway what you will be considering it here same as our FFT.
So, here it will be x1, x3, x5 and then x7 what will be using the thing and then when you multiply with this BDEG coefficients and add them.
up you will be getting the y 0 to y 3.
Then what you are going to do is do the same thing, but you have to subtract with this BDEG coefficients which are getting multiplied with odd numbers.
So, you will be getting the higher that is y 7 that is y 4 to y 7.
So, you will be seeing that it has come in the reverse order.
So, y 7 will be first and then y 4 will be coming later on.
So, this is how you would be reconstructing with the same.
coefficients both in DCT what you will be using it and then in the inverse DCT also.
How we are going to do that?
So, you will be putting that is if you are putting 8 bit 1D DCT when you are putting in this format.
So, that is y is equal to our matrix A into X the matrix with coefficients whatever we have discussed in the previous one that is ACF and then BDEG.
So, you will be seeing that.
all these are a coefficients and these are b, d, e, g minus g minus e minus d and minus b and then the rest of the coefficients are getting filled like this you can go back and then cross verify it and then which are what are the are a, b, c, d, f, g coefficients.
So, it is nothing but root 2 pi n. So, a is cos pi by 4, b is going to be cos pi by 16 and c is this one cos pi by 8 and then g is going to be cos 7 pi by.
So, this is for the 8 by 8 matrix.
So, you can substitute it will be much faster and then computation.
So, the symmetrical property of that is what the DCT coefficients what you have seen the thing IDCT after adding it DCT part what we said by multiplying it what will be getting it.
So, the same thing again it is shown that how from IDCT DCT or DCT to IDCT what you will be traversing with the same type of coefficients.
So, how the architecture in FBGA is going to look like.
So, this will be x is the input.
that is we call it as data recorder unit and then we will be having the ACF matrix vector multiplier and the other one is BDEG matrix vector multiplier and then we are going to have the inverse data recorder unit basically that is output is going to be z coming out of it and then what is z.
So the same data you will be doing the transpose the memory and then get it as y and feed it in the reverse direction.
So this is our ACF matrix and this is our BDEG matrix so you will be you can go from Y to X or X to Z.
So, this will be transposing and then putting it as input and then will be working it out.
So, this is how the hardware implementation is going to happen in FPGA.
This is data recorder unit in the thing.
So, you will have the transpose of memory and you have the ACF matrix vector multiplier input will be coming to here and this output is going to be given to our draw.
inverse data recorder unit here and we will be doing the transpose and then we will be getting the BDEG matrix vector multiplier and then we can feed it in and then we will be taking the output from here.
So, if we are using it in the DCT you can use it in one direction and then if I want to have the IDCT the same hardware is going to be used in the reverse direction as we pointed out in the thing.
So, to give you a flavor of how the 8 point DCT.
I want you to work it out how much we have reduced in the 1DCT with the butterfly structure.
So, you will be seeing that these are the stages what we are going to have it S1, S2, S3 and S4 compared to log2n stages in FFT.
So, we will be having log2n plus 1 for 8 point as you can see there is Sy stage also will be coming in the outside part of it.
So, this is our X0 and then you will be combining with minus S7 input A and B what you will be showing it as a matrix 4 point what you can take it and then put it across this is the even side this is the odd part of it.
So, I want you to work it out so that the output is going to be V0, V4.
V2, V6.
So, input is in order output is going to be in the bit reversal format what you will be getting it.
The odd side you will be seeing that it is V1, V5, V3 and V7 and these are the sine and cos function.
So, if those are interested in this paper I will be uploading it in the thing how they have reduced number of multiplications and additions.
So, that it comes to.
13 multiplications in this case one more paper reduces from 13 multiplications to 11 multiplications with 27 additions along with that.
So this is how you can implement it in hardware that is butterfly structure with cos and sin functions what it has been given and then you can see that to the normal DCT output whether this output for the 8 point what you will be getting it.
gives the complete summary of the DCT in hardware.
So, have a happy learning and then thank you.
Hopefully you have enjoyed this course.
So, we will do the summary of the complete course in the next class what all we covered it and then we will discuss how we can implement it in hardware and then how we have done our labs and other sessions based on the theory part of it to verify our outputs.
Thank you.
Welcome back to real time digital signal processing course.
So today we will discuss about speech coding the first part of it.
So, in the last class to give a recap of the class.
So, we discussed about the graphic equalizer.
Why do we need the graphic equalizer?
So, we said that in different applications even wearing your mobile phones when you are using it so you can make the audio equalize so that whichever part of it you can hear.
Even in your music systems you can use the graphic equalization to get clear cut voice if you want it or if you want to suppress and only have only musical instruments you can have the thing and then use your voice for recording and other purposes as we said that is the application one can use.
So, for that we will be using the graphic equalizer and then if you want to completely block the outside noise also noise cancellation what you can do that.
So, today we will see little bit on speech coding, why do we need it and then what is the advantage of it.
So, what is it?
We know that digital speech which convert analog speech to digital form and then transmit digitally.
So, applications of digital transmission we know that noises whatever channel noise is added we can do the cancellation what we have seen it in the previous classes.
And, then even the storage as we know that we can compress the speech and then keep it and whenever we want to do the thing.
So, we can decompress and then use it.
So, the applications what we will be seeing in this case is as you are seeing the thing first one is in the telephony that is basically in cellular wired and then internet voice over IP we need.
speech conversion and in the speech the speech storage.
So, that is automated call centers.
So, you can record the voices and then you will be playing it.
So, most of you may be receiving it in the automated through your mobile that these are the facilities available or why do not you register and other things voice messages will be coming in your mobiles.
and in the high fidelity recording or voice what we need the thing speech coding.
And next one is all of us know that it is text to speech that is machine generated speech.
So, we will be seeing that for the physically disabled people and then the challenged people who are unable to hear the thing whether we can play them from the text whatever the materials we have most of it we have in the text form whether we can convert it to speech and then they can if they are.
auditory system is good.
So, they can hear the thing and then they can understand.
So, this is one more application what we will be seeing one can work on.
So, what are the issues?
So, one of the issue what we say when we are transmitting or whatever we need the efficient use of bandwidth.
That is we can compress to lower bit rate per user so, that we can cover more users in this particular bandwidth.
And, then we have to look at the speech quality.
So, want what we say is tall grade or better quality in a specific transmission environment.
So, environment is noise is bad, but still we want to have a better quality in the thing.
So, the other one environment itself plays an important role.
So, that is what we call it as bit error rate basically.
So, how many bits we want to transmit or whether we can.
send lesser number of bits and then how much packet lost is going to be one of the challenges one has to look at it.
And then if they are out of order the packets are out of order and then what is the delay.
So, these are the issues when we are transmitting directly.
So, by coding and then we can account for all this losses that is environment losses then we will be able to reconstruct our code at the receiving end properly.
The other issue one has to look at it is hardware complexity that is the speed basically both coding at the sending end and decoding at the receiving end will have a delay.
So, which is going to be defined by what is the hardware you are going to use it.
So, if you are using the software so, we will be seeing that delay will be much more.
So, if we have the codecs basically then we will be having.
much speed.
Then computation requirement and power consumption always one has to keep it in mind.
So, power consumption in most of the handheld devices which is an important criteria and we should not be foregoing the computation basically.
So, we have to cater to whatever the coding techniques we are going to use it.
So, one has to be supported in your hardware.
How we are going to do the processing of speech?
So, we say that in speech coding in wireless systems all this thing 1G systems have analog speech transmission in that and we know that in 2G and 3G systems have digital speech and what is the type of source coding we are going to have it which is going to vary.
So, we will see it in a while now.
So, what is the motivation for digital speech?
So, we want to increase the system capacity as we discussed in the previous slide and then whether is it possible to compress the speech.
So, if it is possible we want to compress and then storage is one of the thing.
The other one as we said even the transmission multiple users can be compressed speech of them can be transmitted in the single line.
And then what is the quality or bandwidth tradeoffs can be made depending on.
are this thing speech.
So, how to improve the quality of speech that is usually will be having the error control coding that is ECC what we call it and possible and as we discussed in the last class even the equalization what we can do using different techniques and then many more what we can use it to improve the quality of speech.
And then how to improve security as encryption possible for privacy.
So, one of the example we said scrambling, where I can scramble my speed signal and then this is the way one can do the encryption or you can do in multiple ways and then at the receiving end whether we can do the decrypted speed signal what we can do it.
So, and then at the same time we have to keep it in mind that reduced cost and operations and maintenance what we have to be considering it because most of the units.
for majority usage we need this parameter to be considered.
Coming to the distinct communication system in wireless mode what it shows in this diagram is we have the source place and we are going to do that encoding basically there.
And then after that we are going to encode the channel also and then use the modulator to.
generate the signal and pass it through channel.
So, if we know the channel, so we will be encoding that also.
And then in the receiving place we are going to do the demodulation.
So, it is corresponding to whatever modulated modulation technique what one has used it.
And then we will go with the channel decoder and then we will be doing the source decoding.
And last is our destination.
So, that is receiving this is from the sending end to this is at the receiving end how the wireless communication system looks like.
What is the characteristics of speech basically?
So, we call it as bandwidth most of energy between 20 hertz to about 7 kilohertz.
So, and then we know that human ear basically sensitive to energy between 50 hertz to 4 kilohertz.
So, that is the reason why what earlier narrowband speech was 8 kilohertz sampling rate what we were using it.
For all now mobile communications we know that the bandwidth what it is going to be covered is in this range.
So, we will be going with the wideband speech which is 16 kilohertz basically.
So, you will be seeing that what is the auditory which is given by this curve based on the things.
So, narrowband and then wideband will be using based on it.
So, the next one is based on the time signal.
So, we say that it is highly correlated and then the speech is short term stationary.
So, for a while we can consider it as it is stationary and then we can process the signal.
So, we classify the speech into 4 categories what we call it as one is voiced basically.
So, we say created by.
air pass through vocal cords example like ha we you will be seeing that.
So, you are seeing the speech how our mouth is going to be considered.
So, we have the lips here and then this thing what is it teeth is here and our oral cavity and this is the nasal cavity what we call it as and then some of the other pharynx and then esophagus what we will be having.
So, this is the vocal folds what we have it.
which will be vibrating and the other one what we call it as unvoiced that is created by air through mouth and then lips.
So, example S F so, you can feel that when you are pronouncing it how the air is passing through your mouth as well as through the lips.
The other one is mixed or transitional or in between what we call it and the other part of it is silence.
So, if nobody is speaking or whatever so, we say that that is the silence zone.
So, these are the four categories one can classify the speech in two.
Now what are the characteristics of speech?
So, we said voice signals are produced when the vocal cords vibrate during the pronunciation of a phoneme what we call it and unvoiced signals by contrast do not entail the use of the vocal cords.
So, as an example so, you can see that.
utterance of 2 what you do the thing and this you call it as the this thing.
So, you will be seeing that consonant when we are pronouncing 2 t this is how the phoneme is going to be generated slash t and then u w the consonant slash t is the unvoiced speech.
So, this is the duration where you will be having it as unvoiced and then look like a noise as you can make out here.
So, then what happens while the vowel u w ok, voice speech is characterized by the strong fundamental frequency.
So, you will be seeing that which is coming with the thing.
So, you can use MATLAB to generate this, this is a time versus amplitude what is given when you when we take up in the lab the example.
So, we will see that how when a voice signal of 2 is given how the.
samples are generated.
So, you can see the same thing in the frequency domain this is what it is shown in the time domain.
So, now, we will come to the digital speech.
So, we say that speech coder why we need it device that converts speech to digital.
So, we will be seeing that it can speech coding is bifurcated into it can be waveform coders or O coders.
So, in this case you are seeing the span how it is varying.
So, you will be seeing the broadcast quality what you are seeing from 64 to 200 here and then the tall quality what you will see from 16 to 64 what it is going to be.
So, this one comes in the waveform coding basically and communication what you can see is from 4 point sorry in between that 5 to 9.6 or little more than that what you have the thing.
And this is the synthetic quality what we can generate the speech from here to here using O coders.
So, O coders are spanning between 1.0 to 16 in this case as whereas, our waveform coders are spanning between 4.8 to 200.
And when you want to use both of them, so you can generate the hybrid coders basically in this domain.
So, what we say is that is waveform coders.
They convert any analog signal to digital form whereas, vocoders that is we call it as parametric coders basically.
It is try to exploit special properties of speech signal to reduce bit rate and then it will be building the model of speech that is transmit parameters of model basically.
And whereas, the hybrid coders combine features of both waveform and then vocoders and then speech coders are generated.
So, what are the quality of speech with various coder is shown in this diagram.
So, usually what we do is mean opinion score.
So, it is a subjective measure of quality that is we put we generate the speech and then we will call the persons to evaluate whether they are able to identify the voice whether it is male voice or female voice and then what it has been sentence has been uttered.
if it is sentence generation and then we will say that what is the opinion of them then we will be calculating the mean opinion score from different characteristics of the people when they evaluate the thing.
So, the other one is trade off in quality versus data rate versus complexity what it is going to be shown.
So, you have seen here that general speech quality versus transmission rate has been plotted.
this is the x axis whereas, of here it is MOS is our mean opinions core is put the thing.
So, you will be seeing that synthetic quality is the data rate goes with 8 kilobit per second to 64 kilobit per second that is what you have seen in the previous one also.
And then you will be putting the source coding is on this side of the line.
So, and then the waveform coding goes.
beyond a 16 kilo bit per second.
So, you will be seeing that synthetic quality is at the bottom and then communication quality just spans between the two of them and the tall quality and broadcast quality has as we have seen in the previous slide also it is going into the waveform coding.
So, you will be seeing that beyond what we can have is 16 kilo bit per second whereas, the hybrid So, you will be between that synthetic and then communication.
So, it lies in this domain and you will be seeing that mean opinions code is very high for our broadcast quality.
And then we will be seeing that it is low for our synthetic quality of speech what it is getting generated.
So, you will be seeing that how to select your now coders.
So, we say that waveform coders what we call it as PCM pulse code modulation all of you would have heard the thing.
So, this is the waveform coders what it does basically convert any analog signal to digital basically A to D converter.
One has to use to do the conversion of speech and analog signal sampled as we know that it should be more than twice the highest frequency component.
Then, what we are going to do is we are going to do the quantization into n bit samples.
So, when we had taken the number system we have seen how many the number of bits what I am going to represent my input signal even the speech coding is going to have the same thing.
So, you are seeing what we want to represent is in a linear way, but what we are going to depending on the number of bits.
So, you will be seeing that it will be.
the nearest value what will be representing it which is the error what we have taken is minus delta by 2 to plus delta by 2.
So, that is what the error what will be getting in representation.
So, n bit samples what we are going to represent it.
Then uniform quantization what we have seen the thing and example is here what will be taking is pulse code modulation and the band limit speech for this is less than.
4000 hertz.
So, pass speech through plus either a mu log compander or a log compander.
So, for more details you can refer to the textbook for what are the companding it is going to happen.
And here the sample is what we will be taking at 8 kilohertz and usually it is 8 bit samples.
Then what we have is a 64 kilobits per second what we can represent and this is a digital rate.
that is digital sample output rate what we are going to get from this representation.
So, as you will be seeing that it is 8 into 8 is 64 kilo bit per second what we will be getting it.
And how is the characteristic of this?
The quality is very high and then we know that complexity for pulse code modulation is low and bit rate as we can see that it is high and in this case it is delay is going to be low.
And, robustness of this is high.
So, coming to that is PCM speech coding system with analog companding then digital conversion the standard the what we will be seeing is that is international telecommunication standard ITU which is G 700 standard basis for speech coding in our PSTN in 60s at you can see in the.
are digital lines whatever telephones what we have it.
N60s is given by this.
So, you will be seeing that this is an analog input what we have is a band pass filter, then we will have the analog compressor here and then sample and then hold circuit.
So, which is going to use the mu log compander and then what the output we will be getting it.
is pulse amplitude modulated time basically what we will get.
And then we will do the conversion analog to digital conversion which it is known as pulse code modulation here and we will be putting it in the transmission medium digital to analog conversion what we have to do it.
And then here again analog modulation you will have it this is the whole circuit.
So, and then.
You have the analog expander and then use a band pass filter to get the analog output.
So, the mu lock expander was used for this purpose fine.
So, what are the companding techniques one has ok. What it says is analog compander emphasizes small values and deemphasizes large values in order to equalize a signal to noise ratio across the samples.
reverse the mapping at the receiver with an expander.
So, one is compander the other one is expander at the receiving end.
So, the thing is given as f of s basically that is sign of s. So, the natural logarithm what will be using it 1 plus mu of s because mu law compander is being used and then divided by ln into 1 plus mu.
So, what is the mu law companding how it is going to look like is shown in this figure.
So, we have the input.
And, this is the output.
So, 0 is no compression is done.
So, you are seeing it is a linear what it is getting passed.
And, then f mu is equal to 5.
So, this is how the companding is going to happen.
And, then f mu is 55.
So, you will be seeing that it is the companding is going to be in this way.
So, that is what the frequency what you will be generating and then sending it out.
So, now, coming to pulse code modulation speech coding, this is digitally companded PCM system.
The standard for this in ITU is G.711 standard.
So, what it has?
So, better quality speech than analog companding as in the previous case.
So, we will see how it is going to be the thing.
And you can modify this PCM coding to differential PCM which is known as DPCM.
to reduce bit rate from 64 kilobit per second which was in PCM to 32 kilobit per second.
So, since the change is small between sample transmit one sample in this case, then on transmit difference between samples use 4 bits to quantize and adaptively adjust range of quantizer that is it is going to improve the quality.
So, what you will be when you are doing adaptation, so DPCM is going to be.
named as ADPCM which has the standard G dot 7 to 6.
So, you can see from G 700, 711 and then 7 to 6 for the ADA PCM.
So, what we have here for the this thing PCM transmitter.
So, you know that it is analog input, you will be band pass filter what you will be using it to eliminate what is the kilohertz what we need it.
If it is in the 8 kilohertz, we know that it is between 50 hertz to 4 kilohertz that is what the samples what we are interested in.
So, that is the reason why what we have the bandpass filter here.
And then do the sample and hold a circuit basically, we call it as a PCM transmitter.
So, again a PAM and then you will be converting analog to digital form.
And what we have is the linear PCM what will be.
taking the output and we will use the digital compression here.
So, this compressed a PCM is going to be transmitted through the transmission medium basically.
Then this is going to be our receiver part which is going to be in the reverse direction as you can see.
So, we will be expanding the thing from compressor will be expander is going to be used here and then this again it is a linear PCM what it is going to be used and then.
will be converting into digital to analog converter and then this will be analog modulation whatever we had the thing and then we will be having the whole circuit and then convert it into or using the band pass filter.
So, we will get back our analog output.
So, this is the transmission as you can see PCM transmitter and then PCM receiver.
So, these are the blocks which are present in the transmitter and then these are the receiver blocks which is going to work on it.
So, coming to what is the this thing are differential PCM speech coding how it is going to be because what we said is from 64 kilobits per second we are reducing it to 32 kilobit per second how it is going to have.
So, we said that it is going to be what is it transmit is going to be one sample that is since the change is small between the sample.
So, we will use transmit one sample and then transmit difference between the samples what it is going to be.
So, we will be using only 4 bits to.
do the quantization.
So, how does the figure look like?
Here it is the analog input, here it is going to be a low pass filter and then what you are going to have is here there is a differentiator basically.
So, that is a summer basically this is positive and negative.
So, you will be taking the difference between that two and then you will be doing the analog to digital converter and encoded different samples what you will be.
sending it out for transmission.
And the same thing what you are going to do is you can convert it into digital to analog converter and then put the integrator and then accumulated signal level what you will be subtracting from this and then the rest of the signals are passed through this.
So, what happens at the receiver actually?
So, it has to be same replica in the reverse way what it is going to work.
So, you have a low pass filter which receives the thing sorry this is the DPCM signal what it is coming and then you are going to take it to the to the digital to analog converter and then you are passing it through the integrator in this case and then you will be adding the signals from the hold and circuit.
to check that the difference between the signals and then reconstruct it and then which is getting passed through the low pass filter and then we will be getting the analog output.
So, this is how our differential pulse code modulated speech transmission and receiver looks like.
The other way of doing is we can do the sub band speech coding.
So, what is it?
We are going to partition signal into non-overlapping frequency bands.
And, then use different A to D quantizer for each band.
So, we will be seeing that as an example.
So, if we have 3 sub bands.
So, we know that this is 5.6 kilo Hertz and 12 kilo Hertz and 13.6 kilo Hertz here.
So, sorry it is in the 3 bands what you will be having it.
So, then you can reduce from 32 kilobit per second in the DPCM to 31.2.
2 kilo bit per second.
So, what is it?
The range is band there are these are the 3 bands what you have it.
So, you will be having 50 to 700, you will be using only 4 encoding bits because most of the signals are present in the thing.
So, you will be giving more number of bits in this range and lesser 1 bit less in 700 to 2000 range and we know that not much information is here.
So, only it is going to be.
with 2 bits.
So, that this is how total what it is going to be generated.
So, what happens to this?
So, here it is going to be this thing so many kilobits per second what we have to transmit in this frequency range basically and this is the kilobit per second and this is in the third band what we have to do it total will be generating 31.2 kilobits per second.
So, how does it this is going to be looking like?
So, as you can see the name itself says that we are going to have 3 bands.
So, we will be using band pass filter in the first stage to pass only 50 to 700 hertz and then the second one is band pass filter in the range 700 to 2000 hertz and the third range is going to be 2000 to 3400 hertz.
These are the 3 bands and we need A to T gun converters in all the 3 bands.
Then, later on mix them and send it through the channel encoder.
So, this is how subband speech coding is going to happen and in the decoder part of it you will be reconstructing.
So, we will see little more on the vocoders and speech coders in the next class.
Thank you.
Welcome back to real time digital signal processing lab actually.
In the last class we discussed adaptive filters in MATLAB.
Today, we will discuss about adaptive filters in Code Composer Studio.
So, we will see that one of the thing what I will do is because the we have one of the experiment that is FIR filter noise cancellation using external inputs.
This is from the book Real-time Digital Signal Processing by Ronald Ray what I have taken the thing.
So, which has the adaptive noise that is a.
2 in IR interrupt driven.
So, that is left gets the noise and then the right channel gets the signal.
So, using the IR filter the interrupt driven what it the demo is because the adaptive value for this is very low.
So, you will be hearing most of the type noise and voice is going to be very little heard in the thing because it has taken little time.
So, I thought I will demo this experiment first and then go back to.
other experiments.
So, what is it in this case?
A desired signal and a reference noise signal to the input to left and right channels respectively what we are going to put it in and a stereo 3 sample jack, a 5 3.5 mm jack what we will be using for inputting from the laptop to the board that is the plug in dual RCA jack plug cable will be used in this case.
And, a test input signal speech noise dot wave is fed through this jack and this may be played through a sound card and input the kit via stereo 3.5 M jack.
So, in our case we are using my music basically and this is the speech noise what we will be feeding into the board.
So, we will build and we will be running this program and test it using this wave file.
So, this adaptation will be taking place the output on the left channel of line out should gradually change from speech plus noise to speech only.
And it has to be adjusted with the volume at which you play the file speech noise dot wave ok.
If the input signals are too quiet then the adaptation may be very slow that is what the thing.
So, one has to look into these things.
Moving to the next slide.
So, we will see that this is the adaptation thing what it is being real time setup.
So, line in gets the right that is signal and line in left jack gets the reference noise and you are using the IR filter here whose weights are going to be controlled using the adaptive filter.
So, you will have the signal plus noise what it is going to come.
which is going to come out as line out R and the error signal which is coming out of left channel will be output.
And this is how you can look at the what I will say is weights basically how they are getting adjusted.
So, from 0 how they will be going up what we will look at the thing.
So, coming to our code composer studio this is the file what we have it.
So, that is adaptive to in IAR.
So, what we have is this is the it uses a bilinear dot coefficient.
So, if I open the coefficient thing.
So, you will be seeing that and then that is poles and zeros have been taken in this fashion.
This is a third order filter what it has been used.
Using MATLAB and the cutoff frequency what it uses is a Chebyshev low pass filter.
with 2B pass band ripple and cut off frequency of 1500 hertz.
So, when you design in the MATLAB, so you will be getting the filters that is type 1 as I was discussing in IR filter class that Chebyshev 1 will have a ripple in the pass band and then it has a steep cut off in the stop band.
So, the ripple what in the pass band is used 2 dB basically.
And these are the coefficients taken from the MATLAB and then it will be using in our a real time implementation.
So, you are seeing that this has been loaded.
And then the this thing beta whatever this is the learning rate in this case it can be alpha beta one each one uses their own notation.
So, what it is a very slow adaptation what it is been taken 1 e power minus 12 ok.
So, and then the length of number of adaptive filter weights what it is chosen is 128 and then you will be.
making variable weights and then your n and then number of sections what you will be taking it with 2 basically because you need both a and b coefficients.
So, then you will be what you are going to get is reference noise you will be getting from the left channel and then the signal is going to be getting from the right channel.
So, that is how it has been recorded and then stored in the thing.
So, we are going to have these two mixed which is coming into our board and then this is you will be inputting reference noise and then you are doing the filtering here basically.
You are calculating your Y n output and you are updating your coefficients W n and then you are putting input Y n ok.
So, this is signal noise.
has both y n plus signal.
So, then you are making it y of n is 0 and then you have the reference noise here and then you will be computing your error basically signal noise minus y n. So, you are trying to reduce this error.
So, and then you are calculating your weights n plus 1 weights basically here using this equation.
This is your mu adaptation parameter which is named here as beta.
And, you will be updating your XFI with the previous values new one will be coming from the input signal.
And output what it is going is both left and right channel has been put with error.
Error has to reduce and then slow down.
So, because if I rerun the code again so, it will be having lot of noise in the thing.
What I will do is because it has already been run for some time.
So, if you want you can change your beta value and then look at it.
So, I had stopped the thing I will be playing it and you will be hearing little voice and there will be little error it will take longer time to adapt.
So, still you are hearing the It will take longer time to adapt actually, still you are hearing the voice in between.
noise in this case.
So, as you will be seeing that I have removed the thing from running basically.
So, from the code composer studio still the input is going into the board and then it is running.
Only when I reset the board you will not hear anything.
So, this is the first experiment because it has lot of noise initially.
So, now little bit of speech is coming it takes longer time.
So, what you can do with.
the your codes basically you can play around with little more on your adaptation by changing the thing.
So, one of the thing what I can do is I can make it 0.001 in this case.
Let us see what is the thing is going to happen.
I can store it and then I have to do recompilation again.
So, it is telling that whether I have to stop the debug session as you can see that here the diagram.
So, what I will do is I will stop the thing.
Memory was not getting cleared actually.
So, let us see it is some memory block it has still a reading error.
Let us see whether it is going to run.
I will be playing the thing.
In these cases in what you have to do is you may have to restart your board by unplugging it and plugging in.
So, all the software reset what I have switch is there I have given the reset command still it is not working.
In that what we do is we unplug and then plug the.
board.
So, that the complete memory is going to be erased.
So, this is one of the thing one has to do it.
So, just we will see whether it is going to have any effect on because I have a re-plugged my power point.
So, even if this occurs one has to take care is that no other go you have to reboot the system for the timing let me see whether I can figure it out without doing that with different experiment whether I can come up with the thing.
So, I can close this project and then restart the thing.
So, the other experiment what I will do is the first experiment will look at it.
weight does not need the real time this is the non real time what we will see it.
So, what we have is this is the adaptive filter LMS algorithm as a C program.
So, it illustrate the following steps what is it for the adaptation process using the adaptive structure as shown here ok.
This is our weight normal adaptive filter.
So, I have the LMS algorithm in this case.
So, why weights are started with 0.
y of n what I will be getting the output and then this is the desired signal what I have given the thing and then we will be subtracting error we are trying to minimize this is fed to our LMS algorithm to adjust our weights.
So, this is the equation what we will be doing it that is y of n is nothing, but w transpose n into x of n and then a of n is nothing, but d of n minus y of n and our weight update w L of n plus 1 is.
given by this mu is the adaptive step one has to follow.
So, L will be going from 0 to order of the filter L minus 1.
So, by one repeat the adaptive process for the next sampling rate what we are going to do the thing.
So, how we are going to show the even all of you with simulator you can run this algorithm.
So, how we are going to show that filter structure.
The desired signal is chosen to be 2 cos 2 n mu into f divided by fs what we have it sorry this should have been pi basically sorry I cannot correct the thing pi into f is the frequency what you wanted and then fs and the input to the adaptive filter is here also it is sin 2 n pi into f by fs where the this is the signal frequency f is equal to 1 kilohertz has been chosen and sampling frequency f is equal to 8 kilohertz.
The adaptation rate mu, so that is filter order n you can change it from that is assumed as 0.01 and then 21 is the order of the filter, number of samples chosen as 60.
So, if we will 0 to small n is this thing 60 samples.
So, we can plot this desired output that is output y output and error using T.
tools in this case graph and then single time in the code composer studio.
So, within a 60 sample instance the filter output converges to the desired cosine signal.
So, you can change the convergence rate that is 0.02 from 0.01 and verify faster rate of adaptation and convergence ok.
So, we will see the demo what the book gives.
are the blocks.
So, what we will do is we will go to this thing, code composer studio and what I will do is I will remove because I wanted to show you how you can use the same thing to run your codes basically.
So, I can remove, these are the files what I have to remove from this, I will delete them.
And, then I can add from the code basically I have stored in D directory in this case wherever in your laptop you are computer you can store wherever you want to have the thing.
So, we will see that these are the LCDK book files what I have taken the thing.
So, in this case this is from the chapter 6.
So, we will be seeing that this is the first code.
So, I will copy this c file into my directory or I can input this project from here also ok.
So, one of the thing one can do it.
So, we will import it and then put it here.
I can do the paste and then I will be do first I can do the compilation to see that I have any error ok.
I know this is about google.
Ok.
I'm sorry.
So, there is a little problem in the thing because this is on a simulator what it is going to run on.
So, what we have to do is I can import the project.
So, what I want is the CCS project.
So, I will put it as next.
I will browse from this folder.
I have imported it.
This has become my active this thing directory basically.
Let me see whether I am going to avoid errors in the thing.
Okay.
So, you will be seeing the errors what are the things listed.
Here, it is telling that what it wants is V2CC XML active what it has the thing.
So, I had to open this, I had to remove this because what I have for the board is sorry, recent update.
I can create a new ok, what I want is the target configuration file.
So, I will be calling it as new target configuration.
So, in this case what I have is USB debug probe what I have it, Texas instrument we have to check on the thing XTS110 what I have it on the board, USB debug probe what I have it.
So, one has to be careful when you are doing it real time which is the debug port what you are connecting to ok.
So, here it is what I have is LCDK6748 port.
So, I will save this configuration.
So, those who have first time they will be doing the lab can discuss that.
how it has to be done I will be giving the procedures and everything.
So, now, we will see whether by doing the this thing compilation whether my error is going to go.
There are some of the errors which is coming in what I will do is I will fix up in the next class and then come back and then tell you what were the problems with it because suddenly what happened is my active directory got crashed and then I have to redo the thing some of the errors it takes little time.
So, which I will fix it and then I will be coming back in the next class.
Thank you.
Good morning.
So in this course, we will be covering real time digital signal processing.
So we will see first.
What is the need for this course?
Ability to collect data and then we are going to analyze it and then see how we can do the modification in real time.
So, whatever data collected we will be analyzing it and then we will be processing.
So, all in one location and in one machine we call it as hardware.
So, the platforms for this machine can be either through software that is we can use PC MATLAB.
the software or using lab viewer, code composer studio these are the things what we will be using it.
The advantage if we do it in the software is flexibility, it is resilient to all conditions and then all of us know that it is very easy to use that.
The disadvantage part of it is because the all softwares we know that it is expensive and then it is slow in nature and then we need platform like PC.
And, then additional hardware to collect the data from the software.
So, the next one what we can use is the firmware or hardware basically.
In this case we will be calling it as DSPs.
So, the advantage of using this firmware or hardware is speed, cost and then practicality.
So, we know that most of the DSPs were manufactured by TI analog devices and then other companies are there in this.
The other advantage is embedded code basically to run your DSPs which we call it as firmware.
So, the signals both collected and then processed by DSPs.
The advantage of using this hardware or firmware is faster and less expensive compared to software and then it is more flexible and easier to use than the hardware.
So, in this case we will be discussing the hardware in a little while.
The disadvantage in this case is also it is going to be slower compared to hardware.
So, the complete we use the solution to use the hardware is basically either field programmable gate arrays that is FPGA or we can go for digital circuits that is basically VLSI design what we can do the thing.
The advantage in this case is because all of us know hardware uses or FPGAs use less power consumption wherever the application is there or we have.
more number of units which have to come out then better to go for complete hardware design.
And then it is going to be fast in running of your algorithms or any application.
So, as an example FPGAs we know that Xilinx, Altira and then now recently Intel is coming with the FPGAs.
The disadvantage in hardware is because it is fragile.
we call it and then it is difficult to use because people should know how to design to the core level and then you should know the knowledge of architecture basically.
So, whether you are using the CMOS architecture or NMOS architecture.
So, you should know core level how to design your circuits.
So, the other level of it is what we can have is system level processors.
what we call it.
So, when we have high volume requirement then we go for the system of course processor design.
So, in the present lectures that is in real time signal processing it is designed to enable the teachers and engineering who are in that program.
And then facilitate the students to become good signal processing.
engineers.
And then this enables students to have hands on experience on the real time signal processing.
The course contains both the theory as well as lab component.
The course is going to be offered in three modules what we call it.
The first module M1 we call signal analysis and filters.
And then the second module will be covering frequency domain analysis.
And then the third module covers applications of some of the real time nature architectures and other things what we will be considering in the real time signal processing.
And, then we have each module will be consisting of one credit and then each module is offered in about 60 units of about half an hour video of lectures which have lab sessions also.
So, we are going to have weekly assignments and laboratory implementations because most of the colleges have DSK 6713 board.
hardware.
So, they can use them in the college or we are going to provide hardware interface.
So, those who want to do it remotely can be used the hardware which is available in our lab.
So, how this course is going to be useful?
It can be for working or aspiring faculty or faculties in engineering colleges.
So, because they will be having little difficulty in interfacing the board and then running some of the experiments.
So, it will help.
all of these people and then even the graduate students.
So, they want to develop some signal processing algorithms in hardware it will be of help to them.
Companies who wish to develop real time signal processing algorithms because we will be covering not just C programming or any other languages.
So, we will be little bit going deeper into the core level design.
So, that people will.
get the hands on information how it has to be coded in the higher level languages also.
And then companies can be can use it for training and then upskilling their employees.
So, what will be the course outcomes that is what we will be seeing in this slide.
At the end of this course that is three modules what we are covering it.
The learner should be able to that is basically module 1.
So, which you will be seeing the sub modules.
Understand DSP elements including your DSP functional blocks, DSP hardware options we will be discussing.
Fixed point and floating point DSP devices and what is the advantage of using fixed point number system compared to floating point.
Real time constraints what we will be discussing about it.
Some of the algorithms what we will be covering will be covered in this course and software development process.
So, this will take us somewhere around 3 hours to complete this module and then followed by what we will have is the lab 1.
So, use of code composer studio in simulator mode initially we will start for DSK6713.
So, the software is simulator software is going to be provided and then you can run few examples those who are unable to access the hardware board.
So, initially we will.
to in simulator mode.
So, the next this thing course outcome what we will be seeing it design low pass high pass band stop and band pass the FIR filters using windowing, handing or hamming or we will be using the case window.
And then same thing what we will be designing using Butterworth or Chebyshev 1 and then 2.
IER filters in cascade mode using initially MATLAB FDA toolbox.
I think it will be renamed as filter design toolbox in the latest versions.
So, whatever version is there students can use that because it is available in the net.
So, we are going to accompany this lab session with how to use the FDA toolbox to design these filters, how we are going to specify the specifications.
and then how we will be using these filter coefficients because the design is going to happen using MATLAB.
And then we will use this filter coefficients to your FIR filtering it can be real time FIR filter what we will be using it in either initially we can do it in the simulator, later on we can compare with the MATLAB code how it is going to work whether it is in a similar fashion or not later on we will be using the hardware to design the same thing.
So, input will be using some noise signal with the original signal and we will see how the filter is going to perform in its best way to get us noise removed from the input signal.
So, the third module what will course outcome is going to be design of our FIR and IR filters that is basically we will be taking care of quantization effects.
Because, in the analog mode we know that we do not have any quantization problems creeping in, but when we come to digital domain we know that quantization is going to play a havoc in so many other cases.
So, we will be seeing that how this effects are going to modify the filter characteristic.
So, that we will be able to check that whether we are in the permitted flavor or not.
So, the same thing we will be implementing in the lab with.
the low pass filter using C code using that DSK6713 board and real time scenario as I was mentioning in the previous outcome also.
Here what we are going to use is the speed signal corrupted with some noise.
So, that is going to be fed into the board and then we will see these filters how it is going to remove the all of us know that noise is high frequency component which is present in the low frequency component.
which is going to be removed and then we will be seeing the whatever the speakers what he want speech is going to be clean speech what it will be coming out of it.
So, we will because it is going to take little interfacing and other things what we have to discuss in hardware.
So, we will be taking around 2 hours to discuss about it.
So, coming to this we saw that we had signal analysis and then filters in the module 1.
two course outcomes are going to be as follows.
So, how first we will be determining the characteristics of signal spectrum using a radix II FFT.
And then we are going to apply it for long signals using overlap add and save methods.
And we will be using the DFT comparison with respect to FFT how it is going to be faster.
And then we will have the because we know that when we are in the digital domain.
We said that how the quantization is going to affect in the filters same way how in doing our frequency domain analysis and then comparing design part of it how quantization and even the scaling of inputs how it will be affecting the signals and how we are going to take care of it is going to be discussed in this module.
So, the accompanying lab part of it is going to be we will be analyzing the spectral basically whatever is given.
using the Radix II FFT.
In this case we will be using the DSK6713 board either in simulator mode or in the hardware.
So, the accompanying code what we will be writing is in C basically.
So, the next one is because how to generate different sine waves signals what we will be checking up because we know that IR filter.
when we put it in oscillatory mode, once the input is remote it can oscillate itself.
So, we can use this concept to generate sine waves with specified frequency and amplitude what we can run it.
And the other way of implementing is you can we can use the lookup table by generating sine or cos functions signals can be generated.
So, component to for the lab is will be using the IR filter in the oscillatory mode to generate sine wave using the DSK673, it can be used both in simulator as well as bolt.
So, coming to the next module that is 3 actually.
So, we will be checking little bit of applications what we have specified.
The first one is going to be how to improve signal to noise ratio.
That is basically will be speech or audio signals.
using LMS algorithm first in MATLAB what we are going to use it.
And then later on the lab component will be implementing in real time using DSK6713.
So, we know that FIR and IR filters have fixed coefficients basically, but if there is any noise in the input or in the surroundings they will be not performing whatever we would like.
So, how we can do the adaptive filter we will be seeing it using LMS algorithm.
So, the next outcome is how we will use this some of the design filters to generate synthetic output.
That is basically process this is baseband signals for one what we will be doing equalization.
So, all of us know that the.
How we can make all of you have heard about the karaoke or whatever may be the thing.
So, in your mobiles and other things what will be using it you will be suppressing the voice and then you will be having the instruments basically.
How you can record your own voice along with the instruments by suppressing some of it by doing equalization what will be looking at one of the application.
The other one we know that if we go for.
out station in a hilly region or wherever we speak about it, we know that how echo is going to be generated, can we generate the synthetically that is what we will be looking as in one more application.
Next one is reverberation basically lot of people will be speaking multiple things, how it can be multiple echoes what we can have it what we call it as reverberation, how we can generate it.
And then later on we can see that how this can be eliminated also.
So, the next one is all of us know that speech basically coding that is whatever the speech we are recording or whatever may be the thing there are different ways of storing them, how to do the compression and other things.
So, one of the example we will take it how we can.
implemented or we will be looking at basically in this module.
The other one we will going to have lab component after learning about the theory.
So, how we will use or whatever the filter we have designed earlier that is low pass, high pass and band pass filters in the baseband signal for the equalization, for the echo how we are going to delay the speech and then generate a echo.
and even the reverberation how multiple peoples are speaking what we can generate it.
And in the speech coding also some of the things what we will be looking using TSK board.
So, this is what this course outcome the last one what we will be looking in this module is going to be little flavor on the image processing.
So, in this case only discrete cosine transform what we will be looking at.
So, we will be seeing how fast.
8.1 ddct implementation in using code composer studio we can implement.
And then check that how this can be used in the 2D domain that is using separable transform to check the compression achieved for images in DSK board.
So, these are the course modules what we have it.
So, in the next session what we will be taking.
with the regular course basically basics of signal processing as a module 1 what we will be looking at.
So, what I will say is happy learning and then thank you with introduction of this real time signal processing.
Thank you.
Namaste, welcome back to real time digital signal processing course.
Last class we discussed about discrete cosine transform in 1D how we are going to reconstruct the 2D form.
So, today we will continue discrete cosine transform.
So, as we are continuing in the previous class as I said from 1D DCT we reconstructed for 2D DCT.
So, today we will see how we can do the that is inverse of 2D DCT how we are going to implement it.
So, forward DCT what we had seen the thing.
So, we know that y is given as c into c x transpose into transpose what will be taking it.
So, this is x transpose what we have it here and then the transpose of it will be giving as this way what is it y is equal to c into x into c transpose what we can write it.
Since c is an orthogonal what we had seen in the last class.
So, we can solve for x using the fact that the inverse of it c inverse what it is going to be equal to c into.
transpose basically what we have assumed it we have shown because of the orthogonal property.
So, therefore, what happens to this it will be equivalent to C transpose Y into C. So, how we are going to reconstruct this image in mathematical terms let X is equal to X side J be a matrix of N squared real numbers and Y will be YKL be the 2D DCT of X.
So, x what will be taking it and we know the a naught coefficient is going to be 1 by root 2 and a k is going to be 1 for k greater than 0.
Then what is our p n s comma that is comma t going to be represented as in the 2 d 2 by n is our scaling factor k will be going from 0 to n minus 1 that is the size of our matrix.
And, because it is a 2D so, I will be having a double summation.
So, y k l into a k into a l. So, into cos k 2 s plus 1 into pi divided by 2 n into cos l 2 j plus 1 into n by 2 n. So, this is how our 2D DCT is going to be represented.
And, we say that the satisfied P n l comma j equal to.
x i j for i comma j is varying from 0 to n minus 1.
So, how we are going to do the reconstruction of this?
So, the new matrix and then what we show is the compressed image here.
So, we have these are the values what it is available and then this is the image what it has been compressed to.
So, can you make the difference between the original?
because, I said this is a compressed image.
So, in the next one we will be comparing with original and then compressed image.
So, how much difference you are going to make out between the two what you can look at it.
So, as you can see that here you will be seeing the little bit of difference in the thing here it is white whereas, here what you are seeing is as white and then here you have seen that all of them have.
white in the thing that is after compression what we are looking at it.
So, that was this thing what is it black and white patches what you had seen the difference between the thing.
Now, we will see the image basically.
So, we have the original lena image and this is the compressed image.
So, is it possible for you to find the difference minute difference.
So, if you are too good enough you can find a difference between the two.
So, what is it we have discussed about the linear quantization in previous classes.
So, we will not zero the bottom half of the matrix.
So, that is idea is to assign fewer bits of memory to store information in the lower right corner of the DCT matrix.
Previous quantization what we did was lower that is half diagonal below that what we have made everything as 0.
So, here instead of making it 0.
So, number of bits allocated for this values is going to be made less.
So, that we can have the method of linear quantization included in it.
So, now how we are going to do that?
So, use the quantization matrix basically Q.
So, what is it Q K i is 8 P into K plus L plus 1 for 0 less than or equal to K comma L which is less than or equal to 7.
So, we say that p is called the last parameter and it is going to acts like a knob to control compression.
So, the greater p is the more you compress the image.
So, p can vary from 1 to whatever value you are going to take it.
So, if you look at it the quantization matrix p multiplied with 8 that is 16, 24, 30, 40, 48, 56 and then 64 are the values.
take 8 as the thing in the first row then you will be seeing that 1624 what you will be seeing it.
This is the multiplication of what you will be seeing is 8 what you are going to assume as the Q matrix.
So, that means, to say you will divide your DCT value with respect to this matrix.
So, that whichever is low values you will be seeing that they become very small and then you can represent.
them with the fewer bits.
As you can see that one each entry in the DCT matrix by the quantization matrix.
So, this is our DCT matrix and this is our quantization matrix.
So, what we are going to do is divide each element by each of these values ok.
The first one is our DC which is going to be divided by 8.
So, what happens it will be when p is equal to 1 this becomes minus 38.
So, you can compute and then cross verify whether you are getting it correctly or not ok.
So, the next one is a 210 is going to be divided by 16.
So, you will be seeing that is the 13 value.
So, you will be seeing for the rest of the values automatically lot of them have got 0s.
And you will be seeing that there are few coefficients which are greater than 0 are left on this.
And then here what you will be seeing it is few of them.
in the what we call it as this is the DC coefficient, these are the few AC coefficients on the top corner what is left.
So, when I use p is equal to 4.
So, what happens to that can you guess that when p is equal to 1 what we had the first one was 8 and 16.
So, whereas, when p is equal to that is this is p is equal to 1 when p is equal to 4 what will be the value of it.
So, you can see that.
So, this becomes 32 and so on ok, you can multiply with the thing and then you will be seeing that minus whether you are going to go it is easier to do minus 9 into your 32 whether it belongs to whatever value you want to get is minus 304.
So, are we getting it?
or you can do minus 3 naught 4 divided by 9 that will be the easiest way of representing it what is the p value what I have chosen.
So, approximately as I am putting it is 32 ok.
So, you eliminate the thing only retain the integer values.
So, you can see that compared to this the value has got.
quite reduced.
So, number of bits to represent this is very a fever bits.
So, can you guess how many bits I needed because I can go 0 to 15 with 4 bits fine.
Whereas, minus 38 means I can I have to go to the power of 2 always.
So, 64 is a maximum what I have to represent.
So, which I will be requiring how many bits can you.
compare here in this case.
So, 2 to the power of 6 is 64, I need 6 bit.
So, 6 bits to represent this value.
So, I have reduced by 2 more bits in this case.
So, it depends on how much detail I want to retain.
So, by using p is equal to 4 whether I can do with that is what it says there are 14 terms left in y in the case of p is equal to 1 whereas, in the new p is equal to 4 we are left with only 10 terms.
So, 4 terms have come down in the thing and then the number of bits representation for this is also reduced.
So, can you see now after doing that p is equal to 1 and then p is equal to 4.
So, what are the differences you are making out between the two that is what one has to consider and then see what kind of quantization matrix you want to use it to represent your output.
So, you will be seeing using the linear quantization.
with respect to p is equal to 1 and then p is equal to 4.
So, how you are changing the thing you can see here by grey value it has gone to completely white and then some of them some of it what you can find the difference.
But coming to the image you may you have not noticed p is equal to 1 later on we will see with p is equal to 4 how much difference we are going to get it.
So, in terms of memory storage what we look at it.
So, the original image what we had it 1 byte that is 8 bits per.
pixel what we wanted it to be represented.
So, the amount of memory needed was 8 into 8 that is a block is basically 8 into 8 square what we wanted that is 512 bits what we want.
For this block 8 into 8 into 8 bits per pixel.
So, that is how we will be needing 512 bits.
So, doing the linear quantization P if we do not use any of the value of P.
then we need 512 bits and the number of bits per pixel what we need it is 8.
Whereas, if we use p is equal to 1 then total number of bits what will be having is only 249.
You can go back and then check in one of the cases and then number of bits per 6 pixel what we need is 3.89.
So, like that 2 and then 3 you will be seeing it that is total bits in p is equal to 2 is 191 whereas, in 3 it is 147.
So, you will be seeing that if we use p is equal to 3 if we are not going to lose much of the information then only 2.3 bits per 6 pixel what we needed to represent it.
So, this is how number of bits and then our memory storage is going to come down.
We have seen the JPEG imaging.
So, what it says is fairly easy to extend this to application to color images.
What we have seen was the black and white in the previous case.
So, Now, you will be wondering why the thing this is for the black and white when I use the color as we discussed in the first class of DCT that it has to be represented RGB.
So, we will be multiplying by 3 colors basically.
So, you will be seeing that each pixel is assigned 3 integers for each color intensity.
So, what is it here it is you will be seeing red you can see that R is 1.
G is 0 and B is 0 in this.
As you move across so, you will be seeing that something here dark pink what you have it which will be having both R component, red component and then a blue component and then green is going to be 0 in this.
When you come to white you will be seeing that all of them are 1 RGB is equal to 1 it becomes white and all of them are 0s it becomes black.
Whereas, when you have only green part of it has to be represented you will be seeing that it is going to be 0 1 comma 0 here.
And, the combination now from here to there you will be seeing that red is 0 here and then you will have the green component and then blue component which will be mixing from both the ends.
And you will be seeing on the other side also as it is represented with the cube how different colours are represented with your RGB.
So, how to go with this basically a few ways to approach the image compression.
That is repeat the discussed process independently for each of the three colors and then reconstruct the image.
So, we will be doing the compression in the R plane and then G plane and then the B plane and then we can mix it and then do it.
So, that is what it says baseline JPEG uses a more delicate approach.
How it is done that is usually we will represent with respect to luminance.
what is that coordinate to be y coordinate.
So, what how the value is going to be defined.
So, you will be taking 0.299 of r plus that is you will be seeing 50 percent of the green value what you will be taking it and then the lowest is 0.114 of the blue component.
Because green is more perceptive to our eyes.
So, which is given more weightage and you will be seeing that one fourth of it is given to red and then.
the blue gets the least preference.
And then you will be defining the color differences coordinates.
So, then we call it as YUV representation.
U is going to have b minus y and then v will be having r minus y.
So, with luminance and then u and v component YUV what we can represent are color images also.
So, how it is going to be the transformation what you will be saying.
RGB what you have it that is this is R, R G is here and then B you will be shifting to YUV system which is both the ways possible.
So, you have been shown from here to here from YUV you can get back your RGB also that is what it means that it is reversible.
So, you will be seeing a few of the colours that is from 3 dimensional what you have done is come down to.
only two dimensional what you have is u and v what are the coordinates with the your colours have been mapped in to.
So, it applies that DCT filtering independently to y u and v using the quantization matrix q r what we can use it and then apply it and then get the result.
So, how is the luminance?
So, I think the bulb shows how it is going to glow correct that is what we call it as luminance.
So, you will be seeing the quantization.
Q y here p is given these values to represent the thing.
So, you are earlier we had taken the quantization matrix basically p is equal to 1 means it is a multiple of 8 what we have taken the thing, but here you can see it is with the different p what you are representing the matrix for the quantization.
And then the chrominance what you will be seeing is Q c.
is represented with this.
So, you will be seeing that most of them are 99 is the value what it will be going.
So, you will be representing these colors using the chrominance value of these matrix basically.
So, how we are going to do that?
We know that human eye is more sensible to luminance that is y coordinate and it is less sensible to our color images that is UV coordinates.
So, then compress more on UV.
and less than y.
Consequences color images are more compressible than grayscale ones as you can see it.
So, how we are going to reconstitute the thing?
After compression our YUV are recombined and converted back to RGB to form the compressed color image.
So, blue is represented with U plus Y and our red is going to be with V and then Y and then G is going to be you are seeing that.
Y into 0.299 of R minus point Y that is luminance Y minus 0.299 of red minus 0.114 of blue whole divided by whatever we had represented our green with that is the 0.587 what we had represented in the original for the green we had given the weightage to calculate luminance.
is divided by 0.587.
So, what is it?
In the equation what you will be substituting it basically what I have in the equation is this is my y.
So, you will be doing 0.587 g equal to transform these into the other part of it.
So, that is why you will be getting y minus 0.299 r minus 0.114 b and to get g we have to divide this by its weight that is 0.587.
So, this is how you will be reconstructing your green.
So, coming to comparing the compression.
So, this is lena has been taken this is the original image and then if I give p is equal to 1.
So, the compressed image is shown in this way and you will be seeing the other compression p is equal to 4.8 basically what it is chosen instead of 4 and then you can see your lena how it is represented.
and compression of 8.6 p is equal to 8.6 and you are seeing your lena here.
How much difference you are going to make out?
Only you can subtract from the original image and then represent that value as an image again and then you will see how much you have lost compared to the original.
But still your eyes is unable to unless you have a very sharp eyes where you can pinpoint that this is the difference what I am seeing from the original to the image.
So, this is one of the advantage of our human visual system.
So, you can see compressed image we have done the blown up of it there it was small.
So, you are not deviating from much of the original.
So, that is what one of the compression advantage in image processing.
So, this is what we have looked at by selection of P how we can do the compression and in the next class we will see it is like our fast FFT what we did for Fourier transform.
So, we can do fast DCT using our butterfly structure here it is not exactly butterfly, but flow diagram what we will look at it in the next class.
Thank you for listening to this class we will come back in the next class for D C T.
Thank you.
So, last class we discussed about what are the basics of signal processing, what course is going to discuss about it.
Today, we will discuss about little bit on basics of signal processing.
So, the real time signal processing has three components basically what you will see that some of the signals are represented with.
The first part is the analog signals.
So, what you will be seeing is the continuous signal, you will be seeing that the amplitude is continuous as well as the time is going to be continuous.
So, coming to the discrete signals how it is going to be represented is shown.
this figure.
So, the frequencies as you can see continuous or continuous time what we call it and then the amplitude is going to be discrete in this.
So, when we come to represent the signals in the digital domain that is in the digital form.
So, we will see that the amplitude is discrete as well as it is going to be discrete in time.
So, as it is represented with n. So, these are.
some of the examples of the signals.
When we come to the system how we are going to represent them.
Analog system is represented with along with the signals whatever we are processing input is going to be analog signal basically input and then the even the output after performing the processing.
So, the output is going to be represented in the analog domain itself that we call it as analog signal output.
So, when we come to represent the system digital systems basically.
input is going to be digital signal input and then we will be doing the processing the output again it will be in the digital signal output what we are going to get from the system.
So, coming to some of the advantages of analog systems or digital systems.
So, we will say that analog systems the first one is it is easy to interface with real world systems and then we say from the.
point of view of digital system.
They offer programming flexibility basically and then capable of performing complex task with low power consumption.
So, whereas, in the case of analog systems we do not need any A to D or DTA converters because input is in the analog format and even output what we wanted in the analog domain.
So, we need not have to convert it into signals in from analog to digital or digital to analog.
And, then whatever we are talking about the speed is going to be independent of the clocking cycles.
So, there is no need to sample the signals whereas, in the digital domain.
So, we have to do sampling has to be done and then it depends on sampling frequency and the frequency component present in the input signals.
So, these are one of the advantage in this case is going to be accurate and reliable.
against environmental changes.
So, we know that analog when we do the processing.
So, some of the components may be resistors or capacitors or other hardware what we will be using it for processing.
So, we know that for the weather conditions we as we say that precision basically percentage of the precision.
So, which may vary depending on the temperature and other environmental changes that is going to occur.
We know that in the digital systems they are not going to be.
affected by this environmental changes.
And one more advantage of the digital system is reproduction of signals.
So, that is going to be multiple times what we can do it without degrading the quality of signals.
In this case what we say is if I have to little bit modify or the same signal what I want to get it in different places which is possible.
Whereas, from the analog domain we know that because environment is going to play a havoc.
So, if we are not taken care of these things.
the multiple outputs for the same input data we may get it differently.
So, this is one of the disadvantage of analog systems.
So, coming to when we have talked about so much of advantage of digital systems.
So, we will see what are the basic elements of real time system DSP systems are going to have it.
So, once I the input if it is a analog signal input as we will see that it is both varying in time as well as amplitude.
which has to be which is represented as x of t. So, we have if it is the amplitude very low then we may have to do little bit of amplification.
And then to curtail the frequency component present in the analog signal we have to pass it through the low pass filter.
So, we call in the analog domain as the anti aliasing filter.
So, we will come to the aliasing part of it in a while.
Then once we have converted we call it as x dash of t. So, as you can see that some of the amplitude is going to be discrete and then it may be continuous in time domain.
Then we pass it through the analog to digital converter or.
So, that ADCs are going to convert analog signals sent to digital domain.
So, we call it as X of NT in this case as you will be seeing that the samples what we are going to get from the analog is represented in this figure.
Then once this it is in the digital signals, but is both in amplitude as well as in time they are being discretized will fit it as input or digital signal processor.
So, for the digital signal processor input as we know that it is going to be discretized signal both in amplitude as well as in time what we will be feeding it.
And we will do the processing whatever application we are intended to, then the output is available as digital output.
As we will be seeing it Y of n in this case after the processing of it, then if it has to be converted back to analog domain, then we have to pass it through the digital to analog converter.
So, that we will be getting y dash t as the output.
Then what we have to do is we need analog output in the continuous domain.
So, we have to do little bit of amplification and then we will use the reconstruction filter.
Reconstruction filters are going to be usually sync filters.
So, we will time permits we will take it up and then we will be getting the analog signal output.
So, if we want to store digital signals in the digital form.
So, in the compression or whatever we can store it in that domain itself.
Whenever we want to have the analog output that time we can retrieve the signals and then convert it back into analog domain.
So, coming to the extending the basic elements of the real time DSP systems.
So, we have the x of n as the input and then this is the digital signal input what we are going to provide it to the DSP processor and then we are going to process it and then will storing digital signal output as I have mentioned in the previous slide.
So, we can store it after computation what it has been done in the digital domain itself.
So, now, we will see little bit of what we will be doing how to do analog to digital conversion that is ADC what we say it.
So, we know that first is the analog input as it is shown here basically which is continuous in time as well as in amplitude.
So, the first step in this going to be we have to do the sampling.
what we have to do it sampling frequency has to be fixed which depends on the Nyquist criteria basically.
And then x of n is the input to our quantizer because we know that although we have the discrete amplitude and discrete in time we would not amplitude need not we cannot represent it in the digital domain as we want it.
It depends on number of bits what we are going to use it.
So, we have to quantize our input signal.
And, then after quantization so, we will be storing it as x t of n. So, as the quantization process little bit is shown and then little more we will be showing in the next slides actually.
So, we will be seeing that number of bits this is the digital output which has to be encoded and then we will be storing it as a digital input as it is shown.
So, we will see that analog signal was this when it comes to the digital domain.
So, this is how the representation with respect to amplitude as well as time what we will be seeing it is discretized.
So, as first step in this block diagram in the conversion is the sampling.
So, we will be seeing that what we call it is uniform sampling that is x of n is the output what we want after sampling.
So, for that this is from the analog signal x a.
So, which is going to be sampled for every n and then t is the period what we will be considering.
So, t is our sampling period and then n will be belonging it to our real world.
And then when we come to sampling frequency how we are going to fix the thing.
So, what we say is f s is the sampling frequency it should be greater than 2 times of the f m, where f m is the maximum frequency that is present in our analog input.
So, as we can see this is the analog signal and then what is the duration here what we call it as delta t is the sampling period what we will be taking it here between two samples.
And, then the complete sampling frequency what fs is going to be represented depending on the maximum frequency present in the signal.
So, just as an example here we will consider 2 sine wave frequencies that is we have f1 as a 2 hertz and then the second frequency component is 10 hertz.
And then we are going to sample this with 8 hertz sampling frequency.
So, we know that we said that according to the previous equation.
So, sampling frequency should be greater than twice that of the maximum frequency whereas, in this case it should be according to this maximum frequency is 10 hertz it should have been 20 hertz instead of that what we are doing is sampling at 8 hertz.
So, then what happens to this ok.
So, you will be seeing that this is the first frequency what I have it at 2 hertz.
and then this is the 10 hertz frequency component which is represented.
When I try to reconstruct these two signals back to original after doing processing and everything.
So, you will be seeing that this is going to be 2 hertz basically that is we have f 1 is at 2 hertz and then the sampling frequency is 8 hertz.
So, which has reconstructed properly.
So, what I have in this case.
is how many points I am going to have there are 4 points 2 points what it has in maximum what you are representing the thing in both domain that is in the positive and then the negative what it has it.
And then when I reconstruct this signal 8 hertz signal so what happens to the thing is it is going to have the aliasing effect.
So, because I have not taken care of twice that of the maximum frequency.
So, we will be seeing that 10 minus 8 hertz is the one reflected basically what I will be getting both as a 2 hertz frequency in the domain.
So, some of these examples we will be doing it in the lab.
So, that you will be able to figure it out what will be the reconstruction is going to happen if normal whatever Nyquist criteria frequency is not met.
So, coming to the other part of the sampling.
So, you will be seeing that two different analog signals sampled at different frequencies leading to some digital signal what we are looking at.
So, we have sampled at 40 hertz here and then this one is sampled at 80 hertz what you will be seeing it.
So, when I do the reconstruction, so the 40 hertz if the sampling frequency is.
So, you will be representing both the signals in their domain reconstructed properly.
So, coming to real world application so, we will be seeing a few of the sampling frequencies and then what are the sampling period associated with each one of them.
So, one of the real world thing is our telecommunication.
So, we know that international telecommunication unit.
union that is ITU what it is going to be representing speech coding and decoding standards which is defined by ITU-T what we call it G729 and then 723.1 standards.
There the sampling frequencies what it is used is 8 kilohertz.
So we know that 8 kilohertz when we say the thing what will be the sampling period is T is going to be given by 1 by fs which is going to be 1 by 8000 seconds so which.
constitute 125 microseconds basically what will be representing it.
So, how we are going to represent 1 microsecond is equal to 10 power minus 6 seconds.
The same thing so, if we consider the wideband telecommunication speech coding standards such as ITU-TG 722 and then 722.2 ok.
Here the sampling frequency is 16 kilohertz then we know that sampling period is going to be 1 by 16000 which is nothing but 62.5 microseconds.
Coming to the third real world signal, so what we call it as high fidelity audio compression basically standards such as MPEG-2 that is moving picture basically what we will be looking at it expressed group basically.
And then AEC standards that is advanced audio coding and then MP3 we know that coding technology technique, so which is we call it as MPEG-1 layer 3 what it is going to be considered for the audio.
And, then we know the DOLBY AC3 systems also.
In these applications the sampling frequency that is used is 48 kilohertz.
And then we know that for the sampling rate for MPEG-2 AAC it can be as high as 96 kilohertz.
So, in that case what happens our sample period is if we are consider 48 kilohertz which is 1 by 48000 which is going to be 20.83 microsecond is the sampling period at which we have to sample the MPEG-2.
signals basically.
So, these are some application shows that how we have to do the sampling thing correctly.
So, now, once we have sampled the signals, then the signal is available in the digital domain which we call it as x of n, then we have to go for the quantization.
So, as we the it depends on as I said number of bits.
In this case as an example, we have taken 2 bit quantizer that is whatever the input which is coming.
So, we will be representing with 2 bits, then I know in the.
digital domain how well we representing the 2 bit number system.
So, that is 0 0 and then 0 1 1 0 and 1 1.
So, this is what my input signal.
So, in the continuous domain.
So, or sample signal what I have got it.
So, I have to map them to the nearest numbers basically whatever I will be representing with the number of bits.
So, we call.
So, whatever the difference between the two as we as can see one of the example, this number which is between 1 0 and 1 1 which I will be representing as 1 0.
So, which we call all these errors as quantization errors that is basically the difference between the quantized number and the original values defined as the quantization error which appears as noise in the output of the converter.
How do we define the quantization error which is given by equation like this eq of n which is nothing, but xq of n minus that is quantized value minus the x of n the original value of it.
So, for all n in my real world basically.
So, coming to next one what is the thing is going to happen.
So, we took it as example as 2 bit quantizer and then we saw the thing.
So, for uniform quantization the resolution is going to be determined by dividing the full scale range by the total number of quantization levels.
That is if I am representing with 8 bit number then the resolution for each value is going to be represented as 2 power 8.
So, B can be any number of bits what it is shown here and then I have to specify signal to quantization noise ratio.
For b bit quantizer is approximately what we call it as 6 b, b is the number of bits d b in represented in decibel.
So, as it is shown in the table here number of bits if I use 8, b is equal to 8, then the levels what I can represent is 2 power 8 which is 256 levels what I can represent the values.
And then the resolution is going to be as we have said that full scale range.
If we take it as 5 volts then I will be getting each sample is represented as 19.5 milli volt level.
And, then in that case what I am going to achieve for 6 into 8 is going to be my signal to quantization noise ratio which is going to be 48 dB.
So, if I increase the number of bits to 12 bits what I am going to look at it then I will be representing the number of levels is 4096.
and then which is 2 power 12 and then the resolution as we will be seeing that it will be 1.22 millivolts.
So, compared to this I have a more resolution between the bits and my SQNR that is quantization noise ratio what signal to quantization noise ratio is going to increase to 72 dB.
So, for the 16 bit conversion or quantization.
So, I will be achieving somewhere around 96.
So, all of us know that CD quality although it is extinguished now today.
So, which had a 91 dB resolution what that is signal to quantization noise ratio was the standard being used for it.
So, you will be seeing that somewhere between these two what you are supposed to have number of bits.
But we know that it depends on ADC what we are going to use it.
So, which we will be discussing it in a while.
So, now once we have done quantization then we have to represent this quantization bits according to the number of bits what we have been using it.
So, then we have to do the encoding of the number or the signal.
So, this is 2 bit encoder we have seen it already and then when I talk about 3 bit then I will be representing the values between 0 to 7.
integer what I will be representing it.
So, when I take up the number system we will discuss about the what I will call it as negative and then positive numbers how we can represent it.
So, once we have done the analog to digital conversion then if we want to do digital to analog conversion.
So, we have these are the digital values what I have it y of n is the thing and then I will be seeing that.
presenting it and then we will try to reconstruct the signal in this way.
So, this is our linear interpolation what I can do it and then reconstruct the signal in this fashion.
So, this is how we will be getting the analog signal output.
So, coming to data converters.
So, we need ADC's and DAC's for both the input analog input conversion to digital domain.
and from digital domain to unlock.
So, in this we will be using the DSK6713 board basically as I mentioned in the previous class that most of the colleges have this.
So, I will be taking this as the basic one and then we will be going with the lab laboratory incorporating this board either in the simulator mode initially then we can use the hardware to test the real time signals.
So, in this case what we have call it as AIC chip which is analog interface chip.
In the DSK6713 is going to be AAC23 codec what we call it both coding and then decoding is incorporated in one of the chip itself.
So, the higher versions of DSP processor from TI what I will be taking it.
So, we will see why we have gone with the TI later on.
The thing is going to be 3 2 version AAC32 version what they will be using in the higher versions of the boards basically.
So, now, when we want to do the data conversion either I can have a parallel converters or serial converters.
So, we will see the advantage of a disadvantage of both parallel and serial converters.
So, parallel converters we know that it receives or transmit all b bits in one pass.
So, whatever data I have considered basically then it will be converting or taking all the 8 bits at a time if it is 8 bit converter.
and then it will be outputting all 8 bits output.
So, whereas, in the serial case it receives or transmit this b bits in a serial of bit stream that is 1 bit at a time.
So, what is the consequence of it as we know that whatever I can get if I am talking about 8 bit 8 bits have taken the thing b is equal to 8 I have considered.
So, all the 8 values will be coming into my system at 1 clock cycle.
Whereas, when I am using the serial converter, I know that 8 bits will take 8 clock cycles because I am taking 1 bit at a time.
So, I have to wait for 8 clock cycles to get complete data.
But what are the disadvantage of the parallel converters we will see.
So, these are attached to the digital signal process basically external address and databases directly it will be connected to that.
So, which are also attached to many different types of.
devices in this case.
So, that means, to say that so many bits are required or what I will call it as I O pins to get the input data and any other devices also using it.
So, so many I O pins has to be there.
Whereas, in the case of serial converters, so we will be using built in serial ports of digital signal processors.
And then we know that it requires few signals or pins to connect with our digital signal processor.
So, most of the many practical DSP systems use serial ADCs and then DACs.
And then coming to the thing what are the kinds of data converters available in the market.
So, we know that some of them are successive approximation, dual slope, flash ADCs are there.
and sigma delta converters are there.
So, we will see advantage and disadvantage of them few of them.
The first one is a successive approximation ADC.
So, we know that it is very accurate and then olden days we were using this type of conversion and we know that it is fast at a relatively low cost.
So, very popular in the olden days.
So, this results in slow response to sudden changes in the input signal due to limitation in its internal cross.
clock rate.
So, internal clock rate is slow.
So, any changes in the thing.
So, the response is going to be slow.
This is the disadvantage of our successive approximation ADC.
Coming to dual slope ADC.
So, this is very precise and can produce ADCs with high resolution.
What is the disadvantage?
They are very slow and generally cost more than successive approximation.
So, where the cost is not going to matter then.
So, people were going to use the dual slope ADCs.
The other one type is the flash ADC.
So, we know that it is very high speed conversion and commercially available flash ADC usually have lower bits because of the power consumption and then speed and other things coming into picture.
So, they cannot have higher bits.
So, in a B bit ADC we know that it requires 2 power B minus 1.
So, bits basically so which is going to be expensive comparators and laser.
trim resistors are required to implement this kind of ADC's in the flash mode.
So, the other advantage of using the sigma delta which we will be looking it in a while.
So, what the input signal we have the analog input signal.
So, we will be feeding it to the sigma delta what we first is sigma basically, then you will be seeing the delta part of it is going to come which is a 1 bit ADC will be taking it.
and then I will be getting 1 bit output and then which is going to be we call it as digital decimator.
So, why we need the digital decimator is we will be sampling at a very high frequency here input signal and then the output has to be brought down to whatever the board is going to support.
So, which will be converted get into 8 bit digital output signal in this case.
So, when I want to reconstruct because this is what we call it as sigma delta or delta sigma basically.
So, when converting it from ADC mode we will be having sigma delta, when I want to convert it back to DAC that is my analog output.
So, I will be taking the delta output and then this is a 1 bit DAC I am going to have it which is going to provide it to sigma and then I will be getting the analog output from it.
So, you will be seeing that this is a digital input how 8 representation of the signal digital signal is shown in this figure.
So, the coming to the its usage.
So, what it does is we use the over sampling and quantization noise shaping to treat the quantizer resolution with sampling rate.
So, we are going to sample it to high sampling rate then what happens to this.
Then we use 1 bit quantizer with a very high sampling rate.
Thus the requirements for an anti aliasing filter are significantly relaxed.
So, we know that anti aliasing filter has to be designed in the analog domain.
So, we know the disadvantage of filter construction there in analog domain.
So, that means, to say that we are going to provide a lower roll off rate for the anti aliasing filter.
So, we say that low order anti aliasing filter requires simple low cost analog circuitry compared to complicated one if we want to have a.
fast roll off and is much easier to build and then maintain them for longer period.
So, in the process of quantization what happens the resulting noise power is going to be spread evenly over the entire spectrum because we have sampled it at high speed.
So, the noise is going to be distributed over the whole spectrum.
So, that is what it says the quantization noise beyond the required spectrum range can be attenuated using a digital low pass filter.
So, we are relaxing on the analog low pass filter and then we can use a digital low pass filter to remove the noise from the component that is present in this input signal.
So, as a result the noise proper within the frequency band of interest is going to be lower because it is distributed over the entire spectrum.
So, to match the sampling frequency with the system and increase its resolution, we use the decimator.
to reduce the sampling rate.
So, the advantages of sigma delta ADCs are high resolution and good noise characteristics at a competitive price using digital decimation filters.
So, the thing is happening in the digital domain.
So, the cost of this ADCs are very less.
So, that is how most of the DSP processors use the sigma delta ADCs in their hardware.
Now once we have discussed about the ADC.
So, we look into the DSP hardware.
So, we can have different as you will be seeing that 5 varieties of them are there.
One is the special purpose that is usually we custom build the chips basically such as application specific integrated circuit.
We call that as ASICs basically.
So, one of the advantage is there if you are going for a very huge volume.
The cost of the units is going to be very less, we will be seeing in a while how they will be comparing.
Then it is worthwhile going for the special purpose processor, but once we have built this to change any of the in between components or any circuitry, then we have to redesign it, it is not possible to modify it.
That is one disadvantage of using ASICs.
The other one is field programmable gate arrays, we call it as FPGAs.
there it is before ASIC what we can use them.
So, that is in the field I can reprogram although gates are present in the thing as an arrays.
So, we will be programming them and then I can later on once we I feel that my circuit is capable of working very well and then I want high productivity then I can go for the ASICs.
So, it is easier to try it in this.
So, compared to this we will be seeing that.
But in terms of the design time and other things which will the first one will have the maximum time to build around and then this is little much easier and coming to some of the levels where in classrooms and then some of the research we can use general purpose microprocessors or microcontrollers for specific applications.
And then we can go if the application is I O oriented it is better to go with microcontrollers.
Or if general purpose processor number of applications are much more what we have to test it.
But when it comes to signal processing, so it is better to go for general purpose digital signal processors.
So, we will see the advantage of them later.
The other one is we can have DSP with application specific hardware that is we call it as hardware accelerators.
So, with respect to general purpose process we can have a hardware accelerators.
Particularly, meant for DSP applications also is a possible hardware one can consider.
So, this table gives you what are the advantages and then disadvantages in terms of that is from the flexibility, from the design time, power consumption and then performance and then what will be the development cost and then the production cost.
So, you will be seeing that ASIC is I do not have any flexibility as I mentioned in.
the previous slide that once you have designed it any change you have to incorporate you have to redesign.
So, I would not have any flexibility in change of design.
And then in the case of design time you will be seeing that it is going to take a longer time and power consumption because according to my requirement application I have designed it which is going to consume low power because I will be using only few components what.
it is much required for it.
And coming to the performance which is going to give very high performance because it is application specific what we have designed it.
Coming to the development cost is going to be very high as it time is going to be longer.
So, one who are very good in designing get they have to be paid heavily that is why it is going to cost us very high development cost.
Coming to the production cost because we think of high volume basically you can see your.
mobiles basically.
So, as the customer increases you will be seeing that cost is going to lower as the trend is if it is older version.
So, we will be getting it for a low cost, but whenever it is new you see that there whatever the your design time is going to be much higher, but production cost will be kept as low as possible.
Coming to FPGA field programmable gate arrays.
So, we have limited flexibility in this compared to ASIC we have some of the flexibility and then our design time is medium and then power consumption is going to be low medium in this case and performance is going to be high as equivalent to ASIC and development cost is going to be medium in this and production cost it will be in the low medium case.
Coming to your microprocessor and microcontrollers as we will be seeing that our flexibility in digital signal processor and microprocessor and microcontrollers are very high and then design time in both the cases is short.
Whereas, in the power consumption here it is can be medium to high, but in the digital signal processor we can have low this thing power consumption processors are available or I can have some of the medium processors.
which I can use it for my applications.
So, when comes to performance they will be low to medium what it is going to be, but whereas, in the case of digital signal processor it is from medium to high performance what I will be getting it.
Coming to the development cost both standard low and then production cost is going to be this one is medium to high whereas, digital signal processor low to medium.
Coming to with hardware accelerators, so the flexibility is going to be medium because my accelerator based on my requirement what I have designed it or what I am using it.
So, that way I will not have much flexibility just like our FPGA we may have the medium flexibility whereas, the design time in this going to be short and then I can have the power consumption between low to medium what I can select and then performance is going to be very high and then development cost is going to be low in this and production cost is going to be medium.
So, if I have the hardware and I want to have increase the speed of my computer DSP, I have then it is better to go with accelerators.
So, these are the table what it decides what kind of hardware one has to select for their basic applications.
Coming to the design how we are going to proceed.
So, signal process system design what we call it.
So, that is if you have been given an application.
So, I will be defining my system requirements.
and develop algorithms and then perform simulation first to see that my algorithms are working fine and then my requirements are correct.
Then I can select DSP chips or devices or whether I have to go for the full custom or FPGA based or hardware based accelerator I can decide it here.
Then what I will do is I will be deciding on initially earlier cases was software development was separate and then hardware development was separate.
As you will I was pointing it out in the last class hardware cost was very less software cost is going to be very high because they were designing it independently.
So, hardware lot of functions are built into our chips and then which is going to come out to make them use software has to be developed in such a way that all the units are used which is going to cost us very high.
So, but now the trend is as we will be calling it as hardware software co-design.
So, they have to go in hand in hand that is why it is put in dotted line.
recent trends they have to go in concurrent design of hardware and software components of complex electronics systems basically.
So, that will be in line with whatever hardware is getting added software also will be able to use that hardware.
So, that is what it says it tries to exploit the synergy of hardware and software with the goal to optimize and satisfy design constraints such as cost.
performance and power of the final product.
So, once this is being done so, we will be doing the integration system integration has to happen.
Then we know that testing and debugging is one of the most critical one.
So, how one is going to do testing and debugging it depends on what application we are going to use for and then how much we have to do it whether for real time systems are that is what I am we are talking about real time signal processing it should not fail then we should have taken care of.
testing and debugging for all possible cases one has to do it.
So, in the case of software development, so we will be using mostly general purpose computer.
In that case will be externally we have to provide the analog to digital converted signal into the system which will be doing it storing it in the data files or we can take it from other computers if we have the converted data.
So, we will be storing it as data files and then we can run the thing DSP algorithms either using C or C++ or MATLAB and then those are the softwares what we can use it DSP software.
And then we can generate some of the signals and then if we want we can store it back in the data files and then the output of it applying the algorithm we can store it in the data files and then externally we can use the digital to analog converter to convert it.
and then send it out or if it has to be given to other computers which has to process it we can give it to other computers.
So, this is the end of the second lecture.
So, in the next lecture we would be taking DSP architecture and then number system in the next lecture.
Again I will tell happy learning and then thank you.
Welcome back to real time digital signal processing course.
So last class we discussed about little on speech coding.
Today we will continue on that regarding the O coders.
So, this is the second lecture what we will have it.
So, we saw that although I did not discuss the A law companding.
So, which was in the analog domain.
So, you can go back and then check the thing.
So, we discussed little on mu law and then little on the sub band coding how we can bring down from PCM that is 64 kilobit per second to sub band coding of 31.5 kilobits per second.
So, today we will see about the O coders.
So, we say it is a parametric coders basically and models the vocalization of speech and the speech sampled and broken into frames approximately we break it up into 25 millisecond.
And instead of transmitting digitized speech we are going to build the model of speech and the transmit the parameters of the model and synthesize.
approximation of speech.
So, we say that the first one is the linear predictive coders in this category LPC.
So, the basic coder model what we are going to have it.
So, models the vocal tract as a filter and then filter excitation what it is going to be done.
So, of it is going to be done it is periodic pulse that is voice speech or noise we call it as unvoiced speech.
So, using that we will do the filter excitation and then synthetically generate the speech at the receiving end.
So, the transmitted parameters are gain, voiced or unvoiced decision and the pitch.
So, if it is voiced we have to send the pitch and the rest of it is LPC parameters what we have used in the coding techniques.
So, coming to the second part of our coders.
We as we said it is the linear predictive coders we are going to use it.
So, the first is the excitation stage.
So, what we are going to have is periodic pulse that is voice speech or noise we call it as unvoiced speech.
So, this is how the pulse generator is going to be and we are going to provide a pitch period in this case.
So, we call this is the voiced generation.
And, here it is unvoiced we say it as noise generator.
So, this is our excitation model what we have it.
Then after the excitation model ah.
So, we have to select the excitation.
So, that is going to happen here and we will be having the gain factor G. So, which is multiplied by this one ok. Then these are the transmitted parameters ah which are the ones we are going to what gain we have used it.
So, whether it is voiced or unvoiced decision we will be putting it and then the pitch if it is a voice signal and the other ones are LPC parameters what will be transmitting it.
So, here you will be seeing that this is the excitation model output is mu of t and how we are going to see the LPC basically.
These are the predictor coefficients.
So, we will be putting the linear feedback.
and do the summation of the two of it and we will be sending y of t along with the parameters of LPC these are the parameters.
So, this is our vocal tract model what we are going to generate and then we will be passing the LPC parameters to the through the channel to receiver place.
So, coming back what is it?
Example 10th order linear predictive coder what the example shows here.
So, the samples voice at 8 kilohertz and we are going to have a buffer of 240 samples that is we are taking 30 millisecond of the data.
And here the filter model is M is 10 is the order of the filter and gain considered is G and we know that Z-1 is the unit delay we are going to have it.
and b k are filter coefficients what we will be using it in the system.
So, then what happens to our impulse response H of z is given by g divided by 1 plus sigma k is equal to 1 m is the order of the filter b k into z minus k then our g is going to be 5 bits and then b k is going to be.
are 8 bits each what we can use for the voiced and unvoiced decision we are going to have 1 bit and pitch is represented with 6 bits.
So, this implies that we have 92 bits per 30 millisecond.
So, it gives this thing 3061 that is band bit per second what we are going to get the thing.
So, this is the model of the LPC coding the previous one we discussed about this.
This is the model which is going to be used in the LPC.
This is bits per second what we are going to have what we have to transmit totally.
What we have is can achieve low bit rates that is from 1.2 to 4.8 kilo bit per second.
So, the characteristics of LPC coding is quality is very low and complexity in this case is moderate and bit rate as we have seen that it is low and delay in this case is moderate and robustness is also low.
So, quality of pure LPC vocoder to low for cellular telephony it try to improve quality by using hybrid coders basically.
So, how to improve the quality by refining model of speech.
model and improve accuracy of the model and improve input speech coder.
So, by using this we can modify our LPC vocoders.
So, how is it you can see that we can use the hybrid coders that is combined vocoder and waveform coder concept basically and we will be using the LPC modified one we call it as residual LPC that is rel basically.
And, we can use the code book excited LPC that is we call it as scalp we will see in a while how we are going to use it.
So, you can see that this is again 2 which is a deferred.
So, you will be seeing that this is the voiced portion and this is the unvoiced region and then how the pitch is generated what you can see the thing this is the frame and then this is the pitch period.
what we call it on the y axis.
So, this is how we will be generating the pitch and then transmitting in our LPC.
So, what how does the this thing RELP-OCODER looks like that is Residual Exited LPC to improve the quality of LPC by transmitting error that is we call it as residue along with the LPC parameters.
So, you have the this is the input signal which is going to be buffered or windowed here.
And then you will be checking that it is voiced or unvoiced decision gain and then pitch which are getting transmitted.
So, this is short time LP analysis what we are going to see that do that and then which is going into the LPC synthesis here and these are the this thing LP parameters which generated from here is going to be transmitted.
and from the synthesis you are going to subtract from this original and then we will be checking the residue.
So, what is the error we have got it or the residue which also is going to be encoded along with the parameters and then the rest of the thing whether it is voiced or unvoiced gain and then pitch.
So, these are the three inputs along with in the LPC only these two are going.
Now even the residue is going to be put into the encoder.
and this encoded output is sent to the receiver.
So, the other one is we call it as GSM speech coding basically.
How does it look like basically GSM we know all of us use the thing uses a regular pulse excited linear predictive coder that is RPLPC for speech.
So, basically what does it have combined.
the DPCM we discussed in the last class concept with LPC.
So, information from previous samples used to predict the current sample and LPC coefficients plus an encoded form of the residual that is predicted minus actual sample equal to error what it is going to be transmitted the represent the signal basically which are transmitted.
So, as you can see here.
This is the analog speech so, which is going to be low pass filtered and then you will be converting it into analog to digital form.
So, the sampling rate used is 8 kilohertz and in this case A to D converter has 13 bit bits per sample what it is going to be represented.
So, what you will be getting at the output will be 104 kilo bit per second samples and then here it is going to be RPLTP speech encoder is going to be put in.
and the output what we will be having is 13 kilo bit per second what it is represented in the GSM module.
So, this is going with our to the input to the channel encoder.
So, how the speech coding is going to happen we will see in a while.
So, we said regular pulse excited long term prediction what we can have the thing.
So, that is speech encoder here our LPS the speech coder.
and LPC we know that it is linear prediction coding filter what it is going to be present.
And LTP is the long term prediction which is going to have pitch plus input parameter and RPE we said that residual prediction error which is going to be transmitted.
So, what we have here is input is a 160 samples per 20 millisecond from our A to D converter.
So, which we call it as Z.
2080 bits what it is going to be transmitted and then this is our encoder here.
So, we will be converting it into different pattern as you can see that is 36 LPC bits per 20 millisecond and this is 9 LTP bits per second bits per 5 millisecond and this is 47 RPE bits per 5 millisecond.
which are getting generated from our GSM.
So, total what it is going to be is 260 bits per 20 millisecond what we are going to have to channel encoder.
So, what we are passing it through the system.
So, how the coding is going to look like the first one we have to see the channel encoder also.
So, here it is going to be using class NEE.
So, this is error correction code what it is going to happen that is 3 bit error detection and convolutional coding that is error correction what we will be having it.
So, we call it as CRC basically both detection and then error correction what we will be having it and if it is a class 1B then convolutional coding is going to take place and class 2 no error protection is going to be provided in the thing.
So, these are the three.
GSM this thing channel encoders are there.
And what we have is tail bits to periodically reset this convolutional coder when being used.
So, what we pass is 260 bits per for 20 millisecond which is equivalent 13 kilobit per second.
So, which class you are going to use is depends on the thing.
So, here if it is 1 A then you will be having 1 A bits then 50 class what you are going to have.
And, this is the error correction 3 bit CRC what we have it and then for class 2 you will have 182 class 2 bits and 78 class 2 bits what is going to be generated out of it.
And this one goes as 53 bits because you are adding 3 bit correction codes.
So, 50 plus 3 will be 53 bits.
The other ones are one more whatever you have 182 class.
2 bits are fed to your this thing convolution coder.
So, which is has what you call it as 2 comma 1 comma 5.
So, you are going to have 4 tail bits basically what it is getting added.
So, which comes down to 470 bits when it is coming out of the thing and this is the bit inter lever what you are going to have it which combines these bits and then the 78 class 2 bits which are coming.
combined and you will be getting 456 bits per 20 millisecond as you can see from 260 you have increased to this and then whereas, in the case of kilobit per second it goes to 22.8 kilobit per second is the data rate what it is going from GSM speech coding from the channel encoder.
So, you can have hybrid basically coders.
That is what we call it as code book excited linear predictive coding.
So, that is problem with simple LPCs that is voiced and unvoiced decision and pitch estimation does not model transitional speech well basically and not always accurate.
So, we said that accuracy was low in the LPC.
So, whether we can use the code book excited model.
So, what is that code book approach?
So, that is pass speech through an analyzer to find closest match to a set of possible excitations that is known as our code book.
And transmit the code book pointer plus LPC parameters and you can see that in NA TDMA standard what they call it IS 95 in 3G what they use it.
So, the standard for this is ITUG.729 standard.
So, how is it going to be it is going to have both the things that is here you have the vocoder basically seeing the thing voiced and then unvoiced what it will be going into the code book generation.
So, from there you will be taking the code book generated signals and it passes through the synthesis filter and this is how the output is going to be represented.
So, if it is having a multiple excitation so, which is taken into the thing pass through the synthesis filter and this is our output.
Then if it is a stochastic excitation is used, use the synthesis filter and then you take the output through that.
So, this way you can use the hybrid model to improve upon the standard of LPC.
So, So, this covers are this thing, a coders basically and then in the next class we will be discussing about code excited linear predictive model.
Thank you.
