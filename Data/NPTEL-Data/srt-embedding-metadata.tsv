filename	timestamp	sentence
8.srt	00:00:00.160 --> 00:00:29.300	Hello, welcome to the NPTEL online certification course on deep learning.
8.srt	00:00:33.109 --> 00:00:40.420	Now, we are discussing about the discriminant function and the decision boundary among different classes.
8.srt	00:00:41.750 --> 00:01:04.390	So, in the previous class we have considered two simple cases where the covariance matrices of the different classes they are same and in one of the case we have assumed that the covariance matrix is of the form sigma square i where sigma is the variance of all the components of the vectors.
8.srt	00:01:05.129 --> 00:01:25.329	And, i is an unit matrix which indicates that the covariance matrix is diagonal all the off diagonal elements are 0 and all the diagonal elements are same and that is a case of distribution of points where the points are spherically distributed or hyper spherically distributed.
8.srt	00:01:26.680 --> 00:01:39.810	And in the second case we have assumed that sigma or the covariance matrix of all the classes are same, but the covariance matrix need not be of the form sigma square i that means, i also have.
8.srt	00:01:40.569 --> 00:01:43.009	of diagonal elements which are nonzero.
8.srt	00:01:43.769 --> 00:01:52.369	And this is a case of distribution of points where the vectors are distributed in ellipsoidal fashion or hyper ellipsoidal fashion.
8.srt	00:01:53.609 --> 00:02:03.049	So, what we have discussed in the previous class is the decision boundary under various cases of covariance matrices.
8.srt	00:02:03.049 --> 00:02:09.490	And we are going to continue with the same discussion in this class with few more examples.
8.srt	00:02:10.629 --> 00:02:14.139	So, what we stopped in the previous lecture is .
8.srt	00:02:14.949 --> 00:02:15.560	matrix.
8.srt	00:02:15.560 --> 00:02:31.989	We have assumed the case where the covariance matrix sigma i is equal to sigma that means, the covariance matrix of all the classes are same, but here the covariance matrices need not be diagonal only.
8.srt	00:02:47.639 --> 00:03:17.769	And given this case we have in the previous class computed that g i x or the covariance the discriminant function of the ith class is given by w i transpose x plus w i naught where we have seen that this w i is of the form sigma inverse mu i and w i naught was simply given by minus half.
8.srt	00:03:18.769 --> 00:03:39.279	mu i transpose sigma inverse mu i plus log of p of omega i where p of omega i is the a priori probability of class omega i .
8.srt	00:03:39.279 --> 00:03:46.649	So, given this again as we have done in the other case I can compute the decision yeah.
8.srt	00:03:49.929 --> 00:03:53.449	So, here you find that because this g i x of the form w i transpose x plus w i naught.
8.srt	00:03:54.069 --> 00:04:02.049	Again this discriminant function is a linear function because I do not have any quadratic term in x in this expression.
8.srt	00:04:02.759 --> 00:04:06.249	So, the discriminant function here again is a linear function.
8.srt	00:04:07.419 --> 00:04:17.699	So, given such a discriminant functions as we have computed in the previous case, I can compute the decision boundary between the two classes omega i and omega j.
8.srt	00:04:18.819 --> 00:04:20.469	So, what will be the decision boundary?
8.srt	00:04:21.269 --> 00:04:40.219	The decision boundary here again will be given by g x is equal to g i x minus g j x and because on the boundary g i x and g j x they are equal.
8.srt	00:04:40.259 --> 00:04:52.549	So, I will have g i x minus g j x equal to 0 and you find that what was our expression for g i x g i x.
8.srt	00:05:23.479 --> 00:05:24.239	was of the form sigma i mu i sigma mu i transpose sigma inverse x minus half mu i transpose sigma inverse mu i plus log of p of i.
8.srt	00:05:25.729 --> 00:05:39.529	Similarly, when I compute g j x, g j x will be mu j transpose sigma inverse x minus half of mu j transpose sigma inverse mu j plus log of p of omega j.
8.srt	00:05:40.719 --> 00:05:53.889	So, if I simply subtract this g i x minus g j x and equate that to 0, my expression will simply become 1, when I compute.
8.srt	00:05:55.399 --> 00:06:26.699	here g x which is nothing but g i x minus g j x equal to 0 that simply becomes mu i transpose sigma inverse minus mu j transpose sigma inverse x of this.
8.srt	00:06:59.069 --> 00:07:29.259	minus half of mu i transpose sigma inverse mu i minus mu j transpose sigma inverse mu j plus log of p omega i upon p omega j that will be equal to 0 ok. And if you simplify in the same way that you have done earlier, you find that this will lead to an equation of the form W transpose X minus X naught which is equal to 0, where this W in this case will be given by sigma inverse mu i.
8.srt	00:07:29.919 --> 00:07:59.619	minus mu j and x naught will be given by half of mu i plus mu j minus 1 upon mu i minus mu j transpose sigma inverse mu i minus.
8.srt	00:08:00.139 --> 00:08:23.129	mu j here it will be log of p omega i upon p omega j into mu i minus mu j .
8.srt	00:08:23.129 --> 00:08:24.149	So, what does it indicate?
8.srt	00:08:24.949 --> 00:08:33.279	It indicates as before that because the equation of the boundary the decision boundary between the classes omega 1 and omega j .
8.srt	00:08:33.759 --> 00:08:37.709	is of the form W transpose X minus X naught equal to 0.
8.srt	00:08:38.109 --> 00:08:49.509	And if you remember this form is similar to what we have obtained in the previous case where the covariance matrix was a diagonal matrix for all the classes.
8.srt	00:08:50.819 --> 00:08:51.989	But what is the difference?
8.srt	00:08:52.479 --> 00:09:02.219	In the previous case this W was simply mu i minus mu j that means, W was the vector drawn from mu i to mu j.
8.srt	00:09:03.139 --> 00:09:06.659	But in this case W is sigma inverse mu i and j.
8.srt	00:09:07.279 --> 00:09:08.459	mu i minus mu j.
8.srt	00:09:09.359 --> 00:09:36.749	So, which means that W is no longer in the direction of the vector from mu i to mu j, but the direction of W depends upon the covariance matrix sigma because the expression is sigma inverse mu i minus mu j. X naught as before if I assume P omega i and P omega j to be equal that is the classes to be equally a priori.
8.srt	00:09:37.409 --> 00:09:44.659	In that case sigma naught as before becomes half of mu i plus mu j, ok.
8.srt	00:09:45.619 --> 00:10:04.439	So, this expression simply becomes again my decision surface the decision boundary between the classes omega i and omega j is orthogonal to W, but unlike in the previous case it is not orthogonal to the line joining mu i and mu j, right.
8.srt	00:10:04.809 --> 00:10:12.519	So, it is orthogonal to W, but under the situation that p omega i and p omega j will to be equal.
8.srt	00:10:13.229 --> 00:10:13.339	.
8.srt	00:10:13.339 --> 00:10:27.249	The line becomes a bisector of the line the decision surface becomes a bisector of the line joining mu i and mu j because when p omega i and p omega j they are equal x naught is half of mu i plus mu j.
8.srt	00:10:27.249 --> 00:10:30.289	So, it is half way between mu i and mu j.
8.srt	00:10:30.289 --> 00:10:44.029	So, my decision surface is a bisector of the line joining mu i and mu j, but it may not be an orthogonal bisector because W is no longer .
8.srt	00:10:44.599 --> 00:10:48.999	in the direction of the line joining mu i and mu j in general.
8.srt	00:10:50.289 --> 00:10:56.699	So, let us see that what will be the nature of the decision surface in this particular case.
8.srt	00:10:57.669 --> 00:11:06.179	So, again for that I take a number of examples number of feature vectors from class omega 1 and from class omega 2.
8.srt	00:11:06.889 --> 00:11:15.479	So, in this case the feature vectors that I am taking from class omega 1 are all these feature vectors which are marked in blue.
8.srt	00:11:15.979 --> 00:11:26.329	So, these are the feature vectors that I am taking from class omega 1 which are 6 2 9 3 7 5 and 10 6.
8.srt	00:11:27.269 --> 00:11:40.399	Similarly, all these feature vectors which are in red they are taken from class omega 2 the feature vectors are 6 11 9 12 7 14 and 10 15.
8.srt	00:11:41.699 --> 00:11:49.799	So, here you find that unlike in the previous case where the set of feature vectors were spherically distributed in this case they are elliptical.
8.srt	00:11:50.109 --> 00:11:53.539	elliptically distributed, they are not spherical distribution anymore.
8.srt	00:11:54.899 --> 00:12:02.439	So, given this feature vectors now let us see that how we can find out the decision surface.
8.srt	00:12:03.819 --> 00:12:15.919	So, for these two sets of feature vectors I compute the mean vectors mu 1 for class omega 1 and also I compute mu 2 for class omega 2.
8.srt	00:12:16.069 --> 00:12:20.619	Again there is a mistake the second one.
8.srt	00:12:20.699 --> 00:12:32.659	1 here this mu 1 this actually should be mu 2 this is not mu 1, but it is mu 2.
8.srt	00:12:33.489 --> 00:12:44.699	So, mu 1 is equal to 8 4 and mu 2 is equal to 8 13 they are the mean vectors of the feature vectors taken from class omega 1 and class omega 2.
8.srt	00:12:52.479 --> 00:12:53.819	So, once I have this then again as before I can compute the covariance matrices.
8.srt	00:12:55.159 --> 00:13:11.999	So, as we have computed in the previouslecture in the same manner if I compute the covariance matrix, you will find that a covariance matrix for both the classes omega 1 and omega 2 will be half into 5, 3, 3, 5.
8.srt	00:13:12.659 --> 00:13:17.439	So, this is the covariance matrix that you get for both the classes omega 1 and omega 2.
8.srt	00:13:19.349 --> 00:13:23.999	And so, this is a case where my off diagonal elements.
8.srt	00:13:24.209 --> 00:13:25.549	they are not 0 anymore.
8.srt	00:13:26.829 --> 00:13:38.799	So, unlike in the previous case where I had the covariance matrix which was completely a diagonal matrix and all the diagonal elements were equal in this case I have off diagonal elements which are non 0.
8.srt	00:13:38.799 --> 00:13:44.739	So, that means, the feature components the different components are not statistically independent anymore.
8.srt	00:13:45.729 --> 00:13:50.999	However, for both the classes I have the same covariance matrix that is half 5, 3, 3, 5.
8.srt	00:13:51.439 --> 00:13:53.989	So, this comes under the case sigma.
8.srt	00:13:57.299 --> 00:13:58.889	i is equal to sigma.
8.srt	00:14:00.939 --> 00:14:25.339	So, once I have this covariance matrix I can compute sigma inverse that is the covariance matrix inverse ok. And using this as we have seen earlier that I can compute thedecision surface and the decision surface is given by W transpose X minus X naught equal to 0.
8.srt	00:14:25.949 --> 00:14:30.569	where W is sigma inverse mu 2 minus mu 1.
8.srt	00:14:32.209 --> 00:14:43.929	And you remember the sigma inverse that you have computed was 1 by 8 5 minus 3 minus 3 5 and mu 2 minus mu 1 is nothing but 0 1 ok.
8.srt	00:14:44.239 --> 00:14:46.959	So, I get W which is minus 3 5.
8.srt	00:14:48.389 --> 00:14:58.349	So, that simply says that W is in the direction of minus 3 5 W will be in this particular direction.
8.srt	00:14:59.539 --> 00:15:20.449	So, here you find that this dark green line this line represents the direction of w ok. And given this I can also compute what is x naught as x naught is given by minus half x naught is given by half mu 1 plus mu 2 minus this.
8.srt	00:15:21.419 --> 00:15:28.749	And under the situation if I assume that p omega 1 and p omega 2 to be equal log of p omega 1.
8.srt	00:15:28.999 --> 00:15:31.119	upon p omega 2 that will be equal to 0.
8.srt	00:15:31.119 --> 00:15:38.229	That means, this term will be cancelled giving X naught to be half of mu 1 plus mu 2.
8.srt	00:15:39.479 --> 00:15:53.439	So, that simply says that our decision boundary which will be orthogonal to sigma inverse mu 2 minus mu 1 or mu 1 minus mu 2 and it will pass through the midpoint between mu 1 and mu 2.
8.srt	00:15:55.559 --> 00:16:00.469	So, this dark blue line is the line joining mu 1 and mu 2.
8.srt	00:16:01.609 --> 00:16:21.109	dark green line is sigma inverse mu 1 and mu 1 minus mu 2 and this dotted red line is the line which is orthogonal to this dark green line and it passes through x naught where x naught is half of mu 1 plus mu 2.
8.srt	00:16:21.109 --> 00:16:27.849	So, this is mu 1 and this is mu 2 ok.
8.srt	00:16:28.139 --> 00:16:32.509	So, here you find that the decision boundary in this case is also linear.
8.srt	00:16:33.119 --> 00:16:39.239	but the decision boundary is no longer orthogonal to the line joining mu 1 and mu 2.
8.srt	00:16:40.339 --> 00:16:50.009	So, this was our second case where sigma i was equal to sigma .
8.srt	00:16:50.199 --> 00:17:08.679	Now, let us consider that what will be the discriminant function and the decision boundary in the most general case where I have sigma i to be the most general one that is for different classes I can have different sigma y .
8.srt	00:17:09.659 --> 00:17:21.089	It is possible that for some of the classes the sigma i will be orthogonal, but some of the some other classessigma i can be diagonal for, but for some other classes it may not be diagonal.
8.srt	00:17:21.479 --> 00:17:30.299	So, every class or the sample vectors taken from every class they have their own covariance matrix sigma i.
8.srt	00:17:30.739 --> 00:17:39.479	So, to see that what will be the nature of the discriminant function in such case let us go back to the original.
8.srt	00:17:40.059 --> 00:18:11.459	g i x where we have seen that g i x was minus d by 2 log of 2 pi minus half log of determinant sigma i minus half x minus mu i transpose sigma i inverse.
8.srt	00:18:12.069 --> 00:18:22.439	x minus mu i plus log of p omega i .
8.srt	00:18:22.439 --> 00:18:42.289	So, here you find that as before I can remove this term from g i x because this is same for all values of i whereas, in the earlier cases we had ignored this term as well half log determinant sigma i because sigma i was same for all the classes.
8.srt	00:18:43.069 --> 00:18:46.669	Now, sigma i is not same for all the classes, it is different for different classes.
8.srt	00:18:47.019 --> 00:18:48.479	So, I cannot ignore this term anymore.
8.srt	00:18:49.249 --> 00:19:13.659	So, that gives me that g i x will be simply minus half x minus mu i transpose sigma inverse x minus mu i plus log of p of omega i.
8.srt	00:19:14.059 --> 00:19:25.099	minus d by 2 log of mod of determinants in i right .
8.srt	00:19:25.099 --> 00:19:44.999	So, given this you will find that this expression is of the form x transpose a i x plus b i transpose x plus b i.
8.srt	00:19:45.159 --> 00:19:55.349	C i. I can simplify this expression in this form x transpose a i x plus b i transpose x plus c i.
8.srt	00:19:55.649 --> 00:20:20.049	And now, we find that because of the presence of the term x transpose x, I will have if the components are x 1, x 2, x 3 and so on of the feature vector x, I will have terms x 1 square, I will have terms x 2 square, I will have term x 3 square, I will have term x 1 into x 2, x 1 into x 3, x 2 into x 3, x 2 into x 5 and so on.
8.srt	00:20:20.959 --> 00:20:36.619	So, that leads to a situation that the discriminant function g i x does not remain linear anymore, but it becomes a quadratic discriminant function because of the presence of quadratic terms.
8.srt	00:20:37.979 --> 00:20:50.509	And over here, this a i it will be simply minus half sigma i.
8.srt	00:21:23.749 --> 00:21:51.209	I will be sigma I inverse mu I and C I will be minus half mu I transpose sigma I inverse mu I minus half log of p of omega i plus sorry this is minus half log of determinant sigma i plus log of p of omega i.
8.srt	00:21:53.019 --> 00:22:02.659	So, C i will be half mu i transpose sigma inverse mu i minus half log of determinant sigma i plus log of p of omega i.
8.srt	00:22:02.659 --> 00:22:12.589	So, my discriminant function becomes a non-linear or quadratic discriminant function.
8.srt	00:22:12.589 --> 00:22:22.189	And when I have such non-linear discriminant functions for to find out the decision boundary between two classesomega i and omega j.
8.srt	00:22:25.429 --> 00:22:29.859	Now, it is difficult to simplify as we have done in the previous case unlike in the previous case.
8.srt	00:22:30.169 --> 00:22:45.549	So, now, what I have to do is I have to find out what is g i x which will be as we have seen it will be x transpose a i x plus b i transpose x plus c i.
8.srt	00:22:55.609 --> 00:23:18.699	Similarly, I have to compute what is g j x which will be x transpose a j x plus b j transpose x plus c j and to compute g x which is the decision boundary between the two classes I have to compute g j x which is nothing but g i x minus g j x and I have to equate this to equal to 0.
8.srt	00:23:19.199 --> 00:23:26.139	So, whatever expression I get that will be the decision boundary between the classes omega i and omega j.
8.srt	00:23:27.959 --> 00:23:32.259	So, now let us see what will be the decision boundary in thiskind of scenario .
8.srt	00:23:34.369 --> 00:23:39.609	So, for this again I take a set of feature vectors .
8.srt	00:23:39.609 --> 00:23:59.609	So, a set of feature vectors say 9 10, 9 14, 7 12 and 11 12 which are taken from class omega 2 that is this one and I have a set of feature vectors 5 4, 9 2, 9 6 and 13 6 .
8.srt	00:23:59.979 --> 00:24:08.189	are taken from class omega 1 and the feature vectors belonging to class omega 1 are these ones right.
8.srt	00:24:08.969 --> 00:24:21.619	So, as before as we have done before given these feature vectors I can compute what is mu 1 and what is mu 2 that is the mean of feature vectors taken from class omega 1 and mean of feature vectors taken from class omega 2.
8.srt	00:24:22.709 --> 00:24:29.839	And I can also compute the covariance matrix sigma 1 and sigma 2 for these two different classes.
8.srt	00:24:30.479 --> 00:24:50.349	So, over here my mu 1 that is the mean of the feature vectors from class omega 1 will be 12 6 and mu 2 will be 9 4 and the covariance matrix sigma 1 is 2 0 0 2.
8.srt	00:25:01.029 --> 00:25:07.119	So, you find that this 2 0 0 2 is the covariance matrix for this feature vectors I think as we have doing doing earlier this sigma 2 sigma 1 should actually be sigma 2 anyway that does not matter much.
8.srt	00:25:08.109 --> 00:25:19.809	And for the other class your sigma or the coviance matrix is 8 0 0 2 which is the coviance matrix over here right.
8.srt	00:25:20.480 --> 00:25:33.059	So, you find that in the first case in this case the points are spherically distributed and here the coviance matrix is of the form 2 0 0 2 which is nothing but of the form sigma square i.
8.srt	00:25:34.859 --> 00:25:54.750	So, the points are spherically distributed whereas, in the second case where my covariance matrix sigma 2 is 8 0 0 2 it is elliptically distributed and because the variance of the component x 1 component is more than the variance of the x 2 component.
8.srt	00:25:55.099 --> 00:26:02.149	So, obviously, the spread in x 1 direction is more than the spread in x 2 direction and that makes it elliptical.
8.srt	00:26:05.259 --> 00:26:07.509	So, given this two set of feature points feature vectors.
8.srt	00:26:07.509 --> 00:26:11.379	Now, as I find that the covariance matrix for the two classes are different.
8.srt	00:26:11.869 --> 00:26:25.049	So, mydiscriminate function for the two classes for the second class where covariance matrix is 8 0 0 2 will be a quadratic one.
8.srt	00:26:25.889 --> 00:26:35.490	Whereas, the discriminant function for the first case where sigma 1 that is this one because it is of the form sigma square i.
8.srt	00:26:35.789 --> 00:26:38.980	the cov the discriminant function for this class will be linear.
8.srt	00:26:39.730 --> 00:26:46.179	So, over here my cov discriminant function will be quadratic for this the discriminant function will be linear.
8.srt	00:26:47.500 --> 00:26:58.609	So, to find out the decision surface between the two classes over here I simply have to make g i x minus g j x and equate that to 0.
8.srt	00:27:00.459 --> 00:27:05.589	And after equating that to 0 whatever I get that becomes 0.
8.srt	00:27:05.879 --> 00:27:07.029	the decision surface.
8.srt	00:27:07.649 --> 00:27:35.359	So, you find that as we have done before that this is the expression of the covariance of the discriminant function or the covariance matrix is not of the form i square i right and the discriminant function is a quadratic discriminant function and given this particular situation if I try to find out that what will be the decision boundary between the two classes.
8.srt	00:27:36.759 --> 00:28:06.939	So, as we said that For this set of points the discriminant function will be linear one, for this set of points the discriminant function will be a quadratic one and if I if I call it say g 1 x and if I call it g 2 x the discriminant functions the equation of the boundary will be given by g 1 x minus g 2.
8.srt	00:28:07.189 --> 00:28:09.569	x that will be equal to 0.
8.srt	00:28:10.199 --> 00:28:29.469	And if you plot the decision boundary you will find that the decision boundary will have a shape something like this which is not a linear decision boundary anymore that we have obtained earlier, but in this case the decision boundary will be a non-linear decision boundary or a quadratic decision boundary well.
8.srt	00:28:31.149 --> 00:28:36.259	So, with this I come to the end of this lecture.
8.srt	00:28:40.419 --> 00:28:53.279	So, in this lecture and the previous lectures 2 lectures what we have tried to do is we have tried to find out the discriminant functions of different classes assuming that the distribution of points is multivariate normal distribution.
8.srt	00:28:54.599 --> 00:28:57.219	And there we have taken 3 different cases.
8.srt	00:28:58.269 --> 00:29:10.989	In the first case we have assumed that the covariance matrices for all the classes are same and they are of the form sigma square i and which case we have obtained the discriminant functions to be linear.
8.srt	00:29:11.549 --> 00:29:28.249	And, not only that the decision boundary between the different classes they are also linear and under the situation when the a priori probabilities are same we have seen that decision boundary is orthogonal bisector of the line joining mu 1 and mu 2.
8.srt	00:29:29.899 --> 00:29:37.909	In the second case we have assumed that the covariance matrices for different classes are same, but they may not be of simple form sigma square i.
8.srt	00:29:39.179 --> 00:29:42.689	In that case also the discriminant functions we have found to be linear.
8.srt	00:29:43.189 --> 00:30:06.429	Decision boundary was also linear, decision boundary was a bisector of the line joining mu 1 and mu 2 under the situation when a priori probabilities are same, but the decision boundary in general was not orthogonal to the line joining mu 1 and mu 2 because of the presence of the term sigma inverse.
8.srt	00:30:06.879 --> 00:30:13.019	So, the direction of the decision boundary in that case depends upon the covariance matrix.
8.srt	00:30:14.149 --> 00:30:33.579	And, the third case was the more general case where we assumed that the covariance matrix of all the classes are different and in which case we have found that the discriminant function is not linear anymore, the discriminant function is a quadratic discriminant function.
8.srt	00:30:34.209 --> 00:30:43.609	And, given such quadratic distribution the decision boundary to be the discriminant function to be a quadratic one using that if I try to find out .
8.srt	00:30:44.209 --> 00:30:52.469	the separating boundary between the two classes, the separating boundary in general is quadratic, it is not linear anymore.
8.srt	00:30:54.279 --> 00:30:55.079	I will stop here today.
8.srt	00:30:56.359 --> 00:30:57.139	Thank you very much.
9.srt	00:00:00.160 --> 00:00:28.940	Hello, welcome to the NPTEL online certification course on deep learning.
9.srt	00:00:32.380 --> 00:00:41.840	You remember in the previous class we have talked about the discriminant functions and we have also seen the decision boundaries.
9.srt	00:00:42.560 --> 00:00:58.010	So, we when we discussed about the discriminant function and then the decision boundary, we have assumed the vectors representing the objects that follow certain probability density function or certain distribution.
9.srt	00:00:59.030 --> 00:01:02.310	And the distribution that we have assumed in this case.
9.srt	00:01:02.579 --> 00:01:04.599	was a normal distribution.
9.srt	00:01:04.879 --> 00:01:08.530	So, it was a multivariate normal distribution.
9.srt	00:01:09.459 --> 00:01:24.859	And based on that based using this multivariate normal distribution under different assumptions of the covariance matrix we have seen that we can have the discriminant functions which are linear, we can have discriminant functions which are quadratic.
9.srt	00:01:25.700 --> 00:01:38.030	And accordingly when we try to compute the decision boundary between the vectors or the patterns belonging to two different classes the boundary can be either a linear boundary.
9.srt	00:01:38.439 --> 00:01:50.600	or the boundary can be a quadratic boundary that depends upon what type of covariance matrix the distribution exhibits.
9.srt	00:01:50.600 --> 00:01:57.579	Now, today we will talk about the linear classifier and we will alsotalk about the support vector machine.
9.srt	00:01:58.770 --> 00:02:09.659	Before talking about the linear classifier and the support vector machine, we will briefly touch upon another two different types of classifiers which are nearest neighbor classifier.
9.srt	00:02:09.930 --> 00:02:13.660	and k nearest neighbor or k n n classifier.
9.srt	00:02:15.140 --> 00:02:20.390	So, let us first talk about what is nearest neighbor classifier or nearest neighbor rule.
9.srt	00:02:21.450 --> 00:02:41.650	So, before going to that you find that in previous few lectures when we talked about the discriminant function which leads to the decision boundary between the two different classes in a particular case that when the covariance matrix of.
9.srt	00:02:41.890 --> 00:02:47.030	all the different classes are of the form sigma square i.
9.srt	00:02:49.100 --> 00:03:00.120	That means, in this case the different components of the vectors were statistically independent and all the components have same variance which is equal to sigma square.
9.srt	00:03:00.820 --> 00:03:10.030	So, there the covariance matrix for all the classes are same and which is in the form sigma square i where this i is an unity matrix.
9.srt	00:03:12.860 --> 00:03:32.790	Under this And, when the a priori probability of the classes P omega i was equal to P of omega j, there we found that the decision boundary between the classes omega i and omega j was a linear boundary.
9.srt	00:03:33.410 --> 00:03:44.530	And, not only that it was a perpendicular or orthogonal bisector of the vector of the line joining the mean points mu i and mu j.
9.srt	00:03:46.220 --> 00:03:57.040	So, if this is mu i, mu j is and this is mu j then the line joining mu i and mu j is bisected orthogonally by the decision boundary between these two classes.
9.srt	00:03:57.750 --> 00:04:03.940	So, this was one of the case in which I can separate two classes by a linear boundary.
9.srt	00:04:04.950 --> 00:04:18.640	And of course, in this case if p omega i is greater than p omega j then this decision boundary is shifted towards mu j.
9.srt	00:04:18.840 --> 00:04:33.380	in the sense that for unknown feature vectors or decision will be biased towards omega i because p of omega i the probability p of omega i is greater than p of omega j.
9.srt	00:04:33.880 --> 00:04:49.320	In the other case if p of omega i is less than p of omega j in that case the decision boundary shifts towards omega i it remains orthogonal to the line joining omega i and omega j, but it shifts towards .
9.srt	00:04:49.690 --> 00:04:58.420	omega i indicating that our decision for unknown feature vectors will be biased in favor of class omega j.
9.srt	00:05:00.610 --> 00:05:20.520	So, particularly in this case when p omega i is equal to p omega j then my decision boundary is orthogonal bisector of the line joining mu i and mu j which clearly indicates that if i have an unknown feature vector say x over here which i need to classify.
9.srt	00:05:21.150 --> 00:05:31.560	This is the mean of the vectors belonging to class omega i and this is mu j which is mean of the vectors belonging to class omega j.
9.srt	00:05:32.830 --> 00:05:44.290	And here we are assuming that the a priori probabilities p omega i and p omega j they are equal that means the classes are equally probable .
9.srt	00:05:44.290 --> 00:05:56.650	So, under this situation when I have this unknown feature vector x over here which have to be classified what I am effectively doing is because this x falls on this side of the boundary .
9.srt	00:05:57.500 --> 00:06:12.810	So, it is to be classified to class omega i or in other words what I am doing is I am trying to compute the distance between mu i and x and I am also computing the distance between mu j and x.
9.srt	00:06:29.090 --> 00:06:35.660	And here the distance between mu i and x which if I represent as d of x mu i and in other case the distance between x and mu j is d of x mu j, you find that d of x mu i is less than d of x mu j.
9.srt	00:06:36.500 --> 00:06:41.270	And that is true for any point x lying on this side of the boundary.
9.srt	00:06:43.070 --> 00:06:46.630	And all these cases this vector will be classified to omega i.
9.srt	00:07:01.450 --> 00:07:02.970	So, in other words the classification rule that I am applying is a minimum distance classification rule where the distance that you are computing is the Euclidean distance between the unknown vector x and the means of the classes.
9.srt	00:07:04.760 --> 00:07:21.400	Let us see the other case where we have assumed that mu i is of the form mu.
9.srt	00:07:22.410 --> 00:07:31.310	That means, the covariance matrix of all the classes are same, but the components of the feature vectors may not be statistically independent.
9.srt	00:07:31.630 --> 00:07:37.290	That means, the off diagonal elements of the covariance matrix may be nonzero.
9.srt	00:08:01.700 --> 00:08:04.870	So, under that situation again under the assumption of equal a priori probability that is p of omega i is equal to p of omega j, we found the decision boundary is bisector of the line joining mu i and mu j, but the decision boundary is no longer orthogonal to the line joining mu i and mu j.
9.srt	00:08:04.900 --> 00:08:10.690	So, it is a bisector, but it may not be orthogonal .
9.srt	00:08:10.690 --> 00:08:12.610	So, what do we do in this case?
9.srt	00:08:12.610 --> 00:08:26.610	Again here if I have an unknown point x on this side, this unknown point x will be classified to class omega i because it is falling on the side of mu i.
9.srt	00:08:26.610 --> 00:08:29.500	Is it a minimum distance classifier?
9.srt	00:08:29.740 --> 00:08:34.759	Yes, again in this case it is a minimum distance classifier because what we are computing is .
9.srt	00:08:35.240 --> 00:09:02.140	x minus mu i transpose sigma inverse x minus mu i and I am also computing x minus mu j transpose sigma inverse x minus mu j .
9.srt	00:09:02.170 --> 00:09:08.740	So, if x minus mu i transpose x sigma inverse x minus mu i this is less .
9.srt	00:09:08.960 --> 00:09:17.580	than X minus mu j transpose sigma inverse X minus mu j, then the point X will be classified to class omega i.
9.srt	00:09:42.909 --> 00:09:57.340	And you find that this is also a distance measure, but it is not Euclidean distance anymore, but this distance is what is known as Mahalanubis distance ok. And you find that, when this covariance matrix sigma is of the form sigma square i and assuming that sigma square is equal to 1, this Mahalanobis distance will be same as Euclidean distance.
9.srt	00:09:58.269 --> 00:10:17.350	So, even in this case where the covariance matrix sigma i of all the classes is same, but the feature components may not be statistically independent, I still get a minimum distance classifier, but the distance that you compute in this case is not.
9.srt	00:10:18.220 --> 00:10:24.710	Euclidean distance, but the distance that you have to compute is Mahalanovitch distance ok.
9.srt	00:10:25.000 --> 00:10:35.559	So, with this background now let me talk about what is meant by nearest neighbor rule or nearest neighbor classification.
9.srt	00:10:36.519 --> 00:10:49.809	So, as we said before that every object or every signal is represented by a vector or feature vectors whichever way the vectors are computed, it may be computed using some signal processing techniques.
9.srt	00:10:50.279 --> 00:10:58.439	Or given an image, I can simply represent this image as a vector by simply concatenating the columns of the image.
9.srt	00:10:58.939 --> 00:11:07.439	So, if I have an image of size say m by n, I will represent this by a vector having m into n number of components.
9.srt	00:11:07.559 --> 00:11:10.899	So, that becomes that an m into n dimensional vector.
9.srt	00:11:12.000 --> 00:11:23.629	So, once I represent these as vectors that means, the signal and image or whatever is represented by a point in that vector space or feature space.
9.srt	00:11:24.569 --> 00:11:37.749	So, as it is an m into n dimensional vector, so I am defining an m into n dimensional feature space and every image will be represented by a point in that m into n dimensional feature space.
9.srt	00:11:38.599 --> 00:11:47.779	But here I am taking a simplistic view because I cannot represent an m into n dimensional space on a two dimensional plane.
9.srt	00:11:47.779 --> 00:11:54.589	So, what I am doing is I am projecting them into two dimensional space.
9.srt	00:11:58.989 --> 00:12:03.939	So, each of these images that you find in this particular plane they are nothing, but different vectors.
9.srt	00:12:04.569 --> 00:12:15.369	So, this image is a vector, this image is a vector, I am simply projecting them into two dimensional space x 1 x 2 assuming that x 1 x 2 are the feature vectors.
9.srt	00:12:17.019 --> 00:12:21.279	Now, given this let us see what is a nearest neighbor rule.
9.srt	00:12:22.429 --> 00:12:29.399	So, here all these images arethe known images, I know what is the class from which this image comes.
9.srt	00:12:33.449 --> 00:12:50.039	So, for example, I know I have a lot of images which are birds, I have a lot of images which are cars, I have lot of images which are dogs ok. Now, given an unknown image this I have to classify or I have to identify what this image is.
9.srt	00:12:51.469 --> 00:12:57.469	You know that all those previous images that we had those are the training images using which I have to classify this unknown image.
9.srt	00:12:58.589 --> 00:13:03.969	So, one of the approach in which this image can be classified is what I do is.
9.srt	00:13:04.309 --> 00:13:16.969	I simply take the distance of this unknown image or the vector representing this unknown image from all other images which are known.
9.srt	00:13:18.219 --> 00:13:28.829	And once I compute this vector, so if I have say p number of previously known images and I have this unknown image which I want to identify.
9.srt	00:13:29.089 --> 00:13:35.799	So, I have to compute p number of distances, distance from every other image which we have in my knowledge base.
9.srt	00:13:36.079 --> 00:13:36.369	right.
9.srt	00:13:37.359 --> 00:13:42.859	And once I do that after that I find out that what is which is the image which is nearest to it.
9.srt	00:13:43.819 --> 00:13:51.369	So, if you go back to the previous one you find that probably this is the one which is nearest to this unknown image.
9.srt	00:13:53.149 --> 00:14:03.429	So, my classification rule is that whichever image is nearest to it I identify this unknown image to be the image corresponding to that class.
9.srt	00:14:04.009 --> 00:14:06.909	So, over here as this was.
9.srt	00:14:07.809 --> 00:14:08.779	the nearest image.
9.srt	00:14:09.009 --> 00:14:12.189	So, I identify this unknown image to be one of these images.
9.srt	00:14:12.869 --> 00:14:31.959	And obviously, in this case you find that your classification is not correct because the unknown image that I had was the image of a car whereas, my nearest neighbor rule has said that it is the image of a dog which is obviously, incorrect.
9.srt	00:14:32.389 --> 00:14:33.889	So, what is the problem in this case?
9.srt	00:14:37.559 --> 00:14:44.789	The problem is I am trying to find out which is the nearest known image in my knowledge base that is nearest to this unknown image.
9.srt	00:14:45.429 --> 00:14:48.799	So, I am taking my decision based on that nearest image.
9.srt	00:14:49.089 --> 00:15:01.599	So, my decision is based on only one vector and if that vector is an outlier then obviously, my decision is going to be wrong and that is what has happened in this case.
9.srt	00:15:03.549 --> 00:15:10.479	So, an alternative is that instead of considering only one image, if I consider multiple number of images.
9.srt	00:15:10.919 --> 00:15:19.639	So, what I will do is I will take multiple number of images.
9.srt	00:15:19.889 --> 00:15:26.229	So, if I take k number of nearest images then it becomes a k nearest neighbor rule.
9.srt	00:15:41.859 --> 00:15:45.639	So, in k nearest neighbor rule what you do is I have as before all these different vectors or images in my feature space again I have this unknown image I compute the distances from all the known images and out of that I consider only few or k number of images which are nearest.
9.srt	00:15:46.679 --> 00:16:03.909	And then among this k number of images I compute a vote that is whichever class of images is in major majority in that k number of images I consider this unknown image to be classified to that corresponding class.
9.srt	00:16:04.779 --> 00:16:11.459	So, in this particular case you find that the out of all these images which are nearest.
9.srt	00:16:12.929 --> 00:16:14.549	So, all these images.
9.srt	00:16:14.989 --> 00:16:18.979	which were nearest to this unknown image.
9.srt	00:16:20.089 --> 00:16:33.109	I have two images which belong to bird, I have two images which belong to dog, but I have 1, 2, 3 and 4, 4 images of cars.
9.srt	00:16:33.609 --> 00:16:35.799	So, this car images are in majority.
9.srt	00:16:36.009 --> 00:16:43.449	So, I classify this unknown image to be one of the car images and my classification in this case is correct.
9.srt	00:16:47.529 --> 00:17:00.309	So, K-nearest timber rule in general, it is gives better result than nearest neighbor rule because you are taking decision based on multiple number of images or multiple number of feature vectors which takes care of the outlets removal of outlets.
9.srt	00:17:02.479 --> 00:17:08.220	So, this nearest neighbor rules are very simple to apply, but what is the drawback?
9.srt	00:17:09.089 --> 00:17:17.409	The drawback is usually in machine learning applications I have lakhs and lakhs of images given for training.
9.srt	00:17:18.670 --> 00:17:25.940	So, whether I want to use nearest neighbor or k nearest neighbor, I have to save all those images in the memory.
9.srt	00:17:26.769 --> 00:17:34.980	And while taking decision for an unknown image or for an unknown vector, I have to compute all those lot of distance values.
9.srt	00:17:35.529 --> 00:17:44.039	And based on the distance values, I have to take a decision that to which class this unknownimage should be classified.
9.srt	00:17:45.190 --> 00:17:47.710	And that is obviously computationally extensive.
9.srt	00:17:49.409 --> 00:17:57.750	So, the simplest approach is that instead of trying to do this you try to find out the decision boundaries which we have also seen earlier.
9.srt	00:17:58.849 --> 00:18:06.730	So, given a number of classes the given images belonging to two different classes if I can compute a decision boundary between the two classes.
9.srt	00:18:07.869 --> 00:18:20.129	Then for an unknown image if that image falls on one side of the boundary it will be classified to say class omega i if it falls on other side of the boundary then it will be classified to class omega j.
9.srt	00:18:20.970 --> 00:18:27.210	And, for that once that boundary is computed I can discard all those training images or the training vectors.
9.srt	00:18:27.910 --> 00:18:35.680	What I need to stored is simply few number of parameters which identifies or which describes that boundary.
9.srt	00:18:36.600 --> 00:18:38.529	So, let us see how this can be done.
9.srt	00:18:39.690 --> 00:18:52.170	So, let us assume in this case take a let us consider this case that all these feature vectors they belong to one class and these are the feature vectors.
9.srt	00:18:52.669 --> 00:18:53.879	which belong to another class.
9.srt	00:18:54.980 --> 00:19:09.279	So, had we used a nearest neighbor rule and given an unknown feature vector over here in order to classify this unknown feature vector I had to compute the distances from all these feature vectors which are known.
9.srt	00:19:10.220 --> 00:19:19.289	And then based on these distance values I had to classify this unknown feature vector to either this class say omega 1 or this class say omega 2.
9.srt	00:19:23.129 --> 00:19:34.719	But now what I am doing is instead ofcomputing those distances or saving all these feature vectors in computer memory, I am trying to find out a boundary between these two classes.
9.srt	00:19:35.479 --> 00:19:46.029	So, assuming that all these feature vectors are linearly separable, I can separate these two classes of feature vectors by a linear boundary.
9.srt	00:19:53.339 --> 00:19:55.559	So, in a two dimensional case, it will be a straight line, in a three dimensional case, it will be a plane in case it will be hyper plane.
9.srt	00:19:57.059 --> 00:20:13.219	So, given such a linear boundary in this two dimensional case you find that the equation of this boundary will be something like a x 1 plus b x 2 plus c is equal to 0.
9.srt	00:20:24.049 --> 00:20:40.249	So, the parameters representing this particular straight line are the parameters a b and c where we know that a vector a b is orthogonal to this separating line to the line and c represents the position of the line in that is two dimensional space.
9.srt	00:20:41.019 --> 00:20:51.969	So, if I vary a and b in that case the orientation of the line will be different and if I vary c in that case the position of the line will be different.
9.srt	00:20:53.789 --> 00:20:55.619	So, this is what we have in case.
9.srt	00:20:55.799 --> 00:20:57.569	of a two dimensional space.
9.srt	00:20:58.069 --> 00:21:16.379	In case of a multi dimensional feature vector the equation will be a x 1 plus b x 2 plus c x 3 plus something like k that will be equal to 0.
9.srt	00:21:28.309 --> 00:21:36.889	So, if I have d dimensional feature vectors I can write this in the form w i x i where i varies from 1 to d plus w 0 that equal to 0.
9.srt	00:21:37.939 --> 00:21:58.219	So, you remember that this equation is similar to what we had derived earlier the decision boundary between two different classes usingthe normal multivariate distribution which was w transpose x plus w naught that equal to 0.
9.srt	00:21:59.449 --> 00:22:05.629	So, this is same as this when this W transpose X is expanded component wise.
9.srt	00:22:05.689 --> 00:22:07.169	So, this is the expression that I get.
9.srt	00:22:09.889 --> 00:22:24.879	So, this is the equation of the this straight line which or the plane which separatesthe feature vectors belonging to two classes omega 1 and omega 2 or omega i and omega j.
9.srt	00:22:28.999 --> 00:22:29.799	So, given this now I can move further.
9.srt	00:22:31.569 --> 00:22:49.689	So, what I need to do is given a set of feature vectors belonging to two different classes and assuming that the feature vectors are linearly separable, I have to find out a separating plane or hyper plane which separates the feature vectors belonging to these two different classes.
9.srt	00:23:02.379 --> 00:23:06.519	And the equation of that separating hyper plane is simply of the form W transpose x plus w naught is equal to 0.
9.srt	00:23:08.629 --> 00:23:19.879	And you remember that such a plane divides the feature space into two half spaces, one of the half space is positive and the other half space is negative.
9.srt	00:23:20.499 --> 00:23:31.659	So, if we say that the feature vectors taken from class omega 1, they belong to the positive half space and the feature vectors taken from class omega 2, they fall in the negative half space.
9.srt	00:23:32.429 --> 00:24:02.129	And, using this once I design such a classifier or the such a separating plane, then for an unknown feature vector say y, if w transpose y plus w naught becomes greater than 0, then we take a decision that w should belong to class omega 1 because y is sorry this is y naught x.
9.srt	00:24:02.599 --> 00:24:05.719	that, because y is falling on the positive half space.
9.srt	00:24:06.779 --> 00:24:18.629	Whereas, if we find that w transpose y plus w naught becomes negative, it is less than 0, then our decision will be that y should belong to class omega 2.
9.srt	00:24:20.839 --> 00:24:32.579	So, what we have is for all the known samples of the training samples, I if the training sample is taken from class omega 1, I should have w transpose x.
9.srt	00:24:32.789 --> 00:24:49.569	plus W naught greater than 0, when X belongs to class omega 1 and W transpose X plus W naught should be less than 0 when X belongs to class omega 2.
9.srt	00:24:50.919 --> 00:25:05.149	So, whichever W weight vectors W and the bias term W naught I choose that must satisfy these relations, these inequalities for the samples taken from class omega 1 and the samples taken from class omega 2.
9.srt	00:25:06.819 --> 00:25:23.279	Now, we find that this particular expression w transpose x plus w naught, I can put this in an unified representation in the form that I can write this as a transpose y.
9.srt	00:25:24.139 --> 00:25:24.969	How I can do it?
9.srt	00:25:25.779 --> 00:25:33.499	I have to append an additional dimension, I have to append an any additional dimension into this x.
9.srt	00:25:33.869 --> 00:25:36.419	So, if x is of dimension d.
9.srt	00:25:36.709 --> 00:25:45.079	I have to append a 1 to this dimension to this X and make it of dimensional d plus 1 .
9.srt	00:25:45.079 --> 00:25:49.829	So, the way it is done is suppose it is a d dimensional vector.
9.srt	00:25:49.829 --> 00:25:54.339	So, this w transpose t w is also a d dimensional vector.
9.srt	00:25:54.339 --> 00:26:09.730	So, I have w 1 w 2 up to w d this multiplied by X 1 X 2 up to X d .
9.srt	00:26:10.919 --> 00:26:22.119	So, this is the expression which gives me w transpose x plus w naught this equating to 0 gives me the equation of the separating plane.
9.srt	00:26:23.939 --> 00:26:41.819	Now, this equation I can rewrite in the form w 1, w 2, w d, w 0, x 1, x 2, x 3 .
9.srt	00:26:42.689 --> 00:26:47.909	1 this equal to 0.
9.srt	00:26:49.909 --> 00:26:56.389	So, I can call this as a and this as y right.
9.srt	00:27:14.119 --> 00:27:16.470	So, my equation simply becomes equation of the plane as a transpose y equal to 0 where a is w appended by w naught and y is vector x appended by and additional component which is equal to 1.
9.srt	00:27:17.919 --> 00:27:25.769	So, I can represent that equation W transpose X plus W naught equal to 0 as W transpose Y equal to 0.
9.srt	00:27:26.919 --> 00:27:33.889	And as before if Y belongs to class omega 1, I have to have A transpose Y greater than 0.
9.srt	00:27:34.639 --> 00:27:38.849	If Y belongs to class omega 2, I have to have A transpose Y less than 0.
9.srt	00:27:43.240 --> 00:27:47.149	What I can do is for all the Y, I can write which are taken from class omega 2, I simply negate them.
9.srt	00:27:48.609 --> 00:27:54.859	So, for them instead of considering y if I consider minus y for all y which are taken from class omega 2.
9.srt	00:27:56.189 --> 00:28:10.159	And if I do this then if y is correctly classified by a I will have simply a transpose y greater than 0, where y if it is taken from class omega 2 it is negated y.
9.srt	00:28:19.130 --> 00:28:33.210	So, given this I have now uniform criteria of correct classification that a transpose y has to be greater than 0 for all the training samples y whether they are taken from class omega 1 or that again from class omega 2 because for all the y's which are taken from class omega 2 they have been negated.
9.srt	00:28:34.819 --> 00:28:49.529	So, my design approach can be that I can start with any a arbitrarily, but if I find so with this a I test all the training samples.
9.srt	00:28:50.119 --> 00:29:00.269	So, as long as for every training sample A transpose Y remains greater than 0, I know this A correctly classifies all those training samples.
9.srt	00:29:01.490 --> 00:29:18.149	But for if for any training sample, I find that A transpose Y becomes less than 0, then I know that this Y has not been correctly classified or it has been misclassified by this vector A.
9.srt	00:29:20.950 --> 00:29:23.970	So, what I have to do is, I in this particular case this a has to be modified.
9.srt	00:29:25.779 --> 00:29:38.730	So, in order to do this what I can do is I can compute some sort of error terms that is for every vector which is misclassified I will compute an error.
9.srt	00:29:41.039 --> 00:29:51.659	So, the error term because y will be misclassified if a transpose y is less than 0 I can simply compute the error term as minus a transpose y.
9.srt	00:29:53.099 --> 00:29:58.089	So, whenever a transpose y is less than 0 minus a transpose y will have a positive positive term.
9.srt	00:29:59.539 --> 00:30:18.549	So, if I check all the feature vectors all the training vectors which are misclassified by this a I collect all of them compute minus a transpose y for all those feature vectors which are misclassified and take the sum of all of them right.
9.srt	00:30:19.230 --> 00:30:22.569	So, I compute an error say g.
9.srt	00:30:23.339 --> 00:30:45.480	y which is equal to minus a transpose y for all y which are misclassified and j will be equal to 0 if all the samples are correctly classified.
9.srt	00:30:46.990 --> 00:30:56.789	So, you find that if I have the misclassified samples this sample this sum sum of minus a transpose y is going to be positive.
9.srt	00:30:57.809 --> 00:31:04.499	And, if all the samples are correctly classified all the vectors are correctly classified then the value of j will be equal to 0.
9.srt	00:31:05.979 --> 00:31:27.729	So, while designing this a or while designing the boundary between the linear boundary between two different classes or approach should be that we should be able to or we should try to reduce this error term j ok. And, for that the kind of approach that can be taken is.
9.srt	00:31:29.700 --> 00:31:32.859	So, something like this .
9.srt	00:31:34.930 --> 00:31:59.269	So, I have this a I will put an initial a to be equal to 0 ok and then gradually in the kth step I should be able to a get a k from a of k minus 1 that is the previous value of a.
9.srt	00:31:59.299 --> 00:32:25.919	a such that I move from a k plus 1 to a k minus 1 to a k in such a way that this movement will try to reduce the error j a if I represent the error as a function of a that when I move from j a k minus 1 to a k the error a should be reduced.
9.srt	00:32:27.559 --> 00:32:31.129	So, we will talk about this more in our next lecture.
9.srt	00:32:31.589 --> 00:32:31.950	Thank you.
17.srt	00:00:00.610 --> 00:00:27.920	Hello, welcome to the NPTEL online certification course on deep learning.
17.srt	00:00:31.870 --> 00:00:48.590	You remember in the previous class we have started our discussion on optimization techniques and we have talked about the differentoptimizationtechniques like stochastic gradient descent, we have talked about batch optimization and we have also talked about mini batch optimization.
17.srt	00:00:49.260 --> 00:01:03.680	In today's lecture we are going to talk about optimization in machine learning in particular that how optimization in machine learning applications differs from general optimization problems.
17.srt	00:01:08.879 --> 00:01:25.459	We will also talk about linear and logistic regression, softmax classifier and we will also talk about the nonlinearity, how nonlinearity is important in case ofdeep learning or machine learning applications.
17.srt	00:01:27.319 --> 00:01:37.530	So, let us first talk about how machine learning optimization in machine learning is different from general optimization techniques.
17.srt	00:01:38.969 --> 00:01:39.849	So, what you do?
17.srt	00:01:40.120 --> 00:01:41.340	in case of optimization.
17.srt	00:01:42.599 --> 00:01:53.450	The goal of optimization is to reduce a cost function given by say J w where w is the parameters which defines your machine learning algorithm.
17.srt	00:01:54.280 --> 00:02:07.560	So, you optimize this cost function J w or minimize the cost function J w in order to optimize some performance measure of your learning algorithm or machine learning model.
17.srt	00:02:08.430 --> 00:02:11.370	So, what is the performance measure in case of machine learning?
17.srt	00:02:11.610 --> 00:02:13.060	that we have discussed so far.
17.srt	00:02:14.030 --> 00:02:25.009	The problems that we have considered are mainly categorization or classification problems that is given objects or signals belonging to different categories.
17.srt	00:02:25.449 --> 00:02:32.420	We try to identify that which signal or which object belongs to which which kind of category.
17.srt	00:02:33.379 --> 00:02:41.719	So, if your categorization or classification is correct there is no error, if the classification is incorrect you incur some error.
17.srt	00:02:42.520 --> 00:02:52.110	So, the performance measure with respect to machine learning is how accurate your classification or categorization problem is decision is.
17.srt	00:02:53.349 --> 00:03:10.680	And in order to do that you minimize a cost function J w which isthis cost function J w iscomprises of the loss that you incur during classification of the training data.
17.srt	00:03:13.100 --> 00:03:15.560	Now, if you talk about the pure optimization problem.
17.srt	00:03:16.180 --> 00:03:28.800	In case of pure optimization problem theoptimization criteria the cost function j is minimized and that is the goal in and of itself.
17.srt	00:03:29.660 --> 00:03:46.490	In other sense suppose you are given a set of observations in two dimension that is I may have x y pairs where I assume that x is an independent variable and y is a dependent variable.
17.srt	00:03:47.480 --> 00:04:16.950	And, if there is sufficient reason to believe that the relation between x and y is linear, then given a set of observations what we would like to do is we would like to fit a minimum error state line passing through the set of observed data and that is the M. And, when you try to find out this state line which minimizes the error actually you go forminimization of sum of squared error.
17.srt	00:04:18.660 --> 00:04:21.810	And, once the line is fit your goal issatisfied.
17.srt	00:04:22.910 --> 00:04:38.490	But, when you talk about machine learning in case of machine learning we minimize the loss function or cost function J wwhere w is the parameters of your machine learning algorithm or the machine learning model.
17.srt	00:04:39.110 --> 00:04:48.370	But, this minimization is done on the training data or the training samples or in other words what you try to minimize.
17.srt	00:04:48.620 --> 00:04:49.800	is the training error.
17.srt	00:04:51.040 --> 00:04:52.600	But what is our actual aim?
17.srt	00:04:53.380 --> 00:04:59.290	Our actual aim is not to classify the training data because for the training data the classes are already known.
17.srt	00:04:59.900 --> 00:05:06.220	So, what is the great thing about classifying the data which are known already.
17.srt	00:05:07.250 --> 00:05:26.420	So, our aim is not to class correctly classify the training data, but our aim is that the machine that you have trained using the training data or the level data that same algorithm or the machine has to be used for classification of unknown or unforeseen data.
17.srt	00:05:26.810 --> 00:05:31.010	data which the machine has not seen before.
17.srt	00:05:31.910 --> 00:05:37.170	And for this unknown data theclass belongingness is not really known because if it is known then I do not have to classify.
17.srt	00:05:38.750 --> 00:05:54.910	So, for this what my aim is that though I am training the machine or minimizing the error on the training data, but my aim is that the same machine has to perform well on the actual data or the test data.
17.srt	00:05:56.960 --> 00:06:03.420	So, I want that not only the training error to be minimized, but also the test error is to be minimized.
17.srt	00:06:04.350 --> 00:06:05.980	So, how do you know the test error?
17.srt	00:06:06.810 --> 00:06:13.540	Because as I said that for your real life classification problem that class belongingness of the data is not known.
17.srt	00:06:14.590 --> 00:06:27.310	So, what you do is you set aside a set of level data which are known as test data for which the classes are known, but you do not use that set of data or test set for training the machine.
17.srt	00:06:28.710 --> 00:06:40.330	So, in that case I can compute what is the error given by the machine while testing, but while training you use one set of data which is training set for testing you set another set of data which is test set.
17.srt	00:06:40.620 --> 00:06:51.790	But again when you come to actual application when you want to deploy this machine learning model machine learning algorithm for classification or recognition there the class belongingness of the data is not really known.
17.srt	00:06:52.660 --> 00:06:59.010	So, accordingly you incorporate some test error when you are testing the machine on the test.
17.srt	00:06:59.170 --> 00:07:02.830	test set of data which are not actually used for training purpose.
17.srt	00:07:03.680 --> 00:07:12.740	And while doing so you incorporate some error or some loss which are the test which is known as the test error or generalization error.
17.srt	00:07:13.860 --> 00:07:29.530	So, in case of machine learning algorithms or optimization in case of machine learning though I am optimizing the machine on the training data, but my aim is that the same machine should perform well on the test data as well as on the real life data.
17.srt	00:07:30.760 --> 00:07:37.930	So, that is the basic difference between a machine learning algorithm or optimization in case of machine learning algorithm.
17.srt	00:07:39.910 --> 00:07:59.800	So, naturally because the test data has not been used for training the machine, how do we really know or how do we really guarantee that the machine or algorithm which has been trained on the training data will also perform well or give?
17.srt	00:08:00.350 --> 00:08:08.450	error while testing on the test data or it will also give minimum error when you actually deploy the machine for real life classification problem.
17.srt	00:08:08.700 --> 00:08:28.680	So, truly speaking this cannot be guaranteed, but under certain assumptions we cansay with certain degree ofconfidence that the machine will also perform well on the test data.
17.srt	00:08:29.670 --> 00:08:31.390	And for that we make some.
17.srt	00:08:31.600 --> 00:08:35.540	assumptionspopularly known as IID assumptions.
17.srt	00:08:36.280 --> 00:08:48.880	So, what you assume is that both of the training data and the test data they are generated by a probability distribution which is known as the data generation process or data generation model.
17.srt	00:08:50.240 --> 00:09:02.900	We also assume that the data samples in each set in data set are independent that is one sample or one vector is independent of the other vector.
17.srt	00:09:04.029 --> 00:09:10.570	And, we also assume that the training set and test set are identically distributed.
17.srt	00:09:10.649 --> 00:09:28.470	So, when you talk about the data distribution, the distribution of the training set of data and the distribution of the test set of data they are identical and that is what is known as IID assumption that is independent identically distributed set of data.
17.srt	00:09:30.320 --> 00:09:34.250	Similarly the performance of a machine learning algorithm.
17.srt	00:09:34.569 --> 00:09:40.509	is measured by its abilityto perform two tasks.
17.srt	00:09:41.579 --> 00:10:05.059	One of the task is that it has to make the training error small that is while training the machine on the training set of data, the training error that you incorporate that should be small and only when it is very small ideally it should be 0, we assume that the machine or your algorithm is properly trained or it has learned the classes.
17.srt	00:10:06.099 --> 00:10:18.749	And, secondly when you test it so, while testing on the test data and as we said before that the test data is not used during training the machine though we know what are the class belongingness of the test data.
17.srt	00:10:19.609 --> 00:10:25.929	So, once the machine is trained on the training data you use the same machine on the test data.
17.srt	00:10:27.099 --> 00:10:36.379	And, in case of test data ideally we want that the error should be minimum or the error should be 0 in ideal cases, but practically that may not be possible.
17.srt	00:10:36.989 --> 00:10:41.419	So, while applying the same machine on the test data we get some test error.
17.srt	00:10:42.379 --> 00:10:50.999	So, again the performance of the machine learning algorithm is measured in terms of what is the gap between the between the training error and the test error.
17.srt	00:10:51.479 --> 00:11:03.939	So, we always expect that whatever is the training error the test error should also be similar that means, the gap between the training error and the test error should be as small as possible.
17.srt	00:11:05.969 --> 00:11:13.739	So, these are certain assumptions and the under those assumptions we talk about how the machine learning algorithm actually perform.
17.srt	00:11:15.409 --> 00:11:32.539	Now, these assumptions and the performance measures that lead to two very importantproblems to challenging problems, one of them is known as underfitting problem and the other one is known as overfitting problem.
17.srt	00:11:33.979 --> 00:11:35.319	So, what is underfitting problem?
17.srt	00:11:35.909 --> 00:11:47.069	Underfitting problem is when yourmodel or the machine is not able to obtain sufficiently low training error, that means, it is not performing well.
17.srt	00:11:47.459 --> 00:11:49.199	on the training data itself.
17.srt	00:11:49.689 --> 00:11:53.299	So, the training error is notacceptably low.
17.srt	00:11:54.009 --> 00:11:58.519	And as we said that in ideal cases we expect this training error should be 0.
17.srt	00:11:58.859 --> 00:12:08.829	That means, all the training samples which are given for training the machine they should be correctly classified and then only we get the training error to be 0.
17.srt	00:12:10.119 --> 00:12:16.089	And the overfitting says that the gap between training and test error is too large.
17.srt	00:12:16.089 --> 00:12:17.449	So, there may be cases.
17.srt	00:12:17.959 --> 00:12:35.719	that while training we have been able to design a machine or a model where the training error is minimum, but the same machine when it is applied on the test data the test data is quite large that means, there is a gap between the training error and the test error.
17.srt	00:12:36.129 --> 00:12:47.509	So, overfitting says that your model has been able to capture even the minute differences in the test data and while doing so.
17.srt	00:12:47.809 --> 00:13:00.949	the model is so tuned to the test data that it is not it has lost the generalization and it is not being able to perform well on the test data and that is what is known as overfitting problem.
17.srt	00:13:02.929 --> 00:13:16.789	So, this problems of overfitting or underfittingcan be controlled by altering another property of the model which is known as model capacity or capacity of the machine learning algorithm.
17.srt	00:13:22.069 --> 00:13:26.109	And this capacity is nothing but a set of functions the learning algorithm can select as being the solution.
17.srt	00:13:27.349 --> 00:13:36.709	So, we will just see after this and you remember that all the problems that we have considered we have discussed till now they are linear problems.
17.srt	00:13:37.449 --> 00:13:51.639	We have assumed that given data belonging to two different classes in the feature space, I can have a hyper plane in the feature space, I can define a hyper plane in the feature space where all the training data belonging to one class.
17.srt	00:13:51.749 --> 00:14:05.269	hyper plane if I pass a curve or a surface a curved surface then a curved surface may be able to separate those twoset of data belonging to two different classes.
17.srt	00:14:05.859 --> 00:14:08.279	So, that is what is known as the set of functions.
17.srt	00:14:09.229 --> 00:14:21.489	Always the linear function may not be sufficient, I may have to go for functions of higher order, maybe quadratic, maybe cubic or even fourth order, fifth order and so on which is known as the capacity.
17.srt	00:14:28.779 --> 00:14:35.189	So, if I control the capacity or the set of functions the training algorithm can adopt as required, then possibly we can have a control over the overfitting and underfitting problems.
17.srt	00:14:35.939 --> 00:14:48.269	And there also it is not that that simple or that easy because it is quite possible that say for example, a data set which is sampled from a quadratic function.
17.srt	00:14:48.729 --> 00:14:55.389	If I want to fit a quadratic functionit will be properly fit that means, all the data will beproperly fit to the quadratic curve.
17.srt	00:14:58.859 --> 00:15:02.199	If I try to fit a surface, then obviously, I will incorporate some error.
17.srt	00:15:03.259 --> 00:15:24.669	If I want to fit a data of say higher dimension say of a curve of higher dimension say order 5 or order 7 and so on, then it is possible that for the given set of data, I will have no loss there will be no error, but the data is too specific for that set of training samples.
17.srt	00:15:25.269 --> 00:15:30.899	It is not general enough to perform well on unknown data set or test data set.
17.srt	00:15:31.969 --> 00:15:42.339	So, even selecting the capacity of the model or capacity of the learning of the machine learning algorithm isalso a difficult task or a challenging task.
17.srt	00:15:43.709 --> 00:15:58.509	So, here we have talked about that what is the difference between a general optimization task and an optimization task as as applicable to machine learning algorithms.
17.srt	00:16:02.109 --> 00:16:10.309	Because in case of machine learning algorithms though we are on the training set of data, but actually I want to perform on a different set of data which is test set of data right.
17.srt	00:16:10.809 --> 00:16:22.519	So, now I talk about two problems which are known as linear regression and logistic regression and we will see the importance of this.
17.srt	00:16:22.519 --> 00:16:26.369	So, what is linear regression?
17.srt	00:16:26.369 --> 00:16:33.229	You find that so far all the problems of the examples that we have considered as .
17.srt	00:16:33.459 --> 00:16:47.849	as we have just mentioned now that I have considered only the linear problems that is given two sets of data I should be able to find outstraight line in two dimension or a surface or a plane in three dimension or a hyper plane in even higher dimension.
17.srt	00:16:48.889 --> 00:17:00.129	So, effectively there what I want to do isthis model that maps a feature vector of dimension d to a scalar.
17.srt	00:17:03.549 --> 00:17:06.469	ywhich is a linear number.
17.srt	00:17:06.469 --> 00:17:33.249	So, this is actually put in this form that this is a mapping which maps a feature vector x of dimension d. So, we write it this way that x belongs to r d. So, it maps this feature vector x to and y or in the other words that given feature vector x we want to predict what is y, what is the value of y.
17.srt	00:17:34.029 --> 00:17:48.319	So, I can write this in the form of a linear equation of this form that y hat is equal to W transpose X, where W is the weight vector and based on the value.
17.srt	00:17:48.529 --> 00:18:03.849	So, while training what we try to do is, we try to minimize the error between actual y which is the two class that is given for the set of data and this y hat that is predicted.
17.srt	00:18:04.459 --> 00:18:07.159	We want to minimize this error during the training operation.
17.srt	00:18:08.249 --> 00:18:20.359	And during classification what we do is based on this predicted value of y which is y hat we take a decision that whether we should classify x to class 1 or we should classify x to class 2.
17.srt	00:18:35.319 --> 00:18:45.979	So, for a binary classification problem that we have donepreviously we have discussed previously we have seen that if y hat is positive that means if it is greater than 0 then we classify x to class 1 and if y hat is negative that it is less than 0, then we classify x belonging to belong to class 2.
17.srt	00:18:46.679 --> 00:18:49.299	Now, what is this linear regression actually?
17.srt	00:18:49.889 --> 00:19:05.289	If you look at this expression that is W transpose x given this example here we have taken the same example in your previous discussion.
17.srt	00:19:05.809 --> 00:19:20.049	that we assume that this is the set of data the set of feature vectors which belong to class say omega 1 and this is another set of feature vectors that belong to class omega 2 .
17.srt	00:19:20.049 --> 00:19:31.119	So, for every point and this is myhyper plane given by the equation W transpose X equal to 0 .
17.srt	00:19:31.119 --> 00:19:36.749	So, you find that for every point belonging to omega 1 your W transpose X will be greater than 0 .
17.srt	00:19:37.079 --> 00:19:42.489	for every sample belonging to class omega 2 W transpose X will be less than 0.
17.srt	00:19:43.699 --> 00:19:59.519	And in fact, this W transpose X upon mod of W that actually gives you an idea of what is the distance or perpendicular distance of the vector X from the plane W transpose X equal to 0.
17.srt	00:20:00.399 --> 00:20:08.039	So, that measure gives us a confidence of how accurate your classification is.
17.srt	00:20:08.839 --> 00:20:25.399	Because, given these two sides if I have a vector over here which is far away from the separating plane in such cases obviously, I can tell with high degree of confidence that my classification result is correct.
17.srt	00:20:26.339 --> 00:20:39.949	Whereas, if I have a data somewhere over here where the distance of this data of this vector from the separating plane is very small my confidence level is not that high.
17.srt	00:20:40.609 --> 00:20:45.859	though here the distance becomes greater than 0 as w transpose X becomes greater than 0.
17.srt	00:20:45.859 --> 00:20:54.409	So, I classify this to belong to class omega 1, but my confidence level is not that high as I have confidence in this particular case.
17.srt	00:20:55.759 --> 00:21:06.649	So, I have a physical interpretation of the value of w transpose X that it says that how well inside the class the data is.
17.srt	00:21:07.899 --> 00:21:12.379	And if it is very high w transpose X is very high on the positive side.
17.srt	00:21:13.480 --> 00:21:33.180	Then, with guarantee I can say that yes this belongs to class omega 1 and if it is very low that is W transpose X is high magnitude, but it is negative then I can tell with confidence that yes it belongs to class omega 2, but if the value is low my confidence level comes down.
17.srt	00:21:34.269 --> 00:21:43.880	So, I can have another interpretation ofthis measure that is what is given by.
17.srt	00:21:44.400 --> 00:21:46.039	logistic regression.
17.srt	00:21:47.339 --> 00:22:15.819	So, in course of logistic regression I can have a probability measure that is I can compute that what is the probability of Y which is the class index given a feature vector X and the model parameter W which is written in this form P Y given X and parameter vector W .
17.srt	00:22:17.339 --> 00:22:23.019	x that can be written as a function of sigma w transpose x.
17.srt	00:22:23.130 --> 00:22:40.269	So, again you find that this w transpose x what you what you said earlier is a measure of distance this was a distance measure distance of x from the surface w transpose x equal to 0 and using this sigma function I can convert this to a probability measure.
17.srt	00:22:40.930 --> 00:22:49.480	So, as we said that if my data vector x is far away from the separating plane my confidence level is very high.
17.srt	00:22:51.490 --> 00:22:58.669	So, that in other sense I can say that the probability of class Y is very high.
17.srt	00:22:59.189 --> 00:23:14.759	So, I can convert this distance measure into a probability measure and that is what is done by this function sigma and I can write this function as a sigmoidal function which is given like this.
17.srt	00:23:20.609 --> 00:23:29.339	So, this sigmoidal function is nothing, but sigma W transpose X equal to 1 by 1 plus e to the power minus W transpose X.
17.srt	00:23:30.459 --> 00:23:35.939	And if I plot this function the function will have a plot like this which is a sigmoidal function.
17.srt	00:23:36.629 --> 00:23:51.969	So, if I plot sigma W transpose X versus W transpose X I get a curve as shown on this slide and here you find that as W transpose X become high as you increase W transpose X.
17.srt	00:23:52.349 --> 00:24:06.399	So, coming to our previousinterpretation of distance from the separating plane as the distance from the separating plane is very high the probability goes on increasing and asymptotically it goes to 1.
17.srt	00:24:08.019 --> 00:24:12.990	On the other hand if W transpose X is negative you find over here.
17.srt	00:24:12.990 --> 00:24:22.569	So, here you find that if W transpose X is equal to 0 what I get is sigma W transpose A X that is equal to half.
17.srt	00:24:23.639 --> 00:24:23.909	right.
17.srt	00:24:24.019 --> 00:24:32.929	So, from here e to the power minus W transpose X, if W transpose X is 0 that means, e to the power minus W transpose X is 1.
17.srt	00:24:33.329 --> 00:24:35.589	So, I get simply the value of half.
17.srt	00:24:36.039 --> 00:24:41.829	So, as at W transpose X equal to 0, the value of this sigmoidal function is half.
17.srt	00:24:42.259 --> 00:24:52.689	That means, if the feature vector lies on the separating plane, it has equal probability of belonging to class omega 1 and class omega 2.
17.srt	00:24:53.089 --> 00:24:57.129	or in other words I cannot really classify the feature vector x.
17.srt	00:24:58.000 --> 00:25:13.970	Whereas, as W transpose x becomes greater than 0, its probability of belongingness to class 1 goes on increasing and when W transpose x becomes very high that is the distance from the separating plane is very high the probability goes towards 1.
17.srt	00:25:24.079 --> 00:25:32.729	And to the other side as W transpose x becomes negative and becomes lower and lower that more on the negative side asymptotically your sigma W transpose X becomes tends to be 0.
17.srt	00:25:33.169 --> 00:25:38.359	That means, its probability of belongingness to class omega 1 is almost 0.
17.srt	00:25:39.429 --> 00:25:46.019	And when I compute the probabilities because I have I am considering only two classes omega 1 and omega 2.
17.srt	00:25:46.629 --> 00:25:54.399	So, I can say that the probability that it belongs to class omega 1 and the probability of it belonging to class omega 2.
17.srt	00:25:54.399 --> 00:25:57.659	So, what I can write is I can write it in this form.
17.srt	00:25:58.269 --> 00:26:16.559	1 thatprobability y equal to 1 given x and w that is the probability that x belongs to class omega 1 and I can also write the probability that x belongs to class omega 2.
17.srt	00:26:16.559 --> 00:26:24.680	So, probability y is equal to 2 given x and w .
17.srt	00:26:24.680 --> 00:26:29.960	So, if I add these two that should be equal to 1 because I am considering only two classes omega 1 and omega 2.
17.srt	00:26:30.889 --> 00:26:38.629	So, here as the probability belonging to class omega 1 becomes high, the probability of belonging to class omega 2 becomes lower.
17.srt	00:26:39.539 --> 00:26:51.119	And this is the point when both of them are equal that is probability of belongingness to both the classes are halfto omega 1 as well as half to omega 2.
17.srt	00:26:52.539 --> 00:26:59.559	So, that is what is logistic regression that is converting my distance measure or the confidence measure.
17.srt	00:27:01.209 --> 00:27:10.869	to a probabilistic measure that what is the probability that X belongs to class omega 1 or what is the probability that X belongs to class omega 2.
17.srt	00:27:11.699 --> 00:27:15.089	There is another concept which is known as soft max classifier.
17.srt	00:27:16.389 --> 00:27:31.059	So, earlier this linear regression orlogistic regression which we have discussed those are with respect to our binary classifier or two class problem, but when we have a multi class problem.
17.srt	00:27:32.889 --> 00:28:00.009	machine, we have discussed earlier that I can have a linear machine where using a linear machine the parameters set of parameters are represented as a weight matrix W, where vectors in every row of the weight matrix W we have said represents a prototype or represents a class or sample belonging to a particular class that is a representative of a particular class.
17.srt	00:28:02.769 --> 00:28:06.539	So, if I have say k number of classes I will have k number of rows in the weight vector.
17.srt	00:28:07.709 --> 00:28:24.709	And what that set of or matrix ofweight vectors give is when you multiply that with your given feature vector you get a score vector and we have seen that the score vector is a set of real numbers.
17.srt	00:28:25.119 --> 00:28:31.029	So, if I have got k number of classes my score vector x was having k number of elements.
17.srt	00:28:31.989 --> 00:28:35.589	So, if I have a feature vector x which belongs to class omega.
17.srt	00:28:36.189 --> 00:29:08.779	which belongs to class say y i the class index is y i, then the corresponding score is given by S of y i which have we have computed as w x i and the y i th component of that or this also you can write as w y i th rho the vector corresponding to y i th rho take the transpose of that vector and multiply that with x i .
17.srt	00:29:10.119 --> 00:29:24.939	So, that gives you the score fact score of class y i for feature vector x or x i which belongs to class y i that is we already know because this is a training vector.
17.srt	00:29:26.979 --> 00:29:40.439	So, again this is on the output of a linear function as we have done in case of in case of logistic regression I can also convert this to a probabilistic measure.
17.srt	00:29:41.019 --> 00:30:11.949	So, I can say that what is the probability of class y i given sample x i and your parameters w given by the parameter matrix or the weight matrix w. And we can compute this as e to the power s y i upon e to the power s j where the summation sum of e to the power s j in the denominator where the summation has to be taken over all j .
17.srt	00:30:13.430 --> 00:30:31.529	So, you find that this also converts or score factors orthe score values to different classes in a probabilistic measure that what is the probability of class y i given of which a vector x or given a feature vector x i.
17.srt	00:30:33.180 --> 00:30:35.279	So, we will continue our lecture further.
17.srt	00:30:36.529 --> 00:30:37.349	Thank you very much.
16.srt	00:00:00.610 --> 00:00:27.879	Hello, welcome to the NPTEL online certification course on deep learning.
16.srt	00:00:31.730 --> 00:00:41.030	In our previous class, we have talked about the loss function in a multiclass support vector machine which is a linear machine.
16.srt	00:00:41.969 --> 00:00:56.219	And we have also seen that how the loss function can beminimized using the gradient descent approach, so that we get the weight matrix corresponding to the minimum loss on the training vectors.
16.srt	00:00:57.409 --> 00:01:02.769	In today's lecture, we will continue with the optimization techniques.
16.srt	00:01:03.709 --> 00:01:19.599	And, we will talk about three variants of the optimization techniques which are stochastic gradient descent approach, a batch optimization technique and a minima mini batch optimization techniques .
16.srt	00:01:20.969 --> 00:01:36.109	So, just to recapitulate what we have done in the previouslecture, we had defined a loss function for a multi class support vector machine which is given by L is equal to 1 upon N .
16.srt	00:02:06.999 --> 00:02:13.049	Then, summation of maximum of 0 and w j transpose x i minus w y transpose x i plus delta plus lambda times sum of w k L square where w was our weight matrix and the first term in this loss function which is 1 upon N of sum of this, this is what constitutes the data loss component.
16.srt	00:02:13.959 --> 00:02:34.429	So, it is data loss component and the second term lambda times sum of W k L squared, this is what we said is regularization loss .
16.srt	00:02:34.429 --> 00:02:36.989	So, in order to minimize this loss .
16.srt	00:02:37.319 --> 00:02:49.060	using the gradient descent approach, we have to take the gradient of this loss function with respect to w y i and the gradient of this loss function with wj.
16.srt	00:02:49.530 --> 00:03:10.399	So, the gradient with respect to w y i is given by this, it is minus 1 over n sum of all those x i, all those training vectors for which w j transpose x i minus w y transpose x i plus delta is greater than 0.
16.srt	00:03:11.550 --> 00:03:41.530	So, you find that for those training samples for which this component this term W j transpose y i minus W y i transposeW j transpose x i minus W y i transpose x i plus delta is greater than 0 such x i such training samples are not correctly classified or not satisfactorily classified by the weight vector W .
16.srt	00:03:42.119 --> 00:03:54.409	So, for these samples we have to correct the weight vector w. So, that is the reason you take the sum of x i only for those samples which are not correctly classified.
16.srt	00:03:55.280 --> 00:04:00.029	And this is the correction term that comes from the data losscomponent.
16.srt	00:04:00.889 --> 00:04:07.859	Similarly, the other term that comes from the regularization loss component which is eta times w y i.
16.srt	00:04:09.060 --> 00:04:13.459	In the same manner when you take the gradient with respect to w j.
16.srt	00:04:13.750 --> 00:04:38.329	Again, I have a component 1 over 1 over n sum of X i where W j transpose X i minus W y i transpose X i plus delta is equal to is greater than 0 and such X i is obviously not satisfactorilyclassified by the W that I have at that iteration step.
16.srt	00:04:39.220 --> 00:04:45.329	So, you take the summation of all those X i which are not satisfactorily classified.
16.srt	00:04:45.870 --> 00:05:02.970	I do not take any corrective measure for attaining sample X i which is satisfactory classified by W. So, this is a term again coming from the data loss component and the other term that comes from the regularization component is zeta times W j .
16.srt	00:05:02.970 --> 00:05:16.300	So, using this gradient you go for gradient descent approach and your weight updation rules becomes W y i k plus 1 gets 1 minus eta times W y i k .
16.srt	00:05:16.649 --> 00:05:24.379	plus 1 over n sum of all those x i which were not satisfactorily classified.
16.srt	00:05:25.480 --> 00:05:43.410	Similarly, W j is modified as W j k plus 1 is equal to 1 minus zeta times W j k minus 1 over n sum of all those x i which are not satisfactorily classified.
16.srt	00:05:44.110 --> 00:05:47.910	So, that is what gives you the gradient descent approach for .
16.srt	00:05:48.450 --> 00:06:06.990	of the weight matrix and once you reach the minimum of the loss or on convergence the W matrix that you get that gives you the support vector machine or the linear machine which now can be used for classification.
16.srt	00:06:07.850 --> 00:06:19.030	And again you remember that all these X i which are being used for training the support vector machine or for training the linear machine once the training is complete that is once we get.
16.srt	00:06:19.360 --> 00:06:40.550	and weight which satisfies our criteria of correct classification, then we can forget about all those training vectors or X i's which were used for training the support vector machine or which were used for obtaining the value of weight matrix W which is now to be used for classification.
16.srt	00:06:40.970 --> 00:06:50.010	So, once this part of learning is complete, we can simply discard all those training vectors and what I need is only this weight matrix weight matrix W.
16.srt	00:06:50.250 --> 00:06:56.430	for classification of any unknown samples or any unforeseen samples right.
16.srt	00:06:57.500 --> 00:07:04.930	So, coming to the nature ofthe optimization functions or the loss functions.
16.srt	00:07:05.490 --> 00:07:23.120	Earlier in case of support vector machine we have seen that the loss function is convex which isalways we want that the loss function to be convex because then I do not have the problem oflocal minima or global minima.
16.srt	00:07:24.670 --> 00:07:31.620	But, in general we will see later that we can have situations where the loss function is not necessarily convex.
16.srt	00:07:31.860 --> 00:07:39.700	So, I can have a loss function which is given over here the nature of the loss function is somewhere over here.
16.srt	00:07:40.590 --> 00:07:50.970	So, here you find that this loss function has a number of maximas and it also has a number of minimas right.
16.srt	00:07:51.930 --> 00:07:56.330	So, a minima which is minima over all the minimas that is what is the global minima.
16.srt	00:07:57.400 --> 00:08:01.800	Similarly, a maxima which is maximum over all the maximums that is the global maximum.
16.srt	00:08:02.140 --> 00:08:08.560	So, we have local minima and global minimum and we have local maxima and global maxima.
16.srt	00:08:09.650 --> 00:08:16.300	So, the target of any optimization technique is to reach the global minima.
16.srt	00:08:17.200 --> 00:08:22.010	However, there is a possibility that you may be trapped into local minima.
16.srt	00:08:23.240 --> 00:08:26.370	So, in case of machine learning and machine learning applications.
16.srt	00:08:26.630 --> 00:08:36.210	even a solution leading to a local minima is acceptable if the loss or the error given by that is not too much.
16.srt	00:08:37.350 --> 00:08:48.600	However, as we said that it is possible that you may be trapped into local minima and obtaining a solution corresponding to a global minima may not be possible always.
16.srt	00:08:51.000 --> 00:08:56.400	So, this is in general is what is the loss function and as I said that we .
16.srt	00:08:56.899 --> 00:09:00.720	always target to have to achieve the global minimum.
16.srt	00:09:02.649 --> 00:09:12.960	Now, I talk about three different optimization variants, one is the stochastic optimization, the other one is batch optimization, the other one is mini batch optimization.
16.srt	00:09:14.480 --> 00:09:19.159	So, if you look at the previous optimization techniques is somewhere over here.
16.srt	00:09:27.969 --> 00:09:49.839	So, you find that whenever I compute the loss function or let me come to the definition of the loss function So, whenever I come to or try to define the loss function, the loss function is defined in terms of all those samples, all those training samples which are not correctly classified or which are not satisfactorily classified by yourclassifier or by the support vector machine.
16.srt	00:09:50.740 --> 00:09:57.359	So, I have to collect all those samples which are not satisfactorily satisfied,satisfactory classified.
16.srt	00:09:58.929 --> 00:10:07.659	That means, for my training algorithm to work I must have access to all the training samples in one go right.
16.srt	00:10:07.909 --> 00:10:30.729	So, I must have access to all the training samples and then you have to try the classification algorithm with all the training samples, we have to identify all the training samples which are not correctly classified and then we have to compute the loss function for each of those individual training samples which are not correctly classified.
16.srt	00:10:31.199 --> 00:10:38.120	And, then you have to combine all such loss functions to get the overall loss function and that is what this expression tells you.
16.srt	00:10:41.579 --> 00:11:02.289	So, wherever this term is greater than 0 that is W transpose W j transpose X i minus W y i transpose X i plus delta if this term is greater than 0, then I assume that this corresponding X i is not correctly classified and this leads to an error term.
16.srt	00:11:03.309 --> 00:11:10.459	So, I have to compute this error term for all those training samples, sum them up and take the take the average to compute the overall loss function.
16.srt	00:11:11.579 --> 00:11:18.899	And that is in some cases problematic if your training sample size is very very large.
16.srt	00:11:19.669 --> 00:11:29.490	And this is the approach which is known as batch optimization technique, because you are considering all the training samples together.
16.srt	00:11:31.889 --> 00:11:39.569	On the other side the so, one of the problem of batch optimization technique is that I must have access to all the training samples.
16.srt	00:11:40.490 --> 00:11:57.759	I have to identify all the training samples which are not correctly classified and then I have to compute the loss function which is the sum of loss functions of all individual training samples, the loss functioncontribution of all individual training samples which are not correctly classified.
16.srt	00:11:58.860 --> 00:12:03.149	So, that needs huge amount of memory and sometimes the computation is also not inefficient.
16.srt	00:12:04.029 --> 00:12:07.769	So, the other variant of that is stochastic optimization techniques.
16.srt	00:12:11.910 --> 00:12:17.950	So, in stochastic case of stochastic optimization, Instead of considering all the training samples together, you take the training samples one by one.
16.srt	00:12:19.360 --> 00:12:34.750	And the moment you find that the training sample is not correctly classified, immediately you compute the loss function corresponding to that training samples and use that loss function to update your weight vector or weight matrix immediately.
16.srt	00:12:36.430 --> 00:12:41.370	If the training sample is correctly classified at by a given W.
16.srt	00:12:41.930 --> 00:12:50.820	Then as the training sample is correctly classified, so far as that training sample is is concerned I need not update W at that moment.
16.srt	00:12:52.030 --> 00:13:00.680	So, you take the training samples one by one, every time a training sample is correctly classified simply skip that sample go to the next sample.
16.srt	00:13:12.310 --> 00:13:14.230	If the sample is not correctly classified immediately you update the weight vector or the weight matrix and then you take the next training sample which has to be tied to the with this updated weight matrix.
16.srt	00:13:14.890 --> 00:13:21.500	So, if the next training sample is correctly classified by this updated weight matrix, then you skip that sample go to the next one.
16.srt	00:13:22.200 --> 00:13:27.030	If the next one is again correctly classified, skip that sample again go to the next one.
16.srt	00:13:27.380 --> 00:13:38.190	If that sample is not correctly classified, then immediately using the corresponding loss function following the gradient descent approach, you update yourweight vector of the weight matrix.
16.srt	00:13:38.760 --> 00:13:42.570	And it continues like this until you come to a situation.
16.srt	00:13:42.830 --> 00:13:54.800	that your error is less than certain acceptable limit or in a single pass over all the training samples all the training samples are correctly classified.
16.srt	00:13:56.110 --> 00:14:00.900	And this is what is known as stochastic optimization or stochastic gradient descent.
16.srt	00:14:02.060 --> 00:14:14.700	When you come to batch optimization or batch gradient descent it is somewhere in betweensorry the mini batch optimization or mini batch gradient descent it is somewhere in between.
16.srt	00:14:15.400 --> 00:14:33.300	So, in case of batch optimization we have considered all the training samples together and then identified all the samples which were not correctly classified, computed the error function, then accumulated all those error functions together to give you the overall error function.
16.srt	00:14:33.870 --> 00:14:38.580	And then you go for a optimization technique to reduce the error.
16.srt	00:14:39.530 --> 00:14:44.030	In case of stochastic optimization you have considered the training samples one by one.
16.srt	00:14:44.600 --> 00:14:45.890	So, that is on other extreme.
16.srt	00:14:46.010 --> 00:14:50.910	In one extreme in case of batch optimization you consider all the training samples in one go.
16.srt	00:14:51.950 --> 00:14:52.500	together.
16.srt	00:14:53.110 --> 00:15:00.340	In case of stochastic optimization which is the other extreme you are considering one training sample at a time.
16.srt	00:15:01.020 --> 00:15:05.820	If it is correctly classified you skip, if it is not correctly classified you update the weight vector.
16.srt	00:15:06.950 --> 00:15:12.870	In case of mini batch optimization you take the training samples in mini batches.
16.srt	00:15:12.920 --> 00:15:25.140	So, there I have to decide that what should be my batch size, whether I should consider 10 10 training samples at a time or I should consider 100 training samples at a time which is by mini batch size.
16.srt	00:15:26.240 --> 00:15:35.530	So, once I once I have this mini batches, then the approach that I have taken for batch optimization I do the same approach for this mini batch.
16.srt	00:15:36.740 --> 00:15:52.840	So, if a mini batch contains say 50 training samples, I have to consider all those 50 training samples together, identify that out of this 50 what are the training samples which are incorrectly classified.
16.srt	00:15:54.080 --> 00:16:01.360	So, you compute the loss function using those incorrectly classified training samples out of your mini batch.
16.srt	00:16:03.010 --> 00:16:10.710	And, using that loss function you go for updation of the weight vector or the weight matrix.
16.srt	00:16:10.710 --> 00:16:17.710	So, in case of mini batch optimization I still take the samples in batches, but not all the samples together.
16.srt	00:16:18.250 --> 00:16:29.850	I divide the samples the training samples into smaller batch size and I go for optimization using those smaller batch sizes that is what is mini batch optimization.
16.srt	00:16:31.730 --> 00:16:38.470	So, So, the mini batch optimization is somewhere in between your batch optimization and stochastic optimization.
16.srt	00:16:39.870 --> 00:16:52.040	So, given this now let us try to see that what are certain advantages or disadvantages of this different approaches of optimization techniques .
16.srt	00:16:52.040 --> 00:17:02.080	So, coming to your stochastic gradient descent approach the advantages areyou are frequently updating the weight vector or the weight matrix .
16.srt	00:17:02.730 --> 00:17:15.240	So, as I said that any moment a sample vectoris misclassified immediately you go for updation of the weights or updation of the weight matrix.
16.srt	00:17:16.010 --> 00:17:30.860	And this gives you an insight into the performance of the model, how the model is performing and howthe improvement in the loss function is taking place.
16.srt	00:17:33.650 --> 00:17:41.110	So, that tells youan insight that gives you an idea of the rate of learning of the model.
16.srt	00:17:42.550 --> 00:18:03.720	And this gradient descent is the simplest one to understand also the simplest one to implement because I do not have to accumulate all the training vectors together or I do not have to identify all the misclassified samples together and combine them collect them and then compute the loss function.
16.srt	00:18:04.280 --> 00:18:28.740	So, the implementation and understanding of thisstochastic gradient descent approach is also simpler than in case of batch gradient descent approach.As we are updatingthe weight vectors quite frequently every time a sample is misclassified you are updating the weight vector or the weight matrix.
16.srt	00:18:34.890 --> 00:19:05.990	So, as a resultyour learning or learning updating of the weight vectors or learning ofthe algorithm that may become faster, but this is not always guaranteed, but in some cases it may become faster.At the same timesince your update process is noisy in the sense that with one training example which is misclassified I can be on one side.
16.srt	00:19:06.870 --> 00:19:25.880	of the optimizationsurface, the error surface with the other one I may simply go to the other side of the error surfaceover while doing that you may simply overstep the global minima or local minima.
16.srt	00:19:26.390 --> 00:19:35.330	So, as a result it may be possible that you may be able to avoid the local minima.
16.srt	00:19:38.100 --> 00:19:43.170	and convergence may be at the global minima .
16.srt	00:19:43.170 --> 00:19:47.340	These are the advantages of the stochastic gradient descent approach.
16.srt	00:19:47.759 --> 00:19:50.140	However, it has got disadvantages also.
16.srt	00:19:50.140 --> 00:19:55.330	Say for example,as the model is updated quite frequently.
16.srt	00:19:56.460 --> 00:20:06.019	So, your computation may be more expensivethan what you do in case of batch optimization.
16.srt	00:20:08.230 --> 00:20:13.130	See Here, this optimization techniques it involves a number of stepsfor optimization.
16.srt	00:20:14.450 --> 00:20:23.099	The first step is for the training samples I have to compute whether it is correctly classified or it is misclassified.
16.srt	00:20:23.950 --> 00:20:27.319	If it is misclassified then I have to compute the loss function.
16.srt	00:20:28.329 --> 00:20:36.130	Once I compute the loss function then I have to compute the gradient and once I compute the gradient I have to update the weight vector.
16.srt	00:20:39.600 --> 00:20:44.400	So, the complexity depends upon the what is the dimensionality of the feature vectors or the dimensionality of the weight vectors.
16.srt	00:20:45.540 --> 00:20:55.610	It depends upon the number of training samples that I have because for every training sample I have to compute whether the training sample is correctly classified or the training sample is not correctly classified.
16.srt	00:20:57.540 --> 00:21:04.780	The complexity also depends upon the number of iterations over whichthe computation has to be made the updation has to be made.
16.srt	00:21:05.840 --> 00:21:14.180	Now, one of the problem of this stochastic gradient descent is though we have said that it is a very very simple approach, very simple to understand, very simple to implement.
16.srt	00:21:15.390 --> 00:21:27.700	So, But, one of the problem may be that suppose for a kth sample vector, I find it is correctly classified by the weight vector at a certainin a certain iteration.
16.srt	00:21:27.700 --> 00:21:45.080	But, as the weight vector is being updated for every sample which is misclassified, this kth vector which in one instant I have found to be correctly classified by the weight vector, but in the next pass the same sample.
16.srt	00:21:45.410 --> 00:21:57.660	may be misclassified by the updated weight vector because the weight vectors are being continuously updated and that may lead toincrease in computational complexity.
16.srt	00:22:18.040 --> 00:22:20.020	Not only that once I find an weight vectoronce I find a sample vector is misclassified by a weight vector in a particular iteration step immediately you are updating that weight vector and using that updated weight vector you go to the you go for testing the next training vector and this continues.
16.srt	00:22:20.410 --> 00:22:26.060	And finally, you have to come back to the same weight vector using which you had updated the weight vector once.
16.srt	00:22:26.610 --> 00:22:33.450	And now you may find that this weight vector again is not correctly classified by the updated weight vector.
16.srt	00:22:33.780 --> 00:22:47.130	So, the same operation has to be done once more and this may repeat many times and that may lead to the computational complexity or increase of computation time of the gradient descent approach.
16.srt	00:22:47.470 --> 00:22:49.890	And this may be significantly longer.
16.srt	00:22:50.240 --> 00:22:53.780	to train a model on a very large data set.
16.srt	00:22:55.470 --> 00:23:19.880	The other problem may be that frequent update can result in noisy gradient signal and that may cause the model parameters and in turn the model error to jump around and this is what I said that I may overstep the minima which I want to reach because I am frequently updating the model parameters.
16.srt	00:23:21.430 --> 00:23:32.580	The other problem may be that the noisy learning process down the error gradient can also make hard the algorithm to settle on an error minimum for the model.
16.srt	00:23:52.260 --> 00:24:03.770	It is again for the same one that even if certain training vector a particular training vector is correctly classified by one weight vector at a particular iteration in the next iteration the same training vectors, the sample vector may be misclassified by the updated weight vector and that does not allow the weight vectors to settle to a minimum of the error.
16.srt	00:24:04.300 --> 00:24:06.850	So, these are the problems of the stochastic gradient descent.
16.srt	00:24:08.540 --> 00:24:19.360	Now, against this when you go for batch gradient descent, the batch gradient descent approach again has got certain advantages, it also has certain disadvantage.
16.srt	00:24:23.220 --> 00:24:39.430	The advantages are that as your updates are not that frequent or if a fewer number of updates because here for every sample we are not updating the weight vector rather we are collecting all the samples which are misclassified then computing the loss function and then you are computing the weight vector.
16.srt	00:24:56.190 --> 00:25:00.790	So, that means, this is usually computationally more efficient than the stochastic gradient descent approach and this decreased update frequency results in a more stable error gradient and may result in a more stable convergence on some problems.
16.srt	00:25:01.140 --> 00:25:07.010	Again you note the term that it is on some problems it is not guaranteed that in every case this may not be true.
16.srt	00:25:08.620 --> 00:25:20.240	And the next one is as your calculation of errors and the update these two are twoseparate processes.
16.srt	00:25:21.270 --> 00:25:27.370	For calculation of error or the loss function what we are doing is we are collecting all the samples which are misclassified.
16.srt	00:25:28.420 --> 00:25:37.870	then you are completing the error and once your error computation is complete, then you are using that error to update your model parameters.
16.srt	00:25:38.100 --> 00:25:47.970	So, these two processes are separate and as the two processes are separate they can be implemented in parallel as well in a pipeline right.
16.srt	00:25:48.510 --> 00:25:58.020	So, these are theadvantages of the batch optimization or batch gradient descent approach.
16.srt	00:26:00.240 --> 00:26:22.020	On, the downside or coming to the disadvantages that as the error gradient is very stable this may result in a premature convergence in the sense that there is a high risk of converging to a local minima because of stable gradient.
16.srt	00:26:31.470 --> 00:26:34.760	The other disadvantage is that the updates at the end of every training epoch require additional complexity of of accumulating prediction errors across all training samples.
16.srt	00:26:34.880 --> 00:26:47.330	And this is what I said that I have to identify all the training samples which are misclassified and using these misclassified training samples I have to get the overall error.
16.srt	00:26:48.100 --> 00:26:49.930	So, that is also a disadvantageous.
16.srt	00:26:50.800 --> 00:27:05.880	It also requires that the entire training data must be available in memory and to the algorithm for processing which requires huge amount of memory and as in case of machine learning applications or deep learning applications.
16.srt	00:27:06.290 --> 00:27:15.470	the number of training samples is huge of the order of maybe lakhs of samples are used for training your machine learning algorithm.
16.srt	00:27:16.410 --> 00:27:33.740	So, this is a problem that for batch optimization techniques or batch batch gradient descent techniques, I require that all the training samples must be available in memory and must be available to your updation algorithm.
16.srt	00:27:34.050 --> 00:27:38.740	And of course, as we are working on all the data at a time.
16.srt	00:27:39.420 --> 00:27:47.130	The model updates and the training speed may become very slow for the data sets we are very very large.
16.srt	00:27:48.560 --> 00:27:55.650	So, these are the advantages and disadvantages of the batch optimization or batch gradient descent approach.
16.srt	00:27:57.610 --> 00:28:05.950	Then coming to the mini batch gradient descent as we said that mini batch is somewhere in between your stochastic optimization and batch optimization.
16.srt	00:28:11.400 --> 00:28:22.170	So, the advantages of mini batch optimization is that the model update is frequency is higher than that in case of batch descent optimization which allows for morerobust convergence avoiding local minima.
16.srt	00:28:22.170 --> 00:28:32.750	So, in case of batch optimization we have seen that as your error rate as the training rate is very very slow, so is more stable.
16.srt	00:28:32.750 --> 00:28:40.070	So, there is a risk of convergence to a local minima in case of batch optimization that is that risk is less.
16.srt	00:28:44.450 --> 00:28:59.740	And, this batch updates provide more efficient process than in case of stochastic gradient descent because in stochastic gradient descent we had to workevery sample at a time in batch optimization we are taking mini batches.
16.srt	00:28:59.830 --> 00:29:06.780	So, here thecomputation computation is more efficient than in case of batch optimization.
16.srt	00:29:06.780 --> 00:29:11.270	And, the other advantage for batch optimization is that in case of mini batch.
16.srt	00:29:14.360 --> 00:29:18.780	I do not need all the training samples to be available in memory and the algorithm.
16.srt	00:29:20.080 --> 00:29:35.260	Rather I need all the training samples in the mini batch to be available in the main memory whose size is much lower than the size of all the training samples.
16.srt	00:29:35.470 --> 00:29:44.130	And coming to the disadvantages here again how do you decide what should be the mini batch size that is mini batch requires configuration of an additional hyper parameter.
16.srt	00:29:44.420 --> 00:29:47.020	which is the size of the mini batch.
16.srt	00:29:48.820 --> 00:30:06.700	And the other disadvantage which is of course, not as severe as we had in case of batch optimization that the error information must be accumulated across batch mini batches of training examples for batch gradient descent.
16.srt	00:30:07.870 --> 00:30:14.580	So, I can have these three variants of the optimization techniques or gradient descent techniques the batch optimization.
16.srt	00:30:14.850 --> 00:30:17.470	the stochastic optimization and mini batch optimization.
16.srt	00:30:18.810 --> 00:30:37.180	And just as a comparison of the performance of these three you find that this shows a set of curves on certain examples forbatch optimization, mini batch optimization and stochastic gradient descent.
16.srt	00:30:37.650 --> 00:30:45.480	So, here you find that this black curve this is for the batch optimization and here you find that this curve is very smooth.
16.srt	00:30:46.660 --> 00:31:02.200	On the other extreme we have this stochastic gradient descent where every sample is taken one at a time ok. And here you find thatthe error reduction over iteration is very easy to read.
16.srt	00:31:02.280 --> 00:31:15.750	And using the batch optimization techniques we have performance in between which is as expected and depending upon the mini batch size your rate of convergence.
16.srt	00:31:17.410 --> 00:31:18.110	is different.
16.srt	00:31:19.620 --> 00:31:28.610	So, this is the one which tells you where mini batch size is 10 and this is the one which tells you whenwhich gives you the performance when mini batch size is 100.
16.srt	00:31:29.570 --> 00:31:38.560	And you find that interestingly that if you in go on increasing the mini batch size finally, it becomes a batch optimization technique.
16.srt	00:31:39.000 --> 00:31:49.300	So, with increase of mini batch size or or in other words with increase of number of samples to be considered to.
16.srt	00:31:50.260 --> 00:32:00.170	together for batch optimization techniques, you find that gradually you are moving towards the performance of your batch optimization technique.
16.srt	00:32:03.000 --> 00:32:17.880	So, in today's lecture we have discussed about the gradient descent and the three different variants of gradient descent, the batch gradient descent, the mini batch gradient descent and the stochastic gradient descent.
16.srt	00:32:19.700 --> 00:32:22.360	So, with this I complete this lecture.
16.srt	00:32:23.330 --> 00:32:23.640	Thank you.
14.srt	00:00:00.620 --> 00:00:26.989	Welcome to the NPTEL online certification course on Deep Learning.
14.srt	00:00:31.599 --> 00:00:35.769	O'Reilly Corporation you just try to recapitulate what we have done in the previous class.
14.srt	00:00:36.479 --> 00:00:46.280	In the previous class we have talked about the linear classifier and then we had moved on to the linear machine.
14.srt	00:00:47.929 --> 00:00:57.039	In today's class we will continue with the linear machine and then we will move to what is known as multi class support vector machine.
14.srt	00:00:58.649 --> 00:01:03.509	So, as you remember in the previous class that a linear classifier.
14.srt	00:01:03.859 --> 00:01:25.439	when I extend that to a multi class problem because linear classifier is usually in case of a two class problem where we try to find out what is the boundary between the two different different class and we try to design that boundary using the feature vectors or the training vectors given from the two different classes.
14.srt	00:01:26.429 --> 00:01:31.000	When it comes to multi class problem then what we have a linear machine.
14.srt	00:01:35.149 --> 00:02:07.229	So, if you remember from the previous class A linear machine tries to map a d dimensional feature vector say r d to a k dimensional feature vector which is known as which is r k. So, this r k is what is known as the score vector that is given a feature vector x i when the linear machine maps that vector to a k dimensional score vector s.
14.srt	00:02:07.859 --> 00:02:21.939	every component of S tells us that what is the score for that particular category the corresponding to the component of S for the given input vector x i.
14.srt	00:02:42.699 --> 00:03:05.270	So, the first question is that how do we get this d dimensional vector r d. Let us take a very simple case that we have talked about of the feature vectors in conventional machine learning techniques, where the feature vectors are handcrafted and they can be generated using the properties of the boundary of the object or using the properties or regional properties which contains the color information, texture information and intensity information and all that.
14.srt	00:03:13.979 --> 00:03:23.530	But when we talk about deep learning, we do not depend upon the handcrafted feature vectors, we want that the machine will learn the features as well based on which it will classify or it will understand the data.
14.srt	00:03:24.829 --> 00:03:29.069	So, for specific example when we have image as the input data.
14.srt	00:03:29.120 --> 00:03:42.919	So, suppose we have an image of size say m by n that means, m number of rows and n number of columns which is a matrix of integer numbers.
14.srt	00:03:46.519 --> 00:03:52.259	So, this is say an m m by n image which will have n number of columns and m number of rows.
14.srt	00:03:54.529 --> 00:04:12.059	So, the way I can convert this into a feature vector is first you take this column and form a part of the vector, then you concatenate the second column that makes another part of the vector.
14.srt	00:04:13.049 --> 00:04:16.959	Like this you continue the last column forms.
14.srt	00:04:17.589 --> 00:04:19.339	the last portion of the vector.
14.srt	00:04:20.339 --> 00:04:37.980	So, when I have an image of size m by n having total number of pixels which is m into n, I have a feature vector of generate a feature vector from this image which has got m into n number of components.
14.srt	00:04:38.310 --> 00:04:41.170	So, this is an m into n dimensional vector.
14.srt	00:04:42.470 --> 00:04:49.029	Likewise if I have a color image then in color image we have three different planes.
14.srt	00:04:50.070 --> 00:04:57.870	I have red plane, I have green plane and I have blue plane.
14.srt	00:05:01.450 --> 00:05:11.290	Each of these color planes let us assume have got m by n number of pixels, there being m number of rows and n number of columns.
14.srt	00:05:21.110 --> 00:05:21.730	So, from first r component r plane I generate a vector having 3.
14.srt	00:05:23.120 --> 00:05:26.180	This is the total number of elements in the switcher vector.
14.srt	00:05:27.100 --> 00:05:39.600	So, we were talking about cipher 10 database yesterday in the previous class and in cipher 10 database we have assumed that there are n is equal to say 50,000 images.
14.srt	00:05:51.420 --> 00:05:55.120	Each image is of size 32 by 32 pixels and those being color images there are 32 pixels 3 planes red green and blue for each of the images.
14.srt	00:05:55.750 --> 00:06:08.350	So, if I convert this into a feature vector of this form every image will be converted into a column vector having say this is 32 by 32 into 3.
14.srt	00:06:08.560 --> 00:06:13.889	So, that is equal to 3 0 7 2 number of elements.
14.srt	00:06:14.290 --> 00:06:16.730	So, one element corresponding to every pixel.
14.srt	00:06:22.329 --> 00:06:27.220	So, when I convert an image into a vector of this form So,this vectorization the way I have shown is not the only option available.
14.srt	00:06:27.220 --> 00:06:51.629	What I can do is first I can have one column of component R. So, using this column I make a part of the feature vector, then you take one column of green make another part of the feature vector, then you take another column from B or the blue component make another part of the feature vector and this you continue.
14.srt	00:06:52.470 --> 00:06:57.180	for every columns taken from red, green and blue components.
14.srt	00:06:57.390 --> 00:07:03.500	So, this can be another way of making converting a color image into a vector form.
14.srt	00:07:04.610 --> 00:07:11.280	And another thing you notice that one I have once I have converted an image into a vector of this form.
14.srt	00:07:11.670 --> 00:07:25.140	So, this vector is of dimension m by n by 3 where the images are of size m by n and the images are are are color image .
14.srt	00:07:25.730 --> 00:07:32.320	For cifar database this will be having 3072 number of components.
14.srt	00:07:32.950 --> 00:07:40.860	So, that means, I am defining a space or 3072 dimensional space.
14.srt	00:07:42.330 --> 00:07:50.970	And every image is now represented by a point or by vector into that 3072 dimensional space.
14.srt	00:07:51.350 --> 00:08:01.540	In this case every image will be defined by vector or it will be represented by a point into m into n into 3 dimensional space.
14.srt	00:08:02.400 --> 00:08:05.460	So, that is what the vector representation of an image.
14.srt	00:08:06.450 --> 00:08:12.350	So, once I have such a vector representation .
14.srt	00:08:12.580 --> 00:08:31.970	So, here this iswhat I was telling that I have this d dimensional vector which is represented which is generated out of an image and the linear machine maps this d dimensional vector into a k dimensional vector where k .
14.srt	00:08:32.210 --> 00:08:36.879	is the number of categories or the number of classes that we have.
14.srt	00:09:03.769 --> 00:09:12.490	And if I expand this expression this expression can be written in this form that f x i w b where x i is my input vector, w is a matrix of dimension k by d having k number of rows and d number of columns and b is a bias vector having again k number of elements.
14.srt	00:09:12.490 --> 00:09:14.570	So, this is a k dimensional bias vector.
14.srt	00:09:15.629 --> 00:09:23.950	This w and b they are the parameters of the linear machine they define the linear machine.
14.srt	00:09:25.389 --> 00:09:37.389	So, this functional form f x i w b is nothing, but w x i plus b where w as I said that it is a parameter matrix or weight matrix.
14.srt	00:09:37.929 --> 00:09:45.360	of this matrix W represents classifier of a particular class.
14.srt	00:09:45.809 --> 00:10:05.529	So, if I take jth row of this matrix W this represents the classifier of the jth class and this is my input vector x this is the bias vector and after computation I get the score function k right.
14.srt	00:10:06.309 --> 00:10:08.419	So, now let us .
14.srt	00:10:09.200 --> 00:10:14.590	take an example to see what it actually means.
14.srt	00:10:15.220 --> 00:10:28.590	Suppose I have somehow I have obtained this matrix W, this is the vector which is generated out of an image.
14.srt	00:10:28.750 --> 00:10:34.389	Let us assume that this vector for simplicity is a vector of dimension 4.
14.srt	00:10:34.759 --> 00:10:38.529	So, I have got 4 elements in this particular vector and there are.
14.srt	00:10:39.009 --> 00:10:48.600	that each of this each element of this scorevector is gives you the score for a particular class.
14.srt	00:10:49.670 --> 00:10:53.690	Here the first element let us assume that the first category is cat category.
14.srt	00:10:53.840 --> 00:11:00.660	So, the first score corresponds to cat score, the second category is bird category in this particular case.
14.srt	00:11:00.940 --> 00:11:05.840	So, the second score corresponds to bird, the third score corresponds to dog and so on.
14.srt	00:11:07.040 --> 00:11:17.550	And here as my input vector is generated from a bird, so you find that the bird score is maximum, it is maximum of all other course.
14.srt	00:11:18.930 --> 00:11:41.960	So, my for my classification purpose whenever an in unknown input vector is presented to the classifier, the classifier will generate or the linear machine will generate a score vector and in that score vector whichever component comes out to be maximum, I have to classify that input vector to that corresponding category.
14.srt	00:11:44.100 --> 00:11:47.940	Now, here comes the interpretation of .
14.srt	00:11:48.639 --> 00:12:12.409	the rows of weight matrix W. You find that effectively what I am doing is this matrixcalculation is doing is that it is taking the dot product of the input vector .
14.srt	00:12:12.409 --> 00:12:18.710	It is taking dot product of the input vector with say jth row .
14.srt	00:12:19.059 --> 00:12:24.179	vector of weight matrix W suppose this is the jth row.
14.srt	00:12:24.929 --> 00:12:53.490	So, it is taking the dot product of the input vector with the vector corresponding to the jth row ofthe weight matrix of the parameter matrix and it is generating the jth component of the score vector S. And as we said that this being a vector that is my input image represented as a vector or as a point in d dimensional space.
14.srt	00:12:53.879 --> 00:13:11.359	and this jth row of matrix W is also a point in the d dimensional space and I am taking the dot product of these two and you know that the dot product of two vectors tells you what is the degree of similarity between the two vectors.
14.srt	00:13:12.199 --> 00:13:26.309	So, if the two vectors are very similar say I have one vector in this and another vector like this the dot product of these two will be quite high whereas, if I have one vector here and another vector here.
14.srt	00:13:27.019 --> 00:13:30.429	are widely different the dot product of these two will be quite low.
14.srt	00:13:32.159 --> 00:13:53.580	So, this jth component of my score vector or S j in other words tells me that what is the similarity between the input vector which I want to classify and the vector corresponding to jth row of the weight matrix W .
14.srt	00:13:58.090 --> 00:14:10.340	So, having thisinterpretation, so, I am going of the weight matrix, I can say that every row of the weight matrix is nothing, but a template of the corresponding category.
14.srt	00:14:11.280 --> 00:14:21.610	So, the j th row is represents a template of the j th category, the k th row represents a template of the k th category.
14.srt	00:14:28.650 --> 00:14:44.370	So, if you again coming to the example of CIFAR database wealso mentioned in our previous class that the CIFAR database contains images of 10 different categories like plane, car, bird, cat, sheep and so on.
14.srt	00:14:45.610 --> 00:14:56.970	And after training the rows of the weight vector the rows of the weight matrix as I said that they representthe weights of different categories.
14.srt	00:15:02.410 --> 00:15:09.710	So, if I convert those rows into the to the form of images every image will be a template of the corresponding class of the corresponding category.
14.srt	00:15:10.460 --> 00:15:15.380	So, how do you convert this weight vector into an image?
14.srt	00:15:16.170 --> 00:15:33.740	So, it is just the reverse process that as we haveshown in the previous example that the way we convert an image into a vector is that I have an image I take every column of this image one by one.
14.srt	00:15:34.210 --> 00:15:35.760	those columns to get the vectors.
14.srt	00:15:36.100 --> 00:15:42.200	So, this is how I form a vector from an image.
14.srt	00:15:42.970 --> 00:15:49.680	Similarly, if I have a vector how do we convert this into an image?
14.srt	00:15:52.920 --> 00:16:05.350	So, if you look at the way we have done this multiplication that is when we have done w.
14.srt	00:16:06.030 --> 00:16:17.360	Pth component of my weight vector W of the jth row corresponds to Pth pixel in the vector representation of my input image.
14.srt	00:16:19.150 --> 00:16:36.190	So, as I have converted an image into a vector by unfolding the columns and concatenating them together to form a vector of dimension d, when I do the reverse process that is given a vector, I want to form a matrix out of it.
14.srt	00:16:36.640 --> 00:16:57.300	So, first you take the first m number of elements of this matrixmy image was I assume to be of size m by n. So, I take first n number of elements of the matrixof this vector and form the first column of the image.
14.srt	00:16:58.600 --> 00:17:06.320	Take the second n number of elements of this vector and use that to form second column of the image.
14.srt	00:17:06.790 --> 00:17:30.070	Similarly, at the end I have mth n number of elements of the vector and use that to form the last column of the matrix, it should be the other way.
14.srt	00:17:30.740 --> 00:17:34.269	I have m number of rows.
14.srt	00:17:39.759 --> 00:17:44.710	So, instead of n number of I have to take m number of elements.
14.srt	00:17:45.049 --> 00:18:05.240	So, here I take first m components of the of the vector from the first column of the matrix, then you take the second m number of elements of the vector from the second column and in the same manner you take the nth m number of elements of this vector from the last column.
14.srt	00:18:06.430 --> 00:18:10.950	If I have color images obviously, I will have other color components according the I form.
14.srt	00:18:11.329 --> 00:18:13.769	other color planes of the input image.
14.srt	00:18:14.200 --> 00:18:19.700	And this is how I convert the vector w in the form of an image.
14.srt	00:18:21.799 --> 00:18:31.390	So, this is what we have the way those vectors can be converted into an image gives me the template.
14.srt	00:18:31.390 --> 00:18:35.369	So, you find that these are the templates corresponding to different classes.
14.srt	00:18:37.339 --> 00:18:42.809	The next we come to the case of we have a bias vector.
14.srt	00:18:43.569 --> 00:18:47.740	matrix, it is also possible to include that bias vector in the weight matrix itself.
14.srt	00:18:48.150 --> 00:19:00.980	So, for that what I have to do is I have to simply increase the number of columns of the weight matrix by 1 and that additional column or the last column is actually the vector column vector corresponding to the bias vector.
14.srt	00:19:14.079 --> 00:19:16.890	And for doing that the modification that I have to do in my vector data vector is that I have to add and additional element and make that equal to 1.
14.srt	00:19:17.680 --> 00:19:28.119	So, this gives me the same matrix equation only difference is now I do not have the bias vector separately, but it is included in the weight matrix itself.
14.srt	00:19:44.530 --> 00:19:50.960	And accordingly the function that I compute is f x i w where w includes the bias vector v b and you can verify that f x i w is same as f x i w b when the bias vector was kept separate.
14.srt	00:19:51.240 --> 00:19:52.769	So, both these computations are same.
14.srt	00:19:53.210 --> 00:19:57.170	So, accordingly the score vector that you get the score vector will also be same.
14.srt	00:20:00.940 --> 00:20:14.330	So, what I get is I get for every vector I compute the function as given by the linear machine.
14.srt	00:20:14.670 --> 00:20:25.529	and the linear basin gives me a score vector which is S. So, if I take S j or the jth component of the score vector as is shown over here.
14.srt	00:20:45.369 --> 00:20:52.069	So, this S j which is the jth component of the score vector which is nothing, but when I do this matrix multiplication W x i and taken the jth component of that which is nothing, but the score for jth class for the ith vector x i .
14.srt	00:20:52.199 --> 00:21:00.719	And ith vector x i is actually given in the form x i y i indicating that this x i belongs to category y i.
14.srt	00:21:00.719 --> 00:21:11.589	You remember that what we are talking about are all training vectors that means, for the training vectors we know the category to which the training vector belongs .
14.srt	00:21:11.589 --> 00:21:15.099	So, I know that the training vector x i belongs to category y i .
14.srt	00:21:17.200 --> 00:21:33.259	And, given this to obtain the score for y i th category for the vector x i, I have to consider I have to look at what is the y i th component of the score vector.
14.srt	00:21:34.990 --> 00:21:45.329	And, y i th component of the score vector as before is nothing, but whatever I get by this matrix multiplication and take the y i th component of that.
14.srt	00:21:45.609 --> 00:21:51.750	because we know that this X i belongs to category Y i.
14.srt	00:21:52.859 --> 00:22:10.160	So, this S Y i that is Y i th component of my score vector X must be maximum among all other components of the score vector because this X i belongs to class Y i ok.
14.srt	00:22:10.329 --> 00:22:17.990	So, the next question is should we be satisfied just with the condition that S Y i is maximum.
14.srt	00:22:19.259 --> 00:22:30.579	or I want that this S y i should be more than all other components at least by some margin delta.
14.srt	00:22:31.009 --> 00:22:37.480	So, that I can say with confidence that whatever classification I have got that is correct.
14.srt	00:22:50.179 --> 00:23:02.019	You remember with what we did in case of support vector machine that in support vector machine your W transpose X plus some bias B, we assumed that this have to be greater than some minimum threshold D. And what is this W transpose X plus B?
14.srt	00:23:03.049 --> 00:23:16.419	This tells you that an idea of what is the distance of X vector X from the plane W transpose X plus B equal to 0 .
14.srt	00:23:16.419 --> 00:23:20.769	And with normalization this we can always write in the form W transpose X .
14.srt	00:23:20.950 --> 00:23:26.609	plus b have to be greater than or equal to 1 after normalization we can always do that.
14.srt	00:23:27.690 --> 00:23:42.329	So, this says that from this boundary W transpose X plus b equal to 0, the normalized distance of my training vector must be greater than or equal to 1 and that is the margin.
14.srt	00:23:52.549 --> 00:24:02.539	Similarly, in this case to have confidence over the result that we get the classification result that we get I should have I should impose that the score for class omega i must be greater than score for any other class j at least by margin delta.
14.srt	00:24:05.029 --> 00:24:17.180	And accordingly I can define a loss function l i which is given by 0 maximum of 0 or S j minus S y i plus delta.
14.srt	00:24:17.930 --> 00:24:23.259	And this should be I have to take some of this for all j which is not equal to y i.
14.srt	00:24:24.289 --> 00:24:38.839	So, here you find that what I get is if S j minus y i this particular value equal to 0, then delta which is a positive constant is greater than 0.
14.srt	00:24:38.839 --> 00:24:39.789	So, output will be 0.
14.srt	00:24:41.219 --> 00:24:58.999	Whereas, if S j minus y i this is minus delta that means, y i minus S j is equal to plus delta then S j minus y i plus delta will be equal to 0, if you take the max function the output will also be 0.
14.srt	00:24:59.669 --> 00:25:10.929	And, it will remain 0 as long as S y i minus S j is greater than delta that is S j minus y i is less than minus delta.
14.srt	00:25:11.269 --> 00:25:30.259	So, for all those cases this max function will be giving an output 0 and the loss component the contribution to this loss function L i in that case will also be equal to 0 and L i will be positive as long as the margin is less than delta.
14.srt	00:25:32.730 --> 00:25:56.329	So, this particular loss function confirms ensures that score for category omega i will always be greater than the score for any other category S j at least by a margin delta right.
14.srt	00:25:57.390 --> 00:26:00.900	So, if I ah.
14.srt	00:26:01.259 --> 00:26:32.069	So, this is an example that suppose I have taken an y i which belongs to class 2 and the score function is given by 10 30 minus 22 minus 20 25 and if you compute the loss function then you find that for the first one the loss function will be equal to 0 because 30 is greater than 10 by a factor by a margin which we have in this case we have assumed to be 10.
14.srt	00:26:32.740 --> 00:26:37.490	byit is 30 is greater than 10 by a margin which is more than 10.
14.srt	00:26:39.069 --> 00:26:45.220	Coming to this one again 30 is more than minus 20 which is score for the third category by more than 10.
14.srt	00:26:46.190 --> 00:26:50.369	Come to the third category fourth category for which the score as 25.
14.srt	00:26:50.639 --> 00:26:55.509	Now, you find that the margin for category 2 to which my input vector belongs.
14.srt	00:26:56.259 --> 00:27:05.190	So, this margin from category 2the difference between the score for category 2 and category 4 is only 5.
14.srt	00:27:05.299 --> 00:27:08.220	1 which is not sufficient because I have assumed margin to be 10.
14.srt	00:27:09.409 --> 00:27:18.159	So, this fourth component that actually gives me a non-zero loss function over here and that non-zero loss function is equal to 15.
14.srt	00:27:18.159 --> 00:27:43.279	Whereas, the others gives me a loss value which is equal to 0 that gives me the overall loss function L i which is equal to 15 ok. And if you plot this loss function I plot this loss function which is max of 0 S j minus S y i plus delta versus S j minus S y i .
14.srt	00:27:44.719 --> 00:28:11.249	You find that as long as S j minus S y isorry it should be just negative of this S y i minus S j if I take the negative value of this that means, S y i minus S j as long as it is greater than delta then your loss function is 0 the moment it becomes less than delta.
14.srt	00:28:14.819 --> 00:28:17.799	loss function goes on increasing which is in this direction.
14.srt	00:28:19.149 --> 00:28:26.669	And because of nature of this variation of loss function this is what is known as hinge loss.
14.srt	00:28:27.709 --> 00:28:43.869	So, in case of a linear machine which minimizes hinge loss you find that we are talking about a margin.
14.srt	00:28:46.659 --> 00:29:00.250	So, the score between the correct class and any incorrect class the difference of these codes must be greater than margin delta which is similar to the two class support vector machine that we discussed earlier this is what is known as multi class support vector machine.
14.srt	00:29:01.240 --> 00:29:10.259	So, in case of multi class support vector machine it tries to minimize the hinge loss as shown in this case .
14.srt	00:29:10.259 --> 00:29:17.059	Now, this hinge loss is not sufficient the reason being .
14.srt	00:29:18.409 --> 00:29:50.179	If I multiply my weight matrix W by a constant say lambda which is greater than 1, you find that the difference between S j and S y i is nothing butif I take the difference of the dot products of the j th row of weight matrix W and y i th row of j th matrix W. So, S j minus S y i is nothing but the difference of these two dot products.
14.srt	00:29:51.460 --> 00:29:58.200	So, accordingly if I scale of W by lambda this difference is also going to be scaled up .
14.srt	00:29:58.230 --> 00:30:18.220	So, if for some W my S j minus S y i was say 15, now if I scale of W by 2 then this S j minus S y i will be 30 .
14.srt	00:30:18.220 --> 00:30:22.349	So, for different values of W I will have different differences of W.
14.srt	00:30:22.559 --> 00:30:23.369	the score function.
14.srt	00:30:25.199 --> 00:30:41.109	So, I have to choose that which value has to be proper among all these different possibilities of W, I have to choose a proper W. That means, I have to have impose a condition on W itself and that is what is known as regularization.
14.srt	00:30:42.169 --> 00:30:49.439	So, when you go for regularization, you include a regularization term in your loss function.
14.srt	00:30:49.779 --> 00:30:53.729	So, this regularization term is what is R w.
14.srt	00:30:54.149 --> 00:31:02.490	and usually the regularization term which is included is the L 2 norm of this weight matrix.
14.srt	00:31:03.279 --> 00:31:25.079	So, accordingly you modify your cost function as L is equal to this was the function corresponding to your hinge loss and you find that the hinge loss depends upon the data along with your parameters of the linear machine.
14.srt	00:31:25.400 --> 00:31:55.140	So, this is a component which is called data loss and I also impose a condition a regularization term which is L 2 norm of my weight matrix which is delta W delta times sum of WKL, WKL is the KLth element of the weight matrix square take the sum of this over L and K and this is what is known as regularization.
14.srt	00:31:55.430 --> 00:32:02.880	loss .
14.srt	00:32:02.880 --> 00:32:11.890	So, now overall loss function includes two terms one is the data loss and other one is the regularization loss.
14.srt	00:32:11.890 --> 00:32:24.350	So, while designing this multi class support vector machine I have to optimize or we have to minimize this overall loss function .
14.srt	00:32:27.330 --> 00:32:29.320	So, with this I will Thank you.
28.srt	00:00:00.610 --> 00:00:27.379	Hello, welcome to the NPTEL online certification course on deep learning.
28.srt	00:00:32.300 --> 00:00:59.689	Till our previous class we have talked about the back propagation learning and we have seen that how the back propagation learning is actually implemented or takes place in a feed forward neural network at the network level and also how the gradient is back propagated within a particular node or different layers or different circuits within a particular node.
28.srt	00:01:01.280 --> 00:01:03.000	And as we said in the previous class.
28.srt	00:01:03.350 --> 00:01:16.790	Now, onwards I will assume that you know back propagation learning and whenever the learning isdiscussed I will simply refer that back propagation learning algorithm is used.
28.srt	00:01:16.790 --> 00:01:23.849	I will not go into details of the learning algorithm until and unless some details is essential.
28.srt	00:01:23.920 --> 00:01:29.790	So, in today's discussion we are going to start to discuss on autoencoders.
28.srt	00:01:34.390 --> 00:01:39.320	So, today subsequent few lectures, we will talk about under complete autoencoder.
28.srt	00:01:40.240 --> 00:01:49.500	We will try to find out what is the relationship between an autoencoder andprinciple component analysis or PCA.
28.srt	00:01:50.060 --> 00:01:55.750	Maybe I will discuss something about PCA for those of you who are not aware of this.
28.srt	00:01:56.780 --> 00:02:06.170	We will talk about the other variants of the autoencoder namely sparse autoencoder, denoising autoencoder.
28.srt	00:02:06.670 --> 00:02:09.130	interactive autoencoder and so on.
28.srt	00:02:09.730 --> 00:02:27.950	And then we will also talk about convolution autoencoder, but not as a continuation of thisseries on autoencoders, but we will come back to convolution autoencoder after we discuss about convolution and convolution neural network.
28.srt	00:02:29.330 --> 00:02:35.920	So, today what we are going to talk about the autoencoder and under complete autoencoder.
28.srt	00:02:37.730 --> 00:02:39.140	Now, what is this autoencoder?
28.srt	00:02:40.599 --> 00:02:49.840	As the name suggests that autoencoder is nothing, but an algorithm that codes itself or that encodes itself.
28.srt	00:02:50.909 --> 00:03:06.900	So, you can say that autoencoder is an unsupervised learning algorithm, where the neural networks are subject to the task of representation learning and what is this representation?
28.srt	00:03:09.960 --> 00:03:17.140	The representation is nothing, but how you code or how you encode the input data that is fed to the network.
28.srt	00:03:18.379 --> 00:03:24.219	And, learning this representation learning this code is what is known as representation learning.
28.srt	00:03:25.460 --> 00:03:40.240	And we say auto encoders are unsupervised learning because when you train an auto encoder for coding an input or forencoding an input we do not use datas which are level datas.
28.srt	00:03:40.510 --> 00:03:43.730	unlike in case of classification problems that we have discussed earlier.
28.srt	00:03:44.880 --> 00:03:58.030	So, if you remember what we discussed in case of classification that for training the network or for training of your classification algorithm machine learning algorithm, we need a lot of training data.
28.srt	00:03:59.330 --> 00:04:06.850	And what that set of training data tells you is that it tells you that what is the class belongingness of a particular training data.
28.srt	00:04:07.800 --> 00:04:12.270	And it is only from that information of class belongingness I can compute the error.
28.srt	00:04:13.210 --> 00:04:30.519	Because, if my machine says that a training data or if my machine infers that training data belongs to some category say 5, whereas the ground truth says that that particular training data belongs tocategory 1.
28.srt	00:04:30.769 --> 00:04:36.259	So, there is a mismatch my machine says it is category 5, whereas the ground truth is category 1.
28.srt	00:04:37.090 --> 00:04:43.639	So, there is an error and your learning algorithm as we said using back propagation tries to minimize this error.
28.srt	00:04:44.129 --> 00:04:58.090	That means, as the machine has interpreted to be 5, what modifications or what updations in the weight vectors we have to do, so that the machine really interprets this data to belong to category 1.
28.srt	00:04:59.240 --> 00:05:07.750	So, those are the supervised learning algorithms, because the data that you use for training or learning are the labeled data.
28.srt	00:05:08.840 --> 00:05:13.939	But in case of autoencoder, the data that we use are not labeled data.
28.srt	00:05:14.620 --> 00:05:33.560	However, we still have back propagation algorithm because we want that whichever way the machine represents or the autoencoder represents the input data from that representation it is possible it should be possible that we should be able to reconstruct the input data.
28.srt	00:05:34.160 --> 00:05:40.759	That means, I have to find out that after encoding whether the encoded data can be reconstructed.
28.srt	00:05:41.220 --> 00:05:46.909	So, if for encoding I call it a forwardencoding algorithm.
28.srt	00:05:47.449 --> 00:05:59.410	So, some mapping function f that gives me the encoded data, then another mapping function g should be able to convert or transform that encoded data to my original input.
28.srt	00:06:00.240 --> 00:06:06.930	And for learning what you do is you compare the original input and this reconstructed input and try to minimize the error between these two.
28.srt	00:06:17.509 --> 00:06:23.280	So, this autoencoder as we said that it is an unsupervised learning and the task of the neural network in this case is to go for representation learning or try to encode or learn how to encode or how to code the input data.
28.srt	00:06:24.889 --> 00:06:31.000	And in order to do this what you do is you introduce a bottleneck in the network.
28.srt	00:06:32.090 --> 00:06:40.910	Because as we said that our learning algorithm will be that I have an input, I have some coding in between then I have a reconstructed output.
28.srt	00:06:41.230 --> 00:06:47.069	And I want that the reconstructed output should be similar to the input or they should be identically possible.
28.srt	00:06:49.550 --> 00:06:56.550	So, there is a possibility that the network may eventually learn an identity mapping ok.
28.srt	00:06:57.689 --> 00:07:03.860	So, if the network learns an identity mapping it does not learn it does not really learn the representation.
28.srt	00:07:05.240 --> 00:07:20.439	So, in order to enforce or in order to force that the network learns the representation or network learns what is the inner structure of the data, it is necessary that in the network you impose a bottleneck layer.
28.srt	00:07:21.030 --> 00:07:24.400	We will come to a bit later details of how this is done.
28.srt	00:07:25.290 --> 00:07:30.620	And this bottleneck actually forces a compressed knowledge representation of the input.
28.srt	00:07:30.939 --> 00:07:50.370	That means, if my input vector input data is of dimension say d, in this compressed knowledge representation it will be mapped to a vector of dimension say m, where m is much much less than d. So, how it is done we will come to this a bit later.
28.srt	00:07:53.640 --> 00:08:04.080	So, for this we have certain assumptions, the assumption is there is a high degree of correlation or structure that exists in the data.
28.srt	00:08:05.530 --> 00:08:22.680	If the components of the input data are not correlated that means, if the features are independent of one another, then this compressed domain representation and subsequent reconstruction of the original input will be difficult in fact, it may not be possible at all.
28.srt	00:08:24.540 --> 00:08:38.639	the neural network goes for representation learning or tries for representation of the input data in compressed domain, what it tries to do is it removes the correlation or the redundancy present in the data.
28.srt	00:08:39.539 --> 00:08:50.269	And what is what it preserves is only the uncorrelated part and from this uncorrelated part then it should be subsequently possible to reconstruct the original input data.
28.srt	00:08:59.840 --> 00:09:04.660	So, that is what an autoencoder is and as we said that the name autoencoder indicates that it encodes the data or it codes the data on its own.
28.srt	00:09:05.100 --> 00:09:11.170	And this is an unsupervised learning because for training an autoencoder we do not use any label data.
28.srt	00:09:11.580 --> 00:09:17.100	What we want is whatever is fed to the input the autoencoder outputs the same thing.
28.srt	00:09:18.509 --> 00:09:26.509	So, for this I need two different functions one is the encoding part one is the decoding part.
28.srt	00:09:27.259 --> 00:09:30.440	So, the encoding part will encode the input data.
28.srt	00:09:31.180 --> 00:09:35.779	to ancompressed domain representation knowledge representation.
28.srt	00:09:36.290 --> 00:09:45.980	And the decoder part will decode the data from that compressed representation from theencoded output to your original input original input.
28.srt	00:09:46.110 --> 00:09:56.830	So, if my input was x it will reconstruct x hat I want that x and x hat should be similar or the error between x and x hat should be minimum.
28.srt	00:09:57.639 --> 00:09:59.970	And that is what is given by the decoder part.
28.srt	00:10:01.250 --> 00:10:04.690	So, I should have half, an encoder half I should also have a decoder half.
28.srt	00:10:05.629 --> 00:10:11.389	And this is the structure the base structure of an autoencoder.
28.srt	00:10:12.309 --> 00:10:24.710	So, you find that in this autoencoder I have an input layer, this is the input layer and I have a hidden layer and I have an output layer.
28.srt	00:10:26.149 --> 00:10:30.539	So, this hidden layer is actually the bottleneck layer.
28.srt	00:10:31.679 --> 00:10:37.669	So, in the bottleneck layer, I have what you are doing is you are compressing the data, you are going for compressed domain representation.
28.srt	00:10:38.139 --> 00:10:48.370	So, you find that the number of nodes in the hidden layer or the number of nodes in the bottleneck layer is much less than the number of nodes in the input layer.
28.srt	00:11:03.649 --> 00:11:13.470	And also you find that the number of nodes in the input layer is same as the number of nodes in the output layer, because finally at the output I want that whatever was the compressed domain representation in the hidden layer from this compressed domain representation it should be possible to reconstruct my original input.
28.srt	00:11:13.559 --> 00:11:18.970	So, original input was x I should be able to reconstruct this x which is x hat.
28.srt	00:11:19.700 --> 00:11:26.090	So, obviously, the dimensionality of x and the dimensionality of x hat should be same.
28.srt	00:11:27.570 --> 00:11:28.519	So, what does it mean?
28.srt	00:11:28.990 --> 00:11:37.120	Say for example, I use this network for compressed domain representation of an input image.
28.srt	00:11:38.590 --> 00:11:46.610	And, suppose image is of size m by n. So, there are m into n number of pixels.
28.srt	00:11:47.490 --> 00:12:07.350	So, as we said before that by column concatenation this m by n matrix can be represented by an one dimensional vector you see having m into n number of elements that we have to do by column concatenation concatenation.
28.srt	00:12:08.950 --> 00:12:15.570	So, if each of the n each pixel isfade to one of the nodes on the input layer.
28.srt	00:12:15.890 --> 00:12:24.030	So, the number of nodes in the input layer has to be m into n because every node input in the input layer gets one pixel.
28.srt	00:12:25.350 --> 00:12:30.150	In addition we have to have one more node to represent the bias.
28.srt	00:12:30.890 --> 00:12:35.570	So, the number of nodes in the input layer has to be m into n plus 1.
28.srt	00:12:39.130 --> 00:12:43.070	Whereas, on the reconstruction side, the I do not need any bias, I just want my x back.
28.srt	00:12:43.300 --> 00:12:45.280	So, that is what I need an x hat.
28.srt	00:12:45.970 --> 00:12:56.210	So, the number of nodes in the output layer has to be m into n as against m into n plus 1 on the input side.
28.srt	00:12:58.600 --> 00:13:09.350	Now, suppose I want that this entire image should be represented by a d dimensional vector.
28.srt	00:13:11.410 --> 00:13:21.380	or a vector having d number of components, where d is much less than m into n .
28.srt	00:13:21.380 --> 00:13:29.240	So, in that case the number of nodes in the hidden layer has to be equal to d, which is my bottleneck layer.
28.srt	00:13:29.240 --> 00:13:36.650	But the reconstruction purpose I need one more additional node to take care of the bias.
28.srt	00:13:36.650 --> 00:13:43.020	So, the number of nodes in the hidden layer for the decoding side or for the reconstruction side will be m into n plus 1 .
28.srt	00:13:44.360 --> 00:13:48.090	So, this is the base architecture of an autoencoder.
28.srt	00:13:50.830 --> 00:13:56.769	Now, you find that so, I have an input layer, I have an output layer, I have an hidden layer or a bottleneck layer.
28.srt	00:13:59.759 --> 00:14:15.420	Now, this same architecture now onwards for simplicity I will represent like this that input layer will be an array of nodes, hidden layer will be another array of nodes where array of array size in the hidden layer.
28.srt	00:14:15.789 --> 00:14:19.009	will usually be less than the array size in the input layer.
28.srt	00:14:20.350 --> 00:14:23.220	Similarly, on the output side also I will have an array of nodes.
28.srt	00:14:24.210 --> 00:14:29.929	And I will have a set of weights say W 1 and W 1 dash.
28.srt	00:14:30.440 --> 00:14:39.720	So, this W 1 connects the input layer to the hidden layer and W 1 dash connects from the hidden layer to the output layer right.
28.srt	00:14:46.429 --> 00:14:46.789	It is also possible that instead of having just one hidden layer, I can have layers.
28.srt	00:14:46.860 --> 00:14:56.129	Now, before that this side when you are going from input to the hidden layer, the hidden layer actually gives you the encodedinformation in a lower dimension in general.
28.srt	00:14:56.129 --> 00:15:09.610	Later on when we talk about sparsity or sparse auto encoder we will see that it is not necessary that I will have to go for dimensionality reduction.
28.srt	00:15:16.509 --> 00:15:20.930	I can have a dimension explosion as well or maybe of the same dimension, but your compressed representation is done by some other mechanism.
28.srt	00:15:22.129 --> 00:15:27.450	However, for the timing let us assume that we are going for compressed domain representation knowledge representation.
28.srt	00:15:27.970 --> 00:15:34.850	So, from input to the reduced dimensional representation that is a part which is the encoding part.
28.srt	00:15:35.220 --> 00:15:37.150	So, this is the encoder side.
28.srt	00:15:39.259 --> 00:15:50.520	So, this is what is your encoder and similarly from compressed domain representation to the reconstruction of the original signal this is what is the decoder part.
28.srt	00:15:50.800 --> 00:15:53.769	So, I have an encoder, I also have a decoder.
28.srt	00:15:55.600 --> 00:16:02.269	It is also possible that I may not have only one hidden layer or only one bottleneck layer.
28.srt	00:16:03.460 --> 00:16:07.379	I can have multiple number of hidden layers.
28.srt	00:16:07.680 --> 00:16:10.389	So, I can have a situation something like this.
28.srt	00:16:10.940 --> 00:16:18.040	So, on the encoder side I have a number of hidden layers, on the decoder side also I will have a number of hidden layers.
28.srt	00:16:18.820 --> 00:16:21.000	I will come back to this one a bit later.
28.srt	00:16:22.100 --> 00:16:35.680	Now, in this case as we said that when I have an autoencoder, what I have is I have input data and output of the autoencoder is also a data and I want that the output should be a faithful reconstruction of the input.
28.srt	00:16:36.540 --> 00:16:55.780	And while doing so, the information passes through the bottleneck layer, where in the bottleneck layer I have a compressed domain representation or coded version of the input data.
28.srt	00:16:58.780 --> 00:17:03.390	Now, I my expectation from such an autoencoder is twofold.
28.srt	00:17:04.250 --> 00:17:22.110	Firstly, I want that the autoencoder should be sensitive enough to the input for accurate reconstruction because what we said is my reconstructed vector x hat should be as close as possible to input x.
28.srt	00:17:27.610 --> 00:17:30.980	So, that means my autoencoder should be accurately should be able to accurately reconstruct my input signal.
28.srt	00:17:31.010 --> 00:17:36.170	So, that is what is it is sensitive enough to input for accurate reconstruction.
28.srt	00:17:37.680 --> 00:17:43.770	Now, if accurate reconstruction is my aim not the representation then an identity function is sufficient.
28.srt	00:17:45.560 --> 00:17:49.950	So, it might be possible that autoencoder simply learns the identity function.
28.srt	00:17:49.990 --> 00:17:57.880	So, if it simply learns the identity mapping it will always reconstruct your output faithfully as the input, but that is not our aim.
28.srt	00:17:58.640 --> 00:18:11.130	Our aim is actually what is happening at the bottleneck layer that is how the input data is represented in in the compressed domain that is what is my interest.
28.srt	00:18:11.840 --> 00:18:28.860	And this encoded data will be useful for some later applications because I have the original if my reconstruction is the is the only aim why do I need it I have the original why do I why do I have to go through the bottleneck and then a reconstruction.
28.srt	00:18:31.130 --> 00:18:40.200	So, the other expectation from an autoencoder is it should be insensitive enough that it does not memorize or over fit the training data.
28.srt	00:18:40.360 --> 00:18:42.810	That means, it does not learn the identity function.
28.srt	00:18:44.260 --> 00:18:57.390	So, I have two conflicting requirements or two conflicting expectations from an autoencoder that it should be sensitive and at the same time it should not be sensitive enough.
28.srt	00:18:58.220 --> 00:19:04.620	So, how do you impose or how do you try to satisfy both these requirements, both these conflicting requirements simultaneously.
28.srt	00:19:06.130 --> 00:19:12.010	So, that is actually done by designing your loss function which takes care of both of them.
28.srt	00:19:13.680 --> 00:19:21.640	And this loss function as we said that the loss function will be used for back propagation learning algorithm when you train the autoencoder.
28.srt	00:19:22.660 --> 00:19:38.450	So, the loss function in this case will be given bythis that this loss function will have two components one is L x x hat which is the error between the input x and the reconstructed x hat .
28.srt	00:19:39.610 --> 00:19:51.670	So, if I want to minimize this, so minimization of this the error takes care of this that the autoencoder is sensitive for faithful reconstruction of the input.
28.srt	00:19:53.360 --> 00:20:02.700	Whereas, the second requirement which conflicts the previous requirement is through a regularized term regularized term.
28.srt	00:20:03.740 --> 00:20:09.390	So, in the loss function you have an error function between x and x hat.
28.srt	00:20:10.510 --> 00:20:13.740	And, you also have a regularizer term.
28.srt	00:20:14.230 --> 00:20:30.990	So, the regularizer term will try to make it insensitive to the input and it will force the autoencoder to learn the low dimensional representation where it learns the salient features of the input.
28.srt	00:20:32.100 --> 00:20:37.070	So, that using the salient features the decoder will be able to reconstruct the data.
28.srt	00:20:38.080 --> 00:20:41.290	So, it does not simply learn the identity function.
28.srt	00:20:41.930 --> 00:20:56.590	So, both theserequirements conflicting requirements are made are satisfied by defining a loss function of this form .
28.srt	00:21:14.200 --> 00:21:24.170	So, this is what I said that the way a variant of the autoencoder which is known as under complete autoencoder takes care of the regularization is by introducingor by introducing restriction on the number of nodes in the hidden layer or the bottleneck bottleneck layer.
28.srt	00:21:25.150 --> 00:21:40.240	So, as we said usually number of nodes in the bottleneck layer or the hidden layer is much less than the number of nodes in the input layer or similarly the number of nodes in the output layer.
28.srt	00:21:45.280 --> 00:21:53.880	So, in such caseswe can consider the The network is made insensitive to the input by restricted number of nodes in the hidden layer.
28.srt	00:21:55.450 --> 00:22:01.990	And when I have an architecture of this form this is what is known as an under complete autoencoder architecture.
28.srt	00:22:03.020 --> 00:22:17.410	And for training such an autoencoder you simply minimize the loss function which is given by L x x hat which is half of x minus x hat take the L 2 norm of that.
28.srt	00:22:18.040 --> 00:22:32.440	And, some of this over all the training vectors ok. And, you find that here as we said that this is an unsupervised learning because I do not need to have a knowledge of the class belongingness of the input vector x.
28.srt	00:22:32.840 --> 00:22:42.720	What I simply only need is that the x and x hat should be similar that is x hat should be a faithful reconstruction of my input x.
28.srt	00:22:43.700 --> 00:22:46.750	So, this is what is my under complete autoencoder.
28.srt	00:22:51.650 --> 00:23:00.140	Now, as we said before that it is not necessary thatthe autoencoder have to have only one hidden layer orthe bottleneck layer.
28.srt	00:23:01.480 --> 00:23:09.990	I can have and stacked autoencoder where a number of hidden layers are stacked one after another.
28.srt	00:23:11.260 --> 00:23:22.530	So, this diagram shows that I have a stacked autoencoder where obviously, x isfade to the input layer.
28.srt	00:23:23.790 --> 00:23:41.100	I have the firsthidden layer in the autoencoder on the encoding side, the connection weights between the input layer and the first hidden layer autoencoder layer is given by the weight vectors or weight matrix W 1.
28.srt	00:23:42.050 --> 00:23:55.230	Then I have the second hidden layer and in this case the second hidden layer happens to be the bottleneck layer and the connection weights between the first autoencoding layer.
28.srt	00:23:55.470 --> 00:24:02.020	to the second hidden layer the second auto encoding layer is the set of connection weights W .
28.srt	00:24:02.020 --> 00:24:04.980	So, this completes my encoding part.
28.srt	00:24:04.980 --> 00:24:20.430	Then on the decoder side from the encoded data it goes to the first hidden layer on the decoding side and the connection weights from this to this is given by W 2 dash.
28.srt	00:24:20.430 --> 00:24:27.740	And similarly from this hidden layer to the output layer the connection weight is given by W 1 dash .
28.srt	00:24:29.800 --> 00:24:38.140	And, what I simply want is that the x hat should be a faithful reconstruction of x that is the input data.
28.srt	00:24:39.160 --> 00:24:47.780	And, for that the loss function that you have to minimize is the L 2 norm between x and x hat.
28.srt	00:24:49.250 --> 00:24:56.250	And, this has to be summed over all the training data and you minimize this L 2 norm using back propagation learning algorithm.
28.srt	00:24:58.920 --> 00:25:21.650	And, while this is minimized, you find that these weights w 1 w 2 similarly w 2 dash and w 2 w 1 dash they will be modified they will be updated until and unless the L 2 norm or the error between x and x hat is 0 or it is within an acceptable limit.
28.srt	00:25:21.650 --> 00:25:26.800	At that point we say that my auto encoder is properly trained.
28.srt	00:25:32.360 --> 00:25:46.800	Now, what you do after the auto encoder is properly I said earlier that reconstruction is not my aim, I want to reconstruction I want to reconstruct the input data from the encoded data just to ensure that my encoding is proper.
28.srt	00:25:47.660 --> 00:26:00.800	That is whatever my is my encoded data from the encoded data I should be able to reconstruct my encoding input data, which ensures that in the process of encoding I have not lost any information.
28.srt	00:26:02.690 --> 00:26:07.770	this decoding part of the reconstruction part is not the one that I am interested in.
28.srt	00:26:08.300 --> 00:26:18.690	What I am interested in is simply this encoding part, my interest is up to this.
28.srt	00:26:20.380 --> 00:26:25.520	So, for subsequent applications if I want to apply this even for classification purpose.
28.srt	00:26:27.540 --> 00:26:34.250	What I can do is after this autoencoder is trained that means my encoding part.
28.srt	00:26:34.480 --> 00:26:39.970	is proper, I can simply forget about this part of the network.
28.srt	00:26:40.520 --> 00:26:52.160	You simply cut it off, you feed your input, I have the encoded output and feed this encoded output to your other application modules.
28.srt	00:26:52.410 --> 00:26:55.740	This is what is my aim, my aim is not the decoding.
28.srt	00:26:56.320 --> 00:27:04.130	Decoding is only a help to ensure that my encoder is working properly.
28.srt	00:27:06.670 --> 00:27:35.340	So, this is whatthe autoencoder will do and for this again we said that what we want is that autoencoder will be trained using the back propagation learning and for during this back propagation learning we will make use of the errors or the gradient of the error that you get at the output layer between the input and the reconstructed output.
28.srt	00:27:35.740 --> 00:27:42.860	And, based on that you modify all the connection weights so that your encoder is properly trained.
28.srt	00:27:43.890 --> 00:27:50.380	So, I will stop here today we will continue with our discussions on autoencoders in subsequent lectures.
28.srt	00:27:50.920 --> 00:27:51.210	Thank you.
29.srt	00:00:00.610 --> 00:00:27.629	Hello, welcome to the NPTEL online certification course on deep learning.
29.srt	00:00:31.979 --> 00:00:37.479	So, since our previous class we have started discussion on auto encoders.
29.srt	00:00:38.409 --> 00:00:53.179	So, what we discussed yesterday or in our previous class is what is an auto encoder and a particular variant of auto encoder that we have introduced is what is known as under complete auto encoder.
29.srt	00:00:54.659 --> 00:01:00.959	Today in this lecture we will discuss about the auto encoder versus auto encoder.
29.srt	00:01:01.170 --> 00:01:16.060	principal component analysis that is whether principal components and the autoencoder outputs they are related, if they are related, how they are related, what is the similarity and what is the dissimilarity between these two.
29.srt	00:01:16.859 --> 00:01:31.980	And then we in subsequent lectures we will discuss about otherautoencoder topics like training of autoencoders, sparse autoencoder, denoising autoencoder, contractive autoencoder.
29.srt	00:01:32.409 --> 00:01:36.599	convolution autoencoder and all that .
29.srt	00:01:36.599 --> 00:01:49.989	So, before we start today's topic on autoencoder versus PCA, let us just briefly recapitulate what we have discussed in our previous class .
29.srt	00:01:49.989 --> 00:01:56.799	So, we have said that autoencoder is an unsupervised learning technique.
29.srt	00:01:56.799 --> 00:02:02.509	So, a learning technique which forces the feed forward or deep neural networks .
29.srt	00:02:03.069 --> 00:02:08.169	to learn what is known as representation learning.
29.srt	00:02:08.909 --> 00:02:22.609	That is given an input vector or an input signal the network or autoencoder learns a compressed domain representation or learns a structure which is present in the input data.
29.srt	00:02:33.770 --> 00:02:36.189	And the way the neural network or the autoencoder learns this representation data representation or data structure is by imposing a bottleneck layer in the network.
29.srt	00:02:37.250 --> 00:02:54.229	And this bottleneck layer actually forces a compressed knowledge representation of the input and that is what the autoencoder learns and this compressed domain knowledge representation is subsequently used for other applications.
29.srt	00:02:56.870 --> 00:03:04.920	So, while doing this we assume something the assumption is the degree of correlation or the structure.
29.srt	00:03:05.589 --> 00:03:09.500	that exists in the input data is quite high.
29.srt	00:03:10.539 --> 00:03:21.729	And in fact, if the input data or the input feature vectors are uncorrelated or they are statistically independent, then compression and subsequent reconstruction would be difficult.
29.srt	00:03:21.729 --> 00:03:27.589	Of course, we will be able to compress, but the compression will be highly lossy compression if there is no redundancy.
29.srt	00:03:27.879 --> 00:03:38.549	Because whatever information is present in the input data unless there is redundancy or there is correlation, then going for any sort of compression leads to loss of data.
29.srt	00:03:39.609 --> 00:03:56.899	And, once in that compressed domain representation the data or the information is lost whichever way I try to reconstruct my signal the original signal from that lossy compressed representation my output will always be lossy.
29.srt	00:03:57.169 --> 00:04:03.919	That means, the decompressed data or reconstructed data cannot be identical to the input.
29.srt	00:04:13.539 --> 00:04:16.569	So, the basic assumption in use of autoencoders when you go for encoding in compressed domain or representation in compressed domain the So, basic assumption is the data is highly correlated.
29.srt	00:04:18.179 --> 00:04:28.419	So, based on this we have seen a basic autoencoder architecture which is something like this that you have an input layer, you have an output layer.
29.srt	00:04:29.269 --> 00:04:32.379	So, input layer actually accepts the input data.
29.srt	00:04:32.909 --> 00:04:41.719	So, if the dimensionality of the input data is n at the input layer I will have n number of nodes.
29.srt	00:04:42.159 --> 00:04:47.459	In addition there will be one more node to take care of the bias.
29.srt	00:04:48.060 --> 00:05:04.110	And, in fact we have seen earlier that addition of this bias in the input vector allows us to go for an unified file representation that is the bias term can be taken can be considered as an additional term in the weight vector.
29.srt	00:05:05.149 --> 00:05:20.139	So, number of nodes in the input layer will be n plus 1 if the input data vector has dimensionality n. Similarly, in the output layer which reconstructs the input as x hat.
29.srt	00:05:20.300 --> 00:05:23.430	So, our input is x and the output is x hat.
29.srt	00:05:23.930 --> 00:05:32.819	So, the output layer will consist of n number of nodes because we want that the input x should be reconstructed at the output.
29.srt	00:05:34.399 --> 00:05:42.709	And in case of a basic model of an autoencoder, we have a hidden layer in between input layer and output layer.
29.srt	00:05:43.569 --> 00:05:57.349	And what we have said in case of under complete autoencoder that the number of nodes in the hidden layer is much less is less than the number of nodes in the input layer or the number of nodes in the output layer .
29.srt	00:05:58.360 --> 00:06:02.149	So, this is what is known as a bottleneck layer.
29.srt	00:06:03.069 --> 00:06:09.509	So, in bottleneck layer as the number of nodes is less than the input layer nodes.
29.srt	00:06:10.139 --> 00:06:19.899	So, what this network does is the network passes the input information through a restricted layer where the number of nodes is much less.
29.srt	00:06:20.569 --> 00:06:31.370	And then subsequently as this information passes through this restricted layer then the decoder side that is the output layer tries to reconstruct.
29.srt	00:06:31.750 --> 00:06:34.959	the original input from this restricted output.
29.srt	00:06:35.870 --> 00:06:44.069	So, as the information passes through this restricted layer, the network tries to learn a compressed domain representation of the data.
29.srt	00:06:45.430 --> 00:07:01.000	So, imagine what will happen if I do not have this bottleneck layer that is if the number of nodes in the hidden layer is same as the number of nodes in the input layer that is the size of the data or even more than the number of nodes in the input layer.
29.srt	00:07:04.240 --> 00:07:15.090	In that case it might be possible that the network will simply learn an identity function that is given an input, it goes to an intermediate representation and then knows how to reconstruct the same output.
29.srt	00:07:15.689 --> 00:07:28.350	And in the process if I have large number of nodes in the hidden layer, the network eventually may not learn the compressed domain representation or the structure present in the data which is not our aim.
29.srt	00:07:28.910 --> 00:07:36.750	So, that is the reason that in the hidden layer or in the bottom layer you put some restriction on the number of nodes that you can have.
29.srt	00:07:38.190 --> 00:07:56.050	Later on we will see that when we talk about the sparse autoencoder that it is not even necessary to have the restriction on the number of nodes, but we can add some other regularization term where the rednodeactivations will be restricted.
29.srt	00:07:56.830 --> 00:08:03.620	So, instead of trying to restrict the number of nodes you try to restrict the node activations.
29.srt	00:08:04.220 --> 00:08:11.920	So, this is the basic structure of an autoencoder and as we said that all subsequent representations we will use this form of representation.
29.srt	00:08:12.170 --> 00:08:14.170	to represent an autoencoder.
29.srt	00:08:14.510 --> 00:08:29.410	So, I have an encoder part which is thefrom input layer to the hidden layer and I have a decoder part which is from the decoder to the output layer and this whole thing taken together the encoder decoder together is known as autoencoder.
29.srt	00:08:29.930 --> 00:08:42.050	And as it is an under complete autoencoder that we are trying to depict the number of nodes in the hidden layer which is the bottleneck layer is less than the number of nodes in the input layer or the number of nodes in the output layer.
29.srt	00:08:42.930 --> 00:08:53.950	And, while training this autoencoder the loss function that youtry to minimize is the squared error loss between the input and output.
29.srt	00:08:54.370 --> 00:09:06.070	So, that is x minus x hat L 2 norm of that x minus x hat square take the summation over all the data points all the training samples that you are feeding for training this network.
29.srt	00:09:06.950 --> 00:09:15.140	So, this is the basic structure of an autoencoder which has got one input layer, one output layer with a hidden layer or a bottleneck layer in between.
29.srt	00:09:16.629 --> 00:09:22.020	Now, when you go for so, what does this auto encoder try to learn?
29.srt	00:09:23.390 --> 00:09:30.060	So, here what has been shown is that if I feed an input to an auto encoder which is an image.
29.srt	00:09:30.060 --> 00:09:37.660	So, in our case x is an image and the output that is x hat which is reconstructed is also an image right.
29.srt	00:09:38.040 --> 00:09:43.140	And in ideal case if the auto encoder is properly trained then x hat will be same as x.
29.srt	00:09:43.910 --> 00:09:46.230	Now, once this auto encoder is properly trained.
29.srt	00:09:46.600 --> 00:09:50.960	what does this encoding layer or the bottleneck layer actually learn.
29.srt	00:09:51.810 --> 00:10:02.280	So, this is an example which has beenobtained from training such an autoencoder with large number of input images.
29.srt	00:10:03.260 --> 00:10:08.100	So, you find that on the right hand side the example image set that we have.
29.srt	00:10:08.730 --> 00:10:19.070	So, this particular image this particular sub image is actually the image or the structure which is learned by the first autoencoder.
29.srt	00:10:20.050 --> 00:10:29.080	Now, here you find that this output is not exactly from this particular network that we are showing here, here you find that there are 100 such sub images or 100 structures.
29.srt	00:10:29.420 --> 00:10:43.529	That means, the autoencoder which has been trained with for this kind ofexample has 100 number of nodes in the middle layer or in the bottleneck layer and every node learns some structure.
29.srt	00:10:44.279 --> 00:10:51.190	So, this first node learns this structure, similarly second node may learn this structure and so on.
29.srt	00:10:51.710 --> 00:10:53.340	And, how this image has been formed?
29.srt	00:10:53.850 --> 00:10:59.300	It is nothing but these weights from the input which are connected to the first node.
29.srt	00:11:00.240 --> 00:11:07.060	You remember the way we have got this vector is by concatenating the columns of the input image.
29.srt	00:11:08.760 --> 00:11:21.790	So, when you form thesestructures when I reconstruct the structures which are learned by these hidden layer nodes, these are these weight vectors which are folded back.
29.srt	00:11:22.480 --> 00:11:25.250	in the form of an image ok.
29.srt	00:11:25.520 --> 00:11:33.680	So, you find that if there are n number of nodes in the input.
29.srt	00:11:34.090 --> 00:11:38.010	So, I have an image consisting of n number of pixels.
29.srt	00:11:38.700 --> 00:11:43.630	Here also I have n number of vectors of course, n plus 1 considering the bias term.
29.srt	00:11:43.810 --> 00:11:45.970	Now, when you form this you remove that bias term.
29.srt	00:11:46.570 --> 00:11:53.160	So, among the remaining vectorsremaining components of the weight vector I fold it back in the form of an image.
29.srt	00:11:53.629 --> 00:11:56.220	So, this is such an image.
29.srt	00:11:56.220 --> 00:12:04.340	So, these are the structures as shown in this set of images which are learnt by this encoding layer.
29.srt	00:12:06.580 --> 00:12:13.360	And as you see over here these sub images appear to be edges oriented in various directions.
29.srt	00:12:13.629 --> 00:12:17.960	So, edges are nothing, but the detailed informations which are present in the image.
29.srt	00:12:19.320 --> 00:12:29.990	So, this simple example shows that this input layers or nodes in the input layer actually learn the structures which are present in the image.
29.srt	00:12:30.330 --> 00:12:34.060	it does not simply pass the input image to the output layer.
29.srt	00:12:35.190 --> 00:12:50.110	And then what this decoder side does is the decoder side use makes use of these structures which which are present in the image and from these structures it tries to reconstruct the original image.
29.srt	00:12:50.110 --> 00:12:59.379	So, when this network is properly learnt this is the form of structure which will which is actually learnt by this encoding layer right.
29.srt	00:13:00.480 --> 00:13:01.259	So, this is how .
29.srt	00:13:01.650 --> 00:13:05.610	an encoder learns the structure which is present in the data.
29.srt	00:13:07.200 --> 00:13:19.460	In case of deep autoencoder, so earlier what we have shown is a basic structure of an autoencoder where I have an input layer, I have an output layer and I have one hidden layer which is a bottleneck layer.
29.srt	00:13:20.590 --> 00:13:30.280	In a deep autoencoder, I can have a number of such auto encoding layers which are stacked one after another.
29.srt	00:13:35.700 --> 00:13:42.630	So, in this diagram what has been shown is This is your input layer, this is the input layer, this is the autoencoder layer 1.
29.srt	00:13:42.750 --> 00:13:51.460	So, I put it as A e 1, this is A e 2 or this is actually the coding layer in this particular diagram.
29.srt	00:13:52.380 --> 00:14:05.710	I can have A e 1, A e 2, A e 3, A e 4 and so on I can go on stacking such autoencoder layers, ok. Then accordingly on the decoder side also I will have stacking of a number of such decoding layers.
29.srt	00:14:06.350 --> 00:14:24.480	So, in case of deep autoencoder the number of layers, number of encoding layers and the number of decoding layers that you make part of the autoencoder that decides what is the depth of the autoencoder that you are going to design or the autoencoder that you are going to use.
29.srt	00:14:24.810 --> 00:14:35.520	However, for training the autoencoder we still use the squared error loss between the input and the output for training the autoencoder.
29.srt	00:14:38.870 --> 00:15:05.780	So, given thishere you find that what this autoencoder does as we have already said that given an input data of dimension say n. So, x having dimension n if in the encoding layer or in the bottleneck layer I have the number of nodes which is equal to d where d is much much less than n.
29.srt	00:15:07.050 --> 00:15:22.450	So, here this autoencoder learns a compressed representation of this n dimensional data to a d dimensional representation which is the latent also called as latent space representation.
29.srt	00:15:23.920 --> 00:15:39.030	And it is expected that if the autoencoder is properly trained then from this latent space representation the decoder will be able to decode this latent space representation of the data to give you the reconstructed data exact.
29.srt	00:15:39.980 --> 00:15:43.430	data which is almost a replica of your input data x.
29.srt	00:15:44.900 --> 00:16:00.270	So, in other sense we can say that while coding the autoencoder actually gives you a transformation that transforms the data from a higher dimensional space to a lower dimensional space.
29.srt	00:16:01.180 --> 00:16:10.140	And while doing so it ensures that your reconstruction error end to end reconstruction error when the data will be reconstructed that is minimized.
29.srt	00:16:10.780 --> 00:16:26.940	So, this lower dimensional representation indicates that the loss it tells that the loss that you incur while compressing the data or while trying to extract the structure from the data the loss incurred will be minimum.
29.srt	00:16:28.280 --> 00:16:38.350	So, in other case you can consider the function of the autoencoder is to go for dimensionality reduction of the input data.
29.srt	00:16:39.820 --> 00:16:45.620	And if I consider the function of the autoencoder as a dimensionality reduction function.
29.srt	00:16:47.020 --> 00:17:02.710	Then, we have to see that what is the other dimensionality reduction function that we have and it is known that traditionally the dimensionality reduction is done by an algorithm known as principal component analysis.
29.srt	00:17:04.180 --> 00:17:09.970	So, naturally then the question comes that how does principal component analysis compare with autoencoders.
29.srt	00:17:10.930 --> 00:17:14.770	So, in order to do that before going to that comparison.
29.srt	00:17:15.990 --> 00:17:23.370	for the benefit of those who does not know what is principal component analysis, let me briefly say what is principal component analysis.
29.srt	00:17:25.130 --> 00:17:36.660	So, in case of principal component analysis our input is let us assume that input is a set of vectors x.
29.srt	00:17:37.670 --> 00:17:47.070	So, I put this as set of vectors x 1, x 2, x 3 up to say x .
29.srt	00:17:53.750 --> 00:18:09.360	x n. So, assuming that we have n number of input vectors and each of the input vector may be of dimension say let me put as capital D .
29.srt	00:18:09.360 --> 00:18:17.160	So, capital D is the dimension of the input vectors that means, each of x 1, x 2 up to x n each of them has D number of components.
29.srt	00:18:18.900 --> 00:18:47.130	Now, once I have such a collection of vectors x, you define the covariance matrix as C x which is defined as expectation value of x minus mu x into x minus mu x transpose .
29.srt	00:18:48.100 --> 00:18:51.520	So, what is mu x?
29.srt	00:18:51.950 --> 00:18:57.410	Mu x is nothing but mean of the input vectors.
29.srt	00:18:57.930 --> 00:19:00.560	So, I have n number of input vectors.
29.srt	00:19:00.790 --> 00:19:21.920	So, this will be 1 upon n sum of x i where i varies from 1 to n. So, this is my mu x and x is each of these individual vectors.
29.srt	00:19:22.800 --> 00:19:32.530	So, I define the covariance matrix of the set of input vectors as the expectation value of X minus mu X into X minus mu X transpose.
29.srt	00:19:33.500 --> 00:19:38.620	And now if you analyze this covariance matrix, so what will be the size of this covariance matrix?
29.srt	00:19:52.940 --> 00:19:54.810	As the vector is n dimensional, so this covariance matrix will be a D by D matrix as D is the dimension of the feature vectors.
29.srt	00:19:55.500 --> 00:19:58.260	So, this covariance matrix will be a d by d matrix.
29.srt	00:19:59.460 --> 00:20:08.870	And in this covariance matrix the diagonal elements will give you the variance of the individual components of the vectors.
29.srt	00:20:09.210 --> 00:20:22.820	That means, if I take the first vector first component of x 1, first component of x 2, first component of x 3 and so on and I compute the variance of all those first components that variance will be my sigma 1 1.
29.srt	00:20:22.900 --> 00:20:26.150	1 which is a first component in this diagonal vector.
29.srt	00:20:26.830 --> 00:20:39.720	Similarly, sigma 2 2 will be the variance of the second component sigma d d will be the variance of the d th component of the last component.
29.srt	00:20:40.430 --> 00:20:48.390	And all the off diagonal elements in this matrix will give you the covariance of different components.
29.srt	00:20:49.070 --> 00:20:54.030	So, sigma 1 2 is the covariance between the first component and sigma second component.
29.srt	00:20:54.270 --> 00:21:20.380	1 2 up to sigma 1 d, sigma 2 1, sigma 2 2 up to sigma 2 d and so on this is sigma d 1, sigma d 2 up to sigma d d. So, this is say my covariance matrix and I want to compute the eigenvectors i and the eigenvalues lambda.
29.srt	00:21:21.710 --> 00:21:28.810	So, the way you compute this eigenvalue is from each of these diagonal elements.
29.srt	00:21:29.360 --> 00:21:33.090	you subtract lambda and then make a determinant.
29.srt	00:21:33.490 --> 00:22:00.640	So, the determinant will be sigma 1 1 minus lambda sigma 1 2 up to sigma 1 d sigma 2 1 sigma 2 2 minus lambda sigma 2 3 goes on sigma d 1 sigma d 2 sigma d d minus lambda make a determinant and equate this to 0 .
29.srt	00:22:02.710 --> 00:22:13.820	So, once you put this you find that this determinant will give you a polynomial of degree d and it will be a polynomial in lambda.
29.srt	00:22:15.030 --> 00:22:19.580	So, when I solve this I will get d components or d values of lambda.
29.srt	00:22:19.580 --> 00:22:33.320	So, I will get lambda i where i varies from 1 to d and then for each of this lambda i, I can compute the corresponding eigenvector.
29.srt	00:22:35.200 --> 00:22:52.940	So, the way you compute eigenvector is if for lambda i the corresponding eigenvector is say e i, then the equation that has to be satisfied is C x e i have to be equal to lambda i times e i.
29.srt	00:22:55.040 --> 00:23:06.300	So, I know what is C x, I know what is lambda i, you solve this equation I get the ith eigenvector which is e. So, this is how.
29.srt	00:23:06.780 --> 00:23:20.340	So, given a set of vectors I can compute the covariance matrix from the covariance matrix I can compute the eigenvectors or eigenvalues and for every eigenvalue I can compute the eigen corresponding eigenvector.
29.srt	00:23:21.800 --> 00:23:30.500	And you see that if this covariance matrix is real and symmetric which usually is then the eigenvectors are orthogonal.
29.srt	00:23:32.780 --> 00:23:37.030	And what this lambda tells you or the eigenvalue tells you.
29.srt	00:23:37.340 --> 00:23:45.950	it simply tells you that what is the scatter or what is the variation of the data in the direction of the corresponding eigenvector.
29.srt	00:23:47.450 --> 00:23:58.040	So, if lambda 1 is very high that in that indicates that the variation of data in the direction of the corresponding eigenvector which is E 1.
29.srt	00:23:58.630 --> 00:24:06.420	So, lambda 1 very high indicates that the variation of data in the direction of E 1 is very high right.
29.srt	00:24:06.890 --> 00:24:07.850	So, given this .
29.srt	00:24:08.340 --> 00:24:12.519	Once, I have this eigenvectors then I can define a transformation.
29.srt	00:24:13.550 --> 00:24:15.150	So, how do you define this transformation?
29.srt	00:24:16.220 --> 00:24:31.890	For defining a transformation you make you form a transformation matrix A, this transformation matrix A is formed using the eigenvectors as the rows in the transformation matrix.
29.srt	00:24:33.780 --> 00:24:40.460	So, the first row in this transformation matrix is E 1, the second row is E 2.
29.srt	00:24:41.420 --> 00:25:14.180	So, the last row is E d you remember that we had d number of eigenvectors as our input vector is of dimension d. And how I get this transformation matrix or how I arrange such eigenvectors into rows of this transformation matrix is in this transformation matrix E 1 corresponding to that my eigenvector is lambda 1 and for vector E 2.
29.srt	00:25:14.520 --> 00:25:20.710	my corresponding eigenvalues eigenvalue is lambda 1 and corresponding to this I have my eigenvalue which is lambda 2.
29.srt	00:25:22.060 --> 00:25:33.290	So, I arrange this eigenvectors as rows in this transformation matrix in descending order of the corresponding eigenvalues.
29.srt	00:25:34.150 --> 00:25:45.020	So, here E 1 is the first row, E 2 is the second row that indicates that I have lambda 1 greater than lambda 2 right.
29.srt	00:26:16.860 --> 00:26:30.130	2 for a pair of eigenvalues say lambda i lambda j where both i and j varies from 1 to d because I will have lambda varies from lambda 1 to lambda d. So, for this pair of eigenvalues lambda i and lambda j if lambda i is greater than lambda j that indicates that E i the eigenvector E i will occupy a higher row than E j in this transformation matrix.
29.srt	00:26:30.130 --> 00:26:35.360	So, for this E i I have the corresponding eigenvalue lambda i for E j I have the corresponding value lambda j.
29.srt	00:26:35.800 --> 00:26:44.470	So, as lambda i is greater than lambda j in this transformation matrix A E will E i will occupy a higher position than E j.
29.srt	00:26:44.470 --> 00:26:48.490	So, that is how this transformation matrix is formed.
29.srt	00:26:51.900 --> 00:26:56.430	So, once I have this transformation matrix, then I can define a transformation.
29.srt	00:26:56.520 --> 00:27:13.170	My input vectors are x, I can have a transformation which is given by a times say x k the kth vector minus mu j mu x which is the mean of the vectors.
29.srt	00:27:13.460 --> 00:27:14.880	So, this defines a transformation.
29.srt	00:27:15.500 --> 00:27:19.270	So, this gives me a transform vector which is y k .
29.srt	00:27:21.200 --> 00:27:32.810	So, for kth vector this transformation gives me a transformed vector y k. So, if you look at this transformation what this transformation is doing?
29.srt	00:27:50.240 --> 00:28:21.270	If I take the first component of a x k, so difference of first component of x k and first component of mu x right, this is transformed or the vector x k minus mu k is being projected onto vector E 1 because this is nothing, but the dot product of E 1 with x k minus mu x that gives that gives me the first component of y k. Similarly, the dot product of x k minus mu x with E 2 which is the second row in my transformation matrix gives me the second component of y k.
29.srt	00:28:23.490 --> 00:28:23.730	right.
29.srt	00:28:24.140 --> 00:28:28.950	So, this transformation that you get this is what is popularly known as K L transformation.
29.srt	00:28:30.210 --> 00:28:38.590	And I can use this K L transformation for data reduction in the sense that if I want to reduce the dimension from D to 2.
29.srt	00:28:39.660 --> 00:28:51.480	What I will do is in this transformation matrix A that I form this A instead of considering all the eigenvectors I will only consider E 1 and E 2 the eigenvectors E 1 and E 2.
29.srt	00:28:53.510 --> 00:29:13.510	And, the transformation will be same as this a times x k minus mu x, where a is now this is actually 2 by d matrix, I have 2 rows and d number of columns right.
29.srt	00:29:13.760 --> 00:29:15.360	So, this is a 2 by d matrix.
29.srt	00:29:15.850 --> 00:29:24.250	So, when you go for this transformation this y k you find that it will be a 2 by d 1 vector that means, it is a 2 dimensional vector.
29.srt	00:29:25.330 --> 00:29:38.250	So, just by truncation of this transformation matrix, I can transform the data from n dimension to 2 dimension or d dimension to 2 dimension.
29.srt	00:29:38.530 --> 00:29:43.940	So, that is what gives me a reduction in the dimensionality of the input data.
29.srt	00:29:45.000 --> 00:29:55.240	And this is what is popularly known as KL transformation and the components of this transform vector Y k that you get that is Y k.
29.srt	00:29:56.210 --> 00:30:09.130	1, the first component and y k 2 that is the second component after this transformation, these are what are known as principal components and the eigenvectors are the principal directions.
29.srt	00:30:30.370 --> 00:30:32.270	So, effectively what you are doing is you are transforming your input data into a space which is known as eigenspace and the eigenvectors being orthogonal, the eigenspace is also orthogonal and the projections in the eigenspace in every eigen direction are the principal components of the input data.
29.srt	00:30:33.430 --> 00:31:00.800	And by arranging the transformation matrix A in this form that is arranging the rows as eigenvectors in descending order of corresponding eigenvalues ensures that the error that you encounter by in by truncating some of the rows from the lower side ensures that the error that you encounter will be minimal.
29.srt	00:31:03.100 --> 00:31:11.490	So, let me stop here today, I will take up this illustrations with principal component in the next class.
29.srt	00:31:12.000 --> 00:31:12.280	Thank you.
15.srt	00:00:00.610 --> 00:00:29.149	Hello, welcome to the NPTEL online certification course on deep learning .
15.srt	00:00:31.810 --> 00:00:43.159	In the previous class we have talked about the linear machines and we have also discussed started our discussion onmulti class support vector machine.
15.srt	00:00:44.359 --> 00:00:53.760	Today's lecture we willdiscuss on multi class support vector machine loss function and also the optimization techniques.
15.srt	00:01:02.219 --> 00:01:23.840	So, what we have done in case of linear machine is that we have seen that linear machine is a function that transforms or that maps a d dimensional feature vector r d into a score function of dimension k. So, score function s that you get is also a vector of dimension k where k is the number of categories or the number of classes.
15.srt	00:01:33.329 --> 00:01:55.979	So, if I expand this the function looks like this that f given an input vector x i f x i w b where w is the weight matrix and b is the bias vector is given by w x i plus b which is equal to the score function s and we have seen that the score function s has got k number of components where k is the number of classes or the number of categories.
15.srt	00:02:07.519 --> 00:02:25.049	So, given this we have seen that the score for the jth class or the jth category is the jth component of the score function S which in this case we have written as S j and this S j is nothing but W x i the jth component of this.
15.srt	00:02:25.620 --> 00:02:29.819	So, we can write this as f x i w the jth component.
15.srt	00:02:30.139 --> 00:02:37.769	So, the jth component of this gives me the score for the jth class of the ith vector x i.
15.srt	00:02:38.169 --> 00:02:41.139	which belongs to class y i.
15.srt	00:02:41.859 --> 00:02:51.699	So, these are the training vectors and because this x i the input vector belongs to class y i.
15.srt	00:02:53.229 --> 00:02:59.609	So, the score function component component y i must be maximum.
15.srt	00:03:00.729 --> 00:03:12.469	So, when this linear machine gives you the score function the score function the y i component of the score function must be maximum because we have taken x i belonging to class.
15.srt	00:03:12.819 --> 00:03:13.339	y i.
15.srt	00:03:14.609 --> 00:03:27.669	And we are not only satisfied with the score function to be maximum, we also want that the score function should be more than the score function of other classes by at least a threshold delta.
15.srt	00:03:28.449 --> 00:03:42.909	That means, taken any other class S j or S of y i the score function of the class y i must be greater than S j, where j is any other category other than y i.
15.srt	00:03:43.339 --> 00:03:47.519	So, this difference must be greater than some threshold delta.
15.srt	00:03:48.139 --> 00:04:04.319	So, accordingly for the ith component the loss function that we get L i which is nothing, but maximum of 0 and S j minus S y i plus delta.
15.srt	00:04:14.739 --> 00:04:18.189	So, you find that as long as S y i is greater than S j, then it is greater than S j by an amount delta.
15.srt	00:04:18.439 --> 00:04:25.209	So, this amount S j minus S y i plus delta will be less than 0.
15.srt	00:04:26.310 --> 00:04:39.569	Whereas, if S j is equal to S y i, then this function will be equal to delta and if S j is greater than S y i, this function will be greater than delta, where delta is a positive threshold.
15.srt	00:04:40.029 --> 00:04:45.779	So, in that case when you take max of 0 and this output will be this only if it is greater than 0.
15.srt	00:04:46.599 --> 00:04:58.370	And, the output of this max function will be equal to 0 only when S y i is greater than S j by at least this threshold amount delta.
15.srt	00:04:59.209 --> 00:05:05.959	And, you sum it over allj not equal to i, I get the loss component S i.
15.srt	00:05:08.159 --> 00:05:16.139	And, the overall loss that you get isgiven by sum of all these loss components.
15.srt	00:05:16.769 --> 00:05:28.439	So, to explain this we had taken an example that suppose I have some x i y i where this y i is equal to 2 that means, this x i belongs to category 2.
15.srt	00:05:29.219 --> 00:05:46.919	And the suppose the score function that is computed is given by this s equal to 10, 30, minus 20 and 25 and let us assume that we have a threshold delta which is equal to 10.
15.srt	00:05:47.799 --> 00:05:54.429	So, if I compute L i in this case i is equal to 2 because we have taken x i from category 2.
15.srt	00:05:55.339 --> 00:06:14.489	So, if I compute L i you find that it will have these three components one is maximum of 0, 10 minus 30 plus 10 this 10 is delta, the first 10 is the score function for category 1 and 30 is the score function for category 2.
15.srt	00:06:15.899 --> 00:06:16.919	So, this is 0.
15.srt	00:06:17.129 --> 00:06:20.019	10 minus 30 plus 10 which becomes minus 30.
15.srt	00:06:20.209 --> 00:06:22.879	So, the corresponding max function gives you an output 0.
15.srt	00:06:23.829 --> 00:06:39.519	Similarly, for the second case it is max of minus 20 which is core function for category 3 minus 30 that is core function for category 2 plus 10 again this part becomes negative.
15.srt	00:06:39.519 --> 00:06:40.409	So, output is 0.
15.srt	00:06:41.729 --> 00:06:47.729	And for the other one the score function is 25 which is the score function for category 4.
15.srt	00:06:48.079 --> 00:06:53.929	So, it is 25 minus 30 plus 10 and that gives you an output 15.
15.srt	00:06:54.179 --> 00:06:57.569	So, as a result L 2 is equal to 15.
15.srt	00:06:58.629 --> 00:07:16.669	So, when I compute this core functions as I said before that if I take summation of this core function of over all value of i for all value of j not equal to y i, I getthe overall score function.
15.srt	00:07:21.549 --> 00:07:48.939	Now, this is how we compute the score function and if you look at the nature of this score function you find that as long as this component S i S j minus S y i ispositive, right.
15.srt	00:07:53.949 --> 00:08:25.999	So, this ok. My score function will be equal to 0 only when this term s j minus s y i as long as this term is less than delta .
15.srt	00:08:26.989 --> 00:08:28.719	delta, my output will be 0.
15.srt	00:08:29.329 --> 00:08:46.379	If it is if it is S y i minus S j this is greater than delta, then output will be equal to 0 because my classification is correct otherwise the output will be high.
15.srt	00:08:46.869 --> 00:08:56.439	So, if I plot this score function with respect to S j minus S y i.
15.srt	00:08:56.870 --> 00:09:07.669	the nature of the score function or theplot of the loss function will be something like this and this loss function is what is known as hinge loss .
15.srt	00:09:07.669 --> 00:09:27.049	So, now we have also talked about a term called regularization because you find that we decide about the classification to be correct or not or whether we are satisfied with the classification output or not depending upon the difference S j minus S y i .
15.srt	00:09:28.040 --> 00:09:40.200	And, which is nothing but W j transpose that is W j is the jth row of the weight matrix W that transpose X i minus W y i transpose X i.
15.srt	00:09:41.610 --> 00:09:57.270	And, if you find you find that if I scale up this W by a factor lambda then the score the difference S j minus S y i will also be scaled up by the same factor lambda.
15.srt	00:09:57.350 --> 00:09:58.250	Say for example.
15.srt	00:09:58.670 --> 00:10:13.650	For some w if the difference S j minus S y i is equal to 15 and if I multiply w or scale up w by a factor 2 then the same difference S j minus S y i will be 30.
15.srt	00:10:14.820 --> 00:10:28.250	So, there are many possible values of w for whichthe value ofthe difference of S j minus S y i can be greater than delta right.
15.srt	00:10:29.080 --> 00:10:37.800	So, what I need is I need to find out an optimum W or best value of W which will satisfy all my requirement.
15.srt	00:10:38.220 --> 00:10:52.890	So, as a result I have to include a regularization termwhich is a function of W or the weight matrix and this regularization term is usually taken to be a L 2 norm.
15.srt	00:10:53.260 --> 00:11:04.720	So, for regularization term L 2 R w becomes lambda times W K L square where you take the summation of W K L square over all value of K and L .
15.srt	00:11:05.570 --> 00:11:32.440	And, as a result our overall loss function becomes L is equal to sum of L ithat divided by n where n is the number of training samples we have plus lambda times R w or the overall loss function in the expanded form is given by this .
15.srt	00:11:32.440 --> 00:11:35.270	So, given this overall loss function now what we .
15.srt	00:11:35.670 --> 00:11:41.410	need to do is we need to optimize this loss function or minimize this loss function.
15.srt	00:11:43.570 --> 00:11:50.570	And in addition to that what we need to do do is we have to also choose the hyper parameters.
15.srt	00:11:50.700 --> 00:12:07.100	So, if you look at the previous expression you find that we have got two hyper parameters over here one of the hyper parameter is delta which is the threshold that we have used and other hyper parameter is lambda.
15.srt	00:12:07.920 --> 00:12:09.440	term which is in the regularization term.
15.srt	00:12:10.050 --> 00:12:32.770	So, if you remember this first term in this loss function we told this we defined this as data loss and the last one is what is known as a regularization loss .
15.srt	00:12:32.770 --> 00:12:38.860	So, we have got two hyper parameters over here one is the threshold delta and other one is this lambda .
15.srt	00:12:40.360 --> 00:12:46.530	So, I need to choose that what should be the proper values of these two hyper parameters.
15.srt	00:12:47.550 --> 00:13:06.760	However, if you look carefully you find that both lambda and delta they control the same tradeoff that is if the lambda is more the difference of S j and S y will also be more, if lambda is less the difference of S j and S y i will also be less.
15.srt	00:13:06.980 --> 00:13:09.070	So, accordingly I will have an effect of lambda.
15.srt	00:13:10.140 --> 00:13:15.370	And, due to this we can safely choose the value of lambda is equal to 1.
15.srt	00:13:16.510 --> 00:13:21.590	So, that is what we have done over here the value of lambda is taken to be 1.
15.srt	00:13:22.220 --> 00:13:29.500	And, accordingly when you go for minimization of this loss function the value of lambda will be chosen.
15.srt	00:13:29.810 --> 00:13:37.050	So, we have taken value of delta equal to 1 and while do your minimization accordingly the value of lambda will be chosen.
15.srt	00:13:39.500 --> 00:14:00.940	And, you find that we have talked about the binary support vector machine where we have said that given the separating plane between two classes omega 1 and omega 2 during training I will be satisfied only when we find that W transpose X i for a training vector X i is more than a normalized distance one.
15.srt	00:14:01.580 --> 00:14:11.800	So, accordingly a loss function for a binary SVM can be defined like this it is max of 0 minus y i W transpose X i .
15.srt	00:14:13.020 --> 00:14:26.680	So, you find that as long as this W transpose X i is lose less than 1 that is the normalized distance from W transpose X equal to 0 that is the separating plane is less than 1 your loss function will be positive.
15.srt	00:14:27.300 --> 00:14:30.040	If it is greater than 1 then only loss function will be 0.
15.srt	00:14:30.900 --> 00:14:44.390	And the regularization term in case of two class support vector machine if you remember we had put this as half of W square that was the regularization term in case of the two class support vector machine.
15.srt	00:14:44.810 --> 00:14:56.570	So, you find that this binary SVM or two class support vector machine is nothing, but a special case of a multi class support vector machine right.
15.srt	00:14:56.920 --> 00:15:09.130	So, now let us go for how to see how this loss functionwhat is the nature of this loss function.
15.srt	00:15:10.240 --> 00:15:18.660	So, for illustrating this I consider a three class problem and stress of vectors that I consider is one dimensional vector.
15.srt	00:15:19.410 --> 00:15:29.710	So, suppose I have got a three classes given by the weights W 1, W 2 and W 3 and as I said that I am considering onedimensional vectors.
15.srt	00:15:30.160 --> 00:15:47.020	So, each of this W 1, W 2, W 3 are scalars ok and I also take three one dimensionaltraining points x 1 taken from class 1, x 2 taken from class 2 and x 3 taken from class 3.
15.srt	00:15:49.820 --> 00:16:04.200	So, given this situation, you find that the loss functions thatwe will get is given by L 1 is equal to max of 0 and W 2 transpose X 1.
15.srt	00:16:04.200 --> 00:16:16.140	So, this W 2 transpose X 1 is nothing, but score of class 2 for this training vector X 1 and this is the score of class 1 for training vector X 1.
15.srt	00:16:17.730 --> 00:16:25.230	So, the loss function L 1 will be max of 0 W 2 transpose X 1 minus W 1 transpose X 1 plus 1 .
15.srt	00:16:26.010 --> 00:16:30.420	plus max of 0 and W 3 transpose X 1.
15.srt	00:16:30.420 --> 00:16:39.770	So, this W 3 transpose X 1 is the score of class 3 for training vector X 1 minus W 1 transpose X 1 plus 1.
15.srt	00:16:40.270 --> 00:16:55.050	Similarly, we define loss functionfor class 2 L 2 for the support vector 2, we also define the loss function L 3 for support for the training vector.
15.srt	00:16:55.710 --> 00:17:07.210	x 3 and the overall loss is given by one third of L 1 plus L 2 plus L 3 .
15.srt	00:17:07.210 --> 00:17:16.340	So, given this now if we try to visualize how this loss function is.
15.srt	00:17:16.340 --> 00:17:31.860	So, here you find that in case of L 1 if W 1 is very small if this weight vector W 1 is very small then W 2 transpose X 1 minus W 1 transpose X 1 .
15.srt	00:17:32.000 --> 00:17:42.740	1, this term will be positive assuming that W 1 transpose X 1 is less than W 2 transpose X 1.
15.srt	00:17:42.990 --> 00:17:47.800	So, output loss function will be positive which is max of 0 and this.
15.srt	00:17:48.790 --> 00:17:59.610	And this particular term will be 0 only when W 1 transpose X 1 is more than W 2 transpose X 1 at least by W 1.
15.srt	00:18:05.420 --> 00:18:07.910	That means, as long as W 1 is very small your loss function given by this value of loss is positive.
15.srt	00:18:08.370 --> 00:18:15.510	Similarly, in this case as long as w 1 is less than w 3 here also it will be positive.
15.srt	00:18:16.290 --> 00:18:28.470	However, as w 1 goes on increasing the loss function gradually reduces and ultimately it becomes 0 and remains 0 for this component L 1.
15.srt	00:18:30.290 --> 00:18:35.430	Similarly, for component L 2 you find that when w 1 is.
15.srt	00:18:37.400 --> 00:18:39.280	very small compared to this.
15.srt	00:18:39.280 --> 00:18:47.850	So, that this term becomes negative the output will be 0 and as W 1 goes on increasing eventually this term becomes positive.
15.srt	00:18:48.070 --> 00:18:56.970	So, output L 1 will also become positive and it will have a certain value it is not 0 and same is for L 3 .
15.srt	00:18:56.970 --> 00:19:06.360	So, by this understanding having this understanding now we can try to plot the different loss functions L 1, L 2 and L 3.
15.srt	00:19:06.390 --> 00:19:07.780	So, if I plot L 1.
15.srt	00:19:07.970 --> 00:19:20.790	with W 1 you find that as we said that when W 1 is very small the loss component L 1 is positive and is it goes on reducing as value of W 1 increases.
15.srt	00:19:21.850 --> 00:19:44.400	Similarly the other component L 2 initially it remains 0 with respect to W 1 initially it remains 0 and when W 1 becomes very high in the sense that W 1 x 1 becomes more than W 2 x 2 by a factor 1 by the threshold 1 then the loss function becomes positive and it is like this .
15.srt	00:19:45.079 --> 00:19:58.710	And, same is the case with component L 3 and my overall loss function is average of all these three components L 1, L 2 and L 3 and the overall loss function is given by this.
15.srt	00:20:00.119 --> 00:20:10.660	So, by looking at this figure on the right which gives you the overall loss function you find that the loss function is convex right.
15.srt	00:20:11.269 --> 00:20:14.440	So, this can be solved using convex optimization problems.
15.srt	00:20:14.660 --> 00:20:17.809	because the loss function that you get is convex.
15.srt	00:20:18.240 --> 00:20:29.759	Now, here the situation is very simple we can visualize it very easily because I am considering W 1 to be a scalar or a one dimensional vector.
15.srt	00:20:31.349 --> 00:20:35.089	Now, what happens in case of multiple dimensions?
15.srt	00:20:35.319 --> 00:20:48.440	Usually our weight vectors orthe samples sample vectors they are of very very large dimension maybe of the order of thousands.
15.srt	00:20:49.150 --> 00:20:53.630	So, the visualization of the loss function in such cases is very very difficult.
15.srt	00:20:54.049 --> 00:20:57.150	However, we can try to visualize thatsection wise.
15.srt	00:20:57.279 --> 00:21:05.730	So, what I do is now I know that my loss function is defined in a high dimensional space.
15.srt	00:21:06.450 --> 00:21:18.529	So, I can take a single point in that high dimensional space at random which is a W and I take a direction W 1 which is also at random.
15.srt	00:21:19.039 --> 00:21:54.079	So, this w 1 I take as a direction passing through the selected selected point w. And as we move along the direction of w 1 you go on recording the loss function or effectively what you do isevery point in the direction of w 1 passing through w is represented by this expression w plus a times w 1 where a indicates that what is the position of the point on the line w 1 passing through w.
15.srt	00:21:55.489 --> 00:22:08.649	And, we are taking the loss function L at those different points by varying a I get different points and you take the loss function W at all those different points.
15.srt	00:22:09.669 --> 00:22:24.049	So, what I can do is I can now plot the loss function loss as a function of a or as a varies I get different points on the line and now if I record the loss functions I get a loss function which is of this form.
15.srt	00:22:24.899 --> 00:22:39.969	which is L w plus A w 1, A is the parameter which defines which determines the points on line w 1 in the direction of w 1 passing through w and you find that the loss function which will which will be of this form.
15.srt	00:22:41.069 --> 00:22:45.479	I can also try to define loss function on a plane if I take the section on a plane.
15.srt	00:22:46.039 --> 00:22:55.609	So, in that case what I have to do is instead of taking just w 1 a single line I have to take w 1 and w 2 as two different lines.
15.srt	00:22:55.849 --> 00:23:13.619	ok. And by giving that every point on that plane defined by these two directions W 1 and W 2 now can be determined by this expression W plus a times W 1 plus b times W 2.
15.srt	00:23:26.459 --> 00:23:27.339	And again if I record the loss value for different values of a and b which are the parameters in this particular case I get a loss function which is given in this form.
15.srt	00:23:27.649 --> 00:23:32.179	So, this is the plot of the loss function in 2 dimension .
15.srt	00:23:32.179 --> 00:23:56.369	So, in both the cases whether I take the previous one like this where you find that again the loss function is a convex function it has a minimum somewhere over here or I take the next one that is visualization of the loss function in a plane you find that here again the loss function is a convex one.
15.srt	00:23:57.369 --> 00:24:08.269	where the blue that is in this particular case at the center here it is minimum and the red represents maximum loss function.
15.srt	00:24:08.599 --> 00:24:11.649	So, I have the minimum of loss over here.
15.srt	00:24:12.279 --> 00:24:17.589	So, the loss function in in two dimension again shows that it is a complex one.
15.srt	00:24:19.209 --> 00:24:26.529	And this is the plot that I get if I consider or if I plot the loss function only for a single sample or a single vector.
15.srt	00:24:27.259 --> 00:24:27.819	vector.
15.srt	00:24:28.649 --> 00:24:35.259	And when I average this over multiple number of training vectors the loss function becomes something like this.
15.srt	00:24:35.259 --> 00:24:43.959	So, you find that this averagingover all the training samples smooths the nature of the loss function.
15.srt	00:24:45.849 --> 00:24:55.989	So, once I have this loss function next what I need to do is I have to optimize this loss function or I have to minimize the loss function.
15.srt	00:24:58.969 --> 00:25:03.049	So, for minimization gradient as we have done earlier we take the gradient descent approach.
15.srt	00:25:03.339 --> 00:25:14.599	So, I have to take the gradient of the loss function that I have and a modify w in the direction of the negative gradient.
15.srt	00:25:14.679 --> 00:25:31.219	So, here what I have is as we have already said that the overall loss function is given by this where this is the data loss component and this is the regularization loss component .
15.srt	00:25:31.699 --> 00:25:40.459	If I take So, I have to optimize this loss function in order to find out the value of w for which this loss function will be minimum.
15.srt	00:25:41.969 --> 00:25:52.579	So, I take the gradient of this loss function with respect to w y i, I also take the gradient of this loss function with respect to w j.
15.srt	00:25:53.499 --> 00:26:02.569	So, when you take the gradient of this loss function with respect to w y i, you find that the expression of the gradient will be.
15.srt	00:26:03.019 --> 00:26:28.359	that it is sum of x i that is gradient of loss function with respect to w y i is nothing, but sum of x i only in those cases where w j transpose x i minus w y i transpose x i plus delta is greater than 0.
15.srt	00:26:31.289 --> 00:26:40.629	And because in all the cases where w transpose j transpose x i minus w y i transpose x i plus delta is less than 0.
15.srt	00:26:41.279 --> 00:26:43.229	the loss function was 0.
15.srt	00:26:44.549 --> 00:27:12.529	So, for those cases those x i's are correctly classified by or w. So, in such cases I need not modifythe weight matrix w. So, this gradient only takes the sum of all those x i all those training vector for which w j transpose x i minus w y i transpose x i plus delta is greater than 0.
15.srt	00:27:12.529 --> 00:27:15.999	That means these are the that x i leads to an error.
15.srt	00:27:17.189 --> 00:27:24.929	plus if you take the gradient of this term this gradient will be actually twice lambda timesW y i.
15.srt	00:27:24.929 --> 00:27:33.199	So, in this case it is written with respect to anotherconstants eta eta times W y i.
15.srt	00:27:34.719 --> 00:27:50.769	In the same manner if you take the gradient with respect to W j then it also becomes sum of y i where W j transpose x i minus W y i transpose x i plus delta is greater than 0 .
15.srt	00:27:51.169 --> 00:28:02.169	So, we will take the sum of only those training vectors for which this condition is true, we will not consider those training vectors for which this condition is not true.
15.srt	00:28:02.369 --> 00:28:22.149	That means, those training vectors are correctly classified for the by the current W. And plus from this regularization term when you take the derivative of this regularization term with respect to W j or takethe gradient of this regularization term with respect to W j.
15.srt	00:28:23.009 --> 00:28:28.619	the term that I get is zeta times W j .
15.srt	00:28:28.619 --> 00:28:56.309	So, these are the gradients and using these gradients we go forour optimization step or gradient descent step where we get the gradient descent as at the kth instant if my weight vector was W y i k then the nextiterated value of W y i is becomes W y i k plus 1.
15.srt	00:28:56.679 --> 00:29:07.769	which is 1 minus zeta times w y i k plus 1 over n sum of x i for all those x i which satisfies this condition.
15.srt	00:29:27.989 --> 00:29:34.239	Similarly, the iterated value of w j at instant k plus 1 from instant k from the iterative state k is given by w j k plus 1 is equal to 1 minus zeta times w j k minus 1 over n sum of all those x i for which this condition is satisfied.
15.srt	00:29:35.199 --> 00:29:51.849	So, we will we will not consider those sample vectors which does not satisfy this condition because we assume that those vectors are correctly classified by the W j at the kth instant ok.
15.srt	00:29:52.619 --> 00:30:01.269	So, if you look at these two gradient descent steps you find that what it indicates is first you are modifying.
15.srt	00:30:02.849 --> 00:30:10.749	W y i which was there at the kth instant by the regularization term.
15.srt	00:30:11.019 --> 00:30:24.669	So, this is a component which is coming from your the regularization error part or regularization loss part and this is the component which comes from your data loss part.
15.srt	00:30:24.669 --> 00:30:31.219	So, that is how iteratively you go on optimizing or minimizingthis loss function and.
15.srt	00:30:31.729 --> 00:30:40.719	when it converges the value of weight matrix that you get gives you the linear machine or the support vector machine for multiple classes.
15.srt	00:30:41.699 --> 00:30:46.119	So, we will stop heretodays lecture we will come back in the next day.
15.srt	00:30:46.369 --> 00:30:46.699	Thank you.
11.srt	00:00:00.610 --> 00:00:30.039	Hello, welcome to the NPTEL online certification course on deep learning.
11.srt	00:00:32.570 --> 00:00:45.799	In our previous lecture, we had talked about linear discriminator and we had also talked about the perceptron algorithm in which a linear using which a linear discriminator can be designed.
11.srt	00:00:46.950 --> 00:00:50.730	Today we are going to discuss about the support vector machine.
11.srt	00:00:51.890 --> 00:01:00.530	And if you remember that the classes that we have considered in the previous day are actually two classes.
11.srt	00:01:00.560 --> 00:01:03.420	So, we wanted to have a linear discriminator.
11.srt	00:01:04.049 --> 00:01:08.459	which discriminates the vectors belonging to two different classes.
11.srt	00:01:09.450 --> 00:01:20.390	And when we talk about support vector machine, we will continue with two classes initially, but later on we will move to multi class classification problems.
11.srt	00:01:21.459 --> 00:01:31.129	So, before we go for support vector machine, I will just quickly recapitulate what we have done in the previous class in the linear discriminator.
11.srt	00:01:33.899 --> 00:01:40.659	So, we what we had done in the previous class is we have taken two sets of feature vectors.
11.srt	00:01:41.219 --> 00:01:52.750	So, this is a set of feature vector which belong to class omega 1 and we have taken another class another set of feature vectors from class omega 2.
11.srt	00:01:54.739 --> 00:02:08.389	And then what we tried to see is we assumed that these two classes these two sets of feature vectors are linearly separable and assuming linear separability we have tried to find out.
11.srt	00:02:08.750 --> 00:02:16.009	a linear boundary or a hyper plane which separates these two classes of each of vectors.
11.srt	00:02:17.129 --> 00:02:39.520	So, you find that an equation of such a linear boundary will be given by this a transpose x plus b equal to 0, where you find that this vector a is a vector which is orthogonal or normal to the separating plane.
11.srt	00:02:41.349 --> 00:03:08.740	So, the vector a will be So, this will be the direction of vector a and as we have assumedthe existence of a separating boundary which is linear, we know from ourschool level mathematics that such a linear boundary divides the feature space into two half spaces, one of the half space is positive half space, the other half space is negative half space.
11.srt	00:03:09.439 --> 00:03:11.469	So, for any feature vector x.
11.srt	00:03:12.030 --> 00:03:19.389	which belongs to positive half space, I must have a transpose x plus b which is greater than 0.
11.srt	00:03:20.240 --> 00:03:30.150	And for every feature vector lying on this plane, so if I take a feature vector lying on this plane for this feature vector a transpose x plus b will be equal to 0.
11.srt	00:03:31.599 --> 00:03:47.099	So, as we have taken a number of feature vectors from the two classes omega 1 and omega 2, if I take any vector x from the class omega 1, so this is the set of vectors belonging to class omega 1.
11.srt	00:03:47.989 --> 00:04:05.969	And, this surface this being the linear boundary having equation A transpose X plus b equal to 0 for every X belonging to class omega 1 which are my training vectors this condition must be satisfied that A transpose X plus b have to be greater than 0.
11.srt	00:04:07.370 --> 00:04:17.909	In the same manner if I take a feature vector X from class omega 2 where this feature vector X falls on the negative side of the linear boundary.
11.srt	00:04:18.409 --> 00:04:23.659	this condition that A transpose A x plus B less than 0 must be satisfied.
11.srt	00:04:25.439 --> 00:04:37.849	So, for this surface for this linear boundary which satisfies this equation A transpose B equal to 0 as we have said that the vector A is orthogonal to the surface.
11.srt	00:04:38.599 --> 00:04:54.439	So, if I modify vector A that means, the orientation of this linear boundary will change and the value of B which is nothing, but a bias it decides the position of this separating plane in the feature space.
11.srt	00:04:56.120 --> 00:04:59.060	So, A gives you the orientation and b gives you the position.
11.srt	00:05:00.389 --> 00:05:16.269	Now, given this I can also represent this equation a transpose b a transpose x plus b equal to 0 in an unified form a transpose x equal to 0.
11.srt	00:05:17.469 --> 00:05:25.939	And for writing this equation a transpose x plus b equal to 0 in the form a transpose x equal to 0 I have to do certain modifications.
11.srt	00:05:26.600 --> 00:05:28.189	So, what are those modifications?
11.srt	00:05:29.079 --> 00:05:54.420	I have to modify a like this that now this modified a contains all the previous components a 1 to a d of my initial feature vector a, initial solution vector a and this bias term b is also now included in the same vector a in this modified vector a.
11.srt	00:05:54.420 --> 00:05:55.959	And in order to do this .
11.srt	00:05:56.279 --> 00:06:06.620	the feature vector x has to be modified as all the components of x that is x 1 to x d are remaining as it is.
11.srt	00:06:07.029 --> 00:06:13.000	Now, what I have to do is I have to append an additional component to x which becomes 1.
11.srt	00:06:14.230 --> 00:06:22.149	So, with this modification your a transpose x plus b equal to 0 now gets modified to a transpose x equal to 0.
11.srt	00:06:22.250 --> 00:06:27.860	So, the my bias term b is included in the solution vector a .
11.srt	00:06:29.629 --> 00:06:39.509	So, you find that the implication of this equation is now this separating plane always passes through the origin in my d plus 1 dimensional space.
11.srt	00:06:39.799 --> 00:06:59.009	In the earlier case depending upon the value of bthe separating plane might have been anywhere within my feature space, but in this modified form as I am increasing the dimension of the feature vector by 1 in this modified feature space the separating plane always passes through the origin.
11.srt	00:07:00.479 --> 00:07:19.089	So, given this my situation will now be of this form the classification will rule now will remain that for every x sorry this should be x for every x belonging to class omega 1 I must have a transpose x greater than 0.
11.srt	00:07:19.249 --> 00:07:20.849	So, this y have to be x right.
11.srt	00:07:23.439 --> 00:07:31.709	For every feature vector x in this modified form taken from class omega 1 I must have a transpose x greater than 0.
11.srt	00:07:32.169 --> 00:07:37.119	and if it is taken from class omega 2, I must have a transpose x less than 0.
11.srt	00:07:37.869 --> 00:07:40.949	So, for correct classification the classification rule remains the same.
11.srt	00:07:42.449 --> 00:08:00.419	And I can do another modification that is so, what does it mean is this that coming over here you find that as one of the components of the feature vector x I have made equal to 1.
11.srt	00:08:01.229 --> 00:08:05.499	So, in the modified form the feature vectors will appear like this .
11.srt	00:08:06.309 --> 00:08:12.169	So, if this is the x 1 component and this is the x 2 component, x 2 component has been made equal to 1.
11.srt	00:08:12.489 --> 00:08:35.490	So, this will be the arrangement of feature vectors in this case and a being the orthogonal to my separating plane, these vectors which belong to class omega 1 appear in the positive half space of the of the separating plane and these vectors which belong to class omega 2 appear in the negative half space in my feature space.
11.srt	00:08:37.589 --> 00:08:45.339	I give another modification that is all the feature vectors which come from plus omega 2 I negate them.
11.srt	00:08:45.659 --> 00:08:51.609	That means, a feature vector x if it is taken from class omega 2 I make it minus x.
11.srt	00:08:52.479 --> 00:08:53.439	What is the advantage?
11.srt	00:08:53.879 --> 00:09:06.669	By negating all the feature vectors coming from omega 2 negating and negating them my classification rule becomessame irrespective of whether x is taken from class omega 1 or x is taken from class omega 2 .
11.srt	00:09:06.799 --> 00:09:12.759	0, because in every case my classification rule becomes a transpose X greater than 0.
11.srt	00:09:13.889 --> 00:09:39.789	And if I find that given a solution vector a for any X irrespective of whether this X belongs to class omega 1 or X belongs to class omega 2, if I find that for any such X a transpose X is less than 0, immediately I can say that this solution vector a misclassifies the corresponding X.
11.srt	00:09:41.189 --> 00:09:50.970	And, whenever there is a misclassification I must try to update a such that the modified a or update a will correctly classify x.
11.srt	00:09:51.840 --> 00:09:53.179	Let us see how we can do it.
11.srt	00:09:54.169 --> 00:09:56.490	So, my situation is something like this.
11.srt	00:09:56.490 --> 00:10:12.210	Now, that in the previous case you find that all these feature vectors belonging to omega 2 they were on the negative side ofthe separating plane.
11.srt	00:10:13.059 --> 00:10:37.919	Now, after negation the negated feature vectors belonging to class omega 2 now comes over here and you find that after negation all the feature vectors the negated feature vectors belonging to class omega 2 and also the original feature vectors belonging to class omega 1 all of them fall on the positive side of the separating plane.
11.srt	00:10:39.259 --> 00:10:42.539	Now you find that I can observe one more thing.
11.srt	00:10:43.609 --> 00:10:48.779	plane, that is what is the limit of the separating plane or what is the limit of the solution vector a.
11.srt	00:10:49.749 --> 00:11:00.089	So, you find that if I rotate the separating plane in the anti-clockwise direction, then the limit to which I can rotate this is given by this.
11.srt	00:11:00.089 --> 00:11:08.269	Because if I rotate it further in the anti-clockwise direction, then this feature vector belonging to class omega 1 is going to be misclassified.
11.srt	00:11:08.269 --> 00:11:17.799	In the same manner, if I rotate it in the clockwise direction, then this is the limit that I can have.
11.srt	00:11:18.719 --> 00:11:26.679	because, if I rotate it further in the clockwise direction then this feature vector belonging to class omega 2 that is going to be misclassified.
11.srt	00:11:27.639 --> 00:11:34.359	So, these two this one this position and this position gives me limit of the separating plane.
11.srt	00:11:35.519 --> 00:11:43.429	And as I have limit on the separating plane in the same manner I can have limits on the correspondingsolution vectors.
11.srt	00:11:51.179 --> 00:11:56.959	So, you find that as this position is the limit of plane, the corresponding limit on the solution vector is this which is orthogonal to the separating plane.
11.srt	00:11:57.739 --> 00:12:02.859	Similarly, here the corresponding limit on the orthogonal or the solution vector is this.
11.srt	00:12:03.709 --> 00:12:15.689	So, it clearly says that I must have an a which correctly classifies all the training vectors must be within this region which is my solution region.
11.srt	00:12:17.219 --> 00:12:26.049	So, the approach for designing a linear classifier should be such that I must get a solution vector lying within this solution region.
11.srt	00:12:27.649 --> 00:12:45.169	So, in order to do this what we can do is for every x which is misclassified as I know that for every x which is misclassified by a I should have this condition that a transpose a x less than 0.
11.srt	00:12:45.569 --> 00:12:55.979	You remember that all these x's that we are talking about all these feature vectors x that we are talking about these are all training vectors that means, for all the vectors I know to which class they belong.
11.srt	00:12:58.569 --> 00:13:13.089	So, as we have said so far that given any a if I find that a transpose x becomes less than 0 that means, that a misclassifies that x and this misclassification leads to an error.
11.srt	00:13:13.389 --> 00:13:22.189	So, I can have an error measured for this misclassified sample which I will put as minus a transpose x.
11.srt	00:13:22.989 --> 00:13:34.089	So, as a transpose x is less than 0, so minus a transpose x is positive that means, if I have a misclassified sample that leads to a positive error.
11.srt	00:13:34.889 --> 00:13:40.209	So, whenever a correctly classifies all the samples then this error will be equal to 0.
11.srt	00:13:41.179 --> 00:13:51.339	So, what I do is for given a you identify all the feature vectors which are misclassified that means, all the feature vectors for which a transpose x becomes negative.
11.srt	00:13:51.979 --> 00:13:58.339	And then you define an error function which is called the perceptron criteria function.
11.srt	00:13:58.339 --> 00:14:04.719	So, I write this as J P a which is a function of now the solution vector a.
11.srt	00:14:05.169 --> 00:14:14.859	which is assum of minus a transpose x and this summation has to be taken over all x which are misclassified.
11.srt	00:14:16.259 --> 00:14:28.259	And once I have this error measured, then I can modify a following gradient descent algorithm, we will discuss more about gradient descent algorithm later.
11.srt	00:14:35.329 --> 00:14:38.019	So, this gradient descent algorithm says that I have toshift a in the direction of the negative gradient.
11.srt	00:14:38.649 --> 00:14:53.769	So, for updation of a I have this updation rule that a gets a minus gradient of J p a and this gradient is scaled by a scale factor eta which is known as rate of convergence.
11.srt	00:14:54.179 --> 00:14:59.219	So, this will be my weight updation rule using gradient descent procedure.
11.srt	00:15:00.219 --> 00:15:06.079	So, in this particular case where I have this perceptron criteria function J p a.
11.srt	00:15:06.609 --> 00:15:20.349	given by minus a transpose x for sum of that for all x which are misclassified .
11.srt	00:15:20.489 --> 00:15:36.579	So, using thiserror function the gradient descent procedure now becomes if you take the gradient of JPA the gradient of JPA becomes minus sum of x .
11.srt	00:15:36.799 --> 00:15:38.829	for all x which are misclassified.
11.srt	00:15:40.089 --> 00:15:58.209	And accordingly my training or learning algorithm will be like this that initially you choose weight vector a 0 at random and then I will go on updating this weight vector a iteratively.
11.srt	00:15:58.539 --> 00:16:10.729	So, in any kth iteration if a k is the weight vector using this a k you try to identify all the feature vector x which are misclassified.
11.srt	00:16:11.309 --> 00:16:31.669	And, once you identify all such feature vectors which are misclassified, then for the next iteration or the next updated weight vector a k plus 1, I can get it from a k by modifying a k as a k plus 1 gets a k plus eta times sum of x for all x which are misclassified.
11.srt	00:16:32.359 --> 00:16:33.749	So, this is my weight updation rule.
11.srt	00:16:34.669 --> 00:16:37.229	Let us say with diagram what does it mean?
11.srt	00:16:38.669 --> 00:16:45.079	So, as we have seen before that given these two sets of vectors belonging to class omega 1 and omega 2.
11.srt	00:16:45.749 --> 00:16:52.659	I have the region solution region which is this.
11.srt	00:16:54.099 --> 00:16:58.149	So, that means, any solution vector must lie within this region.
11.srt	00:16:59.179 --> 00:17:07.199	So, what I do is initially let us assume that we have a separating plane which is given as this.
11.srt	00:17:07.859 --> 00:17:16.139	And here you find that this separating plane misclassifies these two samples which belong to class omega 1.
11.srt	00:17:17.199 --> 00:17:23.229	And, the weight vector a is this which is obviously, outside the solution region.
11.srt	00:17:24.589 --> 00:17:31.889	So, I have to update this vector a by adding to it the sum of these two misclassified vectors.
11.srt	00:17:32.459 --> 00:17:37.609	And when you add the sum of these two misclassified vectors is obviously, in this direction.
11.srt	00:17:37.829 --> 00:17:39.829	So, a has to be moved in this direction.
11.srt	00:17:40.469 --> 00:17:48.759	And if I have sufficient eta eta isproper, then possibly we will stop within this solution region and I get the solution.
11.srt	00:17:49.349 --> 00:17:57.209	But, if eta is large then we will cross the solution region and we will move somewhere over here .
11.srt	00:17:57.279 --> 00:18:11.609	So, here in this case after adding modifying this A using some of these two misclassified samples suppose the next separating plane comes out to be this.
11.srt	00:18:11.639 --> 00:18:20.519	And, again this separating plane as you see misclassifies these two samples and the corresponding solution vector A 1 is over here .
11.srt	00:18:21.569 --> 00:18:27.579	So, again to a 1 you add some add some of these two vectors and some of these two vectors is in this direction.
11.srt	00:18:27.929 --> 00:18:30.219	So, a 1 has to be moved in this direction.
11.srt	00:18:31.679 --> 00:18:53.129	So, at the next level my separating plane will be somewhere like this by updating a 1 and now you find that I have a vector which falls within the solution region and this is my a 2.
11.srt	00:18:54.099 --> 00:19:03.749	And, as it falls within the solution region at and it correctly classifies all the samples whether it belongs to class omega 1 or belongs to class omega 2.
11.srt	00:19:03.979 --> 00:19:06.949	So, I am satisfied with this solution vector.
11.srt	00:19:09.469 --> 00:19:14.669	So, this is the approach for designing a linear classifier.
11.srt	00:19:16.409 --> 00:19:20.859	Now, as we have seen that as the solution region is this.
11.srt	00:19:21.349 --> 00:19:25.199	So, any vector within this region should satisfy my purpose.
11.srt	00:19:26.649 --> 00:19:33.779	But, if the solution vector comes very close to this solution boundary possibly that is not a good solution because it is prone to error.
11.srt	00:19:34.449 --> 00:19:43.409	So, I would like to have a vector which is well within this solution region so that the classification my classifier becomes very very robust.
11.srt	00:19:44.299 --> 00:19:45.559	So, let us see how we can do it.
11.srt	00:19:55.299 --> 00:20:14.329	So, what I mean by this is say given all these different are vectors coming from two different classes and earlier as we said earlier that my solution classification rule is A transpose A x plus b b greater than 0 if x belongs to class omega 1 and A transpose A x plus b is less than 0 if x belongs to class omega 2.
11.srt	00:20:15.259 --> 00:20:22.199	And this is one such separating plane which satisfies this criteria, but is it unique?
11.srt	00:20:23.059 --> 00:20:23.799	Obviously, not.
11.srt	00:20:24.909 --> 00:20:25.329	Let us see.
11.srt	00:20:26.589 --> 00:20:31.139	So, this is one such separating plane that we have seen which satisfies this region.
11.srt	00:20:31.879 --> 00:20:38.379	I can have another separating plane which is given by this blue line that also satisfies this criteria.
11.srt	00:20:39.149 --> 00:20:45.129	This is a separating plane which also satisfies this criteria, this is a separating plane which also satisfies this criteria.
11.srt	00:20:45.889 --> 00:20:49.559	So, I have infinite number of such possibilities.
11.srt	00:20:50.469 --> 00:20:56.899	So, I have to identify that out of all these different possibilities which one is .
11.srt	00:20:57.179 --> 00:21:02.819	should be the preferred solution and that is where the support vector machine comes into picture.
11.srt	00:21:04.479 --> 00:21:09.549	So, to illustrate this let us take a very simple case.
11.srt	00:21:11.539 --> 00:21:28.459	So, the case is like this I assume that these are the vectors which belong to class omega 1 and these are two vectors which belong to class omega 2 and I have a separating plane which separates in these two classes.
11.srt	00:21:29.509 --> 00:21:54.319	And, now as I have shown previously that for any x belonging to class omega 1, my correct classification criteria is a transpose x plus b greater than 0 and for x belonging to class omega 2, I had a transpose x plus b less than 0.
11.srt	00:21:56.049 --> 00:21:57.329	Now, I can take another strategy.
11.srt	00:21:58.679 --> 00:21:59.469	Let us assume.
11.srt	00:22:00.019 --> 00:22:08.939	that every training vector is given as a pair that means, along with the training vector we also have its class level right.
11.srt	00:22:09.639 --> 00:22:25.949	So, I can put it this way that a training vector x i is given as a pair x i y i where this y i indicates that what is the class or to which class x i belongs.
11.srt	00:22:29.499 --> 00:22:51.169	So, I will put y i 1 as plus 1 if x i belongs to omega 1 and y i will be is equal to minus 1 if x i belongs to omega 2 .
11.srt	00:23:31.339 --> 00:23:38.259	So, if I assume this then you find that both of these conditions that a transpose x i plus b greater than 0 for x i taken from class omega 1 and a transpose x i plus b less than 0 for x i taken from class omega 2, both of them can be written in asingle form that is y i times a transpose x i plus b it has to be greater than 0.
11.srt	00:23:39.689 --> 00:23:41.909	So, this becomes my unified representation.
11.srt	00:23:42.929 --> 00:24:04.519	And if you compare this with what we discussed previously that we negated all x and had an unified representation all x taken from class omega 2 and had an unified representation or unified classification rule of a transpose x greater than 0 for correct classification which is .
11.srt	00:24:05.089 --> 00:24:06.479	exactly same as this.
11.srt	00:24:06.579 --> 00:24:24.779	It is just another way of representation that you multiply by y i a transpose x i plus b, where y i is plus 1 if x i is taken from class omega 1 and y i is minus 1 if x i is taken from class omega 2.
11.srt	00:24:25.679 --> 00:24:33.759	And by doing that I get an uniform classification rule that y transpose y i into a transpose x.
11.srt	00:24:34.769 --> 00:24:49.349	plus b will be greater than 0 whenever X i is correctly classified by this vector a and the offset of the bias term b ok.
11.srt	00:24:50.919 --> 00:25:04.369	So, now as we have seen previously that I can have different options of the separating plane and what I have to do is I have to choose out of all those options which is the correct option.
11.srt	00:25:09.319 --> 00:25:13.159	So, if I take this particular separating then you find that my margin is given by this.
11.srt	00:25:14.309 --> 00:25:35.899	You remember one more thing that when I take a transpose x plus b for any feature vector x this is an indication of what is the distance of the feature vector x from the separating plane a transpose x plus b equal to 0.
11.srt	00:25:37.559 --> 00:25:41.599	So, given over here given in this equation if this is my separating plane.
11.srt	00:25:42.029 --> 00:25:58.309	my confidence of correctly classifying a feature vector x which is lying over here is more than my confidence of correctly classifying a feature vector over here or correctly classifying a feature vector over here.
11.srt	00:26:00.529 --> 00:26:02.689	And, what is this A transpose x plus b?
11.srt	00:26:03.359 --> 00:26:12.529	A transpose x plus b as I said it is the distance of vector x from the separating plane A transpose x plus b equal to 0 or in other words.
11.srt	00:26:12.959 --> 00:26:23.279	a transpose x plus b upon mod of a this is the distance of x from the separating plane.
11.srt	00:26:24.309 --> 00:26:31.649	So, more the distance more is my confidence that I have correctly classified this sample x.
11.srt	00:26:33.309 --> 00:26:43.449	Now, going by this if I take the featurethe separating plane to be this I find that my margin is classification is given by this much .
11.srt	00:26:46.189 --> 00:26:57.659	That means, this feature vector the confidence level of this feature vector being classified correctly is this and the confidence level of this feature vector being correctly classified is given by this.
11.srt	00:26:59.419 --> 00:27:10.689	On the other hand if I take some other orientation of the separating plane say this, now the margin or my confidence level in classification is this much.
11.srt	00:27:11.859 --> 00:27:14.019	Let us take another say this one.
11.srt	00:27:15.199 --> 00:27:16.179	the margin is this.
11.srt	00:27:17.039 --> 00:27:24.519	So, you find that for every orientation of the separating plane I have different margins.
11.srt	00:27:46.749 --> 00:28:02.769	So, if my classifier is proper or the separating plane is proper or it is robust, then I must take that particular separating plane which tries to maximize the margin or in other words the separating plane which I use for classification of or the classification of the feature vector belonging to two different classes, this separating plane must be at a maximum distance from all the feature vectors belonging to belonging to two different classes.
11.srt	00:28:03.459 --> 00:28:16.779	That is this separating plane the distance of this separating plane from the feature vectors belonging to class omega 1 and the distance of the separating plane from the feature vectors belonging to class omega 2 .
11.srt	00:28:17.449 --> 00:28:20.109	From both sides this should be maximized.
11.srt	00:28:22.109 --> 00:28:33.349	So, this is just the introduction of support vector machine and the machine which gives such aseparating plane is nothing, but a support vector machine.
11.srt	00:28:34.529 --> 00:28:47.699	So, we stop the today's lecture over here and in the next lecture we will come across that what should be my strategy for designing such a support vector machine.
11.srt	00:28:48.299 --> 00:28:48.589	Thank you.
10.srt	00:00:00.160 --> 00:00:27.850	Hello, welcome to the NPTEL online certification course on Deep Learning.
10.srt	00:00:31.250 --> 00:00:39.039	In our previous class, we have talked aboutwe have recapitulated the discriminant function and the decision boundary.
10.srt	00:00:40.019 --> 00:00:51.090	We have talked about the nearest neighbor and K n n or K nearest neighbor classifier and we had started our discussion on linear classifier.
10.srt	00:00:52.200 --> 00:01:01.030	So, today let us continue our discussion on linear classifier and then we will move on to support vector machine.
10.srt	00:01:03.230 --> 00:01:31.740	So, you see here that the linear classifier that we are discussing over here is for a two class problem that is we have samples belonging to two different classes say omega 1 and omega 2 and I assume that the samples are linearly separable and in which case given these two training samples from classes omega 1 and omega 2, I can separate these samples using a linear boundary.
10.srt	00:01:32.049 --> 00:01:43.359	y is equal to 0, where this a is a d d plus 1 dimensional Fisher vector, y is also a d plus 1 dimensional Fisher vector.
10.srt	00:01:43.479 --> 00:02:04.729	So, as we have said in our previous lecture that this a includes the vector which is perpendicular to the plane separating the feature vectors belonging to two classes and also the bias term.
10.srt	00:02:05.939 --> 00:02:24.109	And, y is obtained asappending 1 to the feature vectors of dimension d. So, that is how we get d plus 1 dimensional vector for a and also d plus 1 dimensional vector representing y that is the feature vectors.
10.srt	00:02:24.990 --> 00:02:37.669	And, we have also assumed that for all the feature vectors taken from class omega 1 y remains as it is whereas, for all the feature vectors which we taken from class omega 2 y is negated.
10.srt	00:02:37.699 --> 00:02:39.919	it, this is for the design purpose.
10.srt	00:02:40.829 --> 00:02:41.739	Why we have done it?
10.srt	00:02:42.149 --> 00:03:02.629	Because while designing the separator A transpose y equal to 0 for correct or incorrect classification I have an uniform decision rule that I should have always A transpose y greater than 0 if attaining vector y is correctly classified.
10.srt	00:03:08.359 --> 00:03:14.479	So, our original classification rule was if y is taken from class class omega 1 that then a transpose y will be greater than 0.
10.srt	00:03:14.969 --> 00:03:19.179	If y is taken from class omega 2 then a transpose y should be less than 0.
10.srt	00:03:19.609 --> 00:03:24.929	So, what we have done is we have simply negated y for all the samples taken from class omega 2.
10.srt	00:03:25.310 --> 00:03:34.679	So, for after negation whether the same samples are taken from class omega 1 or class omega 2 I should always have a transpose y greater than 0.
10.srt	00:03:35.039 --> 00:03:40.060	So, this is simply for the convenience of designing the decision boundary.
10.srt	00:03:41.810 --> 00:03:52.799	So, given this now let us see that we have seen that as we have our decision boundary given by a transpose y is equal to 0.
10.srt	00:03:53.560 --> 00:04:02.799	That means, the vector a is orthogonal to the plane separating the two feature vectors right .
10.srt	00:04:02.799 --> 00:04:09.229	So, can we have can we try to find out what should be should be the limits on a .
10.srt	00:04:10.639 --> 00:04:17.299	So, in order to see that Let us take a very small example, a simple example say something like this.
10.srt	00:04:18.289 --> 00:04:28.039	Here I have samples taken from class omega 1, I have taken a smaller sample size for clarity of the pictures.
10.srt	00:04:28.370 --> 00:04:36.379	So, these are the feature vectors which are taken from class omega 1 and these are the feature vectors which are taken from class omega 2.
10.srt	00:04:42.669 --> 00:04:48.089	So, what I want to have is I want to have a plane which separates these two sets of feature vectors one from class omega 1 and one from class omega 2.
10.srt	00:04:48.089 --> 00:04:49.159	So, how we do this?
10.srt	00:04:49.639 --> 00:04:54.189	So, I am trying to find out a plane something like this.
10.srt	00:04:54.439 --> 00:05:03.379	So, you find that this plane clearly separates the feature vectors from class omega 1 and the feature vectors from class omega 2.
10.srt	00:05:03.729 --> 00:05:09.789	Now, you find that there is a limit of orientation of this particular plane.
10.srt	00:05:14.809 --> 00:05:16.179	If I rotate this plane in say anti-clockwise direction.
10.srt	00:05:16.179 --> 00:05:29.419	So, this is my new position of the plane, this is the limit to which I can rotate because if I rotate it further then this is the point which is going to be misclassified.
10.srt	00:05:46.189 --> 00:05:48.429	Similarly, coming to the other side if I take this plane this is a limit on the other side because if I rotate it further in the clockwise direction then this is a vector which is going to be misclassified.
10.srt	00:05:49.729 --> 00:05:55.839	So, the range in which I can have this separating plane between these two classes is given by this.
10.srt	00:05:58.310 --> 00:05:59.609	So, this is the separating plane.
10.srt	00:06:00.500 --> 00:06:16.519	Given this separating plane what happens to our solution vector a because this solution vector a as we have seen is orthogonal to the plane a transpose y equal to 0 where y's are the feature vectors taken from class omega 1 and omega 2.
10.srt	00:06:18.479 --> 00:06:34.429	So, if I look at that you find that over here what I have done is in earlier case our feature vectors these were the feature vectors corresponding to class omega 2 on this side.
10.srt	00:06:34.689 --> 00:06:39.559	And what we said is for design purpose we want to negate this feature vectors.
10.srt	00:06:39.759 --> 00:06:46.369	So, that always I will have a transpose y greater than 0 while designing this is my .
10.srt	00:06:47.009 --> 00:06:48.739	decision for correct classification.
10.srt	00:06:49.729 --> 00:06:53.669	And I can always do it because now the feature vectors are the training vectors.
10.srt	00:06:53.869 --> 00:06:57.129	So, for every vector I know what is this class belongingness.
10.srt	00:06:57.579 --> 00:07:16.439	But you remember once your classifier is designed that means, once yourseparating plane is designed my decision rule will always be or the classification rule will always be that if A transpose Y is greater than 0, then Y should belong to class omega 1.
10.srt	00:07:16.879 --> 00:07:20.769	if it is less than 0 then y will be classified to class omega 2.
10.srt	00:07:21.599 --> 00:07:35.339	This is what we will do while classification or during testing because in that case the feature vector y that we want to classify I do not know from which class this has been taken because that is what I have to decide.
10.srt	00:07:36.809 --> 00:07:43.779	But during design with the training vectors I know from which from which class which training vector has come.
10.srt	00:07:44.019 --> 00:07:50.539	So, I can negate y in that case for all the y taken from class omega 2 and that is what has been done.
10.srt	00:07:50.919 --> 00:07:51.379	over here.
10.srt	00:07:53.529 --> 00:08:07.359	So, given this you find that when I have this limiting position of the separating plane, the vector a is this one which is orthogonal to this particular plane.
10.srt	00:08:08.649 --> 00:08:17.179	Similarly, on the other limiting side when this is the position of the separating plane, then my solution vector a is this one.
10.srt	00:08:23.399 --> 00:08:30.909	And you find that if the solution vector a is rotated towards left from this limiting position, then this is a vector which is going to be misclassified.
10.srt	00:08:32.029 --> 00:08:44.689	Similarly, if the feature if the solution vector a is rotated in the clockwise direction from this position, then this is a feature vector belonging to class omega 2 which is going to be misclassified.
10.srt	00:08:45.799 --> 00:08:53.289	So, that clearly tells me that I have a solution region and my solution vector.
10.srt	00:08:54.169 --> 00:09:02.480	A vector which is perpendicular or orthogonal to the separating plane must lie within this solution region.
10.srt	00:09:04.129 --> 00:09:17.289	If it is outside this then vectors belonging to class omega 1 will be misclassified, if it is outside on this side then the vector belong to class omega 2 are going to be misclassified.
10.srt	00:09:17.940 --> 00:09:22.389	So, my solution vector must lie within this conical region.
10.srt	00:09:25.460 --> 00:09:28.920	a feature vector of this a solution vector of this form.
10.srt	00:09:30.240 --> 00:09:35.159	So, for doing this I start my algorithm like this.
10.srt	00:09:36.639 --> 00:09:56.769	So, initially I assume that at zeroth instant my feature vector a 0 is chosen arbitrarily right and we have I have also said.
10.srt	00:09:57.559 --> 00:10:20.049	that at any kth step in my iteration I have a solution vectors say a k. And it is possible that this solution vector a k at the kth step will correctly classify for some of the samples and will be mis correctly classify some other samples.
10.srt	00:10:20.870 --> 00:10:28.019	So, for all the samples which are correctly classified I will always have a k transpose y greater than 0.
10.srt	00:10:29.689 --> 00:10:49.249	And, for all the samples which are incorrectly classified I will have a k transpose y less than 0 irrespective of whether the vector is taken from class omega 1 or taken from class omega 2 because all the training vectors taken from class omega 2 have been negated.
10.srt	00:10:50.799 --> 00:11:02.759	So, during design or during training whenever I come across this type of situation that a k transpose y less than 0 immediately I can conclude that.
10.srt	00:11:03.309 --> 00:11:26.079	that current a k has misclassified the vector y and for this misclassification I have to generate an error term and the error term that can be can be generated is a k transpose y and as it is negative I negate this.
10.srt	00:11:27.369 --> 00:11:36.359	So, whenever a k transpose y is negative I generate an error term which is minus a k transpose y which will always be positive.
10.srt	00:11:37.159 --> 00:12:06.669	That means, if I have any misclassified sample by a k I will have a positive error and this I do for all the samples which are misclassified by a k. So, you take the summation of this over all y which are misclassified and I call it the error j as a function of a.
10.srt	00:12:06.699 --> 00:12:12.909	a, because as all the y's are fixed because those are my training samples, but what I can vary is a.
10.srt	00:12:13.599 --> 00:12:23.719	So, I represent this as an error j which is a function of a and this is an error which is normally called perceptron criteria.
10.srt	00:12:23.719 --> 00:12:26.209	So, sometimes it is also written as jpa.
10.srt	00:12:29.119 --> 00:12:30.939	So, what is my solution approach?
10.srt	00:12:40.509 --> 00:12:43.939	If you look at the figure over here, you can You find that this was my solution region.
10.srt	00:12:46.259 --> 00:12:56.689	So, if I have at any instant of time a solution vector a over here, my approach should be that I should be able to push this a towards this side.
10.srt	00:12:56.689 --> 00:13:09.519	So, that it moves inside the solution region or at any instant of time if my solution vector a is on this side, I should push it in this direction or push it towards the solution region.
10.srt	00:13:09.519 --> 00:13:13.199	So, that eventually my vector will land in the solution region.
10.srt	00:13:14.189 --> 00:13:16.649	and I get the proper separating boundary.
10.srt	00:13:19.159 --> 00:13:23.019	So, what is the approach that I should take for this?
10.srt	00:13:25.269 --> 00:13:37.909	The approach can be that as I said that my error J a is given by a transpose y minus sum of this.
10.srt	00:13:40.039 --> 00:13:44.939	So, I can take an approach to reduce this error or to minimize this error.
10.srt	00:13:45.299 --> 00:13:50.209	by following an algorithm known as gradient descent algorithm.
10.srt	00:13:51.979 --> 00:13:53.339	What is gradient descent algorithm?
10.srt	00:13:54.479 --> 00:13:58.049	Let us take a very simple case something like this.
10.srt	00:13:59.119 --> 00:14:06.719	Say I have a variable x and I have a function f x and the function f x is something like this.
10.srt	00:14:08.359 --> 00:14:13.759	And iteratively I want to get a value of x for which f x is minimum.
10.srt	00:14:14.079 --> 00:14:14.979	So, somehow over here.
10.srt	00:14:16.739 --> 00:14:16.969	.
10.srt	00:14:16.969 --> 00:14:25.069	As in this case I want to get a value of a which will minimize this error j a .
10.srt	00:14:25.069 --> 00:14:31.739	So, you find that here what I can do is if I start somewhere over here .
10.srt	00:14:31.739 --> 00:14:38.369	So, this is my x naught , I will take the gradient of f x with respect to x.
10.srt	00:14:38.369 --> 00:14:47.589	So, what I will compute is del f x upon del x and over here the del f x upon del x will be this .
10.srt	00:14:48.589 --> 00:14:53.169	What I do is I move x in the negative direction of del f x del x.
10.srt	00:14:53.449 --> 00:14:54.679	So, I will move in this direction.
10.srt	00:14:55.799 --> 00:15:17.189	So, my x next time will be the previous x minus del f x del x and if I take this movement if I change x in the negative direction of the gradient I am moving in the direction of minimum f x.
10.srt	00:15:18.769 --> 00:15:21.569	So, this is what is known as gradient descent algorithm.
10.srt	00:15:22.389 --> 00:15:25.729	and we will talk more of this in details later.
10.srt	00:15:27.069 --> 00:15:35.709	But for the time being let me take that I will use this gradient descent algorithm to minimize my error term j.
10.srt	00:15:57.349 --> 00:16:19.749	So, what I have is I have j a is equal to a transpose y negative of this sum of this over all y which are misclassified and what I want to perform is I want to take the gradient of j with respect to a and which is nothing, but from here it is y minus take the summation over all y which are misclassified right.
10.srt	00:16:20.809 --> 00:16:26.669	So, my decision rule can be as we said said before that initially.
10.srt	00:16:27.489 --> 00:16:38.329	at the 0th instant I assume that a 0 will be chosen arbitrarily or at random.
10.srt	00:16:57.979 --> 00:17:18.569	So, the better term is I choose a 0 at random and then if I have a k at kth iteration So, from there I want to find out a k plus 1 which should reduce my error j a which was of the form minus a transpose y and for that I go for the gradient descent approach.
10.srt	00:17:28.829 --> 00:17:32.829	So, gradient of j a we have seen was minus sum of y for all y which are misclassified.
10.srt	00:17:33.249 --> 00:17:52.449	So, I can get a k plus 1 from the previous value a k as a k minus minus sum of y and I can put a rate of convergence which is eta.
10.srt	00:17:53.889 --> 00:18:00.429	So, that simply becomes my weight updation rule or vector updation rule as.
10.srt	00:18:00.749 --> 00:18:12.179	a k plus 1 same as a k plus eta times sum of y for all y which are misclassified.
10.srt	00:18:13.499 --> 00:18:30.449	And you remember that when I am talking this y talking this feature vector y the y will be as it is for the samples taken from class omega 1 and y will be negated it is negated vector for all the vectors taken from class omega 2.
10.srt	00:18:33.029 --> 00:18:33.929	So, given this.
10.srt	00:18:34.169 --> 00:18:41.939	Now, let us see how this ruleupgradation rule actually tries to refine a k plus 1 or the weight vector.
10.srt	00:18:41.969 --> 00:18:53.519	So, that eventually the weight vector pushesfalls in the solution region ok.
10.srt	00:18:54.839 --> 00:19:03.819	So, this is what we were talking about this is my solution region solution region is within this ok.
10.srt	00:19:05.239 --> 00:19:12.999	Now, if I take an initial separating plane something like this.
10.srt	00:19:14.149 --> 00:19:26.259	So, I am assuming that this is my initial separating plane and the weight vector a or a 0 is this one which is orthogonal to the separating plane.
10.srt	00:19:27.999 --> 00:19:34.409	So, here you find clearly that the initial solution vector which I have chosen at random.
10.srt	00:19:34.909 --> 00:19:42.969	because this separating plane has been chosen at random, it falls outside the solution region because the solution region is this .
10.srt	00:19:42.969 --> 00:19:58.079	So, naturally I have to upgrade or I have to modify this solution vector a 0, so that it is moved towards the solution region over here .
10.srt	00:19:58.079 --> 00:20:01.399	And for that what updation rule we have used?
10.srt	00:20:01.399 --> 00:20:04.549	The updation rule was a k plus 1 .
10.srt	00:20:05.219 --> 00:20:13.729	is a k plus eta times sum of y where y is misclassified.
10.srt	00:20:14.019 --> 00:20:18.299	So, what is the misclassified sample in this case?
10.srt	00:20:18.879 --> 00:20:25.389	I have these two samples which are misclassified by this separating vector right.
10.srt	00:20:25.969 --> 00:20:35.639	So, if you take the sum of these two feature vectors which are misclassified, I will get a feature vector, I will get the sum of the misclassified y which is in this direction.
10.srt	00:20:37.039 --> 00:20:47.309	And, this sum is scaled by some eta which is known as rate of convergence, I will come to what is the importance of this rate of convergence later.
10.srt	00:20:50.389 --> 00:21:05.639	So, this is a k or a 0, you add this sum of y or sum of these vectors this particular vector scaled by eta to this vector to get your a 1.
10.srt	00:21:06.239 --> 00:21:12.609	So, a 1 will be moved in this direction because sum of y misclassified y is in this direction.
10.srt	00:21:13.419 --> 00:21:21.469	So, eta times this is added to this initial vector which was chosen at random and the vector moves towards this direction.
10.srt	00:21:21.689 --> 00:21:25.399	Now, what is the importance of this state of convergence eta?
10.srt	00:21:26.769 --> 00:21:36.229	If the value of eta is very high then it is possible that I will jump this solution region and my modified vector will be somewhere over here.
10.srt	00:21:37.609 --> 00:21:41.609	So, you find that you have crossed the solution region for larger value of eta.
10.srt	00:21:43.439 --> 00:21:50.189	If the value of eta is very small maybe I will be landing somewhere over here which is again not in the solution region.
10.srt	00:21:51.269 --> 00:21:58.399	So, if the value of eta is very small then your rate of convergence so the rate at which you are moving towards the solution is small.
10.srt	00:21:59.239 --> 00:22:07.909	If the value of eta is very high then the risk is that you may overshoot the solution region and to go to the other side of the solution region.
10.srt	00:22:07.909 --> 00:22:11.099	So, your number of iterations to reach the solution will be larger.
10.srt	00:22:12.239 --> 00:22:27.979	However, if the value of eta is appropriate and then it is possible that your next modified solution vector the vector that you obtain will be in your solution region and which is the solution that you are looking for.
10.srt	00:22:28.409 --> 00:22:42.469	Now, whatever it is once I have this misclassified samples using misclassified samples you refine the weight vector a ok. And for by this refinement it is possible that the next weight vector.
10.srt	00:22:43.049 --> 00:22:48.169	the next separating plane that you will land that you will achieve is this one.
10.srt	00:22:50.059 --> 00:23:04.779	And you find that for this separating plane the weight vector is this which is again as we said that if the value of eta is very large in that case you can cross the solution region you can over shoot the solution region and that is what exactly has happened over here.
10.srt	00:23:07.339 --> 00:23:13.229	So, this is my weight vector which is falls in which falls on the other side of the solution region and the sample.
10.srt	00:23:13.439 --> 00:23:20.169	which is misclassified by this separating plane is this one right.
10.srt	00:23:21.269 --> 00:23:37.899	So, at the nextweight vector that I should get which is a 2 that gets from a 1 that was the previous solution vector which is this will be a 1 plus eta times this misclassified sample y.
10.srt	00:23:44.879 --> 00:23:48.289	And as this misclassified sample is in this direction this solution vector as I add eta times y to this will also move in this direction.
10.srt	00:23:49.539 --> 00:23:56.599	So, it is possible that the next solution that I obtain will be within this solution region is somewhere over here.
10.srt	00:24:15.789 --> 00:24:22.449	So, this approach clearly says that by taking the gradient descent approach to reduce the error, it is possible that I will get eventually I will get a separating plane which separates the two classes of the feature vectors the samples belonging to class omega 1 and class omega 2.
10.srt	00:24:23.679 --> 00:24:31.369	And that is possible when I have the samples which are really linearly separable.
10.srt	00:24:31.369 --> 00:24:39.009	If the samples are not linearly separable then it is not possible to obtain a separating boundary something like this.
10.srt	00:24:49.469 --> 00:24:52.129	And the approach that we have to take in such cases is what is known as minimum error criteria.
10.srt	00:24:53.109 --> 00:25:09.569	So, that the separating plane that you obtain does not totally remove the error, but the plane will try to reduce the squared error or the minima or it will try to minimize the squared error ofclassification.
10.srt	00:25:21.939 --> 00:25:32.299	So, in today's lecture what we have done is we have tried to find out a boundary between the samples taken from the two different classes, the samples which are provided for designing the separating plane are the training samples.
10.srt	00:25:33.569 --> 00:25:52.559	And for designing the separating plane what we have done is we have appended one to all the training vectors and the vectors taken from class omega 1 which actually falls on the negative negative half of the boundary we have negated them for design purpose only.
10.srt	00:25:55.419 --> 00:26:24.729	But, you keep in mind that once your separating plane is properly designed or once I get this equation A transpose y equal to 0 which is the equation of this separating plane by using the training vectors for classification of the unknown sample now my classification rule will be.
10.srt	00:26:24.989 --> 00:26:40.399	for an unknown sample say Y unknown, if it is greater than 0 then Y unknown is to be classified to class omega 1, if it is less than 0 then Y unknown has to be classified to class omega 2.
10.srt	00:26:43.569 --> 00:26:52.029	So, with this we will stop today's lecture, next class we will talk about the support vector machine.
10.srt	00:26:52.749 --> 00:26:53.089	Thank you.
12.srt	00:00:00.610 --> 00:00:15.349	Hello, welcome to the NPTEL online certification course on Deep Learning.
12.srt	00:00:15.349 --> 00:00:26.629	Thank you for joining me.
12.srt	00:00:31.719 --> 00:00:37.229	You remember in the previous class we started our discussion on the support vector machine.
12.srt	00:00:38.359 --> 00:00:42.310	So, in today's lecture we will continue with the same discussion.
12.srt	00:00:43.600 --> 00:00:57.549	So, in the previous class we have just introduced or gave a brief introduction of what the support vector machine is and today we are going to talk about what should be the design approach of a support vector machine.
12.srt	00:00:59.019 --> 00:01:01.200	So, we have seen that.
12.srt	00:01:02.050 --> 00:01:06.219	So, in our case we will assume again a two class problem.
12.srt	00:01:07.100 --> 00:01:13.750	So, we have the feature vectors given from two classes omega 1 and omega 2.
12.srt	00:01:15.340 --> 00:01:33.370	And all the training vectors we assume that are given as leveled pair in the sense that a training vector x i which is the ith training vector will be given as a pair x i y i where.
12.srt	00:01:33.810 --> 00:01:35.900	this y i indicates the level.
12.srt	00:01:37.340 --> 00:01:56.370	So, if the training vector y i is taken from class omega 1 that is if y i belongs to class omega 1, then we will setsorry x i belongs to class omega 1, then we will set the level y i to be plus 1.
12.srt	00:01:58.200 --> 00:02:05.069	And if x i the training vector x i is taken from class omega 2.
12.srt	00:02:05.490 --> 00:02:11.530	then we will set y i the level to be equal to minus 1.
12.srt	00:02:35.870 --> 00:03:01.259	So, that indicates that given a separating plane with an equation a transpose x plus b is equal to 0, if this is the separating plane between the feature vectors belonging to class omega 1 and class omega 2, then our classification rule was a transpose x plus b greater than 0 for x taken from class omega 1 or if x belongs to class omega 1 and a transpose x plus b will be less than 0 for x taken from class omega 2.
12.srt	00:03:02.819 --> 00:03:05.870	Now, by introduction of these levels.
12.srt	00:03:36.169 --> 00:03:54.599	that is y i is equal to plus 1 for if x i belongs to class omega 1 and y i equal to minus 1 if x i is taken from class omega 2 then I have a uniform classification rule that is I can write y i a transpose x i plus b will be greater than 0 if x i is correctly classified by the separating plane A transpose X plus b equal to 0 and this will be less than 0 if X i is misclassified by the separating plane A transpose X plus b equal to 0.
12.srt	00:04:07.349 --> 00:04:17.980	And, we have also seen as in this equation A transpose X plus b equal to 0, A is a vector which is orthogonal to the separating plane and b is a bias which indicates what is the position or location of the separating plane.
12.srt	00:04:19.219 --> 00:04:37.250	So, as as a is orthogonal to x if I modify a that means, the orientation of the separating plane will be different whereas, if I change b then the position or location of the separating plane will be different in my feature space.
12.srt	00:04:39.439 --> 00:04:45.780	So, for different values of a and b I have got I I can obtain different separating planes.
12.srt	00:04:46.759 --> 00:05:04.040	And maybe many of those separating planes will satisfy the same condition that is a i y i into a transpose x i plus b to be greater than 0.
12.srt	00:05:06.740 --> 00:05:08.540	Now, for different values of a.
12.srt	00:05:09.080 --> 00:05:24.900	the vector a and for different values of the bias b I get different such planes, but for each such plane I will have the different margins or different confidence level of classification.
12.srt	00:05:26.129 --> 00:05:26.960	So, what is that?
12.srt	00:05:27.439 --> 00:05:39.870	So, here I take this particular separating plane which separates between this set of feature vectors which belong to class omega 1 and these two feature vectors which belong to class omega 2.
12.srt	00:05:41.620 --> 00:05:50.790	Now, given this you find that if I take this particular separating plane, this separating plane gives me a margin which is given by this.
12.srt	00:05:51.690 --> 00:06:12.700	So, that the distance between these two planes gives me the margin or what is the confidence level ofthe confidence level given by this particular classifier .
12.srt	00:06:14.560 --> 00:06:26.449	Similarly, if I take another separating plane say this one, here again you find that the margin is given bythis much ok.
12.srt	00:06:26.449 --> 00:06:36.439	So, obviously, the margin given in this option is less than the margin given in the previous option.
12.srt	00:06:37.670 --> 00:06:43.090	To continue further, if I take this separating plane.
12.srt	00:06:43.469 --> 00:06:45.959	then again the margin is given by this.
12.srt	00:06:46.800 --> 00:06:56.699	So, out of so many options which one should be preferred and that is the scope of the support vector machine that is what the support vector machine does.
12.srt	00:06:57.490 --> 00:07:14.500	The support vector machine tries to get a separating plane which maximizes the margin and for such a separating planethe separating plane should be at a maximal distance from the vectors belonging to both the classes.
12.srt	00:07:15.109 --> 00:07:35.529	That means, the vectors belonging to class omega 1 should try to maximize the distance of the separating plane from the vectors belonging to class omega 1 and it also try to maximize the distance from the vectors belonging to class omega 2 right.
12.srt	00:07:36.049 --> 00:07:43.949	So, I should get that particular separating plane I should try to obtain that particular separating plane which maximizes this margin.
12.srt	00:07:47.779 --> 00:08:05.699	And for classification, my rule is that I must have y i times a i a transpose x i plus b that should be greater than 0 this is for the classification.
12.srt	00:08:06.349 --> 00:08:20.279	But as I am talking about the margin, I want that for correct classification or for reliable classification for every x i, the distance from the separating plane.
12.srt	00:08:20.559 --> 00:08:22.729	must be more than a certain threshold.
12.srt	00:08:24.199 --> 00:08:33.029	So, that distance as we said earlier that a measure of the distance is given by a i transpose X i plus b.
12.srt	00:08:34.619 --> 00:08:43.089	So, if a i transpose X i plus b equal to 0 that means, X i falls on the separating plane in which case the distance of X i from the separating plane is 0.
12.srt	00:08:45.139 --> 00:08:49.879	For any non-zero value if X i is taken from class when we got 1.
12.srt	00:08:50.399 --> 00:09:22.629	2, then I must have a transpose x i plus b to be greater than certain threshold say d and if x i is taken from class omega 2, then I should have a transpose x i plus b should be less than minus d. And this should be true for all the training samples, whether the training samples are taken from class omega 1 or the training samples are taken from class omega 2.
12.srt	00:09:53.719 --> 00:10:11.519	So, if X i is taken from class omega 1, then this should be satisfied that is a transpose X i plus b should be greater than d. And if the training sample X i is taken from class omega 2, then this one should be satisfied that is a i a transpose X i plus b must be less than d less than minus d. And by taking this particularoption, I have and uniform criteria that is a y i a transpose x i plus b should always be greater than d irrespective of from whichever class this training sample x i has been obtained.
12.srt	00:10:13.449 --> 00:10:16.549	What I can do is I can always normalize this expression.
12.srt	00:10:24.769 --> 00:10:30.909	So, while designing I can have the condition that y i a transpose x i plus b should be greater than or equal to 1.
12.srt	00:10:32.829 --> 00:10:55.049	And, I will use this approach while designing the classifier or while choosing the separating plane, but for classification my rule will be once I fix what should be a and what should be b after designing the separating plane or choosing the separating plane using the training vectors.
12.srt	00:10:55.699 --> 00:11:21.149	Then, for any unknown x my classification rule can be that A transpose X plus B greater than 0 indicates that X belongs to class omega 1 or if A transpose X plus B becomes less than 0 then my decision will be that X should be classified to class omega 2.
12.srt	00:11:22.599 --> 00:11:27.219	So, right now our aim is .
12.srt	00:11:27.729 --> 00:11:51.109	that I should choose this separating plane A transpose x plus b equal to 0 which satisfies the condition that y i A transpose x i plus b must be greater than 1.
12.srt	00:11:52.079 --> 00:11:54.859	So, that is after normalization.
12.srt	00:11:56.559 --> 00:11:57.729	So, how I can do that?
12.srt	00:12:00.749 --> 00:12:09.329	So, what I am saying is that this particular equation of this particular separating plane I should take that particular separating plane which maximizes this margin.
12.srt	00:12:12.589 --> 00:12:16.739	So, how I can obtain this margin and how I can maximize this margin.
12.srt	00:12:17.909 --> 00:12:31.459	So, for that let us take one vector on this margin which is say x plus and I have take I will take another vector on this margin.
12.srt	00:12:32.079 --> 00:12:34.059	which is say x minus.
12.srt	00:12:34.529 --> 00:12:42.719	So, x plus is taken within the class omega 1 region and x minus is taken within omega 2 region.
12.srt	00:12:44.269 --> 00:12:56.739	So, a vector x plus minus x minus is a vector drawn from x minus to x minus to x plus.
12.srt	00:12:59.099 --> 00:13:03.109	And once I have this vector then from here you find that I can obtain.
12.srt	00:13:03.649 --> 00:13:22.559	the margin which is given by this as a dot product of the vector x plus minus x minus with the unit vector in the direction of w right.
12.srt	00:13:34.479 --> 00:14:07.179	So, the situation that I have over here is I have taken a vector x plus in omega 1 region, I have taken a vector x minus in omega 2 region drawn a vector from x minus to x plus and then from this I have to find out the margin which is nothing, but dot product of the vector drawn from x minus to x plus with the unit vector in the direction of w which is nothing, but orthogonal to the separating plane and the unit vector in this direction is given by.
12.srt	00:14:07.589 --> 00:14:11.169	A upon mod of A.
12.srt	00:14:14.049 --> 00:14:35.969	So, the margin that you get is x plus minus x minus take the dot product of this or A transpose into x plus minus x minus upon mod of A.
12.srt	00:14:38.679 --> 00:14:42.539	This is what is the margin given by this particular sephatic plane .
12.srt	00:14:43.989 --> 00:14:49.749	And, now you remember that we had the situation because this x plus is on the margin.
12.srt	00:14:50.639 --> 00:15:08.699	So, I have a transpose x plus plus b is equal to 1 and because x minus is on the margin on the negative side or on the margin into omega 2 side.
12.srt	00:15:09.059 --> 00:15:13.869	So, I have this particular equation a transpose x minus.
12.srt	00:15:14.289 --> 00:15:16.719	plus b is equal to minus 1.
12.srt	00:15:44.769 --> 00:15:45.449	So, from here you find that a transpose x plus minus x minus just subtracting if I call it equation a from equation b, I get a transpose x plus minus x minus is 2.
12.srt	00:15:47.999 --> 00:16:10.619	So, by using this you find that the margin A transpose upon mod A into X plus minus X minus sorry is given by 2 upon mod of A .
12.srt	00:16:12.909 --> 00:16:16.369	So, as we said earlier .
12.srt	00:16:16.979 --> 00:16:29.229	that I should choose or I aim to choose that particular separating plane which maximizes the margin and the margin comes out to be 2 upon mod of a.
12.srt	00:16:47.009 --> 00:17:08.909	So, I should choose that particular a which maximizes this and here you find that obviously, as mod of a comes in the denominator, I can maximize this term indefinitely by making a smaller and smaller, but that is not the solution because the a and b that I choose also must satisfy the requirement that y i a transpose x i plus b that has to be greater than or equal to 1.
12.srt	00:17:10.589 --> 00:17:17.519	So, I have to minimize a subject to the constraint that a transpose y i .
12.srt	00:17:17.709 --> 00:17:22.179	into a transpose x i plus b have to be greater than or equal to 1.
12.srt	00:17:23.769 --> 00:17:35.389	So, it becomes a constrained optimization problem and as you know that to solve a constrained optimization problem we have to make use of Lagrangian.
12.srt	00:17:36.269 --> 00:17:42.339	So, here what I have to do is I have to form a Lagrangian using this particular constant.
12.srt	00:17:48.219 --> 00:18:06.929	So, the Lagrangian can be formed like this I form L as, as I have to minimize mod of w. So, the Lagrangian that I form there I write half of mod of w square, why I am taking at taking this as half of mod of w square will be clear very soon.
12.srt	00:18:18.619 --> 00:18:33.099	And then minus alpha i y i times a transpose x i plus b minus 1 take the sum of this over all i.
12.srt	00:18:35.199 --> 00:18:40.279	So, this becomes my Lagrangian for constant optimization problem.
12.srt	00:18:41.799 --> 00:18:49.999	So, this L of the Lagrangian has to be minimized with respect to sorry.
12.srt	00:18:50.649 --> 00:19:20.639	I am using the term a not w. So, let me put it like this that my Lagrangian L will be half of mod of a square minus sum of alpha i y i times a transpose x i plus b minus 1.
12.srt	00:19:22.969 --> 00:19:25.829	i and the summation has to be taken over all i.
12.srt	00:19:27.749 --> 00:19:39.989	So, this Lagrangian has to be minimized with respect to a and it has to be maximized with respect to our Lagrangian multipliers which are alpha i.
12.srt	00:19:42.689 --> 00:19:49.199	So, first for this optimization problem as you know that we have to make use of the differential operators.
12.srt	00:19:49.969 --> 00:19:52.859	So, first let us try to differentiate L.
12.srt	00:20:23.849 --> 00:20:24.719	with respect to a and if I do that it simply becomes a minus it becomes alpha i a transpose sorry it simply becomes alpha i y i x i sum of this over all i.
12.srt	00:20:26.729 --> 00:20:54.829	So, when I differentiate L with respect to a it becomes a minus sum of alpha i y i x i and that has to be equated to 0 which gives me the solution vector a or the orientation of the separating plane to be equal to sum of alpha i y i x i summation has to be taken over.
12.srt	00:20:55.129 --> 00:21:03.439	all i that is all the training vectors which are given for designing the support vector machine .
12.srt	00:21:03.439 --> 00:21:15.429	In the same manner if I take the differential of a l with respect to b what do I get?
12.srt	00:21:26.679 --> 00:21:34.809	The first term because there is no b over here this becomes 0 over here it becomes minus sum of alpha i y i yeah.
12.srt	00:21:35.149 --> 00:21:37.929	So, it is sum of alpha i y i b.
12.srt	00:21:38.069 --> 00:21:57.899	So, if I differentiate this with respect to b it simply becomes sum of alpha i y i and that I if if I equate to 0 this simply gives me that sum of alpha i y i has to be equal to 0.
12.srt	00:21:58.799 --> 00:22:27.159	2 intermediate solutions that is a is equal to sum of alpha i y i x i summation over all i and the other I get is sum of y i alpha i y i that is equal to 0 .
12.srt	00:22:27.159 --> 00:22:29.509	So, now let us see what Lagrangian that we had.
12.srt	00:22:31.279 --> 00:22:51.609	We had Lagrangian equal to half of mod a square minus sum of alpha i y i a transpose x i plus b minus 1.
12.srt	00:22:55.319 --> 00:22:56.209	This was the Lagrangian.
12.srt	00:23:01.579 --> 00:23:03.969	And over here a is nothing but sum of a alpha i y i x i.
12.srt	00:23:05.559 --> 00:23:31.359	So, putting that in this expression it simply becomes half of alpha i y i x i into I can write the other y as alpha i or alpha j .
12.srt	00:23:32.909 --> 00:23:38.619	j x j minus what I have over here.
12.srt	00:23:38.619 --> 00:23:46.169	So, I will put a transpose a is nothing, but a dot a.
12.srt	00:23:46.169 --> 00:23:50.139	So, let us put it as dot product .
12.srt	00:23:50.139 --> 00:24:02.169	So, over here again it becomes sum of alpha i y i x i again dotted with sum of .
12.srt	00:24:02.619 --> 00:24:06.909	alpha j y j x j.
12.srt	00:24:07.769 --> 00:24:33.379	So, that takes care of alpha i y i a transpose x i plus or minus b times sum of alpha i y i and sum of alpha i y i equal to 0 and then I get plus sum of alpha i right.
12.srt	00:24:34.329 --> 00:24:56.749	And, this simply gets gives me sum of alpha i minus double summation alpha i alpha j y i y j x i dotted with x j .
12.srt	00:24:56.749 --> 00:25:05.489	So, the final Lagrangian that I have is L is equal to sum of alpha i .
12.srt	00:25:06.009 --> 00:25:25.099	half alpha i alpha j y i y j then x i dot x j or x i transpose x j .
12.srt	00:25:25.099 --> 00:25:35.499	So, this is the final form of Lagrangian and you find that under .
12.srt	00:25:36.089 --> 00:25:51.159	we get as a, a is equal to sum of alpha i y i x i summation over all i and here it has to be summation over all j and summation over all i.
12.srt	00:25:51.629 --> 00:26:02.499	So, thus solution vector a is given by this expression alpha i y i x i .
12.srt	00:26:08.069 --> 00:26:12.979	taken summation over all i and what should be the values of alpha?
12.srt	00:26:13.839 --> 00:26:22.719	The values of alpha will be should should be those alphas which maximizes this expression of this Lagrangian.
12.srt	00:26:24.419 --> 00:26:37.839	So, now you can make use of any of the optimization tool to optimize L with respect to alphas and the set of such alphas that you get which maximizes this L.
12.srt	00:26:38.259 --> 00:26:42.279	can give you what is my solution vector a.
12.srt	00:26:43.539 --> 00:26:59.689	And once you have the solution vector a you get your separating plane and this is the separating plane which maximizes the margin or in other words this separating plane will give you a robust linear classifier.
12.srt	00:27:01.209 --> 00:27:11.739	So, today what we have done is we have tried to find out a linear boundary between the feature vectors taken from two different classes omega 1 and omega 2.
12.srt	00:27:12.609 --> 00:27:32.519	And, using support vector machine we have tried to find out one suchlinear separator or plane between the two separating planes in such a manner that this separator maximizes the margin between the vectors belonging to class omega 1 and the vectors belonging to class omega 2.
12.srt	00:27:32.819 --> 00:27:42.939	So, so far whatever we have discussed whether it is a linear discriminator or a support vector machine.
12.srt	00:27:43.209 --> 00:27:46.809	problem, we have considered a problem which is only two class problem.
12.srt	00:27:47.789 --> 00:27:59.609	So, next we will generalize this and try to find out that how we can obtain or how we can extend similar concepts to multi class problems.
12.srt	00:28:00.519 --> 00:28:02.019	With this I stop here today.
12.srt	00:28:02.319 --> 00:28:02.669	Thank you.
13.srt	00:00:00.610 --> 00:00:15.009	Hello, welcome to the NPTEL online course on Deep Learning.
13.srt	00:00:31.260 --> 00:00:40.509	You remember in the previous class we have talked about the linear classifier and the support vector machine.
13.srt	00:00:41.740 --> 00:00:54.000	So, what we have done in case of a linear classifier is that we assumed that we have a number of training samples.
13.srt	00:01:05.879 --> 00:01:08.980	So, training samples Y i which were assumed to belong to class omega i.
13.srt	00:01:09.980 --> 00:01:31.680	In the sense that I had a number of training samples from two different classes the class omega 1 and class omega 2 and using this training samples we wanted to find out a separating plane which separates the samples belonging to class omega 1 and class omega 2.
13.srt	00:01:36.060 --> 00:01:38.909	Now, before that if you remember when we talked about the discriminant function.
13.srt	00:01:39.900 --> 00:02:07.520	For every class we defined a discriminant function which was given by g i x and in case that the covariance matrix of the training samples coming from all different classes are same this g i x came out to be a linear one which is of the form W transpose X plus W naught .
13.srt	00:02:09.560 --> 00:02:27.209	Of course, if the covariance matrices of the training samples coming from the different classes they are not same, then we have seen that this g i x or the discriminant function of the different classes that does not become linear anymore, but it becomes a quadratic function.
13.srt	00:02:28.419 --> 00:02:36.689	So, in case of linear classifier what we tried to find out is we tried to find out the boundary between two different classes.
13.srt	00:02:37.859 --> 00:02:48.829	class omega j in that case g i x minus g j x becomes greater than 0 and our conclusion is that x belongs to class omega i.
13.srt	00:02:49.930 --> 00:03:04.939	Whereas, if g j x is less than g i x then obviously, x belongs to class omega j and the boundary between the two classes is given by g x is equal to 0 when g i x and g j x are both of them are same.
13.srt	00:03:05.969 --> 00:03:16.949	So, in such case if this g i x or g j x they are linear as given in this case then g x also becomes linear which is the separating boundary between .
13.srt	00:03:17.139 --> 00:03:18.080	2 different classes.
13.srt	00:03:18.990 --> 00:03:36.219	So, given that if you are given a set of samples say belonging to class omega 1 and a set of samples belonging to class omega 2, then the boundary between these 2 classes omega 1 and omega 2 becomes a linear one.
13.srt	00:03:37.189 --> 00:03:49.829	So, when we talked about the linear classifier we assumed that the boundary is linear that means, the training samples or the samples belonging to class omega 1 and omega 2 they are linearly separable.
13.srt	00:03:50.750 --> 00:04:01.159	And, while designing linear classifier we did not really think of what is the distribution of the vectors belonging to class omega 1 and class omega 2.
13.srt	00:04:01.810 --> 00:04:04.980	We simply assumed that they are linearly separable.
13.srt	00:04:06.219 --> 00:04:19.550	And, we have seen while designing linear classifier is that as over here you find that this straight line is not unique, I can have line over here, I can have a line here, I can have a line here and so on.
13.srt	00:04:20.189 --> 00:04:22.560	So, there are multiple number of solutions possible.
13.srt	00:04:23.550 --> 00:04:33.629	And, out of this multiple number of separating planes some of the separating planes gives you lessermerging, some of the separating planes gives you higher margin.
13.srt	00:04:33.629 --> 00:04:43.640	So, there we had gone for support vector machines which ensures that the margin that you get is maximum.
13.srt	00:04:43.640 --> 00:04:55.370	That means, your separating plane given say a set of samples to omega 1 and another set of samples to omega 2, it gives you .
13.srt	00:04:55.680 --> 00:05:08.340	a maximum margin from the samples belonging to class omega 1 and the samples belonging to class omega 2 and this is what was the aim of support vector machine or SVM.
13.srt	00:05:10.189 --> 00:05:25.360	So, for all these cases what we have seen is that you are given a set of training samples for designing the linear classifier or for designing the support vector machine and those training samples are actually labeled.
13.srt	00:05:26.000 --> 00:05:32.720	That means, for each sample I know that from which class or from which category that sample has been taken.
13.srt	00:05:33.420 --> 00:05:41.070	Or in other words every sample or feature vector x i comes with a level y i.
13.srt	00:05:41.530 --> 00:05:45.070	So, your samples are given in the form x i y i.
13.srt	00:05:46.250 --> 00:05:59.200	And in case of a linear machine or support vector in case of a linear classifier or a support vector machine that we have discussed so far because we are concentrating on only two class problem.
13.srt	00:05:59.829 --> 00:06:09.960	So, this y i which actually tells you from which category this sample x i has been taken this y i can have one of the two values.
13.srt	00:06:10.569 --> 00:06:26.639	So, we assumed that y i was is plus 1 if x i is taken from class omega 1 and y i is minus 1 if x i is taken from class omega 2.
13.srt	00:06:27.650 --> 00:06:37.000	And accordingly we could have a single classification rule or unified classification rule which we said that W transpose .
13.srt	00:06:37.500 --> 00:06:44.250	x plus x w naught of this form.
13.srt	00:06:45.250 --> 00:07:00.310	So, this vector x is x i this whole thing multiplied by y i that should be greater than 0 if x i is correctly classified by the weight vector w and the margin w naught.
13.srt	00:07:01.220 --> 00:07:07.560	This is obvious because if it is if the sample x i is taken from class omega 1.
13.srt	00:07:07.870 --> 00:07:13.040	Then, my condition is W transpose X i plus W naught should be greater than 0 for correct classification.
13.srt	00:07:13.800 --> 00:07:20.980	If it is taken from omega 2 as the sample as omega 2 is on the negative side of the separating plane.
13.srt	00:07:21.200 --> 00:07:30.300	So, I have to have W transpose X i plus W naught less than 0 and for samples taken from class omega 2 because Y i is minus 1.
13.srt	00:07:30.540 --> 00:07:38.690	So, if I multiply this expression W transpose X i plus W naught by Y i which is minus 1 in this case.
13.srt	00:07:39.400 --> 00:07:40.560	that will be greater than 0.
13.srt	00:07:40.600 --> 00:07:42.900	So, I get a uniform classification rule.
13.srt	00:07:43.670 --> 00:07:49.970	So, while designing the support vector machine or while designing the linear classifier we have taken advantage of this.
13.srt	00:07:50.220 --> 00:08:05.110	So, for any x i when y i w transpose x i plus w naught was less than 0 wehad taken that that particular w and w naught could not classify x i properly.
13.srt	00:08:05.330 --> 00:08:12.710	So, the vectors have to be modified and that is how we have designed the linear classifier and also the support vector machine.
13.srt	00:08:14.020 --> 00:08:28.500	So, in this case also we assume that we are given a set of feature vectors for training purpose.
13.srt	00:08:28.650 --> 00:08:37.050	So, in a multiclass problem now w i will not take only two values now because now we have multiple number of classes.
13.srt	00:08:37.860 --> 00:08:44.400	So, what we assume is that suppose I have got n number of feature vectors.
13.srt	00:08:45.870 --> 00:08:50.370	And, I have say k number of categories or k number of classes.
13.srt	00:08:51.440 --> 00:09:02.290	So, a training vector which is given in the form x i y i as I have got n number of feature vectors given for training.
13.srt	00:09:02.600 --> 00:09:09.530	So, this i will vary from 1 to n as there are n number of feature vectors.
13.srt	00:09:10.790 --> 00:09:17.820	And my categories there are k number of categories and this y i is an index to the category.
13.srt	00:09:19.010 --> 00:09:25.900	So, this y i will vary from 1 to k .
13.srt	00:09:25.900 --> 00:09:28.300	So, y i is an index to the category.
13.srt	00:09:28.300 --> 00:09:37.760	So, for example, if I have 5 categories corresponding say corresponding to say apple, bird,then cat, dog, car and so on.
13.srt	00:09:37.760 --> 00:09:43.280	If apple is the first category for apple y i will be is equal to 1.
13.srt	00:09:44.080 --> 00:09:48.300	If cat is the third category, then for all the vectors.
13.srt	00:09:49.020 --> 00:09:53.360	belonging to cat class will have y i value is equal to 3 and so on.
13.srt	00:09:55.060 --> 00:09:59.640	So, for example, there is a public database called c for 10.
13.srt	00:10:07.330 --> 00:10:12.770	So, this c for 10 database it contains 50,000 images.
13.srt	00:10:19.340 --> 00:10:20.330	So, n is equal to 50,000 and there are 10 categories.
13.srt	00:10:20.420 --> 00:10:33.540	So, k is equal to 10 and the categories of images are images belonging to car, images belonging to cat, images belonging to dog, images of sheep, images ofhorse and so on.
13.srt	00:10:33.540 --> 00:10:49.040	So, there are 10 such categories and there are 50,000 images and each of this image is of size 32 by 32 pixels and these are color images.
13.srt	00:10:51.009 --> 00:10:53.009	That means, there are 3 planes red green and blue.
13.srt	00:10:53.400 --> 00:10:57.670	So, the number of pixels is 32 by 32 by 3.
13.srt	00:11:26.310 --> 00:11:30.490	So, for discussion we will assume that every vector or feature vector given forclassification purpose is of dimension D. So, our X i the feature vectors will be D dimensional and the number of categories will beand there are k number of categories.
13.srt	00:11:32.180 --> 00:11:36.580	So, I have d dimensional feature vectors and I have k number of categories.
13.srt	00:11:37.759 --> 00:11:58.269	So, using this now you find that if I go for the same discriminant function we had the discriminant function of the form g i x for category omega i or i th category and this g i x.
13.srt	00:11:59.010 --> 00:12:04.070	As, we are assuming that our discriminant functions are linear discriminant functions.
13.srt	00:12:04.440 --> 00:12:21.150	So, this g i x is nothing, but of the form w i transpose x plus w i naught where this x is a d dimensional vector w i is also a d dimensional vector.
13.srt	00:12:22.430 --> 00:12:31.130	And, you find that if I expand this expression then my g i x becomes of the form w i 1.
13.srt	00:12:32.170 --> 00:12:40.850	1 plus w i 2 x 2 plus as there are d number of components.
13.srt	00:12:41.090 --> 00:12:55.260	So, I will have w i d x d plus I can write this as w i 0 1 which is the bias term.
13.srt	00:12:55.760 --> 00:13:00.950	So, this is what is my g 1 x for category omega 1.
13.srt	00:13:03.140 --> 00:13:13.510	Similarly, So, for category 2 G 2 x will be W sorry I am taking i is equal to 1.
13.srt	00:13:14.290 --> 00:13:20.840	So, this expression will be different let me put it like this.
13.srt	00:13:20.840 --> 00:13:31.040	So, I want to find out G 1 x which is nothing but W 1 transpose X plus W 1 naught.
13.srt	00:13:32.830 --> 00:13:38.360	As W 1 has got d number of components X also has got d number of components.
13.srt	00:13:38.690 --> 00:14:02.930	So, I can expand this expression in the form W 1 1 X 1 plus W 1 2 X 2 plus W 1 d X d plus W 1 0 .
13.srt	00:14:02.930 --> 00:14:06.170	This is what is my G 1 X.
13.srt	00:14:08.960 --> 00:14:26.740	Similarly, G 2 X becomes W 2 1 x 1 plus W 2 2 x 2 plus continue like this W 2 d x d plus W 2 naught which is the bias forcategory 2.
13.srt	00:14:27.180 --> 00:14:34.410	And as I have got k number of classes I will have k number of discriminant functions.
13.srt	00:14:34.780 --> 00:14:40.650	So, g k x will be of the form W k 1 x 1 .
13.srt	00:14:41.210 --> 00:14:52.520	plus W k 2 x 2 W k d x d plus W d W k 0 .
13.srt	00:14:52.840 --> 00:15:10.610	So, this is your discriminant function g 1 x, this is the discriminant function g 2 x .
13.srt	00:15:13.280 --> 00:15:18.390	this is the discriminant function g k x .
13.srt	00:15:18.390 --> 00:15:28.530	Now, given this k number of linear equations, you find that I can represent this k number of linear equations in the form of matrix equation.
13.srt	00:15:28.530 --> 00:15:43.330	So, the matrix equation simply becomes W x plus W naught where this W is a matrix having k number of rows.
13.srt	00:15:43.540 --> 00:15:44.820	and d number of columns.
13.srt	00:15:44.820 --> 00:15:56.550	So, this W is a K by d matrix and W naught is a bias which is a column vector having d number of components.
13.srt	00:15:58.180 --> 00:16:08.000	So, a linear machine is a one which is specified by this matrix W and this bias vector which is W naught.
13.srt	00:16:08.000 --> 00:16:11.590	So, they are the parameters of a linear machine.
13.srt	00:16:12.650 --> 00:16:13.950	So, once I have this.
13.srt	00:16:14.270 --> 00:16:27.960	for given any unknown vector x i or if I take the training vector x i which belongs to omega isorry which belongs toomega i.
13.srt	00:16:27.960 --> 00:16:30.800	So, corresponding that my index is y i.
13.srt	00:16:45.260 --> 00:16:52.390	So, for this x i y i pair if I compute this expression w x i plus w 0 this will give me a column vector let me call that column vector to be S. So, what this column vector gives?
13.srt	00:16:54.570 --> 00:17:11.170	You find that here what you are computing is you are multiplying X i with every row of W. So, if I take the jth row of W to be W j .
13.srt	00:17:16.820 --> 00:17:37.890	So, this X i is you take the dot product of X i with the jth vector in this matrix W and multiply and add to that the jth component of your bias vector W naught to give the jth component of S or S j .
13.srt	00:17:37.890 --> 00:17:46.769	So, we call this S to be a score function .
13.srt	00:17:46.769 --> 00:17:47.970	So, what this linear machine is doing?
13.srt	00:17:48.579 --> 00:18:09.309	The linear machine is nothing, but a function f which operates on an input vector i, the parameters of the linear machine as a W and W naught and this gives you a score function which is S again a d dimensional vector.
13.srt	00:18:20.589 --> 00:18:35.769	So, this operation I can say that it is a mapping which mappings map my d dimensional feature vector x d into a score which is of dimension k. And every component of this score vector of this score gives you the score for the corresponding class.
13.srt	00:18:36.190 --> 00:18:51.039	So, given my input vector x i the score component S j tells me that what is the score of this input vector x i.
13.srt	00:18:51.699 --> 00:19:04.899	to a category omega j as given by the linear machine decided by which are having the parameters w and w naught.
13.srt	00:19:06.169 --> 00:19:08.359	So, this is what the linear machine does.
13.srt	00:19:24.699 --> 00:19:41.469	And now if my training vector says that this x i is taken from class omega i or the corresponding class index is y i, then obviously, what I would like to see is that for the score function S, the y i th component of this score function should be maximum.
13.srt	00:19:42.169 --> 00:19:48.879	So, that the classification or the categorization as given by this linear machine is correct.
13.srt	00:19:50.240 --> 00:19:54.759	And if it is not correct, then I have to go for correction.
13.srt	00:19:55.049 --> 00:20:09.819	ofthe parameters or updation of the parameters of the linear machine, so that the output classification becomesor the error in the categorization or the classification is minimized.
13.srt	00:20:11.899 --> 00:20:26.460	So, what I want to do is I want to now define something called a loss function .
13.srt	00:20:26.460 --> 00:20:28.930	So, one thing we have seen is the score function .
13.srt	00:20:30.169 --> 00:20:42.490	The linear machine gives you the score function and the score function indicates that for a given feature vector what is the core for what is the score for different classes or for different categories.
13.srt	00:20:44.209 --> 00:20:52.129	And I want that this score should be similar to the ground truth, it should be same as the ground truth.
13.srt	00:21:00.379 --> 00:21:07.339	That means, if my feature vector belong to class omega 1 or it is from category 1 in that case in this core vector that I get the first component should be maximum and all other components should be less than the first component.
13.srt	00:21:07.409 --> 00:21:08.980	So, that my classification is correct.
13.srt	00:21:09.769 --> 00:21:27.740	If it is not then I have to go for updation of the parameters of the linear machine and this parameters are nothing but w 1 w naught and by updation I should be able to tune the parameters so that I get a correct classification ok.
13.srt	00:21:28.470 --> 00:21:32.940	So, what I want is ok before I define this loss function.
13.srt	00:21:33.369 --> 00:21:36.759	I want to show this with an example say for example, over here.
13.srt	00:21:38.609 --> 00:21:48.509	Here what we are doing is we have taken an image and this image is the is flattened out to convert this to a vector.
13.srt	00:21:49.460 --> 00:21:50.779	So, how do you flatten it out?
13.srt	00:21:51.160 --> 00:21:57.190	You can take every column of the image and concatenate the columns to get a vector right.
13.srt	00:21:58.170 --> 00:22:03.839	So, if I assume that this image is converted to a vector having four components.
13.srt	00:22:04.550 --> 00:22:12.830	And, this is my linear machine the linear machine takes care of four different categories the categories are cat, bird, dog and car.
13.srt	00:22:13.450 --> 00:22:21.710	So, in this case cat is the first category, bird is the second category, dog is the third category and car is the fourth category.
13.srt	00:22:22.070 --> 00:22:34.490	So, for cat y i will be equal to 1, for bird y i will be taken as 2, for dog it will be taken as 3 and for car it will be taken as 4.
13.srt	00:22:34.930 --> 00:22:39.040	which are the indices to all these different categories.
13.srt	00:22:40.900 --> 00:22:52.480	So, you find that when you multiply this vector with thismatrix w and this is my bias vector w naught, I get this output which is the score.
13.srt	00:22:54.720 --> 00:23:03.030	And over here because this isan image of a bird you find that the bird score is maximum.
13.srt	00:23:16.400 --> 00:23:25.980	If these parameters are not properly tuned, then it it is possible that the score for car will be might be more than the score of bird in which case my classification that I get the linear machine the classification it gives that is an erroneous classification and I should be able to modify the parameters or update the parameters.
13.srt	00:23:27.370 --> 00:23:39.270	So, in order to do this what I go for is I define a loss functionok, I will come to this a bit later.
13.srt	00:23:40.300 --> 00:23:49.550	So, what is the loss function?
13.srt	00:24:21.260 --> 00:24:39.700	So, I will As I said that if my classification is not correct or even if my classification is correct, but I want to have better confidence over the classification or in other words I want that if the vector x i actually belongs to category omega i or the index is y i, then in the in the score function S y i should be greater than S j for all j not equal to y i this is what I want and just that S i is more than S j I may not be satisfied with this because I want to have more confidence over this classification.
13.srt	00:24:40.180 --> 00:24:48.930	So, for that I may like to have S y i minus S j should be greater than some delta.
13.srt	00:24:49.760 --> 00:24:51.590	So, that is your confidence factor.
13.srt	00:24:52.850 --> 00:25:05.000	That means, it is not only that S i S y i should be more than S j, but S y i should be more than S j at least by a factor of delta.
13.srt	00:25:06.470 --> 00:25:12.780	And only then I will be satisfied and in such case I will assume that my loss function will be equal to 0.
13.srt	00:25:14.540 --> 00:25:26.280	In other cases I will assume that my loss function will not be 0, but I will have a finite loss function and that loss value I want to minimize to get the correct classification.
13.srt	00:25:27.520 --> 00:25:37.920	I will come to this loss function in detailsin our previous class, but before that let me just tell you what isthe interpretation of this linear machine.
13.srt	00:25:39.180 --> 00:25:56.460	So, as we have seen so far that in this linear machine what we are doing is for every class or for every category.
13.srt	00:25:56.790 --> 00:26:26.350	I have a vector which is a row inthe vector w and for this input vector I am taking the dot product of this input vector with the ith row of my matrix w the parameter matrix w and this dot product gives me the score along with the bias term the score for the ith class of the given vector I .
13.srt	00:26:27.420 --> 00:26:35.860	And, as you know that when you take the dot product of two different vectors, the dot product gives you a measure of similarity.
13.srt	00:26:36.560 --> 00:26:43.710	That is if the two vectors are similar, then the dot product will be higher, if the two vectors are dissimilar, then the dot product will be lower.
13.srt	00:26:44.770 --> 00:26:55.050	So, going by that I can consider this linear machine the operation given by a linear machine is something like a template matching operation.
13.srt	00:26:57.340 --> 00:27:04.830	Or in other words, if row in the parameter vector in the parameter matrix W is a template of that corresponding class.
13.srt	00:27:05.970 --> 00:27:10.480	And you are trying to find out you are trying to match your input vector with that template.
13.srt	00:27:11.520 --> 00:27:34.670	And in fact, in CIFAR 10database when you train the linear classifiersyou can see that these are the different classes different categories whichthe CIFAR 10 database contains you have the category of plane, car, bird, cat, deer, dog, frog, horse, sheep and truck.
13.srt	00:27:35.610 --> 00:27:57.930	And, once the linear machine is properly trained it isproperly trained then all the vectors of your weight matrix W if you fold it back to form an image then you will find that those vectors represent the templates of these different categories.
13.srt	00:28:06.740 --> 00:28:13.930	Say for example, here this is the a plane, this is the template of a car, this is the template of horse, this is the template of truck and so on.
13.srt	00:28:14.820 --> 00:28:21.640	So, these weight vectors that I get for different classes are nothing but these templates.
13.srt	00:28:22.150 --> 00:28:27.740	And what the linear machine is doing is it is matching your input vector with these templates.
13.srt	00:28:28.590 --> 00:28:36.690	So, I will stop here today in your in our next lecture we will talk about the loss functions details of the loss functions.
13.srt	00:28:36.970 --> 00:28:42.020	and how these loss functions can be used for designing of the linear machine.
13.srt	00:28:42.690 --> 00:28:42.990	Thank you.
22.srt	00:00:00.610 --> 00:00:17.820	Hello, welcome to the NPTEL online certification course on deep learning.
22.srt	00:00:31.940 --> 00:00:32.250	.
22.srt	00:00:32.250 --> 00:00:39.179	We are discussing about the multilayer perceptron or feed forward neural network.
22.srt	00:00:39.179 --> 00:00:59.179	So, in your previous class we have given an introduction to the multilayer perceptron or feed forward neural network and we have also started our discussion on training a neural network or the algorithm which is known as back propagation learning.
22.srt	00:01:01.509 --> 00:01:17.590	So, in the previous class we have considered a back propagation learning algorithm or back propagation training procedure for a single layer neural network having only one neuron that is a function which is having only one output.
22.srt	00:01:19.000 --> 00:01:26.810	And while discussing that we also have assumed that the neuron does not impose any nonlinearity.
22.srt	00:01:33.199 --> 00:01:43.699	That means, given the training vector x and w being the weight vector of the neural network the output simply becomes W transpose X and because the neural network had only one output.
22.srt	00:01:44.599 --> 00:01:49.310	So, the output could be either positive or negative.
22.srt	00:01:50.089 --> 00:02:01.549	So, if it is positive thenthe sample input vector is classified to one class, if it is negative it is classified to another class.
22.srt	00:02:04.310 --> 00:02:27.800	And we consider the case that the training vectors are given as pair ordered pair given in the form x i y i where x i is the training vector and y i indicates the index to the class to which the x i belongs and because it was a two class problem.
22.srt	00:02:28.610 --> 00:02:34.909	So, we assumed that y i could assume either a value 0 or a value 1.
22.srt	00:02:36.139 --> 00:02:51.819	Whereas, W transpose X when I compute W being the weight vector and X being the feature vector or the input vector, it is not necessary that W transpose X will always be either 1 on 0 or 0.
22.srt	00:02:52.259 --> 00:02:57.289	In fact, it will be a real number, it may be 0, it may be greater than 0, it may be less than 0.
22.srt	00:02:58.210 --> 00:03:05.370	So, our classification rule was that if it is greater than 0, it is belonging to one class, if it is less than 0, it belongs to another class.
22.srt	00:03:06.379 --> 00:03:12.830	But, coming to the neural network the output should be either 1 or 0.
22.srt	00:03:13.340 --> 00:03:20.860	That means, if W transpose X is greater than 0, the output should be 1 indicating that it belongs to class say omega 1.
22.srt	00:03:21.759 --> 00:03:28.219	If the output is less than 0, then it should be truncated to 0 indicating that it belongs to another class.
22.srt	00:03:28.730 --> 00:03:36.770	So, that our class index 0 and 1 matches with whatever you get from the as output of the neuron .
22.srt	00:03:37.969 --> 00:03:57.150	And, in order to do that we also have seen before that when we have an implemented an OR function or AND function or XOR function with the help of neurons that the kind of nonlinearity that we have used were simple threshold nonlinearity.
22.srt	00:03:58.210 --> 00:04:07.890	That means, if W transpose X beta is greater than or equal greater than 0, we have put the output to be 1, the moment it is less than 0.
22.srt	00:04:08.180 --> 00:04:11.699	the output was clamped or truncated at 0.
22.srt	00:04:11.909 --> 00:04:15.469	That means, the threshold value was set at W transpose X equal to 0.
22.srt	00:04:16.120 --> 00:04:23.959	So, the moment the output of the neuron becomes more than 0, it is clamped at 1, if it is less than 0 the output is set to 0.
22.srt	00:04:25.550 --> 00:04:39.730	Now, here you remember that when we talk about the training of the neural network or updating the weights of the neural network, our training procedure makes use of the gradient descent procedure.
22.srt	00:04:40.670 --> 00:04:56.009	That means, we have to take the gradient of the error function or the gradient of the loss function and the loss functions of the error functions are computed based on the feature vectors which are misclassified.
22.srt	00:04:56.800 --> 00:05:11.939	If the feature vectors which are correctly classified for them I do not have to take any action or I do not have to correct or update the weight vectors, but the feature vectors which are misclassified for them with them I have to define a loss function.
22.srt	00:05:12.240 --> 00:05:21.750	or I have to define an error function and the weights are updated in such a way that the loss or the error is minimized.
22.srt	00:05:22.770 --> 00:05:42.129	And for that in gradient descent procedure what you do is you take the gradient of the loss function or you take the gradient of the weight function with respect to the weight vector W. And for that if I want to take the gradient it is necessary that your loss function .
22.srt	00:05:42.350 --> 00:05:48.390	or the error function should be differentiable because the gradient is nothing, but a differential operator.
22.srt	00:05:49.720 --> 00:05:57.170	Whereas, if I put the output nonlinearity which is also known as the activation function of the neurons.
22.srt	00:05:58.140 --> 00:06:10.280	So, if the activation function of the neurons is a threshold function a threshold function is not differentiable because I have an abrupt change at W transpose X equal to 0.
22.srt	00:06:11.440 --> 00:06:16.200	Hence the threshold function is not differentiable though it is a very very simple nonlinearity.
22.srt	00:06:17.460 --> 00:06:28.290	So, instead of using the threshold function a sort of nonlinearity which is used is what is thesigmoidal function.
22.srt	00:06:28.290 --> 00:06:34.840	We have also talked about the sigmoidal function when we have discussed about the nonlinearity.
22.srt	00:06:47.650 --> 00:06:54.150	So, the sigmoidal function is simply given as say I can represent sigmoidal of some function s some argument s is equal to 1 over 1 plus e to the power minus s .
22.srt	00:06:54.150 --> 00:07:11.790	So, here you find that as s is equal to 0 at s is in our case this s is nothing, but W transpose X which is the weighted sum of the feature vector components weighted by the corresponding weight component ok.
22.srt	00:07:11.790 --> 00:07:14.410	So, s is this .
22.srt	00:07:14.590 --> 00:07:18.590	So, at s equal to 0 sigma s is equal to 0.5 which is over here .
22.srt	00:07:20.330 --> 00:07:40.260	And, as s goes on increasing say as s tends to infinity sigma x sigma s tends to plus 1 and as s tends to minus infinity sigma s tends to be 0.
22.srt	00:07:40.960 --> 00:07:48.480	So, that is what is given by this particular curve and at s equal to 0 sigma s is equal to 0.5.
22.srt	00:07:49.470 --> 00:08:09.510	So, you find that as s increases on the positive side, the sigmoidal function asymptotically reaches value equal to 1 and as s decreases on the negative side, the sigmoidal function asymptotically reaches value equal to 0.
22.srt	00:08:10.960 --> 00:08:21.410	The other advantage is this is a differentiable function and also for when s is sufficiently high.
22.srt	00:08:21.900 --> 00:08:25.330	to be positive, I can consider the output to be equal to 1.
22.srt	00:08:26.130 --> 00:08:41.830	And if it is sufficiently low that is on the negative side, I can consider the output of the neural network or output of the sigmoidal function to be 0 indicating whether the class is omega 1 or class is omega 2.
22.srt	00:08:42.660 --> 00:08:47.130	The other advantage that you find that if I take the derivative of sigma.
22.srt	00:08:52.019 --> 00:09:11.019	So, I my sigma s was 1 over 1 plus e to the power minus s. So, if I take the derivative of sigma s with respect to sig s this simply becomes sigma s into 1 minus sigma s which is also a very very simple form.
22.srt	00:09:11.590 --> 00:09:19.159	So, you can take the derivative of this with respect to s and you can verify that actually this is the derivative that you get.
22.srt	00:09:25.179 --> 00:09:29.360	So, these are the other advantages or many of the advantages of using sigmoidal function as a non-linearity or as an activation function of the neural network right.
22.srt	00:09:31.090 --> 00:09:43.450	So, given this so, again I consider a single output, but now this neuron is with a non-linear activation function and the non-linearity I consider is a sigmoidal function.
22.srt	00:09:43.600 --> 00:09:50.830	So, given this now how can such a single layer neural network can be trained.
22.srt	00:09:51.149 --> 00:09:55.259	So, as before I assume that my training samples are given as.
22.srt	00:09:56.439 --> 00:10:04.299	ordered pairs x i y i, x i being the feature vector and y i is the class level of that feature vector.
22.srt	00:10:05.819 --> 00:10:24.129	Here when I feed in this input vector x i to this neural network, I get an output y i hat in the previous case without nonlinearity this y i hat was simply W transpose x i.
22.srt	00:10:25.389 --> 00:10:28.879	But now I impose a nonlinearity by the sigmoidal function.
22.srt	00:10:29.169 --> 00:10:35.500	So, y i hat is now sigma of W transpose X i right.
22.srt	00:10:36.190 --> 00:10:44.210	So, this is my y i hat whereas, the class level for this X i is given as y i.
22.srt	00:10:45.220 --> 00:10:52.289	So, as a result I have an error which is given by y i hat minus y i.
22.srt	00:10:53.500 --> 00:11:02.399	So, this is the error if my output y i hat does not agree with the class level y i that is given.
22.srt	00:11:04.269 --> 00:11:16.850	So, using this error I can define again a loss function or an error function which is nothing but e is equal to half of y i hat minus y i square.
22.srt	00:11:17.110 --> 00:11:25.820	So, you find that now the procedure that I am following is a stochastic optimization procedure.
22.srt	00:11:26.429 --> 00:11:37.120	If I take the sum of this error over all the samples i equal to 1 to n the kind of optimization procedure that I will be using is a batch optimization procedure.
22.srt	00:11:37.769 --> 00:11:41.279	So, if I take single vectors it is a stochastic optimization procedure.
22.srt	00:11:41.559 --> 00:11:44.359	So, let us now continue with the stochastic optimization.
22.srt	00:11:45.379 --> 00:11:57.669	So, my error is given by half of y i hat minus y i square which is nothing but half of sigmoidal function of W transpose X i minus y i square.
22.srt	00:11:59.089 --> 00:12:07.379	So, now if I take the gradient of this error function or this loss function the gradient with respect to W.
22.srt	00:12:07.929 --> 00:12:11.179	you find that the gradient will be given by this.
22.srt	00:12:13.409 --> 00:12:32.570	You find that in the earlier case when our y i hat in absence of non-linearity absence of non-linearity was y i hat minus y i square half of this, okay.
22.srt	00:12:38.950 --> 00:13:05.450	Then the gradient of sorry this is not sorry y i hat this is when my error was e is equal to half of y i hat minus y i square, then gradient of e with respect to w was simply y i hat minus y i times x i this was without non-linearity.
22.srt	00:13:05.450 --> 00:13:09.470	Now, as we have imposed non-linearity which is a sigmoidal function.
22.srt	00:13:11.069 --> 00:13:41.509	And, we have said just before that for sigmoidal function if you take the gradient if you take the derivative with respect to argument it becomes sigmoidal s into 1 minus sigmoidal s. So, here just before because of that if I take the gradient of E gradient of the error function the gradient of error function becomes y i hat into 1 minus y i hat where this y i hat is nothing, but my sigmoidal which is sigma times.
22.srt	00:13:41.960 --> 00:13:47.110	W transpose X i and the other one term simply comes from here.
22.srt	00:13:48.580 --> 00:13:55.899	This is basically gradient of E with respect to W without the sigmoidal function or without the non-linearity.
22.srt	00:13:55.899 --> 00:14:05.730	So, this is the gradient of E or gradient of the error function that we get when the sigmoidal non-linearity is imposed.
22.srt	00:14:05.730 --> 00:14:13.009	And once you do that now my weight updation rule following the gradient descent procedure .
22.srt	00:14:13.910 --> 00:14:30.660	simply becomes W gets W minus eta again the rate of convergence, convergence factor into y i hat into 1 minus y i hat into y i hat minus y i times x i.
22.srt	00:14:32.210 --> 00:14:44.370	This is myweight updation rule in case I have a single output layer node or a single layer neuron with only one node.
22.srt	00:14:45.740 --> 00:15:01.860	and by assuming non-linearity of the neurons, ok. And here again you can compare that this is a rule which is similar to same perceptron algorithm that we considered earlier, hence the perceptron network.
22.srt	00:15:01.860 --> 00:15:15.360	So, the network that we are talking about right now is what is known as a single layer perceptron, because I have only one layer in this neural network and that too I have only one node in the neural network to implement.
22.srt	00:15:16.320 --> 00:15:17.290	are two class problem.
22.srt	00:15:18.040 --> 00:15:25.360	If the number of classes are more than 2, then I have to go for more than 2 neurons, but again that number of layers will be 1.
22.srt	00:15:26.180 --> 00:15:30.600	So, let us see such a neural network now.
22.srt	00:15:31.730 --> 00:15:42.529	So, now I will consider a neural network again a single layer neural network, but the number of neurons in the output layer is more than 1.
22.srt	00:15:42.529 --> 00:15:47.000	That means, we are considering multiple classes multi class problem.
22.srt	00:15:47.310 --> 00:15:49.420	where the number of classes is more than 2.
22.srt	00:15:50.980 --> 00:16:05.800	So, here as we said before that I will have 2 layers, one of the layer is an input layer and this input layer does nothing other than simply passing the input to the output.
22.srt	00:16:06.029 --> 00:16:16.700	So, if I take this i th neuron, i th neuron gets x i which is i th component of the feature vector x and simply passes this to the output.
22.srt	00:16:17.820 --> 00:16:18.029	Ok.
22.srt	00:16:18.450 --> 00:16:28.210	So, the output of this neuron is also X i that is what this input neurons does, it simply passes the input to the output nothing else it is just for an interface.
22.srt	00:16:29.360 --> 00:16:32.790	The actual classification is done by this output layer neuron.
22.srt	00:16:34.460 --> 00:16:48.440	And when I discuss this I also assume that these output layer neurons have non-linearity as activation function and as we have done before just in the previous problem.
22.srt	00:16:49.529 --> 00:16:54.090	The non-linearity we consider in this case is sigmoidal non-linearity or a sigmoidal function right.
22.srt	00:16:54.090 --> 00:17:14.930	So, if I consider an ith neuron, the output of the ith neuron in the input layer is x i which is ith component of my feature vector x ok. And this x i is fed to the inputs of all the neurons in the output layer.
22.srt	00:17:14.930 --> 00:17:20.559	So, in the output layer now if I consider a jth neuron.
22.srt	00:17:22.339 --> 00:17:32.759	So, this i th neuron in the input layer is connected to the j th neuron to the output layer wide a connection weight which is W ij.
22.srt	00:17:33.960 --> 00:17:47.129	You find that when we introducedthe feed forward neural network in its totality we had put an index a superscript which was k to indicating the layers right.
22.srt	00:17:52.789 --> 00:17:57.529	So, superscript k indicates that this is a connection from the i th layer from the ith node in k minus first layer to the jth node in kth layer.
22.srt	00:17:58.529 --> 00:18:02.079	Now, since we are talking about a single layer neuron neural network.
22.srt	00:18:02.079 --> 00:18:08.619	So, I will not use that superscript k because it is simply connection from input layer to the output layer that is known.
22.srt	00:18:09.130 --> 00:18:12.500	So, this superscript k I will not use for this purpose.
22.srt	00:18:12.500 --> 00:18:28.589	So, let us remove this superscript k. So, I have this situation that x i which is the output of the ith node in the input layer is connected to the jth node in the output layer.
22.srt	00:18:28.879 --> 00:18:31.009	through a connection weight x ij.
22.srt	00:18:31.700 --> 00:18:37.990	So, every node in the input layer is connected is feeding input to every node in the output layer of the jth layer.
22.srt	00:18:38.889 --> 00:18:59.730	As a result the weighted sum of all the inputs collected by the jth node in the output layer is given by theta j is equal to w ij times x i .
22.srt	00:19:00.409 --> 00:19:10.549	where i varies from 1 to d assuming d to be the dimensionality of the feature vectors the input feature vector has got d number of components.
22.srt	00:19:32.219 --> 00:19:41.269	So, this is the sum of or weighted sum of the inputs or this is nothing, but if I represent all the weights from the input layer to the jth layer by say W j the weights from all the nodes from the input layer to the jth layer to the jth node in the output layer if those connection weights are represented by a vector W j, this expression theta j is nothing but W j transpose x.
22.srt	00:19:42.109 --> 00:19:48.929	So, I can also put in this vector form or this is a scalar form, but both of them are same.
22.srt	00:19:50.869 --> 00:19:53.799	So, that is the weighted sum of the inputs.
22.srt	00:19:54.399 --> 00:19:59.250	And then we said that every neuron has a sigmoidal activation function.
22.srt	00:19:59.980 --> 00:20:10.669	So, the output O j that I am getting from the jth neuron is given by a sigmoidal function of theta j which is nothing but 1 upon 1 plus e to the power minus theta j .
22.srt	00:20:12.109 --> 00:20:12.409	right.
22.srt	00:20:13.519 --> 00:20:23.629	Again you remember that our input vectors are given by x i y i where y i is the class node.
22.srt	00:20:25.329 --> 00:20:43.269	So, if this input x is said that it belongs to class j that means, we we know that what is the output of the jth neuron which should be the output of the jth neuron when this x is fed to the input of the neural network.
22.srt	00:20:44.109 --> 00:20:56.230	And, that is what we are representing by T j which is the expected output or the true class of the input vector x which is fed to the neutral network.
22.srt	00:20:57.099 --> 00:21:05.799	But, O j is the actual value that you are getting from the j th node of the neutral network when you are feeding the same input vector x.
22.srt	00:21:06.500 --> 00:21:10.750	So, as a result you have an error which is O j minus T j.
22.srt	00:21:14.709 --> 00:21:21.619	So, as before we define the sum of squared error which is nothing but O j minus T j square because now output is a vector right.
22.srt	00:21:23.259 --> 00:21:36.209	For every input x I will have if there are say m number of classes I have j number of m number of nodes in the output layer every output layer node will give me some value.
22.srt	00:21:37.699 --> 00:21:46.709	So, if this input vector x belongs to jth class only output of the jth node in the output layer should be equal to 1.
22.srt	00:21:46.979 --> 00:21:48.279	all other outputs should be 0.
22.srt	00:21:49.189 --> 00:22:02.359	So, that is what is my target vector and using this what is my target vector and what is the actual vector that I get we define what is this sum of square data .
22.srt	00:22:02.359 --> 00:22:15.429	So, again for training this neural network or for learning I use the back propagation learning algorithm for that what you have to find out is the gradient for using gradient descent approach.
22.srt	00:22:17.859 --> 00:22:30.819	So, if I take the gradient of E which is the loss function or the error function with respect to W ij which is the weight component com component connecting the ith node from the input layer to the jth node in the output layer.
22.srt	00:22:31.529 --> 00:22:50.179	So, this gradient del E del W ij I can compute this using chain rule it is del E del oj where oj is a function of theta j ok because oj is nothing, but .
22.srt	00:22:50.399 --> 00:22:51.279	sigma theta j.
22.srt	00:22:51.649 --> 00:23:00.619	So, I compute del o j upon del theta j into del theta j again del theta j is a function of w i j.
22.srt	00:23:01.689 --> 00:23:04.879	So, del theta j upon del y jdel w i j.
22.srt	00:23:06.499 --> 00:23:22.019	And through this chain rule you find that what I get as del e del w i j is nothing, but o j minus t j o j is the output of the j th node the actual output of the j th node.
22.srt	00:23:22.709 --> 00:23:24.359	T j is the target output.
22.srt	00:23:25.119 --> 00:23:44.439	So, del E upon del W i j becomes O j minus T j into O j into 1 minus O j times X i where X i is the ith component of the input vector or X i is the output of the ith neuron in the input layer.
22.srt	00:23:45.919 --> 00:23:47.819	So, this is the gradient that you get.
22.srt	00:23:49.019 --> 00:23:53.529	So, using the weight updation ruleusing the gradient descent procedure.
22.srt	00:23:54.339 --> 00:24:17.639	The weight updation rule for the weight component W ij as before will be simply W ij is equal to W ij minus some constant the convergence rate eta into O j minus T j into O j into 1 minus O j times x i ok, this is the weight updation rule.
22.srt	00:24:18.629 --> 00:24:25.559	So, if you do it for every i and every j you are updating.
22.srt	00:24:26.189 --> 00:24:42.149	every component of the weight vectors which are connecting the outputs of the input layer nodes to the inputs of the output layer nodes .
22.srt	00:24:42.149 --> 00:24:47.769	So, once you do this for all ij, so all the weight components.
22.srt	00:24:57.499 --> 00:25:03.249	Now, you find that we have two sets multiple sets of weights right, because for every output node I have a weight vector So, since there are m number of nodes here instead of a single vector I have a matrix.
22.srt	00:25:03.599 --> 00:25:26.649	So, I can put this matrix as W, where W will have say m number of rows andright d number of columns ok, where every row corresponds to weight vector .
22.srt	00:25:28.619 --> 00:25:31.949	of a particular class right.
22.srt	00:25:32.539 --> 00:25:48.039	So, later on when we talk aboutmultiple multiple multi layer perceptron with multiple nodes at the output very often we will use this matrix convention other than singlevector convention.
22.srt	00:25:49.949 --> 00:25:57.789	So, this is the weight updation rule or the training procedure for a two layer network having multiple nodes in the output layer.
22.srt	00:25:58.499 --> 00:25:58.709	right.
22.srt	00:26:01.479 --> 00:26:17.689	So, given this now we can go for training of thefeed forward neural network having multiple number of hidden layer nodes and also multiple number of output nodes.
22.srt	00:26:29.839 --> 00:26:37.699	So, for that the network that we have considered was having this kind of architecture which also we said before that I have an output layer which I put as kth layer the input layer over here.
22.srt	00:26:38.489 --> 00:26:50.049	So, this is the output layer which is kth layer I am putting it as capital K, this is the input layer and as we said before the function of the input layer is simply pass the input vector to its output.
22.srt	00:26:50.519 --> 00:27:02.309	So, which we are representing as jas 0th layer in between a kth layer represented by lowercase k and as we said before that we will also assume .
22.srt	00:27:02.649 --> 00:27:23.069	that from a node i in K plus first layer to a node j in Kth layer, I have a connection weight which is given by W i j K. So, this is the convention that I will use.
22.srt	00:27:24.209 --> 00:27:35.789	I will also use the convention that in the Kth layer the number of nodes is given by M k. So, M k is the number of nodes in the Kth layer.
22.srt	00:27:36.569 --> 00:27:51.399	So, while doing this in the output layer which is capital K the number of nodes will be given by M capital K which is same as the number of categories or the number of classes we will consider.
22.srt	00:27:53.769 --> 00:27:58.379	Now, unlike in the previous case here I will have two distinct situations.
22.srt	00:27:59.029 --> 00:28:09.019	One is as we said that we can only compute the error at the output because there only at the output I know what is the target.
22.srt	00:28:09.959 --> 00:28:13.759	I cannot compute error at any of these layers.
22.srt	00:28:14.679 --> 00:28:20.619	I cannot compute error here, I cannot compute error here because here I do not know what are the targets.
22.srt	00:28:21.399 --> 00:28:35.959	That is the reason these all these layers are known as hidden layers and this is the layer where the output is visible and the output is known for known classes, this is a output layer or visible layer all rest of the layers are hidden layers.
22.srt	00:28:40.119 --> 00:28:53.439	So, we will see that when we talk about the the back propagation learning of such a multi layer perceptron or a feed forward neural network, then we will have a little difference because now I have a number of hidden layers which I did not have earlier.
22.srt	00:28:55.369 --> 00:29:04.239	So, error that you computed the output that can directly propagated to the connections between the output layer and the hidden layer just before that.
22.srt	00:29:05.229 --> 00:29:10.059	So, here computing the gradient of the error is straightforward.
22.srt	00:29:11.279 --> 00:29:27.299	But, when we try to update the weights of the layers in between hidden layers, then I have to see that how this error actually propagates to this level and that is where we will have a little bit of mathematics.
22.srt	00:29:28.349 --> 00:29:36.719	So, we will talk about this training or backpropagation learning of the feed forward neural network in our next class.
22.srt	00:29:37.129 --> 00:29:37.439	Thank you.
23.srt	00:00:00.610 --> 00:00:17.809	Hello, welcome to the NPTEL online certification course on deep learning .
23.srt	00:00:31.929 --> 00:00:32.030	.
23.srt	00:00:32.030 --> 00:00:49.820	We have started our discussion on the neural network particularly the feed forward neural network and in the previous class we have discussed about or we have started our discussion on learning in a feed forward neural network .
23.srt	00:00:50.469 --> 00:00:55.420	We have discussed about learning in a single layer perceptron.
23.srt	00:00:55.420 --> 00:01:01.150	In today's class we will talk about the back propagation learning in multi layer perceptron .
23.srt	00:01:01.549 --> 00:01:03.899	or multi layer feed forward network.
23.srt	00:01:05.250 --> 00:01:20.539	So, just to recapitulate what we did in our previous lecture is we had taken single layer neural neuronsneural networks with nonlinearity as well as without nonlinearity at the output.
23.srt	00:01:21.569 --> 00:01:33.949	So, when we have considered a single layer neural network withnonlinearity at the output and the nonlinearity that we have considered was a sigmoidal function.
23.srt	00:01:34.329 --> 00:01:41.969	as given in the right hand side in this slide .
23.srt	00:01:41.969 --> 00:02:05.239	So, this is the sigmoidal function that we have considered and for such a kind of network the output of the neuron which is given as y i hat is equal to sigma of W transpose X, where W is the weight vector at the input side of the neuron and X i is the input vector .
23.srt	00:02:06.439 --> 00:02:26.349	So, for training you remember that we have said that we obtain the training vectors as ordered pairs given as x i y i, where x i is the feature vector and y i is the class to which this feature vector belongs.
23.srt	00:02:27.280 --> 00:02:38.379	And when I have a single output in the neural network or only one neuron at the output layer actually we are considering a two class problem.
23.srt	00:02:39.150 --> 00:02:51.449	And, in two class problem this y i can take value of 0 or 1, 0 means it belongs to one class and 1 means it belongs to another class.
23.srt	00:02:52.509 --> 00:03:09.680	So, given this we have seen that the training algorithm or the weight updation algorithm wasobtained as W that is the weight vector is updated as W minus.
23.srt	00:03:10.040 --> 00:03:37.689	some eta times y i hat into 1 minus y i hat into y i hat minus y i times x i, where x i is the input vector and y i hat is the computed output and y i is the desired output, it is the class index of the class to which x i belongs.
23.srt	00:03:41.400 --> 00:03:47.700	So, this is what we have obtained for a single output with nonlinearity where nonlinearity was a sigmoidal function.
23.srt	00:03:49.469 --> 00:04:06.110	Then we had moved on to single layer network with multiple outputs and when we have multiple outputs then obviously, I have to consideran weight weight of the form W ij.
23.srt	00:04:12.500 --> 00:04:26.180	So, what I have considered is from the input layer if I take an ith neuron And, we have considered that this i th neuron in the input layer is connected to the j th neuron of the output layer through a connection weight which is given by W ij .
23.srt	00:04:26.180 --> 00:04:37.220	So, training in this case means that I have to find out the optimal values of W ij for all values of i and j .
23.srt	00:04:37.220 --> 00:04:43.370	So, as you vary the index i that means, I am considering different neurons at the input layer as I vary.
23.srt	00:04:43.539 --> 00:04:49.250	the index j that means, I am considering the connection to all neurons in the output layer.
23.srt	00:04:50.620 --> 00:05:13.909	And as before if I consider the output of the jth neuron which we are putting here as o j, o j is a sigmoidal function of theta j, where theta j is nothing but weighted sum of all the input feature components or in other words this is the dot product.
23.srt	00:05:14.329 --> 00:05:21.860	of W ij for all values of i the vector that I get with the input vector x.
23.srt	00:05:23.029 --> 00:05:44.360	And given this we had defined an error function or a loss function which is half of o j minus t j square where t j is the target output or I can say this t j is nothing but y j .
23.srt	00:05:44.360 --> 00:05:47.110	So, the t j that we have considered it is nothing but y j .
23.srt	00:05:47.389 --> 00:05:52.230	that is the actual class belongingness ofthe feature vector.
23.srt	00:05:54.660 --> 00:06:03.610	So, what we need to do is we need to minimize this error function with respect to W ij or this loss function with respect to W ij.
23.srt	00:06:04.650 --> 00:06:08.530	So, for that again we are using the gradient descent approach.
23.srt	00:06:08.689 --> 00:06:13.269	So, I have to find out what is the gradient of this loss function with respect to the weights.
23.srt	00:06:17.830 --> 00:06:27.470	So, I compute del E del W ij which is equal according to chain rule comes out to be del E del o j into del o j del theta j into del theta j del w i j.
23.srt	00:06:28.129 --> 00:06:36.439	And if you compute this, this comes as o j minus t j into o j into 1 minus o j times x i.
23.srt	00:06:37.540 --> 00:06:50.970	And given this my weight updation rule in this case becomes w i j gets w i j minus theta times o j minus t j into o j into 1 minus o j times x i .
23.srt	00:06:51.240 --> 00:07:03.050	where X i is the ith component of the input vector and W i g is the connection weight from the ith node in the input layer to the jth node in the output layer.
23.srt	00:07:04.470 --> 00:07:16.400	So, this is the updation rule that we get within a single layered perceptron when I have number of outputs or multiple number of outputs.
23.srt	00:07:18.700 --> 00:07:23.430	Now, let us go to a multi layer perceptron.
23.srt	00:07:24.910 --> 00:07:47.210	So, as we justindicated in the previous class that when I consider a multi layer perceptron or multi layer feed forward network, then obviously, I have to have an input layer which receives the input vector and I have to have the output layer which tells you the class or class belongingness of the input vectors.
23.srt	00:07:54.480 --> 00:07:56.379	So, if I have say C number of classes, then I will have C number of neurons at the output layer.
23.srt	00:07:56.410 --> 00:07:58.390	So, accordingly I will have c number of outputs.
23.srt	00:07:59.689 --> 00:08:10.960	And if a feature vector belongs to say class 5, then output of the fifth neuron should be high and the output of all other neurons should be low.
23.srt	00:08:12.450 --> 00:08:24.650	In this case in this particular example we are assuming that there are k number of layers where capital K isthe output layer.
23.srt	00:08:26.350 --> 00:08:39.379	At the input layer we are considering that this is zeroth layer and we said in the previous class that the neurons in the zeroth layer simply passes the input to its output, it does not perform any other function.
23.srt	00:08:40.700 --> 00:08:55.149	Whereas, in all the hidden layers the neuronsperform two tasks every neuron takes the weighted sum of all the inputs that it receives from its previous layer.
23.srt	00:08:55.879 --> 00:09:03.799	And, then computes a non-linear function over it and the non-linearity that we are considering over here is nothing, but a sigmoidal non-linearity.
23.srt	00:09:03.799 --> 00:09:13.069	And, if I consider any layer say kth layer where this k I represent as a lowercase in lowercase.
23.srt	00:09:13.069 --> 00:09:24.639	So, every kth layer passes its output to k plus first layer and it receives inputs from k minus first layer.
23.srt	00:09:26.559 --> 00:09:39.579	So, every node in the K minus first layer passes output to every node in the Kth layer and every node in the Kth layer passes the output to every node in the K plus first layer.
23.srt	00:09:40.839 --> 00:09:56.199	Now coming to the error function or the loss function which we want to optimize while training this neural network,you can easily imagine that we can only compute the error function or the loss function at the output layer.
23.srt	00:09:57.069 --> 00:10:02.709	Because, it is only at the output layer I know what is my target output T j.
23.srt	00:10:04.499 --> 00:10:25.839	The reason being if I say that a feature vector a training vector belongs to jth class I know that T j should be high or ideally T j should be 1 and all other outputs except T j or except the output of the jth neuron in the output layer should be low or ideally they should be 0.
23.srt	00:10:26.979 --> 00:10:27.849	So, this is known .
23.srt	00:10:28.629 --> 00:10:38.819	And, as the expected output or the ground truth at the output layer is known, I can only compute the error function at the output layer.
23.srt	00:10:39.999 --> 00:10:52.999	I cannot compute error function in any of the layers any other layers the reason being I do not know what is the expected output or what is the target output at the outputs of any other layers.
23.srt	00:10:53.699 --> 00:11:03.209	And, that is the reason all other layers except the output layer and the input layer of course, are known as the hidden layers because I do not know what is their outputs.
23.srt	00:11:04.809 --> 00:11:08.579	So, given this now let us see that how we can train this neural network.
23.srt	00:11:10.229 --> 00:11:22.929	So, over here the training unlike in case of a single layered neural network where training was very simple because I had to update the connection weights from the input layer to the output layer.
23.srt	00:11:23.899 --> 00:11:35.039	Now in this case the training for the output layer and training for the hidden layers will be slightly different because I can compute the error at the output layers.
23.srt	00:11:35.369 --> 00:11:53.829	And, once I compute the error at the output layers, I can back propagate that error through the gradient descent approach to the connection weights in between this K minus first layer K capital that means, it is the layer just before the output layer.
23.srt	00:11:54.989 --> 00:12:04.789	So, I can back propagate the error for updation of the weight vectors from K minus first layer to Kth layer.
23.srt	00:12:08.129 --> 00:12:22.809	But, want to update any of the weight vectors in between the hidden layers, you find that I do not have I cannot compute directly what will be the error at the output of any of the hidden layers.
23.srt	00:12:23.669 --> 00:12:38.619	So, following chain rule I have to get the feedback or I have to back propagate the effect of the output error error that you can compute at the output layer to the hidden layers and that we have to use .
23.srt	00:12:38.799 --> 00:12:45.609	for updation of the weight vectors in between the hidden layers following our gradient descent approach.
23.srt	00:12:46.049 --> 00:12:50.769	So, let us see how we can do it .
23.srt	00:12:50.769 --> 00:13:08.939	So, given this you find that updation of the weight vectors at the output layer is almost similar to updation of the weight vectors in a single layer single layer neural network where we had multiple number of outputs .
23.srt	00:13:09.899 --> 00:13:16.019	So, here again I assume that this capital K indicates index of the output layer.
23.srt	00:13:17.459 --> 00:13:40.719	I take a jth neuron in the output layer and the output of the jth neuron is represented by O j k. And from our previous discussion you can recollect that O j k is a sigmoidal function, it is the sigmoidal function of weighted inputs of .
23.srt	00:13:41.149 --> 00:13:45.349	weighted sum of the inputs which are coming to the jth neuron.
23.srt	00:13:46.649 --> 00:13:54.399	So, that weighted sum of the inputs I am representing as W ijk x i k minus 1.
23.srt	00:13:55.549 --> 00:13:57.289	What is this x i k minus 1?
23.srt	00:13:58.099 --> 00:14:12.549	This k minus 1 indicates that this is the output of a neuron from the previous layer that is k minus first layer and this subscript i indicates that it is the output of the ith neuron.
23.srt	00:14:12.919 --> 00:14:14.029	in the k minus first layer.
23.srt	00:14:14.569 --> 00:14:45.479	So, I take this ith neuron in the k minus first layer, this ith neuron is connected to the jth neuron in the kth layer through a connection weight w i j k. So, the weighted sum of all the inputs to the jth neuron in the kth layer is given by w i j k into x i k, I have to take the sum over i is equal to 1 to m k minus 1, where m k minus 1 is the number of neurons in the k plus first layer.
23.srt	00:14:46.019 --> 00:14:52.479	So, this is the weighted sum and once I have this weighted sum then I have to compute the sigmoidal function over it.
23.srt	00:14:52.779 --> 00:15:19.859	So, the sigmoidal function is given by 1 over 1 plus e to the power minus theta j k where this theta j k is the weighted sum and that is the output of the j th node in the output layer which is o j k. So, once I have this output I know because all the vectors that we are feeding to the input of this neural network are the training vectors.
23.srt	00:15:20.719 --> 00:15:31.369	So, I know what is my target output at the jth node, because if the sample belongs to class j ideally T j should be equal to 1.
23.srt	00:15:32.459 --> 00:15:44.439	And this O j k is the output as computed by the neural network at a particular instant of time known as epoch that is the different steps of training.
23.srt	00:15:45.679 --> 00:15:52.799	So, I compute the sum of squared error which is given by O j k minus T j square take the summation.
23.srt	00:15:53.029 --> 00:16:02.689	over all j for j is equal to 1 to m k, m k is nothing but the number of nodes at the output layer.
23.srt	00:16:04.259 --> 00:16:09.199	So, that gives you the sum of squared errors.
23.srt	00:16:09.809 --> 00:16:18.709	We take half of this because as we have seen in our previous class also that we have to take the gradient descent and this is a squared error.
23.srt	00:16:19.689 --> 00:16:25.219	So, when I take the derivative this when I take the derivative 2 comes over here.
23.srt	00:16:25.219 --> 00:16:26.869	So, that 2 and half that gets cancelled.
23.srt	00:16:27.199 --> 00:16:32.479	So, that is the only reason that we are putting a scale factor which is half .
23.srt	00:16:32.479 --> 00:16:47.979	So, for updation of the weight vector W ij what I need to do is I have to take the gradient of the derivative of this error e with respect to weight vector W ij k .
23.srt	00:16:47.979 --> 00:17:01.089	So, as you take the derivative of the error or squared error withW ij k. So, this is what we just said I need to take the derivative del E del W ij k .
23.srt	00:17:01.929 --> 00:17:12.519	And, if I compute this again following the chain rule I get del E del W ijk is equal to del E del ojk.
23.srt	00:17:12.879 --> 00:17:25.209	The reason we are using thischain rule is that E is given as a function of oj that is the output W ijk comes indirectly.
23.srt	00:17:27.049 --> 00:17:32.959	So, we compute this derivative using the chain rule that is del E del ojk.
23.srt	00:17:33.449 --> 00:17:53.139	times del o j k del theta j k. So, if you remember that o j k is nothing, but sigmoidal function of theta j k. So, it is del o j k times del theta j k and theta j k is the weighted input or weighted sum of the inputs at the j th node.
23.srt	00:17:53.849 --> 00:17:59.500	So, that is given by w i j k times theta i k minus 1.
23.srt	00:18:04.819 --> 00:18:16.679	So, the last component in thischain becomes theta j k del w i j k. And if you compute this you find that del E del theta j k we said that one advantage yeah.
23.srt	00:18:18.869 --> 00:18:28.509	So, del E del o j k that simply becomes o j k minus t j because E was half of o j k minus t j square.
23.srt	00:18:28.719 --> 00:18:35.549	So, del E del o j k becomes o j k minus t j then del o j k del theta j k.
23.srt	00:18:36.549 --> 00:18:45.719	O j k is a sigmoidal function of theta j k so as given by this expression .
23.srt	00:18:45.719 --> 00:19:06.099	So, del O j k del theta j k becomes O j k into 1 minus O j k we said that the advantage of using sigmoidal function is the derivative becomes very simple which is of this form and del theta j k upondel theta j k del W i j k simply becomes O i k minus 1 .
23.srt	00:19:06.199 --> 00:19:13.329	1 because if I take the derivative of this with respect to del W i j k it simply simply becomes O i k minus 1.
23.srt	00:19:14.529 --> 00:19:33.179	So, if I put this O j k into O minus 1 minus O j k into O j k minus T j as delta j k that is why I am putting this as delta j k will become clear when we go for updating of the hidden layer weights .
23.srt	00:19:38.049 --> 00:19:53.419	So, if I put this then del E del W i j k simply becomes delta j k into O i k minus 1, where O i k minus 1 is the output of the ith node in the k minus first layer.
23.srt	00:19:54.609 --> 00:20:09.559	And given this the weight updation rule W i j k simply becomes W i j k minus eta times delta j k O i k minus 1, where this eta as we said before.
23.srt	00:20:10.039 --> 00:20:18.809	is nothing, but a constant which controls the rate of convergence orthe learning rate.
23.srt	00:20:21.179 --> 00:20:33.169	So, this is how I can update the weights of the output layer that is the layer between the output layer and the layer just before the output layer.
23.srt	00:20:35.089 --> 00:20:39.299	Now, let us say how we can update the weights of the hidden layer.
23.srt	00:20:41.059 --> 00:20:46.909	As we said that, I can only compute error at the output layers this is where I can compute the error.
23.srt	00:20:47.799 --> 00:20:59.179	But when I am updating the weights at the hidden layer, I cannot compute what is the error at the output of any of the hidden layers, because I do not know what is the target output over here.
23.srt	00:21:00.629 --> 00:21:14.869	So, whatever error I compute here that through back propagation has to be brought to this particular layer and in this layer I have to see what is the effect of this error and using that.
23.srt	00:21:15.109 --> 00:21:20.349	I have to go for weight updation again following the gradient descent approach.
23.srt	00:21:20.349 --> 00:21:23.939	So, let us see how we can do that.
23.srt	00:21:23.939 --> 00:21:33.319	So, for doing this I assume that initially we have updated the weights between the output layer and the layer just before the output layer.
23.srt	00:21:33.859 --> 00:21:37.229	So, which was my K minus first layer.
23.srt	00:21:38.849 --> 00:21:41.769	Now, K minus second layer is one of the hidden layers.
23.srt	00:21:45.809 --> 00:21:52.739	So, let us see that how we can update the weights between k minus first layer and k minus second layer.
23.srt	00:21:52.739 --> 00:22:00.249	Then we can generalize that result that we get the weight updation rule to any of the hidden layers.
23.srt	00:22:00.249 --> 00:22:22.219	So, in order to do this what I do is I take a neuron say p-th neuron in k minus second layer, I take i-th neuron in k minus first layer you follow you see over here that I am just following a chain because in the previous case I am I have assumed that.
23.srt	00:22:23.429 --> 00:22:32.939	from ith neuron in the k minus first layer, I have a connection from the jth neuron in the kth layer and that connection weight was W ijk.
23.srt	00:22:34.279 --> 00:22:39.829	Now, I am going one more layer before k minus first layer.
23.srt	00:22:40.389 --> 00:22:56.369	So, in k minus second layer I have this pth neuron and this pth neuron in the k minus second layer is connected to ith neuron in the k minus first layer and ith neuron in the k minus first layer is connected to jth neuron in the kth layer.
23.srt	00:22:58.429 --> 00:23:13.129	And, I am also assuming that this pth neuron in k minus second layer is connected to ith neuron in the k minus first layer through a connection weight which is given by W pi k minus 1.
23.srt	00:23:15.329 --> 00:23:24.279	But, you remember as we just said that I can compute the error only at the output layer, I cannot compute the error in any of the hidden layers.
23.srt	00:23:24.609 --> 00:23:30.699	So, my error function or the loss function is still given by E is equal to half.
23.srt	00:23:31.189 --> 00:23:42.809	o j k minus t j square j varying from 1 to m k that is output that I am computing the error that I am computing at the output of the output layer.
23.srt	00:23:43.199 --> 00:23:46.129	So, this is still my error function .
23.srt	00:23:46.129 --> 00:24:02.599	So, now in order to update this connection weight W p i k minus 1 what I have to do is I have to take the derivative of this error function E this loss function E .
23.srt	00:24:02.919 --> 00:24:28.069	with respect to W pi k minus 1, it is no more with respect to W ij k. So, again I have to follow the chain rule in order to find out that how this error e which is computed at the output layer varies with the variation of W pi k minus 1.
23.srt	00:24:29.659 --> 00:24:34.039	So, let us apply this chain rule again over here .
23.srt	00:24:35.129 --> 00:24:39.579	I will just skip this slide .
23.srt	00:24:39.949 --> 00:24:52.029	So, this is what I have to do and the derivative that I just said that I have to compute del E del P i k minus 1.
23.srt	00:24:52.419 --> 00:25:05.849	So, this is the derivative that I have to take and following the chain rule you find that I can write this as del E del O i k minus 1 into del O i k minus 1.
23.srt	00:25:06.489 --> 00:25:08.519	1 del W P i k minus 1.
23.srt	00:25:10.179 --> 00:25:28.839	And again del O i k minus 1 W P i k minus 1 using the chain rule can be written as del O i k minus 1 del theta i k minus 1 del theta k i k minus 1 del P i k minus 1.
23.srt	00:25:30.429 --> 00:25:36.529	So, these two are very simple because .
23.srt	00:25:36.759 --> 00:25:46.049	I know that O i k minus 1 is just the sigmoidal function of theta i k minus theta i k minus 1.
23.srt	00:25:47.149 --> 00:26:01.959	And I also know that theta i k minus 1 is nothing but W pi k minus 1 O p k minus 2 and you take the summation from p is equal to 1 to m k minus 2.
23.srt	00:26:02.269 --> 00:26:08.089	You remember that we thiswe are considering k minus second layer.
23.srt	00:26:08.089 --> 00:26:11.699	So, number of nodes in the k minus second layer is m k minus 2.
23.srt	00:26:12.980 --> 00:26:33.769	So, as these two functions are known I can easily compute what is del o i k minus 1 del theta i k minus 1 which is nothing, but this the derivative of the sigmoidal function and del theta i k minus 1 del p i k minus 1 which is simply o p k minus 2 that is this.
23.srt	00:26:35.139 --> 00:26:40.159	So, what I am left with is del e del o i k minus 1.
23.srt	00:26:44.120 --> 00:26:49.660	So, how I can compute this del e del o del o i k minus 1 .
23.srt	00:26:49.660 --> 00:27:11.190	So, over here you find that E is given as as we have already said the error at the output layer and where o j k is the sigmoidal function of theta j k and theta j k is nothing, but weighted sum of o i k minus 1 .
23.srt	00:27:15.010 --> 00:27:33.240	So, given this you find that del E del o i k minus 1 again by chain rule I can write this as del e del o j k into del o j k del theta j k into del theta j k del o i k minus 1 right.
23.srt	00:27:34.480 --> 00:27:45.510	And that simply becomes sum of o j k minus t j into o j k into o j k minus o j k which is the derivative of this .
23.srt	00:27:46.510 --> 00:28:05.360	into del theta j k del o k minus 1 is nothing, but w i j k. So, this is w i j k and del e del o j k is nothing, but o j k minus d j it is o j k minus d j and that has to be summed over all j.
23.srt	00:28:05.440 --> 00:28:16.090	So, it is again varying from j is equal to 1 to m k and this I can write as now you can .
23.srt	00:28:17.080 --> 00:28:29.509	Try to recollect earlier we had written this term O j k minus T j into O j k into 1 minus O j k as delta j k. So, that I put over here.
23.srt	00:28:30.210 --> 00:28:47.049	So, that simply tells me that O del O e del sorry del e del O i k minus 1 simply becomes sum of delta j k W i j k where you take the summation .
23.srt	00:28:47.440 --> 00:28:54.550	over j is equal to 1 to m k that is the total number of nodes of the neurons that you have at the output layer.
23.srt	00:28:56.580 --> 00:29:18.530	So, given this now our weight updation rule of the weights between k minus second layer to k minus first layer simply becomes W k minus 1 W pi k minus 1 that is updated as .
23.srt	00:29:18.920 --> 00:29:33.380	W pi k minus 1 minus eta times del i k minus 1 intosorry this was the weight updation rule at the last, but output layer.
23.srt	00:29:33.670 --> 00:29:40.740	So, that was eta times delta i k minus 1 into O p k minus 2.
23.srt	00:29:41.310 --> 00:29:46.880	So, this was the weight updation rule between the output layer and the layer before output layer.
23.srt	00:29:47.570 --> 00:29:48.920	So, in the hidden layer .
23.srt	00:29:49.260 --> 00:30:17.160	I will have a summation term here I am putting delta i k as summation of this as I said that I can generalize this from output layer to any of the hidden layers.
23.srt	00:30:17.440 --> 00:30:19.990	So, I am taking any of the hidden layers say kth layer.
23.srt	00:30:20.710 --> 00:30:36.690	layer at which I can put this delta i k, k is lower case means it is any of the hidden layers that simply becomes o i k into 1 minus o i k into summation of the contribution error of error term that you are getting from k minus first layer.
23.srt	00:30:38.140 --> 00:30:51.610	So, that gives you delta i k and using this my weight updation rule in the kth layer that simply becomes w i j k getting w i j k minus eta times delta j k .
23.srt	00:30:51.930 --> 00:30:53.720	times O I k minus 1.
23.srt	00:30:53.850 --> 00:31:03.940	So, this O I k minus 1 is the output of the k minus first layer the ith node of the k minus first layer.
23.srt	00:31:05.269 --> 00:31:11.930	And using this I can update the weights of any of the hidden layers.
23.srt	00:31:24.410 --> 00:31:26.150	So, what I have to do is I have to compute this for all values of i j and k. And while you do that you have to start from your output layer and then gradually move to all the hidden layers.
23.srt	00:31:27.180 --> 00:31:34.830	So, this is what is the weight updation rule or the back propagationlearning algorithm in multi layer neural network.
23.srt	00:31:34.830 --> 00:31:44.539	And you find that here the error function that we have considered is the sum of squared error or that is also known as quadratic error.
23.srt	00:31:45.120 --> 00:31:53.730	So, in your in our next class we will try to see that what is the problem that we face with the quadratic errorquadratic error.
23.srt	00:31:54.680 --> 00:31:57.019	and what sort of remedy we can have.
23.srt	00:31:59.190 --> 00:31:59.529	Thank you.
21.srt	00:00:00.610 --> 00:00:17.940	Hello, welcome to the NPTEL online certification course on deep learning.
21.srt	00:00:32.160 --> 00:00:32.280	.
21.srt	00:00:32.280 --> 00:00:50.679	We have started our discussion on the neural network and in our previous class we have talked about the basicimplementation of few of the logic functions and OR and XOR function using the neural networks.
21.srt	00:00:50.879 --> 00:01:00.780	Today we will continue our discussion with the neural network and particularly we will talk about the feed forward neural network also known as multi layer perceptron .
21.srt	00:01:01.820 --> 00:01:09.099	And, then we will see that how these neural networks can be trained to solve certain problems.
21.srt	00:01:09.989 --> 00:01:16.870	So, for that the algorithm that we will talk about is what is known as back propagation learning algorithm.
21.srt	00:01:18.060 --> 00:01:34.920	And, in fact we will talk about back propagation learning in details the reason being that this back propagation learning is the basic of the deep learning or the deep neural networks that we are going to discuss in future.
21.srt	00:01:37.319 --> 00:01:50.950	So, just to recapitulate what we did in the previous class is that we have implemented three of the logic functions AND function OR function and XOR function using the neural network.
21.srt	00:02:06.669 --> 00:02:17.729	And we have seen that in case of an AND function if the input is X 1 and X 2 for unified representation as we have done before that we have appended an additional component which is equal to 1 and this is what helps in giving a bias to the neural network or every nodes in the neural network.
21.srt	00:02:18.840 --> 00:02:34.819	And the weights that we considered was minus 1.5, 1 and 1 and with this we have seen in the previous class that output becomes x 1 and x 2 and that is what our AND function.
21.srt	00:02:41.589 --> 00:02:46.849	In case of an OR function, Of course, there was a non-linearity involved in it, the non-linearity that we have considered was a threshold non-linearity.
21.srt	00:02:46.849 --> 00:03:05.139	That means, if the output or weighted sum of the input that is W transpose X, this was greater than or equal to 0, we have assumed the output to be 1 and if it is less than 0, we have assumed the output to be 0.
21.srt	00:03:05.139 --> 00:03:11.449	And with that we have seen that this network, this simple node implements an AND function.
21.srt	00:03:13.609 --> 00:03:20.419	Similarly, in case of OR function again our input is the binary input x 1 and x 2.
21.srt	00:03:23.250 --> 00:03:42.699	The bias term in this case is minus 0.5, here we have giventhe weights as 1 and 1 and with this again we have seen that the output becomes x 1 or x 2 .
21.srt	00:03:45.209 --> 00:03:45.489	function.
21.srt	00:03:45.489 --> 00:03:56.559	We could implement this AND function and OR function using a single neural network because we have seen before that these functions are actually linear functions.
21.srt	00:03:57.119 --> 00:04:06.529	I can separate the outputs which are 1s from the outputs which are 0s by a straight line which is not possible in case of an XOR gate.
21.srt	00:04:07.319 --> 00:04:12.509	So, XOR is a non-linear function and we have seen in the previous class.
21.srt	00:04:13.519 --> 00:04:15.780	that, because XOR is a non-linear function.
21.srt	00:04:15.780 --> 00:04:21.129	So, it cannot be implemented a single neural network or single neuron.
21.srt	00:04:21.129 --> 00:04:27.420	So, I need multi layer neural network and that is what is in this figure.
21.srt	00:04:27.420 --> 00:04:34.469	So, here again our inputs are 1, X 1 and X 2 those are the binary inputs.
21.srt	00:04:34.469 --> 00:04:43.949	And one of these two gates we have seen before that it implements an OR gate and the other one implements a NAND function.
21.srt	00:04:45.250 --> 00:04:54.250	So, let us assume that the first one implements an OR function and this one implements a NAND function.
21.srt	00:04:59.170 --> 00:05:13.240	So, for implementing OR function just as we have seen over here our weights will be minus 0.5, 1 and 1 and for implementing a NAND function it has to be just complement of AND.
21.srt	00:05:15.310 --> 00:05:22.800	So, weights for implementing NAND function will be plus 1.5 minus 1 and minus 1.
21.srt	00:05:22.800 --> 00:05:43.519	And these two outputs are finally, to be ANDed because our XOR function X 1 XOR X 2 is nothing, but X 1 or X 2 ANDed with X 1 NAND X 2 .
21.srt	00:05:47.099 --> 00:05:48.099	So, here I have to have .
21.srt	00:05:48.300 --> 00:05:49.310	a AND function.
21.srt	00:05:53.829 --> 00:05:59.300	So, for this weights will be minus 1.5, 1 and 1.
21.srt	00:05:59.300 --> 00:06:04.779	So, here at the output what I get is x 1, x or x 2.
21.srt	00:06:05.680 --> 00:06:13.419	So, you find that these are simple implementations of the logic functions usingneural networks.
21.srt	00:06:19.560 --> 00:06:31.939	Now, from particularly this XOR function, it is quite obvious that if the function that we have to implement or the problem is a non-linear problem, the non-linear problem cannot be solved using a single layer network.
21.srt	00:06:31.939 --> 00:06:38.470	I need multiple or multi-layer neural network for implementing a non-linear problem.
21.srt	00:06:38.639 --> 00:06:49.370	So, for a non-linear problem as we also have seen in the previous class that I have layers of neural networks.
21.srt	00:06:52.400 --> 00:07:10.400	So, I have neural networks in multiple layers and from every layer say layer 1 to layer 2, I havecomplete connection that is every node in the layer 1 is connected to every node in the layer 2 and if the final function.
21.srt	00:07:10.400 --> 00:07:13.620	So, here you find that there there are k number of layers.
21.srt	00:07:14.090 --> 00:07:18.449	So, at the output I call the output layer to be kth layer.
21.srt	00:07:19.160 --> 00:07:22.220	So, the final function that is being implemented is.
21.srt	00:07:22.790 --> 00:07:29.069	f k ok and the input layer implements a function f 1.
21.srt	00:07:30.360 --> 00:07:54.579	So, with my input vector at as x the first layer that is f 1 layer it implements function f 1 of x, the second layer implements f 2 of f 1 x, third layer will implement f 3 of f 2 of f 1 x and finally, the k th layer implements f k of the output.
21.srt	00:07:55.110 --> 00:07:57.399	that has been generated by all the previous layers.
21.srt	00:07:58.939 --> 00:08:24.629	So, when it is a non-linear problem we can say that all the layers from f 1 to f k minus 1 they will implement a non-linear mapping because as we said earlier that if I have a non-linear problem then instead of trying to design a non-linear classifier you try to map the input vectors using a non-linear mapping function.
21.srt	00:08:26.720 --> 00:08:37.070	So, that they are mapped into intermediate feature space and in the intermediate feature space this non-linearly mapped input vectors will be linearly separable.
21.srt	00:08:37.070 --> 00:08:46.690	And then finally, at the final layer or at the kth layer I can have a linear classifier to classify all those samples correctly.
21.srt	00:08:46.690 --> 00:08:52.179	So, all these layers from f 1 to f k they actually implement this non-linear mapping.
21.srt	00:09:00.139 --> 00:09:14.860	So, at the output of f k the new feature vectors that I get so, feature vectors which are now linearly separable and the kth layer I can implement a linear classifier which will classify all these vectors h which are now linearly separable .
21.srt	00:09:14.860 --> 00:09:23.490	So, this is just a block diagram representation of a multi layer perceptron or a feed forward neural network .
21.srt	00:09:23.490 --> 00:09:25.679	Now, why it is feed forward?
21.srt	00:09:25.679 --> 00:09:30.190	Because I am inputting the feature vector x at the input layer .
21.srt	00:09:31.350 --> 00:09:41.559	They are being processed at every layer and being forwarded in the forward direction to the next layer and finally, you get the output from the final layer at the output layer.
21.srt	00:09:42.189 --> 00:09:46.809	And nowhere in this path the information is fed back to the previous layer.
21.srt	00:09:47.129 --> 00:09:50.389	So, always the information flows in the forward direction.
21.srt	00:09:50.600 --> 00:10:01.610	So, it is feed forward network, but we will see later that for learning or for training this neural network the error is propagated in the backward direction.
21.srt	00:10:02.169 --> 00:10:07.499	Because, our aim is to minimize the error by adjusting the weights in between the layers.
21.srt	00:10:08.319 --> 00:10:22.699	So, for training this neural network the error is propagated in the backward direction through each of the layers and while it is being propagated at every layer the weights are updated in order to minimize the error.
21.srt	00:10:24.219 --> 00:10:28.669	So, that is why the learning algorithm is known as back propagation learning.
21.srt	00:10:28.819 --> 00:10:31.749	So, our neural network is a feed forward neural network.
21.srt	00:10:32.370 --> 00:10:35.959	algorithm, but the learning algorithm is a back propagation learning algorithm.
21.srt	00:10:35.959 --> 00:10:44.720	Now, let us see in details that this how this neural network or multi layer perceptron that looks like.
21.srt	00:10:45.139 --> 00:10:56.879	So, this is what is a somewhat detailed representation of the speed forward neural network.
21.srt	00:10:58.159 --> 00:11:02.799	So, here I have assumed that there are k number of layers in the network.
21.srt	00:11:05.029 --> 00:11:09.699	At the beginning we have an input layer which is represented as zeroth layer.
21.srt	00:11:10.699 --> 00:11:16.470	The purpose of this layer is simply whatever comes at the input is simply passes to the output.
21.srt	00:11:33.029 --> 00:11:46.259	So, this layer does not have any other function other than simply passing the input to the output and every other layer from 1 to say layer k minus 1 each of these layers participate in non-linearly mapping the input feature vector x to a new feature space H. And kth layer which is represented by capital K it is the final output layer right.
21.srt	00:11:47.259 --> 00:12:01.679	And we also assume that from every layer every intermediate layer K where this K is represented by lower case letter, the nodes are connected or the neurons are connected to the next layer which is K plus 1.
21.srt	00:12:01.679 --> 00:12:05.350	And this connection is .
21.srt	00:12:05.559 --> 00:12:12.480	complete in the sense that every node in the kth layer is connected to every node in the k plus first layer.
21.srt	00:12:13.620 --> 00:12:24.129	And if I take an ith node in the kth layer, it is connected to jth node in the k plus first layer through.
21.srt	00:12:24.129 --> 00:12:26.169	So, let me put it like this.
21.srt	00:12:26.720 --> 00:12:37.149	So, I take a node i or a neuron i in the kth layer and I take a neuron g in the k plus first layer which is the next layer.
21.srt	00:12:38.750 --> 00:13:00.909	So, the output from the node i is connected to the input of node j output from node i in kth layer is connected to the input of k plus first layer to a connection weight which is W i j k plus 1.
21.srt	00:13:01.099 --> 00:13:06.059	So, this is the convention that we will use when we discuss about the back propagation learning.
21.srt	00:13:07.149 --> 00:13:08.139	So, this is the overall .
21.srt	00:13:09.079 --> 00:13:11.329	of our feed forward neural network.
21.srt	00:13:11.329 --> 00:13:17.819	There are k number of layers, kth layer is the final output layer.
21.srt	00:13:19.689 --> 00:13:39.289	Every node or every neuron i in an intermediate layer k represented by lower cost k is connected to the nextconnected to the jth node in the k plus first layer through an weight which is given by .
21.srt	00:13:39.629 --> 00:13:42.250	W ij k plus 1.
21.srt	00:13:44.080 --> 00:14:06.340	And the purpose of training this neural network or learning is that iteratively using the training vectors you try to find out what should be the value of W ij k plus 1 for every i j and k so that the neural network is finally, trained to solve your problem.
21.srt	00:14:06.840 --> 00:14:09.970	So, that is the purpose of back propagation neural network.
21.srt	00:14:11.429 --> 00:14:11.629	network.
21.srt	00:14:11.629 --> 00:14:15.370	And in this network you find that as we are feeding the input X i.
21.srt	00:14:15.370 --> 00:14:36.019	So, for training the training data is fed in the form of X i Y i as a doublet for say i is equal to 1 to n, where n is the number of training samples I have which is given for training this neural network.
21.srt	00:14:40.690 --> 00:14:48.450	So, for every training sample X i, as it is labeled because these are used for the training purpose, I know that to which class this sample X i belongs.
21.srt	00:14:48.960 --> 00:14:51.730	So, X i in this case belongs to class Y i.
21.srt	00:14:53.460 --> 00:15:02.050	So, if I have a binary classification problem we will do thatquickly, this Y i can be either 0 or 1.
21.srt	00:15:02.409 --> 00:15:12.180	If Y i is 0 that means, the sample X i belongs to say class Y i.
21.srt	00:15:13.009 --> 00:15:20.039	1 omega 1 and if y i is 1 that means, the same the sample x i belongs to class omega 2.
21.srt	00:15:20.399 --> 00:15:26.009	So, this tells you that what is the class belongingness of the training sample that I have.
21.srt	00:15:26.009 --> 00:15:47.049	If I have c number of classes, if I have c number of classes then y i will take one of the values 1, 2, c. So, this y i in that case is the index to the class to which x i belongs.
21.srt	00:15:48.240 --> 00:16:01.850	So, if I have a data X i 5, this is the training data given then this means that the training data X i belongs to class 5.
21.srt	00:16:05.279 --> 00:16:19.090	Secondly at the output node if I take a jth node jth neuron at the output layer, I represent the output of the jth node.
21.srt	00:16:19.300 --> 00:16:27.240	in the kth layer as x j k. So, these are the conventions that we will use when we talk about back propagation learning.
21.srt	00:16:28.840 --> 00:16:39.009	And here you find that only at the output given a training vector x i only I know that what should be the corresponding output.
21.srt	00:16:40.060 --> 00:16:49.240	Because if it is x i 2 this is the training pair that is given I know that when this x i is fed to the input vector.
21.srt	00:16:50.050 --> 00:17:03.800	output of the second node that should be high, the outputs of all other nodes should be equal to 0 because my training pair says that this vector x i belongs to class 2.
21.srt	00:17:04.860 --> 00:17:20.980	Similarly, if a training vector x is given which belongs to class 9, then when I fit this x to the input only the output of the ninth node from the output layer should be high and all other output should be low.
21.srt	00:17:21.529 --> 00:17:24.189	So, this I can decide only at the output layer.
21.srt	00:17:25.189 --> 00:17:32.079	I really do not know that what should be outputs of any of the hidden layers that is not visible.
21.srt	00:17:33.149 --> 00:17:51.459	So, that is the reason that all the nodes or all the layers except the output layer they are known as hidden layers because I can only observe I can only decide at the output I cannot decide what should be the outputs of any node in the intermediate layers or hidden layers.
21.srt	00:17:51.569 --> 00:17:54.569	And this is a layer as we said that this is known as input layer.
21.srt	00:17:55.190 --> 00:18:07.510	So, the purpose of every neuron in the input layer is simply to pass whatever is coming to the input to its output and it is subsequently fed to the neurons of the next layer.
21.srt	00:18:08.480 --> 00:18:14.180	So, this is what the architecture of the neural network looks like and the conventions that will follow.
21.srt	00:18:15.900 --> 00:18:24.740	Now, let us see that how can we train the neural network or what is back propagation learning.
21.srt	00:18:24.740 --> 00:18:26.460	So, to talk about back propagation learning.
21.srt	00:18:27.130 --> 00:18:37.110	First, I will consider a very simpleneural network consisting of a single layer which is the output layer.
21.srt	00:18:38.410 --> 00:18:48.850	Of course, you remember that we said before that using a single layer I can solve only linear problems, I cannot solve any non-linear problem.
21.srt	00:18:48.850 --> 00:19:02.780	And as I said that this learning algorithms will do in details because this forms the basis of all subsequent deep learning or deep networks, deep neural networks that we will talk about.
21.srt	00:19:03.460 --> 00:19:11.390	So, it is very important that you understand the back propagation learning very very clearly right.
21.srt	00:19:12.309 --> 00:19:25.569	So, again I take a single network a single neuron where the weight vector is w if I feed an input vector x i.
21.srt	00:19:36.920 --> 00:19:53.150	So, as we said before that for training I get the input vectors as pairs x i y i where this y i is that the output of the neural network should be y i and only when I get the output as y i which matches with my true values, then at least this x i is correctly classified by this neuron.
21.srt	00:19:53.710 --> 00:20:01.970	But what we get is I get a value x i hat which is an approximation of x i.
21.srt	00:20:10.590 --> 00:20:13.100	So, if x i hat, so this x i hat is nothing but W transpose x i where W is my vector and x i is the input vector.
21.srt	00:20:14.019 --> 00:20:29.360	And for the time being I am assuming that I have a neural network with single layer and single output node and I am not assuming there is any nonlinearity in this neuron, ok.
21.srt	00:20:29.920 --> 00:20:39.390	So, my output simply becomes W transpose x i and I am assuming that this W transpose x i is an approximation to y i which is y i hat.
21.srt	00:20:40.190 --> 00:20:42.970	So, if y i and y i hat they are same.
21.srt	00:20:43.230 --> 00:20:45.349	that means, my input vector is correctly classified.
21.srt	00:20:45.660 --> 00:20:58.990	So, I do not have to take any action to modify the weight vector w. Now, suppose y i hat and y i they are not same they are different ok.
21.srt	00:20:59.819 --> 00:21:09.589	So, my error will be y hat minus y i this is the error and what I compute is the sum of squared error.
21.srt	00:21:09.589 --> 00:21:13.240	So, this is sum of y i minus x i.
21.srt	00:21:13.599 --> 00:21:28.289	where this i will vary from 0 to n. So, this square error is computed over all the training vectors that I have as i varying from 0 to capital N and I have capital num capital N number of vectors for training purpose.
21.srt	00:21:29.379 --> 00:21:41.980	And I scaled it this by half the reason of scaling it by half is as we have seen earlier also for any learning algorithm or any training algorithm we go for gradient descent approach.
21.srt	00:21:44.989 --> 00:21:49.079	That means, I have to take differentiation of the error function or the loss function that we have generated.
21.srt	00:21:49.989 --> 00:21:59.879	And because it is squared error or squared loss, so having a factor half will simplify our expressions.
21.srt	00:21:59.979 --> 00:22:01.569	So, that is the reason this half is put.
21.srt	00:22:02.899 --> 00:22:14.419	If I put it in an elaborated form, so this error function or the loss function e is nothing, but half of W transpose X i, this W transpose X i is nothing, but our Y hat.
21.srt	00:22:15.659 --> 00:22:18.089	So, W transpose X i minus Y i squared.
21.srt	00:22:18.479 --> 00:22:28.209	take the summation over all i varying from i equal to 1 to n that means, you are summing the errors of all the training vectors that you have.
21.srt	00:22:48.629 --> 00:22:55.099	Next as we said that we will employ the gradient descent approach as we have done before for training the network or for updating the weight vector w. So, I take the gradient of E with respect to weight vector w and here you find that this gradient is nothing, but y hat minus y i into x i where x i is the input training vector right.
21.srt	00:22:55.529 --> 00:23:05.019	And now you find that why we have put this half because otherwise there would have been a scaling function 2 over herescaling factor 2 over here.
21.srt	00:23:05.369 --> 00:23:07.239	So, in order to avoid that you put half.
21.srt	00:23:08.339 --> 00:23:15.189	So, this is the gradient of the error or the loss right.
21.srt	00:23:15.749 --> 00:23:19.649	So, I have to update w.
21.srt	00:23:20.109 --> 00:23:25.369	or the weight vector in such a way that this loss is minimized or the error is minimized.
21.srt	00:23:26.299 --> 00:23:32.389	And for that as before my weight updation rule follows the gradient descent procedure.
21.srt	00:23:33.069 --> 00:23:45.220	So, my weight updation rule will be simply W gets if this is the previous value of the weight vector, the updated weight vector will be W minus some eta times the gradient.
21.srt	00:23:46.389 --> 00:23:47.230	What is this eta?
21.srt	00:23:50.460 --> 00:23:52.819	We also said before that this is nothing but a rate of convergence factor.
21.srt	00:23:53.269 --> 00:24:04.180	So, this eta indicates if the value of eta is very high then the rate of convergence will be fast, if the value of eta is low then the rate of convergence will be low.
21.srt	00:24:05.069 --> 00:24:12.650	So, I will have a slower convergence of course, both has their individual merits and demerits we also discussed about those before.
21.srt	00:24:20.259 --> 00:24:21.210	Now, if you look at this weight updation rule you find that we get something more.
21.srt	00:24:22.309 --> 00:24:28.110	I said my output Y should be either 0 or plus 1.
21.srt	00:24:29.340 --> 00:24:34.289	So, if it is 0 it belongs to one class, if it is plus 1 it belongs to another class.
21.srt	00:24:35.549 --> 00:24:48.039	And if you remember that earlier the linear discriminators that we have talked about that is a linear plane which separates two different classes which are linearly separable.
21.srt	00:24:51.460 --> 00:24:58.160	We have said for one of them if W transpose X greater than 0, then it belongs to one class if it is less than 0 it belongs to one another class.
21.srt	00:25:00.019 --> 00:25:23.579	Now, here let us come to a situation that if I find that W transpose X is greater than 0 for samples belonging to some class omega 1 and this is represented by Y i is equal to plus 1 .
21.srt	00:25:24.799 --> 00:25:32.930	So, as long as my W transpose X i is greater than 0 then it is correctly classified right.
21.srt	00:25:35.220 --> 00:25:53.039	Now, here you find that if my Y i is plus 1, but I get W Y i hat to be negative then and instead of taking the sum let us consider a single feature vector X i.
21.srt	00:25:55.630 --> 00:25:58.800	So, which is nothing, optimization, we have also talked about that before.
21.srt	00:25:59.540 --> 00:26:05.880	If you sum all of them that means, you are considering all the training vectors together it becomes a batch optimization technique.
21.srt	00:26:05.960 --> 00:26:11.269	So, we have talked about batch optimization, mini mini batch optimization and stochastic optimization.
21.srt	00:26:11.960 --> 00:26:26.240	So, if I consider only X i that becomes a stochastic optimization procedure and then our weight updation rule will be simply W gets W minus eta times Y i hat.
21.srt	00:26:26.300 --> 00:26:29.970	hat minus y i times x i.
21.srt	00:26:31.620 --> 00:26:44.150	So, here if my y i is actually plus 1 that means, W transpose x should be greater than 0 for correct classification of x i.
21.srt	00:26:45.070 --> 00:26:51.290	But suppose W transpose x which is nothing but y i hat happens to be negative.
21.srt	00:26:54.720 --> 00:27:00.410	In that case this y i hat minus y i this whole term will be negative.
21.srt	00:27:02.640 --> 00:27:19.210	And, in fact what we are doing is we are making W updating W as W plus some factor say eta times let us put chi times x i .
21.srt	00:27:19.210 --> 00:27:30.810	So, here you find that there is some similarity with the perceptron algorithm that we talked about towards the beginning of our course that if an x i is misclassified.
21.srt	00:27:32.240 --> 00:27:41.120	we add a fraction of x i to the weight vector for weight vector updation right.
21.srt	00:27:41.680 --> 00:27:53.910	In the same manner if I assume that y i is 0 for which this y i hat should be negative because it belongs to the other class.
21.srt	00:27:55.440 --> 00:27:59.550	But if I get y i to be positive y i hat to be positive say over here.
21.srt	00:28:02.000 --> 00:28:28.290	my y i is 0 that means, x i belongs to another class for which y i hat which is computed by this neuron should be negative, but if I get this as positive ok. Again as before the updation that we are doing is W as W minus sum eta chi times x i .
21.srt	00:28:28.290 --> 00:28:32.960	So, this is the other vector for which W transpose x i should have been negative .
21.srt	00:28:33.750 --> 00:28:41.090	But, it has been misclassified because y i hat has been positive has been computed as positive by the neuron by the neural network.
21.srt	00:28:42.020 --> 00:29:01.250	And in this case what we are doing is we are subtracting a fraction of y i from w or in the other words we are adding a fraction of negated y i to w again the same thing that we have done in case of our perceptron algorithm.
21.srt	00:29:01.250 --> 00:29:04.160	So, this is what you have in case of single layer perceptron .
21.srt	00:29:05.310 --> 00:29:20.260	that following gradient descent procedure the way we update the weights or the weight vector is by adding or subtracting a fraction of the misclassified samples to the weight vectors.
21.srt	00:29:21.680 --> 00:29:25.780	So, I will stop this lecture here we will continue with this next.
21.srt	00:29:26.100 --> 00:29:26.450	Thank you.
20.srt	00:00:00.610 --> 00:00:27.949	Hello, welcome to the NPTEL online certification course on deep learning.
20.srt	00:00:33.079 --> 00:00:51.899	In our previous lecture, we started discussions on the topic in neural network and we have talked aboutimplementation of two of the logic functions the AND logic and OR OR logic using the neural network.
20.srt	00:00:52.929 --> 00:01:01.939	And we have seen that AND logic and OR logic both of them being linear functions, they can be implemented.
20.srt	00:01:02.200 --> 00:01:04.670	very easily using a single neuron.
20.srt	00:01:06.000 --> 00:01:12.989	These single neurons are known as or a single layer neuron, they are known as single layer perceptron.
20.srt	00:01:13.239 --> 00:01:17.069	We will see later that why they are single layer perceptron.
20.srt	00:01:18.710 --> 00:01:32.980	Today, we will talk about other implementations of neural network like XOR logic, we will also talk about feed forward neural network or a multi layer perceptron.
20.srt	00:01:33.509 --> 00:01:43.739	And, we will also talk about how the neural networks can be trained using learning mechanism known as back propagation learning.
20.srt	00:01:45.250 --> 00:01:49.789	So, let me just recapitulate what we did in our previous class.
20.srt	00:01:50.339 --> 00:01:54.489	We have implemented two logic functions AND logic and OR logic.
20.srt	00:01:55.149 --> 00:02:02.829	And, we said that both this AND logic and OR logic can be implemented using single neuron or single layered neural network.
20.srt	00:02:06.810 --> 00:02:20.620	So, for implementation of a AND logic, we what we have done is we have taken our input vector to be 1, x 1 and x 2 and the weight vectors were taken as minus 1.5, 1 and 1.
20.srt	00:02:20.620 --> 00:02:30.990	In the neuron I can consider that it has two functional parts, in the first part it computes W transpose X.
20.srt	00:02:31.019 --> 00:02:39.459	So, in this case it will compute W 0 which is nothing but minus 1.5 minus 1.5 times 1.
20.srt	00:02:41.189 --> 00:02:44.680	1 into x 1 plus 1 into x 2.
20.srt	00:02:45.010 --> 00:02:53.900	So, effectively this function which is computed is x 1 plus x 2 minus 1.5.
20.srt	00:02:54.030 --> 00:03:11.120	Now, this computed value is passed on to the second compartment of the neuron which computes the nonlinearity and in this case the nonlinearity is a threshold nonlinearity.
20.srt	00:03:11.120 --> 00:03:15.460	So, the nonlinear function that we have considered is a threshold nonlinearity.
20.srt	00:03:15.460 --> 00:03:19.850	So, for x transpose W transpose x greater than 0.
20.srt	00:03:20.620 --> 00:03:27.500	the output is 1 for w transpose x less than or equal to 0 it is equal to 0.
20.srt	00:03:28.610 --> 00:03:39.460	So, as a result at the output the function that I get is an AND function .
20.srt	00:03:39.460 --> 00:03:48.530	So, this is what we get in case of an AND function when the input vectors are minus 1.5 1 and 1.
20.srt	00:03:49.870 --> 00:03:51.900	Then I want to compute an OR function .
20.srt	00:03:52.819 --> 00:04:22.839	I simply my input vectors remains the same that still is 1 x 1 and x 2 whereas, weight vectors are changed to minus 0.5 1 and 1 as before the first compartment computes W transpose x and the second compartment gives you the nonlinearity which imposes nonline threshold on nonlinearity in W transpose x.
20.srt	00:04:22.839 --> 00:04:25.149	So, as a result at the output.
20.srt	00:04:26.120 --> 00:04:30.789	what we get an OR function OR of x 1 and x 2.
20.srt	00:04:31.339 --> 00:04:53.519	And here with these weight vector this weight vector the classifier that you are doing of the separating plane that you are designing is nothing, but x 1 plus x 2 minus 0.5 that is equal to 0 that is the separating plane between the two classes omega 1 and omega 2.
20.srt	00:04:56.229 --> 00:05:08.560	And we have also said that we could implement AND function and OR function using a simple single layer neuron or a single neuron because the classes in this case are linearly separable.
20.srt	00:05:10.370 --> 00:05:14.169	Now, what happens if the classes are not linearly separable?
20.srt	00:05:15.239 --> 00:05:25.229	So, we have discussed earlier that in non-linearly separable cases or linearly non-separable cases either I can have a non-linear classifier.
20.srt	00:05:27.060 --> 00:05:48.859	that is the boundary which is its which itself is non-linear or the other approach can be that you can map the feature vectors using non-linear functions to an intermediate feature domain where because of this non-linear mapping the in the intermediate feature domain the feature vectors will be linearly separable.
20.srt	00:05:48.859 --> 00:05:54.299	And as in the intermediate feature domain the feature vectors are linearly separable.
20.srt	00:05:57.699 --> 00:06:03.120	So, I can now have linear classifiers which classifies the features in the intermediate feature domain.
20.srt	00:06:03.970 --> 00:06:23.879	So, I have two levels of operation in the first level of operation the feature vectors will be non-linearly mapped to an intermediate feature domain, where they will be linearly separable and in the second step you these feature vectors in the intermediate feature space where they are linearly separable.
20.srt	00:06:23.879 --> 00:06:32.269	In the second step I can design a linear separator or a linear classifier which classifies these vectors in the feature space.
20.srt	00:06:33.470 --> 00:06:40.300	So, I have a non-linear mapping of the feature vectors in the original space and finally, a linear classifier.
20.srt	00:06:40.530 --> 00:06:54.340	So, let us again see a very simple example, what happens that in case of and instead of and function or or function if I want to implement an XOR function.
20.srt	00:06:54.340 --> 00:07:05.699	So, all of you know that in the in case of XOR function when the inputs are 0 0 that is both X 1 and X 2 both of them are 0s the output is 0.
20.srt	00:07:06.660 --> 00:07:21.710	If both of them are ones that is x 1 is equal to 1 and x 2 is equal to 1, then also the output is 0 only when the x 1 and x 2 are different that is in case of 0 1 or 1 0 the output will be 1.
20.srt	00:07:22.930 --> 00:07:25.439	So, that is what I have in case of xOR function.
20.srt	00:07:37.000 --> 00:07:45.260	And in the same manner as we have done before if I want to plot this in the feature space if I plot this feature space and plot all these feature vectors and x 1, x 2 that is 0 0 0 1 1 0 and 1 1 in this feature space then this is the situation that I have.
20.srt	00:07:46.190 --> 00:08:00.540	You find that when x 1, x 2 both of them 0 then the output is 0, if both of them are 1 then the output is 0, if they are 0 1 or 1 0 then the output is 1.
20.srt	00:08:02.230 --> 00:08:06.450	And now find that I have a difficult situation in the earlier cases.
20.srt	00:08:06.930 --> 00:08:19.850	when we talked about OR function OR AND function, the classes were linearly separable on one side of the straight line of a straight line I had the value 0 on the other side the values were 1s.
20.srt	00:08:21.180 --> 00:08:28.780	But here you find that the values of 0s and 1s cannot be separated by a single straight line rather I need two different straight lines.
20.srt	00:08:29.450 --> 00:08:36.620	And in between the straight lines the values are 1 and outside the straight lines the values are 0s.
20.srt	00:08:37.980 --> 00:08:43.070	So, this is a clear case where the problem is not a linear problem, but it is a non-linear problem.
20.srt	00:08:44.360 --> 00:08:54.509	So, can I implement or can I implement this XOR function using neural networks or neurons let us see.
20.srt	00:08:54.509 --> 00:09:08.830	So, you know from your digital circuits course that an XOR function X 1 or X 2 X 1 XOR X 2 .
20.srt	00:09:08.900 --> 00:09:14.460	2 can be broken into a multiple stepped function.
20.srt	00:09:15.870 --> 00:09:27.350	So, what I can do is I can perform OR operation of X 1 and X 2 and I can also perform NAND operation of X 1 and X 2.
20.srt	00:09:28.710 --> 00:09:39.600	So, here what I have this first I compute X 1 or X 2 and the second one is NAND operation of X 1 X and X 2.
20.srt	00:09:42.900 --> 00:09:54.790	Obviously, this is NAND operation because this is nothing, but x 1 and x 2 complement of that which is nothing but x 1 complement or x 2 complement .
20.srt	00:09:54.790 --> 00:10:12.680	So, I perform AND operation of x 1 x 2, I perform I perform OR operation of x 1 x 2, I perform NAND operation of x 1 x 2 and these two outputs the AND output OR output and AND output I AND them AND them together.
20.srt	00:10:14.390 --> 00:10:17.730	and that gives me x 1 x or x 2.
20.srt	00:10:19.390 --> 00:10:34.310	So, effectively what I am doing is as shown in this particular table I am converting the input vectors x 1 x 2 to an intermediate vector h given the given by components h 1 h 2.
20.srt	00:10:35.310 --> 00:10:43.320	So, here you find that if I consider that output of the OR operation is h 1.
20.srt	00:10:44.440 --> 00:10:58.810	and output of NAND operation is H 2 as we have shown here, then when the input is 0 0 H 1 will be 0 and H 2 will be 1.
20.srt	00:11:00.350 --> 00:11:05.950	When the input is 0 1 H 1 will be 1 H 2 will also be 1.
20.srt	00:11:16.000 --> 00:11:20.950	When the input is 1 0 H 1 will be 1 H 2 will also be 1 and when the input is 0 1 H 1 1, then H 1 will be 1 and H 2 will be 0.
20.srt	00:11:22.140 --> 00:11:31.420	So, as we have done before if I plot H 1 and H 2 that is the intermediate feature space.
20.srt	00:11:31.420 --> 00:11:46.890	So, say this is H 1 and this is H 2, you find that when H 1 and H 2 they are having values 0 and 1, H 1 is equal to 0, H 2 is equal to 1. .
20.srt	00:11:47.440 --> 00:11:51.759	which is the mapped x as x 1 equal to 0 and x 2 is equal to 0.
20.srt	00:11:52.679 --> 00:11:59.799	So, I have h 1 0 and h 2 1 this is where I want my xor output to be equal to 0.
20.srt	00:12:02.740 --> 00:12:15.779	Similarly, when the values are 1 1 both h 1 and h 2 they are 1 1 which is equivalent to x 1 is 0 and x 2 1 or x 2 x 1 is 1 x 2 is 0.
20.srt	00:12:16.740 --> 00:12:20.850	In both these cases I want the xor output to be 1.
20.srt	00:12:24.939 --> 00:12:26.679	sorry I just made some mistake.
20.srt	00:12:28.309 --> 00:12:42.860	So, over here when the h 1 h 2 both of them are 0, x 1 x 2 both of them are 0 that is h 1 is 0 and h 2 is 1.
20.srt	00:12:43.079 --> 00:12:43.860	So, this was correct right.
20.srt	00:12:44.289 --> 00:12:46.179	So, here I want the output to be 0.
20.srt	00:12:48.779 --> 00:12:54.579	In the other case when x 1 is 0, x 2 is 1 or x 1 is 1, x 2 is 0.
20.srt	00:12:54.769 --> 00:13:01.119	which are mapped to both h 1 and h 2 become becoming 1 1, I want the output to be 1.
20.srt	00:13:01.119 --> 00:13:08.739	So, here I want the output to be 1 which is the case when both x 1 and x 2 are either 0 1 or 1 0.
20.srt	00:13:11.279 --> 00:13:22.209	And in the other case when x 1 x 2 are 1 1, I get h 1 to be 1 and h 2 to be 0 that is somewhere over here and here my xor output should also be 0.
20.srt	00:13:23.799 --> 00:13:27.119	So, you find that now I have this is the place where I.
20.srt	00:13:27.929 --> 00:13:40.449	have XOR output 0, this is the place where I also have XOR output to be 0 and this is the place where I want to have XOR output to be 1 and now you find that del linear is a variable.
20.srt	00:13:43.219 --> 00:13:57.429	So, the first non-linear mapping or the first step in the first step when I am computing X 1 or X 2 and X 1 NAND X 2.
20.srt	00:13:58.769 --> 00:14:06.929	These two operations are transferring transforming my input vector to an intermediate vector given by h 1 h 2.
20.srt	00:14:07.829 --> 00:14:15.559	And in this intermediate space in this intermediate feature space the classes the problem is linearly separable.
20.srt	00:14:15.859 --> 00:14:28.379	So, now I can have a linear classifier to classify the input vectors x 1 and x 2, where the linear classifier instead of operating on x 1 x 2.
20.srt	00:14:28.929 --> 00:14:32.669	the in-linear classifier operates on H 1 and H 2.
20.srt	00:14:32.669 --> 00:14:38.129	So, I can represent this again in matrix form.
20.srt	00:14:38.369 --> 00:14:46.789	So, what I have is in the first level I have a set of matrices given by set of weights given by the matrix W 1.
20.srt	00:14:46.789 --> 00:15:00.449	So, these weights are so, if you look at the first one it is minus 0.5 1 1 which are the weight vectors we have used for an OR operation.
20.srt	00:15:02.429 --> 00:15:07.969	The second one the second weight vector is given by 1.5 minus 1 minus 1.
20.srt	00:15:07.969 --> 00:15:17.549	And if you remember from our previous discussion that minus 1.5 1 1 was the weight vector corresponding to AND operation.
20.srt	00:15:17.619 --> 00:15:26.809	So, if I negate it I make it plus 1.5 and this has minus 1 and this has minus 1 this is the weight vector which is used for NAND operation.
20.srt	00:15:26.809 --> 00:15:31.129	So, using this weight vectors I compute W 1.
20.srt	00:15:33.199 --> 00:15:42.279	transpose X, where W 1 is actually the weight matrix consisting of minus 0.511 and 1.5 minus 1 minus 1.
20.srt	00:15:42.279 --> 00:15:47.179	So, this is my intermediate the matrix product that I get.
20.srt	00:15:47.179 --> 00:16:02.289	Now, if I apply the nonlinearity which is a threshold nonlinearity, I get 1 0 0 0 1 1 1 1 and 1 1 1 0 that is my intermediate set of vectors.
20.srt	00:16:03.349 --> 00:16:05.589	which is given by matrix H .
20.srt	00:16:05.589 --> 00:16:16.509	So, this is my H 1 this first row corresponds to vector H 1 the second row corresponds to vectors H 2 .
20.srt	00:16:16.509 --> 00:16:35.529	So, my final output if I put another weight vector now you find that this weight vector corresponds to an AND operation that is minus 1.5 1 and 1 this was my intermediate matrix or set of intermediate feature vectors H 1 and H 2 .
20.srt	00:16:36.249 --> 00:16:52.909	which is given by H. So, if I compute H transpose W 2 now, the output of this matrix multiplication becomes minus 0.5, then 0.5, 0.5 and minus 0.5.
20.srt	00:16:53.009 --> 00:17:01.179	Again I pass this through this threshold nonlinearity and I get the output as 0, 1, 1, 0.
20.srt	00:17:06.259 --> 00:17:21.599	So, you find that, when my h 1 h 2 are 0 1 or 1 0 the output becomes 0 and these are equivalent to the input vectors becoming being 0 0 or 1 1.
20.srt	00:17:23.279 --> 00:17:38.469	And when my h vector that is the intermediate features are 1 1 that is this case the output is also 1 and this is the case when both x 1 and x 2 .
20.srt	00:17:38.769 --> 00:17:41.069	they are either 0 1 or 1 0.
20.srt	00:17:42.230 --> 00:17:46.919	So, I have implemented this XOR function in two steps.
20.srt	00:17:47.549 --> 00:17:51.889	So, I can consider this to be implemented using two layer neural networks.
20.srt	00:17:52.679 --> 00:18:00.539	In the first layer I will have two neurons one giving an OR operation and other one giving an NAND operation.
20.srt	00:18:01.179 --> 00:18:09.259	And you find that because AND is a linear problem NAND is also a linear problem because NAND is nothing but complement of AND.
20.srt	00:18:09.809 --> 00:18:21.139	And, that is what we have done over here that plus 0.1 plus 1.5 minus 1 minus 1 this weight vector actually gives a NAND operation ok.
20.srt	00:18:21.139 --> 00:18:39.089	So, I can implement this XOR operation which is linearly non-separable, but for implementation of this as obvious from this operation that a single layer neural network or a single neuron is not sufficient rather I need 3 neurons.
20.srt	00:18:40.799 --> 00:18:45.349	And, those three neurons are to be arranged in two layers.
20.srt	00:18:46.479 --> 00:19:06.399	One neuron in the first layer will compute OR operation, the other neuron in the first layer will compute NAND operation and the then the third neuron which is in the second layer will combine the outputs of these neurons in the first layer using an AND operation to give you the final output.
20.srt	00:19:11.679 --> 00:19:13.099	So, effectively the kind of neural network that I have is this.
20.srt	00:19:13.559 --> 00:19:20.549	So, here I put my input to be again 1 x 1 x 2.
20.srt	00:19:21.719 --> 00:19:24.549	Suppose this first neuron computes OR operation.
20.srt	00:19:25.109 --> 00:19:31.939	So, we know that for OR operation my weight vectors should be minus 0.5 1 and 1.
20.srt	00:19:31.939 --> 00:19:43.409	And suppose this second neuron computes NAND operation for which I have to have weight vector.
20.srt	00:19:44.319 --> 00:19:51.059	as plus 1.5 minus 1 and minus 1.
20.srt	00:19:51.059 --> 00:20:04.409	So, here what I get is x 1 or x 2 and here what I get is x 1 and x 2.
20.srt	00:20:04.999 --> 00:20:16.869	So, I use this as h 1 and this as h 2 and this second third neuron in the second layer.
20.srt	00:20:17.689 --> 00:20:20.979	This computes AND operation.
20.srt	00:20:21.289 --> 00:20:27.509	So, here I have to have the weight vectors as minus 1.5, 1, 1.
20.srt	00:20:27.809 --> 00:20:39.329	So, this performs an AND operation and finally, at the output what I get is XOR of X1 X2.
20.srt	00:20:39.329 --> 00:20:43.969	So, I get X1 or X2 at the output .
20.srt	00:20:49.309 --> 00:20:58.979	So, through this discussion it is quite clear that, if I have linearly separable problems, single neuron for a two class problem is sufficient.
20.srt	00:21:00.369 --> 00:21:05.779	If I have multiple classes, then I have to have multiple neurons.
20.srt	00:21:06.219 --> 00:21:22.489	So, in case of multiple classes, the way this has to be done is I can have a number of neurons, but in a single there here I have the weight vectors say.
20.srt	00:21:30.199 --> 00:21:31.299	something like this.
20.srt	00:21:32.129 --> 00:21:43.639	So, here I have x over here we have the weight vectors a set of weight vector for this out this neuron, a set of weight vectors for this neuron, a set of weight vectors in this neuron.
20.srt	00:21:44.719 --> 00:21:54.009	Each of these neurons perform suppose the weight vector for this is a W 1 weight vector for this neuron connecting to this neuron is a W 2.
20.srt	00:21:54.489 --> 00:22:24.559	weight vector connecting to this neuron is a W n, if I have got n number of classes or n number of categories, this neuron will compute W 1 transpose X and then a function of this, this one will compute W 2 transpose X and then a function of this, this one will compute W n transpose X .
20.srt	00:22:24.989 --> 00:22:27.089	and a nonlinearity on this.
20.srt	00:22:27.819 --> 00:22:42.919	So, I will get a number of outputs o 1, o 2 and o 3 which actually gives you the score functions or score values for different classes or different categories corresponding to input vector x.
20.srt	00:22:43.869 --> 00:22:51.479	And here you find that all these are linear combinations, linear combinations of different components of the input vector.
20.srt	00:22:52.439 --> 00:22:55.529	So, if my problem is a linear problem.
20.srt	00:22:56.769 --> 00:23:01.209	I can solve it using single layer neuron or single layer neural network.
20.srt	00:23:02.099 --> 00:23:19.229	But if it is not a linear problem, if it is a non-linear problem that as has been demonstrated with a very simple non-linear function of XOR function, I need multiple levels of neurons or multi layer neural network.
20.srt	00:23:19.229 --> 00:23:26.909	So, the kind of neural network that I have to have over here is as given by this.
20.srt	00:23:28.899 --> 00:23:56.139	You find that every layer of the neural network computes a non-linear function of the input feature vector of the feature vector inputted to that particularlayer of neurons and the output of that layer of neurons is an intermediate feature vector maybe of same dimension or maybe of different dimension depending upon how many neurons I have in that particular layer.
20.srt	00:23:56.139 --> 00:23:57.999	We will see that.
20.srt	00:23:58.649 --> 00:24:00.719	as we proceed through our discussions.
20.srt	00:24:01.679 --> 00:24:11.079	But effectively what I have is I have a multi layer neural network and in every layer the neurons compute a non-linear function.
20.srt	00:24:11.079 --> 00:24:21.459	So, when I have a cascade of this non-linear functions as given by the multiple layer neural network as has been shown in this particular diagram.
20.srt	00:24:21.459 --> 00:24:29.229	So, here you find that suppose each of these are neurons a layer of neurons.
20.srt	00:24:31.549 --> 00:24:34.359	And, in every layer it computes a non-linear function.
20.srt	00:24:34.359 --> 00:24:51.309	So, in ith layer it computes a non-linear function f i on the feature vectors which are computed by the previous layer given by the function f i f i minus 1 and each of this are non-linear function.
20.srt	00:24:51.309 --> 00:25:00.299	So, I can cascade all of them together to give you an overall cascaded function as given by this.
20.srt	00:25:02.249 --> 00:25:13.459	So, if my input vector is x the first layer computes f 1 of x, this f 1 of x is inputted to the next layer.
20.srt	00:25:14.289 --> 00:25:31.519	So, which computes f 2 on this f 1 of x that means, this layer computes f 2 of f 1 of x and this way it continues when it comes over here say I have a.
20.srt	00:25:32.099 --> 00:25:52.669	set of mapped feature vectors over here which is given by say h k minus 1 which is a mapped feature vector mapped from this vector x through a series of non-linear mapping where each of these layers of neurons gives some sort of non-linear mapping.
20.srt	00:25:54.289 --> 00:26:06.049	And then I have a final layer of neuron which is the kth layer which when I come to this h k minus 1 these feature vectors are non-linearly mapped from x.
20.srt	00:26:07.629 --> 00:26:21.859	And, as these are non-linearly mapped, so this in in this feature space as given by this vector h k minus 1, these feature vectors are the problem that is posed is a linearly separable problem.
20.srt	00:26:21.859 --> 00:26:31.969	And, once I have such a linear problem, the final layer or the kth layer can solve this using a linear discriminator.
20.srt	00:26:31.969 --> 00:26:39.889	So, effectively I can put all of them in a cascade of operations something like this.
20.srt	00:26:42.029 --> 00:26:51.569	So, at the first layer you compute f 1 of x which gives you say set of feature vectors h 1.
20.srt	00:26:52.879 --> 00:27:00.739	In the second layer you compute f 2 of f 1 of x which gives you a set of feature vectors h 2.
20.srt	00:27:00.899 --> 00:27:02.749	So, you find that each of them are non-linear mappings.
20.srt	00:27:02.749 --> 00:27:12.349	Over here through this cascading operations I get a set of feature vectors say.
20.srt	00:27:12.969 --> 00:27:14.609	h k minus 1.
20.srt	00:27:16.589 --> 00:27:33.349	And when I have this h k minus 1 in thisfeature space as these are non-linear mapping of X, I can have a set of non-linear mapping such that h k minus 1 will lead to a linear problem or a linearly separable problem.
20.srt	00:27:33.349 --> 00:27:41.969	And once I have that the final one that is f k can be a linear machine or it might be a linear classifier.
20.srt	00:27:44.159 --> 00:27:53.039	So, I have a set of operations which maps an input vector non-linearly into a space where they are linearly separable.
20.srt	00:27:53.039 --> 00:27:59.059	And once they are linearly separable then in the final step I can have a linear classifier.
20.srt	00:27:59.059 --> 00:28:05.569	That is what a multi layer feed forward neural network does.
20.srt	00:28:05.569 --> 00:28:08.279	And why is it feed forward?
20.srt	00:28:08.279 --> 00:28:13.349	Because you find that the information is always flowing from input to output.
20.srt	00:28:14.519 --> 00:28:16.869	right, the information does not flow in the reverse way.
20.srt	00:28:17.839 --> 00:28:24.889	Of course, there are other variants of the neural network known as recurrent neural network, where the information can also be fed back we will come to that later.
20.srt	00:28:26.759 --> 00:28:37.689	And here you find that in the number of such cascading stages, here the number of cascading stages which is equal to k, this tells you what is the depth of the network.
20.srt	00:28:37.999 --> 00:28:47.359	So, in this particular case the depth is k. And as the value of k increases, that is the number of layers increases, the depth also increases.
20.srt	00:28:47.909 --> 00:28:52.699	the network giving you the non-linear transformation, it is related to that.
20.srt	00:28:52.699 --> 00:28:59.219	So, I will stop here today and I will continue with the discussion in our next class.
20.srt	00:28:59.219 --> 00:29:00.429	Thank you.
18.srt	00:00:00.610 --> 00:00:28.989	Hello, welcome to the NPTEL online certification course on deep learning.
18.srt	00:00:32.850 --> 00:00:51.649	So, you have seen thatin previous lecture we have talked aboutthe optimization problem particularly optimization in machine learning and we have discussed how optimization in machine learning is different from the general optimization tasks.
18.srt	00:00:53.100 --> 00:00:57.329	We have also talked about the linear and logistic regression.
18.srt	00:01:02.840 --> 00:01:29.590	So, in case of linear regression we have seen that a variable y a dependent variable y ispredicted using a linear function of the components of the feature vector y or a feature vector x or we have written y in the form of y hat the predicted value of y as y hat as w transpose x where x is the feature vector and w is the weight vector.
18.srt	00:01:33.069 --> 00:01:37.810	And in case of linear regression We have said that based on this predicted value of y you take certain decision.
18.srt	00:01:38.810 --> 00:01:57.269	And, we have also seen we have also discussed that this linear regression at W transpose X gives you an idea of what is the distance of feature vector X from the separating plane that is a plane having equation W transpose X equal to 0.
18.srt	00:01:58.359 --> 00:02:03.939	And, more the distance of the feature vector X is from the separating plane.
18.srt	00:02:04.429 --> 00:02:07.030	more confident our decision is.
18.srt	00:02:07.059 --> 00:02:14.930	That means, we know that the feature vector x is well within the region given to the corresponding class.
18.srt	00:02:16.240 --> 00:02:24.579	In case of logistic regression we have seen that this distance measured can be interpreted as a probabilistic measure.
18.srt	00:02:39.150 --> 00:02:41.900	That means, more our confidence is that a feature vector x belonging to some class say y, the probability of that class y given x and the parameters w the parameter vector w should also be high.
18.srt	00:02:42.960 --> 00:03:00.640	So, as the distance goes on increasing the probability asymptotically reaches to 1 or in the other case as the distance goes on reducing in the negative side the probability of the other class goes on increasing.
18.srt	00:03:00.990 --> 00:03:11.920	So, that some of the probabilities belonging to the two classes always becomes equal to 1 because the data has to belong to either of the classes either class omega 1 or class omega 2.
18.srt	00:03:13.770 --> 00:03:24.950	So, both this linear regression and the logistic regression we have discussed with respect to the problems which are two class problems or binary classification problems.
18.srt	00:03:24.950 --> 00:03:34.370	Then we have generalized this logistic regression which is a probabilistic measure to a class of classifier set of classifiers which are known as soft max classifier.
18.srt	00:03:35.280 --> 00:03:41.060	So, the soft max classifier is a classifier which deals with multi class problem.
18.srt	00:03:43.490 --> 00:03:50.870	So, earlier we had seen that in case of multiclass problem we could have a linear machine or we could have a multiclass support vector machine.
18.srt	00:03:51.740 --> 00:04:10.960	Where the linear machine or this multiclass support vector machine gives you class score or it outputs a k dimensional vector where k is the number of classes and the linear machine or the support vector machine tell or multiclass support vector machine gives you a score for every class.
18.srt	00:04:11.830 --> 00:04:14.970	And then for whichever class the score was maximum.
18.srt	00:04:15.000 --> 00:04:19.740	2, we could classify the vector to that corresponding class.
18.srt	00:04:20.740 --> 00:04:29.910	So, as in case of logistic regression for a two class problem or a binary problem that the distance measure is converted into a probabilistic measure.
18.srt	00:04:30.660 --> 00:04:37.579	In case of softmax classifier the class score can also be converted to a probabilistic measure.
18.srt	00:04:38.420 --> 00:04:45.589	For that what we have done is given the class score plus course a class y i to be S y i.
18.srt	00:04:46.399 --> 00:05:19.099	And, class score for every class J to be S j, we have converted this class score into a probabilistic measure that P of y i given X w is equal to e to the power S y i upon sum of e to the power S j, where the summation is taken over all j that comes into a denominator and that is what becomes a normalized probabilistic measure and that is what you have done in case of softmax classifier.
18.srt	00:05:20.389 --> 00:05:38.139	In today's lecture, we are going to discuss about the nonlinearity, how considering nonlinearity is important for machine learning techniques and then we will extend our discussion to neural networks or deep neural networks.
18.srt	00:05:38.410 --> 00:05:49.730	And here it is very very important because when we talk about deep learning the entire deep learning algorithm entire set of deep learning algorithms are based on .
18.srt	00:05:50.000 --> 00:05:51.840	neural network architecture only.
18.srt	00:05:52.379 --> 00:06:00.329	So, in some cases the deep learning is also known as deep neural network algorithms or deep neural network architectures.
18.srt	00:06:01.889 --> 00:06:04.370	So, first let us talk about nonlinearity.
18.srt	00:06:20.199 --> 00:06:42.610	So, again I am repeating the samefigure that earlier we had seen that if the classes are linearly separable, I can pass a straight line or a plane or a hyper plane in multi dimension between the vectors given for two different classes or in other words that this linear function or the hyper plane can separate support can separate the feature vectors belonging to classes omega 1 and omega 2 and I can pass I can have such a hyper plane without any error.
18.srt	00:06:44.000 --> 00:06:50.279	But, you consider a case say something like this if my feature vectors are of this form.
18.srt	00:06:51.229 --> 00:06:56.419	So, here all the feature vectors marked as plus.
18.srt	00:06:58.779 --> 00:07:17.959	So, these are the vectors belonging to belongs to one class let us call it class omega 1 and all the vectors which are marked as minus they are the feature vectors belonging to belonging to class omega 2 .
18.srt	00:07:17.959 --> 00:07:20.659	So, I have the distribution of the feature vectors .
18.srt	00:07:21.169 --> 00:07:27.999	to classes omega 1 and classes omega 2 as shown over here and you can well imagine.
18.srt	00:07:27.999 --> 00:07:48.119	So, this is the case in a 2 dimension,in 3 dimension I can have a spherical distribution of feature vectors belonging to one class and outside the sphere I can have feature vectors belonging to another class and I can have many such complicated distribution of the feature vectors.
18.srt	00:07:48.179 --> 00:07:51.839	So, given this you can well imagine.
18.srt	00:07:53.009 --> 00:08:02.159	that here it is not possible to have a linearseparator between the classes omega 1 and omega 2 ok.
18.srt	00:08:02.779 --> 00:08:10.569	Whichever straight line I form whichever I take I will always have some specification.
18.srt	00:08:11.519 --> 00:08:15.579	So, this is the problem which is linearly non separable problem.
18.srt	00:08:16.029 --> 00:08:24.049	I can I cannot separate the classes using a linear function or this problem cannot be solved using linear function.
18.srt	00:08:25.099 --> 00:08:27.129	So, what we can do in such cases?
18.srt	00:08:28.349 --> 00:08:38.859	Let me just simplify the problem instead of taking vectors in two dimension, let us consider that I will take vectors in one dimension or say scalar features.
18.srt	00:08:40.749 --> 00:08:45.369	So, I take a set of features let me draw it properly.
18.srt	00:08:49.619 --> 00:08:53.889	So, as I said that I have the features on in one dimension.
18.srt	00:08:55.449 --> 00:09:20.629	So, I have a set of samples which are like this that belongs to one class and I can have another set of samples which I am marking in pink which belong to a separate class .
18.srt	00:09:20.629 --> 00:09:25.470	So, given this you find that all the samples which are marked in pink .
18.srt	00:09:26.080 --> 00:09:28.860	are sandwiched between the samples which are marked in blue.
18.srt	00:09:30.090 --> 00:09:44.769	So, given such a case I cannot draw a straight line or I cannot separate the samples belonging to these two classes using a single point on say line x.
18.srt	00:09:44.889 --> 00:09:47.500	So, this is the feature direction.
18.srt	00:09:48.470 --> 00:09:58.649	I cannot have a single point on this featureline x which separates the samples belonging to class omega 1 and the samples belonging to class omega 2.
18.srt	00:09:59.840 --> 00:10:21.350	I can of course, separate them if I take a curve of this form ok or in other words I have got two points on this feature line using which I can separate these two classes.
18.srt	00:10:21.610 --> 00:10:26.670	So, this becomes a non-linear problem it is not a linear problem anymore.
18.srt	00:10:30.120 --> 00:10:35.790	So, how to solve I can still solve this by having some non-linear mapping of the feature vectors right.
18.srt	00:10:37.090 --> 00:10:48.500	So, what I will do is I will have a non-linear mapping of this feature vectors in such a way that these feature vectors will be remapped in this direction ok.
18.srt	00:11:01.280 --> 00:11:12.270	So, as a result the feature vectors all the feature vectors belonging to class say omega Let me draw redraw this figure .
18.srt	00:11:12.270 --> 00:11:32.200	So, all the feature vectors which are marked in pink they will be mapped over here and all the feature vectors which were marked in blue they will be mapped over here .
18.srt	00:11:32.200 --> 00:11:32.860	So, you find that .
18.srt	00:11:33.200 --> 00:11:39.210	which separates the feature vectors which are pink from the separate feature vectors which are blue.
18.srt	00:11:40.389 --> 00:11:47.169	So, one way we can tackle the problem of non-linearity that is if the feature vectors are mixed.
18.srt	00:11:47.169 --> 00:12:04.710	So, that problems can still be solved using a linear classifier, but for that instead of trying to use a non-linear classifier you apply some non-linear mapping on the feature vectors and once the feature vectors are non-linearly mapped.
18.srt	00:12:07.009 --> 00:12:17.209	possibly on a higher dimensional space in that higher dimensional space the feature vectors can be classified using a linear classifier.
18.srt	00:12:18.799 --> 00:12:23.500	So, what we will do in that two dimensional example that we have just shown.
18.srt	00:12:24.949 --> 00:12:28.409	Let us go to this two dimensional example again.
18.srt	00:12:29.579 --> 00:12:31.679	So, the example was like this ok.
18.srt	00:12:37.479 --> 00:12:49.009	So, what I can do here is you find that this is something a circle at the center and the feature vectors belonging to class omega 1 are within this circle and all the feature vectors belonging to class omega 2 they are outside the circle.
18.srt	00:12:50.109 --> 00:12:57.969	So, I can have a non-linear mapping of this feature vectors say non-linear mapping using a non-linear function say phi.
18.srt	00:12:57.969 --> 00:13:02.759	How this non-linear function will work?
18.srt	00:13:02.759 --> 00:13:10.049	You find that I have feature vectors in two-dimensional space which is given by x 1 and x 2.
18.srt	00:13:12.419 --> 00:13:27.679	If I introduce a third dimension say I want to have a value of z where z will be equal to x 1 square plus x 2 square right.
18.srt	00:13:28.389 --> 00:13:34.849	So, if I do that then you find that for any feature vector which which is outside the circle.
18.srt	00:13:35.719 --> 00:13:45.039	So, over here the value of x 1 square plus x 2 square will be more than the value of x 1 square power.
18.srt	00:13:45.189 --> 00:13:49.239	plus x 2 square for any feature vector which is within the circle.
18.srt	00:13:50.229 --> 00:13:59.999	Because for any point on the circle x square plus x 1 square plus x 2 square is nothing but square of the radius of the circle.
18.srt	00:14:01.079 --> 00:14:12.049	And because all these feature vectors which are negative are outside the circle for them the square of the distance will obviously, higher than the square of the radius of the circle.
18.srt	00:14:16.089 --> 00:14:26.209	So, for all these feature vectors which are outside the circle x 1 square plus x 2 square or the value of z will be more than the value of x square plus y square for any feature vector which is within the circle.
18.srt	00:14:27.169 --> 00:14:32.059	So, what I will do is I will now represent all these feature vectors.
18.srt	00:14:32.059 --> 00:14:37.189	So, in the original form the feature vectors are two dimensional having components x 1 and x 2.
18.srt	00:14:37.559 --> 00:14:44.120	Now, I will add a third component z which is x 1 square plus x 2 square ok.
18.srt	00:14:46.559 --> 00:14:53.299	So, now, my feature vectors will be x 1 x 2 and x 1 square plus x 2 square.
18.srt	00:14:55.559 --> 00:14:57.870	So, this becomes the feature vector .
18.srt	00:14:57.870 --> 00:15:10.149	So, you find that I have applied a non-linear function which non-linearly maps these feature vectors from a two dimensional space to a three dimensional space.
18.srt	00:15:10.149 --> 00:15:16.129	And when you consider in the third dimension that is in the dimension of z.
18.srt	00:15:17.699 --> 00:15:30.269	For all these feature vectors which are within the circle having marked positive for them the z value is less than the z value of the feature vectors which are marked negative.
18.srt	00:15:30.869 --> 00:15:39.339	That means, when I consider in the z dimension all the feature vectors which are negative is somewhere over here and all the feature vectors which are positive is somewhere over here.
18.srt	00:15:51.230 --> 00:16:03.220	So, once I have this then I can always pass a plane in between which is passing through the feature vectors belonging to one class and the feature vectors belonging to another So, to by this non-linear mapping on the feature vectors, I am converting on linearly non-separable set of feature vectors to a linearly separable set of feature vectors.
18.srt	00:16:03.220 --> 00:16:17.799	And we can say that this is being done by a non-linear mapping phi and this phi is nothing, but a collection of three functions.
18.srt	00:16:21.210 --> 00:16:29.889	phi 1, phi 2 and phi 3 where phi 1 and phi 2 phi 1 works on x 1 x 2.
18.srt	00:16:29.889 --> 00:16:33.680	So, I will write it in this way let me clear this.
18.srt	00:16:35.710 --> 00:16:40.190	So, x is my feature Richter which is having two components x 1 and x 2.
18.srt	00:16:53.610 --> 00:16:55.130	So, phi of x I can write it as phi 1 x phi 2 x phi 3 x phi x and phi 3 x.
18.srt	00:17:00.570 --> 00:17:01.730	What is phi 1 x?
18.srt	00:17:03.540 --> 00:17:23.560	Phi 1 x gives you x 1, phi 2 x gives you x 2 and phi 3 x gives you x 1 square plus x 2 square and that is what is the non-linear mapping that we are going to have.
18.srt	00:17:25.550 --> 00:17:40.450	So, you find that now I have converted this feature vectors from x 1, x 2 plane from 2 dimension to 3 dimension where now the dimensions are given by phi 1, phi 2 and phi 3.
18.srt	00:17:40.970 --> 00:17:58.800	So, I can simply write this as the space now I can represent as I am having 3 dimensions, I can put it like.
18.srt	00:17:59.440 --> 00:18:06.960	this is phi 1, this is phi 2 and this is phi 3 .
18.srt	00:18:06.960 --> 00:18:28.960	And once I have this you find that the hyper plane in this phi 1, phi 2, phi 3 space can now be written as say W 1 phi 1 plus W 2 phi 2 plus W 3 phi 3 that equal to 0 .
18.srt	00:18:31.070 --> 00:18:31.430	right.
18.srt	00:18:32.520 --> 00:18:38.800	And now if you expand this phi 1, phi 2 and phi 3 what I have phi 1 is nothing but x 1.
18.srt	00:18:39.010 --> 00:18:45.000	So, this simply gives you w 1 x 1 phi 2 is nothing but w x 2.
18.srt	00:18:45.130 --> 00:18:54.160	So, that gives you w 2 x 2 plus phi 3 is x 1 square plus x 2 square.
18.srt	00:18:54.790 --> 00:19:00.890	So, I have w 3 x 1 square plus x 2 square .
18.srt	00:19:01.520 --> 00:19:05.470	which is equal to 0 that is the equation of the plane that I have.
18.srt	00:19:07.080 --> 00:19:22.160	Now, I find that I can have a dual interpretation of this equation in the sense if I consider this equation where my variables are x 1 and x 2 the equation is a non-linear equation right.
18.srt	00:19:23.870 --> 00:19:33.230	Whereas, while training I am given the training vectors that means, for all those training vectors x 1 x 2 are fixed.
18.srt	00:19:34.520 --> 00:19:53.810	So, I can also consider this equation to be a equation in W 1, W 2 and W 3 where W 1, W 2 and W 3 are the variables, but because the feature vectors given for training are fixed so I can also consider X 1 and X 2 to be constants.
18.srt	00:19:54.700 --> 00:19:59.230	So, if I consider X 1 and X 2 to be constants then this equation is a linear equation.
18.srt	00:19:59.740 --> 00:20:04.590	So, if I consider this equation to be a equation in X, X 1, X 2 it is the non-linear equation.
18.srt	00:20:05.480 --> 00:20:08.490	which gives you a non-linear mapping of the feature vectors.
18.srt	00:20:08.550 --> 00:20:15.590	So, the feature vector x 1 x 2 is non-linearly mapped into phi 1 phi 2 phi 3 domain.
18.srt	00:20:15.590 --> 00:20:28.580	And the classifier or the separating plane is a plane where w 1 w 2 w 3 are variables and x 1 and x 2 are fixed ok.
18.srt	00:20:28.580 --> 00:20:38.880	So, by this non-linear mapping you are mapping the feature vectors into another space and possibly a higher dimensional space and in that higher dimensional space.
18.srt	00:20:41.430 --> 00:20:43.510	the feature vectors are linearly separable.
18.srt	00:20:44.270 --> 00:20:57.570	So, you will come to so, this is a very simple example where using a simple mapping I can convert a non-linearly a linearly non-separable set of feature vectors into a linearly separable set of feature vectors.
18.srt	00:20:57.570 --> 00:21:10.920	However, the type of non-linearity may not be so simple, there can be complicated non-linearities and those are the non-linearities which are to be solved by the neural networks that we will see later.
18.srt	00:21:12.300 --> 00:21:17.950	this mapped space is of higher dimension than the original space.
18.srt	00:21:19.050 --> 00:21:39.320	And theoretically it can be proven that if I map feature vectors to infinite dimensional space, then whatever be the complexity of the nonlinearity every nonlinear problem can be solved as a linear problem when you are increasing the dimension to 0.
18.srt	00:21:43.310 --> 00:21:45.560	And for such nonlinear mapping, we can I obviously, I have to have some non-linear functions.
18.srt	00:21:45.560 --> 00:21:52.930	So, now let us see that what are the different kinds of non-linear functions that can help us in such a non-linear mapping.
18.srt	00:21:52.930 --> 00:22:01.580	So, one of the non-linear function which we will use is what is known as threshold function, it is a very very simple function.
18.srt	00:22:01.580 --> 00:22:16.610	So, the threshold function says that if y is a function of x, then output y the dependent variable y will have a value of 1 if x is greater than or equal to 0.
18.srt	00:22:18.660 --> 00:22:22.890	and it will have a value of 0 if is x is less than 0.
18.srt	00:22:24.420 --> 00:22:28.550	So, here this non-linear function is depicted in this form.
18.srt	00:22:28.550 --> 00:22:33.610	So, as x is greater than 0 value of y is 1.
18.srt	00:22:33.610 --> 00:22:39.140	So, here it is 1, if x is less than 0 the value of y is 0.
18.srt	00:22:39.140 --> 00:22:40.310	So, here it is 0.
18.srt	00:22:40.310 --> 00:22:46.650	So, this is the simplest kind of non-linearity which is a threshold function that we can have.
18.srt	00:22:46.650 --> 00:22:52.470	And we will see the use of this sort of non-linearity when we start our discussion on neural network.
18.srt	00:22:55.900 --> 00:23:00.980	The next type of nonlinearity which we have already discussed is logistic regression.
18.srt	00:23:01.070 --> 00:23:10.010	You find that this mapping that we have done from W transpose X to sigma W transpose X is nothing but a nonlinear function, ok.
18.srt	00:23:10.370 --> 00:23:19.500	So, this sigma W transpose X which is 1 over 1 plus e to the power minus W transpose X this is a nonlinear function.
18.srt	00:23:23.980 --> 00:23:28.560	So, this function also helps us to transform a non-linear problem to a linear problem.
18.srt	00:23:28.560 --> 00:23:43.820	The other kind of non-linearity which is widely used in case ofneural network or modern deep neural network is what is known as ReLU or rectified linear unit.
18.srt	00:23:43.820 --> 00:23:55.330	So, this rectified linear unit simply puts as if y is a function of x, then y will get a value of maximum of 0 or x.
18.srt	00:24:00.080 --> 00:24:11.780	So, naturally you find that if x is greater than 0, y gets the value of x and if x is 0 or less y will have a value of 0.
18.srt	00:24:12.980 --> 00:24:24.410	So, for all positive x y and x are same for 0 and less if value of x is 0 or negative then y will assume a value of 0.
18.srt	00:24:25.550 --> 00:24:29.710	So, I can depict this function in this form.
18.srt	00:24:29.960 --> 00:24:36.670	So, here you find that as x is greater than 0, y is equal to x.
18.srt	00:24:36.670 --> 00:24:43.950	So, if you take the gradient of thisslope of this line, this slope is nothing but 45 degree.
18.srt	00:24:44.080 --> 00:24:50.320	So, as y is greater than 0 value as x is greater than 0, y becomes equal to x.
18.srt	00:24:50.630 --> 00:24:54.250	If x is less than 0 or 0, then value of y is 0.
18.srt	00:24:54.900 --> 00:25:01.220	So, this is a linear rectified unit rectified linear unit.
18.srt	00:25:01.520 --> 00:25:04.280	which is in short it is written as ReLU.
18.srt	00:25:05.270 --> 00:25:20.570	And obviously, you find that it is also a non-linear mapping this also gives a non-linear mapping because if y is equal to x or y is some constant a times x that is a linear function, but the moment I put y in this form it is a non-linear function.
18.srt	00:25:20.570 --> 00:25:30.530	So, in case of neural networks we will see later that in simpler cases we can use threshold functions.
18.srt	00:25:33.260 --> 00:25:48.620	In most of the popular neural networks the nonlinearity that is used as a sigmoidal function, but in modern neural networks in deep neural networks instead of sigmoidal function people prefer nonlinearity.
18.srt	00:25:49.080 --> 00:26:02.200	The reason isthreshold function is a simple sort of nonlinearity for simple networks we can use that, but the problem with the threshold function is it is non-differentiable I cannot differentiate it threshold function.
18.srt	00:26:03.840 --> 00:26:19.810	And, we have seen in training earlier that in most of the cases training uses a gradient descent approach where gradient is nothing, but a differentiation right differentiation in multiple directions.
18.srt	00:26:20.810 --> 00:26:26.700	So, because threshold function is an cannot be differentiated it is a non-differentiable function.
18.srt	00:26:26.700 --> 00:26:33.200	So, there it leads to problem in case of training of the neural network because gradient descent cannot be applied on that.
18.srt	00:26:34.340 --> 00:26:40.490	So, that problem is slightly overcome if we use sigmoidal function is a non-linearity.
18.srt	00:26:40.490 --> 00:26:43.790	Of course, sigmoidal function is not the only one.
18.srt	00:26:43.790 --> 00:26:53.519	The other kind of non-linearity which people also have tried is what is known as tan hyperbolic non-linearity, where you have variation of the output from minus 1 to plus 1.
18.srt	00:26:53.519 --> 00:26:56.230	In case of sigmoidal function it is 0 to plus 1.
18.srt	00:27:03.980 --> 00:27:14.700	So, tan hyperbolic kind of non-linearity has also been used, but there again the problem is when the value of W transpose X is very high or the value of the argument is very high the gradient is very very slow right because your curve is almost parallel.
18.srt	00:27:14.890 --> 00:27:33.220	So, gradient almost vanishes and because of that your training or the learning algorithms becomes very slow which is solved by this ReLU because in case of ReLU as long as X is greater than 0 the gradient of the function is unity right.
18.srt	00:27:33.370 --> 00:27:35.170	So, here the gradient does not vanish.
18.srt	00:27:35.800 --> 00:27:48.280	So, that is an advantage of ReLU and when you have modern deep neural networks where you have large number of nodes, large number of layers, hidden layers,then ReLU becomes more advantageous over sigmoidal function.
18.srt	00:27:48.280 --> 00:27:57.760	So, today we have discussed about nonlinearity and we will continue with this discussions in our next lectures.
18.srt	00:27:57.760 --> 00:27:58.780	Thank you.
30.srt	00:00:00.610 --> 00:00:17.820	Hello, welcome back to the NPTEL online certification course on deep learning.
30.srt	00:00:31.140 --> 00:00:38.760	So, in our previous class we have started discussion onautoencoder versus principal component analysis.
30.srt	00:00:40.100 --> 00:00:50.859	So, what we had discussed in the previous class is how you get the principal components from the covariance matrix of the input data.
30.srt	00:00:52.789 --> 00:00:58.140	So, let me just briefly tell youwhat we have discussed in the previous class.
30.srt	00:00:58.609 --> 00:01:05.090	So, that our platform for discussion on comparison between autoencoder and principal components.
30.srt	00:01:05.530 --> 00:01:06.120	becomes complete.
30.srt	00:01:07.430 --> 00:01:36.140	So, what we presented in the previous class is that given a set of your input vectors x, where x we have considered to be a vector set of vectors x 1, x 2 up to say x n having n number of population, where each of this vector x is of dimension d.
30.srt	00:01:36.359 --> 00:01:40.740	that means, there are d number of components in the feature vector.
30.srt	00:01:42.070 --> 00:01:48.260	Then first you find out the covariance matrix from this set of input vectors.
30.srt	00:01:48.600 --> 00:02:07.460	So, the covariance matrix is given by C x is equal to expectation value of x minus mu x into x minus mu x transpose where this mu x.
30.srt	00:02:08.879 --> 00:02:12.500	is the mean of the input vector.
30.srt	00:02:12.500 --> 00:02:22.960	So, mean mu x is equal to sum of x over all x where x is the set of these vectors.
30.srt	00:02:24.349 --> 00:02:35.139	Once you form this covariance matrix C x, then for from this covariance matrix C x is compute the eigenvectors and the eigenvalues.
30.srt	00:02:35.629 --> 00:02:38.599	So, I have set of eigenvalues lambda i.
30.srt	00:02:39.049 --> 00:02:56.060	where i varies from 1 to d as d is the dimensionality of the feature vectors and for each lambda i I have the corresponding eigenvector E i .
30.srt	00:02:56.060 --> 00:03:10.299	And once I had this E i the set of eigenvectors then we had formed a transformation matrix A where A was formed as with the eigenvectors E s as rows.
30.srt	00:03:10.299 --> 00:03:13.479	So, the first row was E 1, the second row was E 2 .
30.srt	00:03:13.840 --> 00:03:32.319	and the last row was E d and these eigenvectors were arranged in rows in such a way that here lambda i or the lambda 1 is greater than lambda 2 and so on it is greater than lambda t .
30.srt	00:03:32.319 --> 00:03:52.199	So, an eigenvector corresponding to the maximum eigenvalue is put as first element or the first row in my transformation matrix and the eigenvector corresponding to the minimum eigenvalue is put as the last row in the transformation matrix.
30.srt	00:03:58.789 --> 00:04:01.530	So, all the eigenvectors are actually arranged in rows in order of the descending order of the corresponding eigenvalues.
30.srt	00:04:03.449 --> 00:04:21.689	So, once I define thistransformation matrix, then I have a transformation which is given by Y is equal to A into X minus mu X and this transformation is what is known as K L transformation.
30.srt	00:04:37.269 --> 00:04:46.049	And from the nature of this transformation you find that x is an input vector and a is the transformation matrix where every row in this transformation matrix are the eigenvectors.
30.srt	00:04:47.189 --> 00:05:04.669	So, every component of y is nothing, but projection of the vector x minus mu x onto the ith eigenvector which is the ith row in this transformation matrix.
30.srt	00:05:05.120 --> 00:05:15.309	So, ith component of my transform vector y is nothing, but the projection of the vector x minus mu x onto the ith eigenvalue .
30.srt	00:05:16.370 --> 00:05:24.469	And, these components of the vector y the transform vector y is are nothing, but my principal components.
30.srt	00:05:25.239 --> 00:05:36.889	And, you find that this principal components are nothing, but the transformation of the input vector x shifted by mu x onto the eigenvector.
30.srt	00:05:36.889 --> 00:05:43.099	So, this transformation basically gives you a mapping from the input space to an eigen space.
30.srt	00:05:43.269 --> 00:05:48.259	And, as we said the eigenvectors been orthogonal, eigen space is also orthogonal.
30.srt	00:05:49.449 --> 00:06:03.439	So, effectively what this transform and the way you obtain the data reduction is that in the transformation matrix A, where A is of dimension d by d right, it has d number of rows, d number of columns.
30.srt	00:06:04.209 --> 00:06:14.609	So, if I reduce the number of columns from the bottom that is I remove columns corresponding to minimum eigenvalues that ensures that in the reconstruction I will have minimum amount of error.
30.srt	00:06:16.119 --> 00:06:19.209	So, that is a different analysis which is beyond the scope of this lecture.
30.srt	00:06:20.329 --> 00:06:29.339	So, I assume that I truncate this transformation matrix A by reducing some number of rows from the bottom.
30.srt	00:06:30.239 --> 00:06:53.750	So, what I do is I make a transformation matrix A with say p number of rows and of course, d number of columns I am not reducing the number of columns where this p is much less than d. So, using that when I go for this transformation y is equal to A into x minus mu x.
30.srt	00:06:54.989 --> 00:07:04.009	This vector a that you get that will have p number of components and if I do not go for any truncation this vector a will have d number of components.
30.srt	00:07:04.869 --> 00:07:12.589	So, as I reduce the number of rows my in my transformation matrix I go for reduction of the dimensionality ok.
30.srt	00:07:12.969 --> 00:07:25.379	But this reduction is done in such a way by removing the eigenvectors in such a way that when I try to reconstruct my original x from y by an inverse transformation.
30.srt	00:07:27.369 --> 00:07:34.029	So, from here x will be A inverse y plus mu x.
30.srt	00:07:36.209 --> 00:07:41.919	So, as in transformation matrix A, I am not retaining all the components or all the rows.
30.srt	00:07:42.099 --> 00:07:51.029	So, obviously, the reconstructed x that I will have will not be actual x, but it will be an approximation of x which is exact ok.
30.srt	00:07:51.819 --> 00:07:55.829	So, this is what I get after reducing the dimensionality.
30.srt	00:07:59.559 --> 00:08:05.889	So, as PCA gives you reduction in dimensionality and we have also seen that autoencoder gives you reduction in dimensionality.
30.srt	00:08:06.469 --> 00:08:12.259	So, whether we can have some relation we can establish some relation between PCA and autoencoder.
30.srt	00:08:12.939 --> 00:08:18.649	We will come to that a bit later, but before that let us try to see what this PCA is actually giving you.
30.srt	00:08:19.719 --> 00:08:23.969	So, to further illustrate the principal components I have taken this binary image.
30.srt	00:08:24.249 --> 00:08:28.969	So, here you find that it is a binary image where all these.
30.srt	00:08:29.529 --> 00:08:40.449	elements which are blue these are 1 that means, I can say that I have pixels present in this location in these locations I do not have any pixel.
30.srt	00:08:41.939 --> 00:08:46.639	So, I can form a vector with only the pixel locations where the pixels are present.
30.srt	00:08:47.669 --> 00:08:52.909	So, accordingly my population of vectors will be given by this 3 4 ah.
30.srt	00:08:54.059 --> 00:09:00.220	So, this is 3 4 right sorry this is 4 3 .
30.srt	00:09:00.819 --> 00:09:04.929	0 1 2 3 4 0 1 2 3.
30.srt	00:09:05.009 --> 00:09:06.250	So, this is 3 4 3.
30.srt	00:09:07.120 --> 00:09:10.470	Similarly, this is the vector which is 3 4 and so on.
30.srt	00:09:10.870 --> 00:09:21.090	So, all the vector positions all the positions where I have a pixel present, I take those positions as my vector population.
30.srt	00:09:22.370 --> 00:09:30.419	And from this set of vectors, I compute the mean of the vectors which is mu x and in this particular case you can compute that this mean vector will be 4.5 4.5.
30.srt	00:09:32.820 --> 00:09:42.009	So, once I have this computation now as we said before that for principal components or for KL transformation I need to have the covariance matrix.
30.srt	00:09:42.730 --> 00:09:49.529	And we defined covariance matrix as expectation value of X minus mu X into X minus mu X transpose.
30.srt	00:09:50.529 --> 00:09:52.559	So, here I have a very small example.
30.srt	00:09:53.000 --> 00:09:57.740	So, from hereif I try to compute that covariance matrix.
30.srt	00:09:58.269 --> 00:10:01.759	So, the covariance matrix for I take this as my first.
30.srt	00:10:02.109 --> 00:10:03.240	vector x 1.
30.srt	00:10:04.259 --> 00:10:17.849	So, x 1 minus mu x where mu x was 4.4 5 4.5, if you subtract 4.5 4.5 from 3 4 what you get is your x minus mu x becomes minus 1.5 minus 0.5.
30.srt	00:10:17.849 --> 00:10:26.179	So, x minus mu x into x minus mu x transpose if you do this multiplication it simply becomes 2.25 0.75.
30.srt	00:10:32.769 --> 00:10:37.979	0.75 sorry yeah 2.25, 0.75, 0.75 and 0.25.
30.srt	00:10:38.149 --> 00:10:43.419	So, that is for the first vector in my vector population that I get.
30.srt	00:10:43.419 --> 00:10:58.359	Similarly, when I compute x 2 minus mu x into x 2 minus mu x transpose in the same manner that will give you 0.25, 0.75, 0.75 and 2.25 you can compute this and verify .
30.srt	00:10:58.359 --> 00:11:08.509	So, this way you compute x minus mu x into x minus mu x transpose for all the vectors that we have in set of vectors x .
30.srt	00:11:11.399 --> 00:11:22.219	And, the expectation value is nothing but average of these matrices that you are getting for each of the vectors I am getting x minus mu x into x minus mu x transpose.
30.srt	00:11:22.699 --> 00:11:25.229	So, in this particular case I have 8 such vectors.
30.srt	00:11:25.229 --> 00:11:31.989	So, I will have 8 such matrices and the average of all those matrices gives you the covariance matrix.
30.srt	00:11:32.829 --> 00:11:45.019	So, covariance matrix in this case is nothing but if you compute that will come out to be the covariance matrix C x equal to 0.75, 0.375, 0.375 and 0.75.
30.srt	00:11:48.539 --> 00:12:03.249	And, from here you compute the eigenvalues as I said that it will be the determinant 0.75 minus lambda 0.375, 0.375 and 0.75 minus lambda you set this determinant equal to 0.
30.srt	00:12:03.249 --> 00:12:14.759	So, you get a quadratic equation in lambdas you solve that and you get two values of lambda, lambda 1 comes out to be 1.125 and lambda 2 comes out to be 0.375 .
30.srt	00:12:18.479 --> 00:12:36.339	And, for these values of lambda you compute the corresponding eigenvectors as we said that the eigenvectors will be nothing, but C X e is equal to lambda e where C X is your covariance matrix e isthe eigenvector and lambda is the eigenvalue.
30.srt	00:12:37.069 --> 00:12:40.949	So, you solve those equations you get your eigenvectors .
30.srt	00:12:40.949 --> 00:12:47.819	So, it comes out to be that in this particular case your e 1 for eigenvalue lambda 1.
30.srt	00:12:48.109 --> 00:12:50.729	comes out to be 1 upon root 2 1 1.
30.srt	00:12:51.359 --> 00:12:58.359	Similarly, E 2 for eigenvalue lambda 2 comes out to be 1 upon root 3 1 minus 1.
30.srt	00:12:59.869 --> 00:13:07.479	Now, what comes next is the interesting one that is we want to see that what are these eigenvectors.
30.srt	00:13:08.649 --> 00:13:14.739	So, I simply superimpose these eigenvectors in the same image space here.
30.srt	00:13:18.979 --> 00:13:43.359	So, here you find that if you look at this you find that the direction of E 1 if you look at this direction, this is the direction in which your spread of data is maximum right and that is what we said that lambda 1 that is the eigenvalue indicates that what is the variation of data in the direction of the corresponding eigenvector.
30.srt	00:13:48.989 --> 00:13:53.119	Similarly, lambda 2 this tells you that the that the variation of data in this direction is minimum right.
30.srt	00:13:53.679 --> 00:14:11.899	So, I get lambda 1 and lambda 2 and here again you find that thissorry E 1 and E 2 and here again you find that E 1 and E 2 they are actually orthogonal and they are centered at the centroid of the pixels.
30.srt	00:14:12.649 --> 00:14:23.289	So, that also says that a KL transformation is a transformation which gives you translation and rotation operations because E 1 E 2 are nothing, but rotated x 1 x 2.
30.srt	00:14:23.959 --> 00:14:30.989	And, this coordinate system u 1 e 2 is translated to the mean of the vectors that we have.
30.srt	00:14:31.019 --> 00:14:36.019	So, this also gives you the rotation and translation transformation right.
30.srt	00:14:36.939 --> 00:14:44.229	Now, coming to the concept ofyour principal components.
30.srt	00:14:44.889 --> 00:14:46.539	So, what are principal components over here?
30.srt	00:14:47.019 --> 00:14:55.069	So, I have data point this, if I take the projection of this data point.
30.srt	00:14:58.699 --> 00:14:58.859	.
30.srt	00:14:58.859 --> 00:15:08.589	See if I take the projection of this onto E 1, so this is the projection on E 1 and this is what is the principal component.
30.srt	00:15:08.589 --> 00:15:12.599	Similarly, if I project this onto E 2, this is also the principal component.
30.srt	00:15:12.599 --> 00:15:18.139	So, this is the first principal component and this is the second principal component.
30.srt	00:15:26.739 --> 00:15:37.369	If I want to represent this by a single dimension or by scalars, I will not consider the projection onto E 2 rather I will consider only projection onto E 1 because E 1 corresponds to the eigenvalue which is maximum.
30.srt	00:15:37.849 --> 00:15:42.239	So, this is my first principal component.
30.srt	00:15:42.239 --> 00:15:51.229	So, to think of this in other way the principal components or the KL transformation is actually a linear transformation.
30.srt	00:15:51.229 --> 00:15:57.909	So, what you are doing is given your input vector input data you are linearly transforming it.
30.srt	00:15:58.119 --> 00:15:59.949	to your principal components right.
30.srt	00:16:00.069 --> 00:16:07.019	So, principal components gives you a linear transformation or linear mapping from the input data space to the output data space.
30.srt	00:16:07.809 --> 00:16:18.409	So, if I want to retain only one component you find that that component is nothing but projections onto this eigenvector E 1.
30.srt	00:16:18.409 --> 00:16:20.039	So, you are projecting onto a line.
30.srt	00:16:20.909 --> 00:16:34.029	If I want to retain two components I want to convert the input data into two principal components by this principal component analysis I will take projections onto E 1, I will also take projections onto E 2.
30.srt	00:16:34.669 --> 00:16:39.849	That means, every vector will now be mapped to a point in the plane E 1, E 2.
30.srt	00:16:41.689 --> 00:16:44.259	So, this transformation is a linear transformation.
30.srt	00:16:45.849 --> 00:16:55.259	So, given this now can we try to establish that what will be the relation between the principal component analysis and autoencoders.
30.srt	00:16:57.119 --> 00:17:03.509	So, bothbefore that just to illustrate what is the power of this principal component analysis.
30.srt	00:17:03.509 --> 00:17:04.629	So, the principal components.
30.srt	00:17:05.839 --> 00:17:11.259	You find that this is just an illustration that I havethis input image.
30.srt	00:17:11.259 --> 00:17:24.079	So, this is the original input image and this is the image which has been reconstructed using only one principal component and you find that the reconstruction is amazing.
30.srt	00:17:24.219 --> 00:17:28.409	So, that simply says that principal components retains the structure of the data.
30.srt	00:17:29.919 --> 00:17:36.199	Instead of onethis original image is actually 256 by 256 number of pixels.
30.srt	00:17:37.379 --> 00:17:42.049	So, you find that reduction is from 256 to by 256 to 1.
30.srt	00:17:42.409 --> 00:17:44.269	So, the amount of compression that has been achieved.
30.srt	00:17:45.259 --> 00:17:50.009	Instead of 1, if I use 5 principal components, then this is the reconstruction that you get.
30.srt	00:17:52.119 --> 00:17:56.969	Instead of 5, if I use 25 principal components, this is the reconstruction that you get.
30.srt	00:17:57.909 --> 00:18:08.599	So, here you can imagine what is the amount of compression that we are getting or what is the compression amount of compression that we are getting over here 256 by 256 is to 256 is to 25.
30.srt	00:18:09.480 --> 00:18:15.200	So, that shows you what is the power of the principal components.
30.srt	00:18:15.200 --> 00:18:20.000	So, this principal components using principal components I can go for dimensionality reduction.
30.srt	00:18:20.659 --> 00:18:26.440	And as we have seen that using auto encoders also we can go for dimensionality reduction.
30.srt	00:18:27.649 --> 00:18:33.210	So, definitely I can establish some relation between these two.
30.srt	00:18:41.250 --> 00:18:53.049	So, what we have seen is in case of principal components this is a linear transformation from n dimensional space or say d dimensional space you are transforming it to say two dimensional space or three dimensional space depending upon the number of principal components that you want to use.
30.srt	00:18:54.240 --> 00:18:58.330	And this mapping is a linear mapping.
30.srt	00:18:58.330 --> 00:19:07.990	As against auto encoders beingneural networks which can implement non-linear functions.
30.srt	00:19:12.600 --> 00:19:16.650	So, the kind of mapping mapping that we can use in case of auto encoders is a non-linear mapping.
30.srt	00:19:16.690 --> 00:19:28.319	That means, in other words we can say that the principal components or the auto encoders can be thought of as generalization of principal components.
30.srt	00:19:28.319 --> 00:19:44.080	So, whatever principal components analysis can do auto encoders can also do the same thing, but auto encoder can do something more because here I can have non-linear mapping not simply linear mapping.
30.srt	00:19:45.289 --> 00:19:51.649	whereas, in case of principal components we have only linear mapping ok.
30.srt	00:19:52.669 --> 00:20:09.359	So, this is what I just said that given a set of data which are just red dots in this figure and I want to convert this set of data using principal component analysis into principal components.
30.srt	00:20:10.129 --> 00:20:14.960	So, if I use just two principal components P c 1 and P c 2.
30.srt	00:20:15.969 --> 00:20:27.769	I am transforming this set of data into onto a state line as given by this pink line right.
30.srt	00:20:28.209 --> 00:20:51.169	So, this issorry I am transforming this set of data onto a plane as defined by P c 1 and P c 2 and this being a linear transformation or linear mapping what I can do is given this set of data this can be approximated on a straight line or the straight line is defined in space P c 1 P c 2.
30.srt	00:20:52.899 --> 00:21:00.339	Whereas, autoencoders are capable of going for imparting non-linear transformation.
30.srt	00:21:00.339 --> 00:21:11.440	So, using autoencoders I can even go toestablish or to extract the non-linear structures which are present in the data.
30.srt	00:21:11.440 --> 00:21:21.789	So, it is possible the same data or autoencoder will learn the inner structure which is not just linear, but it is non-linear as shown by the blue curve.
30.srt	00:21:23.230 --> 00:21:35.419	So, all this set of data points which are red points can now be represented by points on this blue curve, whereas principal components will represent this set of data by points on the pink line.
30.srt	00:21:37.149 --> 00:21:46.899	So, we will present some experiment fromthis particular source which is given at the bottom.
30.srt	00:21:47.649 --> 00:21:53.599	So, these experiments are done on MNIST data set, MNIST data set which is a public domain data set.
30.srt	00:21:54.480 --> 00:22:04.269	which has total this dataset is actually dataset of handwritten digits digits from 0 to 9.
30.srt	00:22:04.880 --> 00:22:14.220	It has total 60,000 training images and total 10,000 test images all handwritten character handwritten digits.
30.srt	00:22:14.220 --> 00:22:22.410	Every image is of size of dimension 28 by 28 that means, it has got 784 number of pixels.
30.srt	00:22:23.019 --> 00:22:32.920	So, when you think in terms of autoencoder at the input side we have 784 plus 1 to take care of the bias 785 number of neurons.
30.srt	00:22:34.940 --> 00:22:39.990	dimension dimensionality reduction from 784 to 2.
30.srt	00:22:40.410 --> 00:22:53.920	So, using autoencoder as well as PCA and then we will also talk about the reconstruction fromthe reduced dimension where for reconstruction the dimension was reduced to 30 from 784.
30.srt	00:23:05.230 --> 00:23:10.640	For dimension dimensionality reduction demonstration it was reduced to 2 because the plane on which we will be projecting this data are two dimensional So, if it is reduced to two dimensional data then projection is I can visualize it.
30.srt	00:23:11.190 --> 00:23:18.660	Then the other things thatoptimizer which is Adam optimizer we will come to that later we have not yet talked about the different types of optimizers.
30.srt	00:23:19.290 --> 00:23:26.200	The loss function that was considered is mean square error that we said and for training 100 iterations was used.
30.srt	00:23:27.260 --> 00:23:29.040	So, this is what is the experiment setup.
30.srt	00:23:30.390 --> 00:23:40.370	Now, what is this is an example of the MNIST data set I was as I said that this is data set of handwritten digits digits from 0 to 9.
30.srt	00:23:40.960 --> 00:23:45.730	ok. And again this is taken from the source asgiven at the bottom.
30.srt	00:23:48.500 --> 00:24:00.460	Now for this data set, the data reduction was done using principal component analysis to two dimensional data you remember our input was 784 right.
30.srt	00:24:01.440 --> 00:24:11.400	So, using principal component analysis it was reduced to two dimensional vectors and also by using auto encoders it wasreduced to .
30.srt	00:24:11.730 --> 00:24:12.869	2 dimensional vectors.
30.srt	00:24:13.579 --> 00:24:20.640	But in this particular caseno non-linearity was used the activation function of the neurons was linear function.
30.srt	00:24:43.699 --> 00:24:45.019	And as is shown in these two data setthese two outputs you find that the output as given by PCA is almost identical to output as given by two layer autoencoderwhich has just one hidden layer right hidden layer and an output they are almost identical.
30.srt	00:24:45.649 --> 00:24:57.519	So, and this is what we said that principal component analysis is our data dimensionality reduction technique, autoencoder can also be thought of as dimensionality reduction technique.
30.srt	00:24:57.799 --> 00:25:02.699	So, somewhere there must be a relation between these two and this is what ok.
30.srt	00:25:03.099 --> 00:25:08.789	So, you find that in some case PCA and autoencoders they give you identical results.
30.srt	00:25:09.679 --> 00:25:13.119	Of course, we will havedifference of results as we said that .
30.srt	00:25:13.449 --> 00:25:24.179	auto encoders are more general than principal component analysis because auto encoders can impose can implement non-linear functions ok.
30.srt	00:25:24.539 --> 00:25:30.749	So, let us see what other results that we can obtain.
30.srt	00:25:30.749 --> 00:25:35.759	So, this is a comparison between deep versus shallow autoencoder.
30.srt	00:25:35.789 --> 00:25:41.709	So, on the left hand sidewhat is shown as the output of a two layer autoencoder.
30.srt	00:25:43.879 --> 00:25:47.099	and on the right hand side what is shown as a deep autoencoder.
30.srt	00:25:47.999 --> 00:25:58.409	And here you find that a deep autoencoder having multiple number of layers as the architecture of the deep autoencoder is shown on the right .
30.srt	00:25:58.519 --> 00:26:16.839	So, deep autoencoder with multiple autoencoding layers or decoding layers can capture the structure of the data better and that is where the beauty of the auto or the beauty of the deep learning .
30.srt	00:26:17.009 --> 00:26:17.429	comes.
30.srt	00:26:19.489 --> 00:26:29.799	Coming to another example, so if we have so in the previous case the output was from deep autoencoder without any non-linear activation function.
30.srt	00:26:29.799 --> 00:26:47.529	Now, you find thatif we use non-linear activation function in a deep autoencoder, then as shown in this diagram on the right the deep autoencoder with non-linear activation function can even capture the structure of the data better.
30.srt	00:26:48.609 --> 00:27:02.609	So, here you find that the different digits this is 0 yeah this is actually 0 set of 0s here it is set of 1s and so on.
30.srt	00:27:02.859 --> 00:27:11.539	So, it can capture the inner structure of the data even better than a shallow autoencoder ok.
30.srt	00:27:12.609 --> 00:27:18.559	So, that is what is the beauty of autoencoders with non-linearity it can.
30.srt	00:27:19.169 --> 00:27:25.519	understand or it can learn the inner structure of the data much better.
30.srt	00:27:25.519 --> 00:27:36.439	This is another example where it was a data reduction from articles from Reuter corpus those scanned images were reduced to two dimensional data.
30.srt	00:27:36.889 --> 00:27:49.029	So, here again you find that autoencoder as compared to principal components that has captured the inner structure much better than what the principal components can do.
30.srt	00:27:51.069 --> 00:27:59.819	This is just another reconstruction example where we said that for reconstruction the data reduction was done up to dimension of 30.
30.srt	00:27:59.929 --> 00:28:02.399	So, from 784 it was reduced to dimension 30.
30.srt	00:28:02.949 --> 00:28:08.349	So, here the top row gives you what was the original image.
30.srt	00:28:09.479 --> 00:28:19.169	In the middle row you have the reconstruction using autoencoder where the autoencoder architecture is given over here and the activation function was relu.
30.srt	00:28:19.749 --> 00:28:28.969	that is rectified linear unit and the bottom row is the reconstruction using principal component analysis.
30.srt	00:28:28.969 --> 00:28:33.299	So, the principal components again having 30 principal components.
30.srt	00:28:34.339 --> 00:28:51.209	So, here again you find that though the data reduction was equal the data were reduced to the same extent both using autoencoder as well as principal components, but the reconstruction using the encoded data using autoencoder.
30.srt	00:28:52.729 --> 00:29:01.799	is much better than reconstructionfrom the principal components though the reduced dimensionality was same.
30.srt	00:29:02.489 --> 00:29:06.289	So, that tells you what is the power of auto encoder over principal components.
30.srt	00:29:06.739 --> 00:29:08.649	Earlier we have seen the power of principal components.
30.srt	00:29:08.649 --> 00:29:15.429	Now, it shows thatthe auto encoders are even more powerful than principal components.
30.srt	00:29:16.929 --> 00:29:22.369	Similarly, this is another example of reconstruction where we have a set of face images.
30.srt	00:29:22.789 --> 00:29:44.339	So, the top row is youroriginal image, the second row is again output that is the reconstruction from 30 dimensional autoencoder outputs and the bottom row isreconstruction from 30 dimensional principal components.
30.srt	00:29:45.269 --> 00:29:53.739	So, here again you find that the middle row in the middle row the data structure of the input data or the input images.
30.srt	00:29:54.059 --> 00:29:58.489	has been reconstructed much better than in the bottom row.
30.srt	00:29:59.319 --> 00:30:13.099	So, it also shows that auto encoders with nonlinearity or deep on auto encoders with deep nonlinearity are much more powerful than principal components ok.
30.srt	00:30:14.669 --> 00:30:18.579	So, let me stop thistodays lecture here.
30.srt	00:30:18.649 --> 00:30:22.149	We will next talk about .
30.srt	00:30:24.259 --> 00:30:26.819	the training algorithms of autoencoders.
30.srt	00:30:26.819 --> 00:30:41.669	Of course, the training will be back propagation training as we said earlier and the errors or the loss function for back propagation training that we will be using will be the sum of squared error loss.
30.srt	00:30:41.839 --> 00:30:42.869	So, we will come back later.
30.srt	00:30:43.519 --> 00:30:43.809	Thank you.
24.srt	00:00:00.610 --> 00:00:27.730	Hello, welcome to the NPTEL online certification course on deep learning.
24.srt	00:00:31.640 --> 00:00:41.250	In our previous lecture, we were discussing about the back propagation learning in feed forward neural network or multi layer neural network.
24.srt	00:00:42.509 --> 00:00:56.829	And you remember that the loss function or the error function to be minimized that was considered in our previous lecture was sum of squared error or which is also known as quadratic error.
24.srt	00:00:58.019 --> 00:01:01.039	So, the error function which was considered .
24.srt	00:01:01.460 --> 00:01:16.760	was given by E is equal to half of O j k minus T j square, where the summation is taken over j is equal to 1 to m k that is all the nodes in the output layer.
24.srt	00:01:16.760 --> 00:01:35.510	Now, we will see that what are the problems with this quadratic loss function or squared error function and we will try to find out or we will try to investigate that what alternative loss function that can be used .
24.srt	00:01:35.809 --> 00:01:41.729	to avoid the problem which is given by this quadratic loss function .
24.srt	00:01:41.729 --> 00:02:08.879	So, for updation of the weight rules you find that the updation rule that we have used is W i j k gets W i j k minus eta times delta j k times O i k minus 1 in case of quadratic loss function, where this delta j k was derived from the derivative of the sigmoidal output .
24.srt	00:02:09.460 --> 00:02:21.000	So, we got delta j k as o j k, o j k is obviously, the output of the j th node in the k th layer and we are considering the layer to be the output layer here.
24.srt	00:02:22.129 --> 00:02:31.560	So, it is o j k into 1 minus o j k into o j k minus t j .
24.srt	00:02:31.599 --> 00:02:39.150	So, you willappreciate that when this error updation rule or weight updation rule is necessary .
24.srt	00:02:40.500 --> 00:02:50.689	If, I feed a training vector and I get the output if I find that the vector is correctly classified obviously, I need not go for weight updation.
24.srt	00:02:51.830 --> 00:03:05.450	So, I have to weight update the weights only when I find that I have fed an input vector which may belong to say class i, but my classifier is misclassifying that to class j.
24.srt	00:03:06.490 --> 00:03:11.800	So, only in such cases when the decision given by the classifier is wrong.
24.srt	00:03:12.120 --> 00:03:13.780	I need to update the weight vector.
24.srt	00:03:14.340 --> 00:03:18.349	As long as the decision is correct the weight vectors need not be updated.
24.srt	00:03:19.599 --> 00:03:29.000	And for updation of the weight vectors when the moment you get an error is obtained by gradient descent rule as is given over here.
24.srt	00:03:31.069 --> 00:03:34.270	So, as is givenin this particular case.
24.srt	00:03:37.670 --> 00:03:45.939	And the one that is involved in the weight updation rule that is derived from the gradient is delta j k .
24.srt	00:03:47.699 --> 00:04:02.659	So, you find that this O j k into 1 minus O j k is nothing, but derivative of the sigmoidal function which is W transpose X .
24.srt	00:04:02.659 --> 00:04:13.870	Now, let us consider a case that I have an weight vector X which actually belongs to class say 1 .
24.srt	00:04:13.870 --> 00:04:16.060	So, this was the training pair which was given .
24.srt	00:04:16.550 --> 00:04:19.589	x that weight vector x it actually belongs to class 1.
24.srt	00:04:20.819 --> 00:04:31.250	So, when it is classified by this classifier the output of the node if I consider I have a single neuron at the output say it is a two class problem.
24.srt	00:04:32.480 --> 00:04:47.750	So, output of the neuron should be 1 or close to 1, if the output of the neuron is not 1 or say it is very close to 0 that means, I have an error.
24.srt	00:04:49.029 --> 00:04:49.259	right.
24.srt	00:04:49.779 --> 00:05:05.240	And because I have an error I have to go for updation of the weight vectors by propagating this error in the backward direction and that is where this gradient of the output that comes into picture.
24.srt	00:05:06.970 --> 00:05:20.110	So, here you find that actually my y should be equal to 1, but I am getting an y which is equal to 0 or near to 0 and that comes over here.
24.srt	00:05:20.400 --> 00:05:30.639	my output is O j k times 1 minus O j k. So, this product O j k minus 1 into 1 minus O j k becomes very very low.
24.srt	00:05:32.660 --> 00:05:51.360	Similarly, in the other case if attaining vector is given as belonging to 0, but the classifier classifies that to class 1 that means, my output of the neuron should actually be 0, but the classifier has given a very high output.
24.srt	00:05:52.660 --> 00:05:54.069	That means, it is a misclassification.
24.srt	00:05:55.079 --> 00:06:23.730	Again in this case I have to go for updation of the weights following the same weight updation rule and here you find that O j k as decided by the classifier being very high 1 minus O j k will be very low and that is becauseif you look over here when your output is very low in my sigmoidal function I am somewhere over here .
24.srt	00:06:24.909 --> 00:06:29.349	When the output is very high in the sigmoidal function I am somewhere over here.
24.srt	00:06:30.589 --> 00:06:39.659	And in both these regions your derivative of the sigmoidal function that is sigma dash w transpose x that is very very low.
24.srt	00:06:41.279 --> 00:06:44.159	And in the extreme case it may even vanish.
24.srt	00:06:44.419 --> 00:06:56.559	So, the gradient vanishes and if the gradient vanishes or the gradient is very very low you find that this gradient is directly influencing the rate of training.
24.srt	00:06:57.919 --> 00:07:22.469	k because your rate of training is controlled by not only theconvergence rate eta it is also controlled by delta j k. So, if O j k minus O j k into 1 minus O j k whether O j k is 0 or O j k should be 1 whatever the case may be if any of the terms is very low then your rate of learning becomes very very low.
24.srt	00:07:22.469 --> 00:07:28.189	So, that is the effect of or the bad effect of this quadratic loss function that we have.
24.srt	00:07:30.349 --> 00:07:32.879	So, is there any remedy of this?
24.srt	00:07:33.459 --> 00:07:43.349	So, let us try to see that whether any other loss function can avoid this tendency of slow training or slow learning.
24.srt	00:07:43.569 --> 00:07:51.119	So, here comes another loss function which is called cross entropy loss.
24.srt	00:07:51.959 --> 00:07:54.449	So, how do you define this cross entropy loss?
24.srt	00:07:55.649 --> 00:07:57.189	Again I am taking a two class problem.
24.srt	00:08:00.849 --> 00:08:01.959	So, if of which are vector x.
24.srt	00:08:01.959 --> 00:08:20.999	So, again I am assuming that my input training vectors are given by given as ordered pairs x y, where x is the input vector and y is the ground truth that is the actual class to which this vector x belongs this is given for training purpose right.
24.srt	00:08:23.089 --> 00:08:31.169	So, if y is actually equal to 1 that means, I get a training vector from class.
24.srt	00:08:32.429 --> 00:08:39.629	1 for which output should be equal to 1 whereas, output of your neural network is O.
24.srt	00:08:41.059 --> 00:08:46.769	So, whatever is the output this output actually gives you the likelihood that Y is 1.
24.srt	00:08:48.909 --> 00:09:03.599	In the same way if Y is equal to 0 that means, the training vector belongs to class belongs to another class then 1 minus O where O is the output of the neuron that gives you the likelihood that Y is 0.
24.srt	00:09:05.289 --> 00:09:19.749	So, I can combine these two to get a likelihood that needs to be maximized which is given by o to the power y into 1 minus o into 1 minus o to the power 1 minus y.
24.srt	00:09:20.829 --> 00:09:26.399	So, this is the likelihood that needs to be maximized for training this neural network.
24.srt	00:09:27.129 --> 00:09:34.679	And from here of course, you find that an exponent is involved in this expression and I do not like exponents.
24.srt	00:09:34.789 --> 00:09:36.899	So, how do we how do we avoid the exponents.
24.srt	00:09:37.319 --> 00:09:41.849	So, obviously, you take instead of the likelihood you take the log likelihood.
24.srt	00:09:43.039 --> 00:09:58.349	So, the log likelihood simply becomes y log o where o is the output of the neuron ok. Again here I am assuming that the output is a sigmoidal function of the weighted sum of the inputs as given over here.
24.srt	00:10:00.229 --> 00:10:08.189	So, I get this log like log likelihood which is given by y log o into 1 minus y log o minus y .
24.srt	00:10:08.899 --> 00:10:10.549	log 1 minus o.
24.srt	00:10:12.039 --> 00:10:28.909	So, here you find that if y is equal to 1 in that case this term that is if the training sample x is taken from class omega 1 then I should get y equal to 1 right in that case 1 minus y is 0.
24.srt	00:10:29.509 --> 00:10:33.559	So, what I have to maximize is y log o.
24.srt	00:10:36.339 --> 00:10:41.569	In the other case if y is equal to 0 that means, the training sample has been taken from other class.
24.srt	00:10:41.929 --> 00:10:44.789	So, this term y log o becomes 0.
24.srt	00:10:45.129 --> 00:10:49.919	So, what I have to maximize is 1 minus y log 1 minus o.
24.srt	00:10:52.059 --> 00:10:55.799	So, this is what is the likelihood that I need to maximize.
24.srt	00:10:56.869 --> 00:11:12.669	So, once I have this log likelihood from here I can find out thecost function, I can define a cost function which is minus y log o.
24.srt	00:11:15.879 --> 00:11:27.649	into 1 minus y log 1 minus o take the sum over this sum of this over all the input feature vectors and then you take the average.
24.srt	00:11:45.399 --> 00:11:54.819	So, I am defining a cost function c to be minus of 1 by n summation of y log o plus 1 minus y log 1 minus o taking the summation of this over all input vectors and taking the average which is given by 1 by n and this is what is known as cross entropy loss.
24.srt	00:11:55.879 --> 00:12:14.679	So, you find that the in the previous case when we talked about we said that we want to maximize this log likelihood which is y log o plus 1 minus y log 1 minus o which is equivalent to minimization of the function c which is our cross entropy loss.
24.srt	00:12:15.589 --> 00:12:16.599	So, again as before .
24.srt	00:12:16.949 --> 00:12:21.009	So, for minimization of this cross entropy loss we have to follow the gradient descent approach.
24.srt	00:12:21.469 --> 00:12:33.869	So, I need to take the derivative of this cross entropy loss C with respect to the weight vector of the gradient of C with respect to weight vector w and I can do it partially.
24.srt	00:12:33.869 --> 00:12:46.899	So, you take the derivative of thiscross entropy loss C with respect to w i that is the ith component of the weight vector w. So, what I compute is del C del w i .
24.srt	00:12:48.189 --> 00:13:04.339	And, from here you find that when I take the derivative of this cos entropy loss c the derivative of c with respect to w i what I get is y by sigma theta as we have said earlier this this theta is nothing, but w transpose x .
24.srt	00:13:04.339 --> 00:13:18.509	So, I get 1 upon sigma theta minus 1 minus i 1 minus y upon 1 minus sigma theta .
24.srt	00:13:19.339 --> 00:13:25.309	into del sigma theta del w i because this is a logarithmic function.
24.srt	00:13:25.999 --> 00:13:30.109	So, it is actually 1 upon O and O is nothing but sigma theta.
24.srt	00:13:31.539 --> 00:13:50.089	So, del C del w i simply becomes 1 upon n sum of y upon sigma theta minus 1 minus y upon 1 minus sigma theta into del sigma theta del w i take the summation over of this.
24.srt	00:13:50.569 --> 00:14:07.619	over all input vectors x and that simply becomes minus 1 upon n then sum of y upon sigma theta minus 1 upon y upon 1 minus sigma theta into again here I apply the chain rule.
24.srt	00:14:08.139 --> 00:14:16.239	So, it is del sigma theta del theta into del theta del w i simply using the chain rule.
24.srt	00:14:18.139 --> 00:14:20.209	So, if I go for simplification further .
24.srt	00:14:20.849 --> 00:14:48.809	The same expression is written as minus 1 upon n then sum of 1 upon sigma theta minus 1 minus y upon 1 minus sigma theta into del sigma theta del theta into del theta del w i which simply becomes if I go for simplification of this it simply becomes minus.
24.srt	00:14:48.869 --> 00:14:52.089	So, here you find that del sigma theta del theta.
24.srt	00:14:56.649 --> 00:15:13.579	This del sigma theta del theta as it is a sigmoidal function is nothing, but sigma theta into 1 minus sigma theta and del theta del w i as you remember that del theta was w transpose x.
24.srt	00:15:14.189 --> 00:15:22.459	So, del theta del w i simply becomes x i because it is nothing, but w i times x i take the summation over all i.
24.srt	00:15:23.259 --> 00:15:24.759	So, it simply becomes x i.
24.srt	00:15:25.559 --> 00:15:34.249	So, this term del sigma theta del theta into del theta del w i is simply sigma theta into 1 minus sigma theta into x i.
24.srt	00:15:35.549 --> 00:15:52.919	And when I simplify this term that is y upon sigma theta minus 1 minus y upon 1 minus sigma theta the say expression simplified expression simply becomes y minus sigma theta upon sigma theta into 1 minus sigma theta.
24.srt	00:15:53.949 --> 00:16:05.159	So, from here you find that this sigma theta into and thissigma theta into 1 minus sigma theta and this sigma theta into 1 minus sigma theta gets cancelled.
24.srt	00:16:05.549 --> 00:16:16.949	So, my expression simply becomes 1 by n into x i times sigma theta minus y take the summation of this and then you take the average.
24.srt	00:16:23.479 --> 00:16:36.509	So, my gradient del C del w i simply becomes 1 over n then x i o minus y where o i is nothing but sigma theta take the summation over all input vector x that is what is my del C del w i.
24.srt	00:16:56.939 --> 00:17:16.289	And once I have this del C del w i I can just write the weight updation rule which is nothing but w i gets w i minus eta times 1 by n sum of x i into O minus 1, where the summation has to be taken over all the feature vectors input feature vectors.
24.srt	00:17:17.579 --> 00:17:19.139	Now, what is the advantage that we get?
24.srt	00:17:24.989 --> 00:17:31.299	You find that in case of cross entropy ah in case of the squared error loss or the quadratic loss.
24.srt	00:17:32.939 --> 00:17:47.489	In the updation term we had a term sigma theta into 1 minus sigma theta which is nothing, but derivative of sigma theta with respect to theta.
24.srt	00:17:48.639 --> 00:17:54.519	And this sigma theta into 1 minus sigma theta these terms are responsible for slow learning.
24.srt	00:17:55.509 --> 00:18:02.029	because, if sigma theta is very high very high means it is very near to 1, 1 minus sigma theta almost vanishes.
24.srt	00:18:02.689 --> 00:18:11.159	On the other hand if I am on the other side that is sigma theta is almost equal to 0, then also the derivative term almost vanishes.
24.srt	00:18:11.879 --> 00:18:17.309	And because of the vanishing of the derivative the learning becomes very very slow.
24.srt	00:18:24.839 --> 00:18:33.569	Whereas in this case in my updation term I simply have O minus y i times x i, where O is the output and y i is the ground truth.
24.srt	00:18:34.789 --> 00:18:51.009	So, here you find that if my ground truth is actually 0 that means, if y is equal to 0 whereas, if I get O to be very high say 0.99 something like this, then O minus y is high unlike in the previous case.
24.srt	00:18:54.999 --> 00:19:03.559	Similarly, if my y is 1, then I get O minus 0 and O is a 0.001 it is very low, then again O minus Y the absolute value is very high.
24.srt	00:19:03.559 --> 00:19:11.949	That means, my rate of learning is now proportional to the difference of the output that you get and what is my ground truth.
24.srt	00:19:12.059 --> 00:19:26.509	So, if the error is more the rate of learning is more which is in contrast to what we have obtained in case of quadratic error that if error is very very high.
24.srt	00:19:28.089 --> 00:19:32.019	your rate of learning becomes low which is not desirable.
24.srt	00:19:32.419 --> 00:19:36.929	So, here if your error is high the rate of learning is also high.
24.srt	00:19:38.329 --> 00:19:43.719	So, that is the advantage of this cross entropy loss over thequadrature loss.
24.srt	00:19:43.909 --> 00:19:57.519	So, this is what we have got in case of a binary classifier or a two class problem and this cross entropy that we have defined.
24.srt	00:20:00.480 --> 00:20:00.849	.
24.srt	00:20:00.939 --> 00:20:17.609	As given by this term this is what is known as binary cross entropy that is y log o into 1 minus y log 1 minus o this is what is known as binary cross entropy right.
24.srt	00:20:17.609 --> 00:20:28.750	So, what we have done is in case of a two class problem or binary classifier, how do we extend this to a multi class problem?
24.srt	00:20:28.750 --> 00:20:29.359	So, you remember .
24.srt	00:20:29.819 --> 00:20:40.759	that in a multiclass problem, I have at the output layer say c number of nodes where c is the number of categories or the number of classes.
24.srt	00:21:01.240 --> 00:21:05.290	And when I want to use this concept of entropy loss or cross entropy loss, then the outputs are to be defined or are to be obtained in a probabilistic sense in the manner that O j should give me that, what is the likelihood that y j is equal to 1.
24.srt	00:21:06.280 --> 00:21:24.390	And for that we had defined something called softmax classifier, where softmax classifier gives you the normalized probability at the output that 2 what is the probability that an input vector x belongs to class omega j.
24.srt	00:21:24.720 --> 00:21:26.769	So, that is what is given by softmax classifier.
24.srt	00:21:28.250 --> 00:21:31.740	So, when I want to use this cross entropy loss.
24.srt	00:21:32.150 --> 00:21:40.710	for training the feedback feed forward neural network at the output layer I assume that the output is a soft max output.
24.srt	00:21:41.100 --> 00:21:48.810	That means, the outputs aregives you the probability of belongingness of a of an input vector to a particular class.
24.srt	00:21:51.030 --> 00:22:07.980	So, given this the same thing that we have defined before that we discussed before that if my y j is equal to 1 then o j k that is the output of the j th node at the output layer that is k th layer that gives you what is the likelihood.
24.srt	00:22:08.350 --> 00:22:10.240	of Y j belonging being 1.
24.srt	00:22:11.030 --> 00:22:18.760	Similarly, 1 minus O j k tells you that what is the likelihood that Y j k Y j is 0.
24.srt	00:22:19.730 --> 00:22:30.320	So, accordingly in the same definition of the binary cross entropy for every individual output node I can use.
24.srt	00:22:30.600 --> 00:22:38.040	So, for the j th node the corresponding cross entropy is defined as Y j .
24.srt	00:22:38.380 --> 00:22:47.300	log o j k plus 1 minus y j log 1 minus o j k take the negative of this.
24.srt	00:22:47.520 --> 00:22:54.920	So, that becomes the cross entropy or binary cross entropy corresponding to the j th layer j th node in the output layer.
24.srt	00:22:55.970 --> 00:23:05.560	And to get the overall cross entropy what I have to do is I have to take the sum of all these entropies all these cross entropies over all the nodes in the output layer.
24.srt	00:23:10.080 --> 00:23:20.820	So, that is the reason that I take the summation over of this over all j, where j varies from 1 to m k, where m k is the nodes number of nodes in the output layer.
24.srt	00:23:22.110 --> 00:23:26.030	And this I have to compute over all the feature vectors x.
24.srt	00:23:26.260 --> 00:23:31.810	So, I have this outer summation you take the summation over all input feature vectors x.
24.srt	00:23:33.390 --> 00:23:44.320	And again here as before if I take the derivative of C with respect to w i j k. Now, you find that I have multiple number of layers.
24.srt	00:23:44.640 --> 00:23:46.930	I have multiple number of nodes in every layer.
24.srt	00:23:47.650 --> 00:23:56.810	So, my index becomes i j that is from ith node in k minus first layer to jth node in the kth layer.
24.srt	00:23:58.000 --> 00:24:14.370	So, I compute del C del w i j k and as before you can verify that the output will be 1 upon n summation of o i k minus 1 where o i k minus 1 is the output.
24.srt	00:24:14.800 --> 00:24:18.180	of the ith node in the k minus first layer.
24.srt	00:24:19.530 --> 00:24:30.490	So, it is sum of O i k minus 1 into O j k minus y j and you take the summation over all j and take the average.
24.srt	00:24:31.280 --> 00:24:46.759	So, accordingly your weight updation rule using this cross entropy loss function becomes W i j k getting W i j k minus eta times again eta is your rate of convergence .
24.srt	00:24:47.530 --> 00:24:56.630	1 over n summation of O i k minus 1 into O j k minus y j.
24.srt	00:24:57.560 --> 00:25:18.070	And again as before you can find that more the difference between O j k and y j, O j k is your actual output that you are getting from the j th neuron in the k th layer and y j k is the expected output or this is the ground truth.
24.srt	00:25:19.420 --> 00:25:38.900	So, if o j k minus y j is more that indicates that error is more and your updation component the value by which you want to update the weight vector is now directly proportional to o j k minus y j.
24.srt	00:25:39.720 --> 00:25:47.410	That means, if the error is more your rate of learning is more, if the error is less the rate of learning is less.
24.srt	00:25:48.390 --> 00:25:52.340	So, this is the advantage of using the cross entropy laws.
24.srt	00:25:52.610 --> 00:25:59.550	for training the neural network over the quadratic error which is used for training the neural network.
24.srt	00:26:00.350 --> 00:26:12.280	But you have to remember that if I want to use this cross entropy loss, then output of the neural network must be a softmax output because it has to be a probabilistic measure.
24.srt	00:26:13.740 --> 00:26:18.710	We will stop here today, we will continue with other neural networks in future classes.
24.srt	00:26:18.790 --> 00:26:19.090	Thank you.
25.srt	00:00:00.610 --> 00:00:27.579	Hello, welcome to the NPTEL online certification course on .
25.srt	00:00:30.230 --> 00:00:30.949	deep learning.
25.srt	00:00:32.469 --> 00:00:51.120	In previous few classes we have discussed about the back propagation learning, we have also talked about the different types of loss functions which the back propagation learning algorithm tries to minimize while training a neural network.
25.srt	00:00:52.390 --> 00:01:01.799	Now, as we said earlier that back propagation learning is the heart of the deep learning process.
25.srt	00:01:03.049 --> 00:01:06.459	So, understanding the back propagation is very very important.
25.srt	00:01:07.590 --> 00:01:17.759	So, though we have talked about the back propagation learning algorithms before, I want to explore further on back propagation learning with examples.
25.srt	00:01:18.560 --> 00:01:24.259	So, that the process of back propagation learning is very very clear to you.
25.srt	00:01:25.069 --> 00:01:38.379	The reason being in all subsequent lectures whenever learning is involved, I will simply refer to as back propagation learning without going into details of the algorithms.
25.srt	00:01:39.230 --> 00:02:02.280	So, it is very very important that you fully understand what is back propagation learning and what is the mechanism for back propagation learning or even when you write an algorithm, when you write a program involving the learning of a neural network, how you can write simple programs even exploring the parallelism of the machines.
25.srt	00:02:03.019 --> 00:02:08.770	And that is also important because when we talk about deep learning in today's scenario.
25.srt	00:02:09.650 --> 00:02:21.710	You will find that the concepts that we discussed in deep learning those concepts are not very new the concepts even existed long back the neural network is few decades old.
25.srt	00:02:22.930 --> 00:02:38.050	But why this branch of machine learning was not so popular earlier or not being used in a broader sense is that we did not have the computational power.
25.srt	00:02:40.680 --> 00:02:50.600	Now, we have the computational powers in the form of high performance computers, in the form of GPU or graphics processing units which are massively parallel.
25.srt	00:02:51.120 --> 00:03:04.030	So, making use of those parallel processing capability now implementing the machine learning algorithms working onhuge amount of data has become feasible.
25.srt	00:03:04.070 --> 00:03:12.680	So, over there exploiting parallelism is also very very important in order to make your machine learning algorithm successful.
25.srt	00:03:13.960 --> 00:03:33.539	So, over there the deep learning or understanding of the deep learning and how the parallelism in deep learning algorithms can be exploited knowing that is very very important for application of deep learning algorithms or development of any deep learning solution for any kind of problem.
25.srt	00:03:35.090 --> 00:03:44.680	So, what we have done as I said in our previous classes is that we have talked about back propagation learning inmultilayer perceptron.
25.srt	00:03:45.560 --> 00:03:56.310	We also talked about the loss functions like sum of squared error loss function and also we talked about the cross entropy loss function.
25.srt	00:03:57.130 --> 00:04:16.670	And over there we have seen that the problem or the drawback of squared error loss function which sometimes leads to very slow learning rate particularly when your actual output that you are getting from the network is far away from the target output.
25.srt	00:04:18.000 --> 00:04:18.490	output.
25.srt	00:04:19.209 --> 00:04:24.930	There the derivative almost becomes 0, the derivative almost vanishes.
25.srt	00:04:25.149 --> 00:04:47.029	So, as a result the learning rate becomes very very low, which in case of cross entropy loss function that problem is avoided because there your learning rate as we have seen before is proportional to the difference between the target output and the actual output that you get.
25.srt	00:04:47.969 --> 00:05:02.329	So, as a result if I use cross entropy loss as loss function to be minimized, the learning rate is much higher than the learning rate that you get in case ofusing sigmoidal function andthe squared error loss.
25.srt	00:05:02.329 --> 00:05:17.479	So, today we will further explore on back propagation learning with some examples, examples at the network level and also examples at the node level because within every node.
25.srt	00:05:18.059 --> 00:05:20.029	partial derivatives.
25.srt	00:05:21.449 --> 00:05:36.129	So, what we have is say I have a feed forward network let us assume that I have a feed forward network having 5 layers.
25.srt	00:05:41.199 --> 00:05:49.319	So, I have first layer, what the input is actually input vector x.
25.srt	00:05:50.519 --> 00:06:14.169	The first layer transforms this x with a mapping function say f 1 and this gives me an output of say theta 1 which goes to next layer of this feed forward network that computes a function f 2 on the input which is fed to it.
25.srt	00:06:51.049 --> 00:07:00.669	So, it computes f 2 on theta 2 and this gives me an output say it computes f 2 on theta 1 and that gives me an output say theta 2 which in turn is fed to the next layer which has a mapping function f 3 and this gives an output of theta 3 and so on it theta 3 enters f 4 giving you an output of theta 4 and finally, this theta enters the final layer which computes the mapping f 5 and so, you get your final output say O right.
25.srt	00:07:02.089 --> 00:07:09.029	So, now, if I want to find out the derivative of O with respect to X.
25.srt	00:07:10.019 --> 00:07:12.819	So, remember what this what does this derivative actually tell you?
25.srt	00:07:21.579 --> 00:07:33.169	That derivative tells you that considering O as a function of X, if I make a little per perturbation if I perturb x slightly what is its effect on the final output O and that is what is given by del O del x.
25.srt	00:07:34.979 --> 00:07:39.189	Now, in this case your final output is f 5 ok.
25.srt	00:07:39.519 --> 00:07:52.469	So, I can say that my final output O which is equal to function f 5 that works on f 4 that works on f 3 .
25.srt	00:07:53.159 --> 00:08:03.839	which works on f 2 and finally, f 2 works on f of x .
25.srt	00:08:03.839 --> 00:08:08.199	So, this is my final output function o.
25.srt	00:08:08.229 --> 00:08:22.469	So, if I want to compute del o del x, I cannot really directly compute del o del x because output o is quite far away from x .
25.srt	00:08:22.669 --> 00:08:26.449	So, from input x I cannot directly see what is O.
25.srt	00:08:27.369 --> 00:08:33.129	So, to come to O or the output I have to pass through the functions f 1, f 2, f 3 and f 4.
25.srt	00:08:34.259 --> 00:08:40.909	So, to compute this f x what I have to do is O is directly visible to theta 4 right.
25.srt	00:08:41.479 --> 00:08:48.129	So, what I have to compute is I have to compute del O del theta 4.
25.srt	00:08:52.799 --> 00:08:55.979	Then theta 4 which is the output of f 4, 2 that is directly visible to theta 3.
25.srt	00:08:56.529 --> 00:09:08.929	So, I have to compute into del theta 3 del and theta 3 is directly visible to theta 2sorry theta 4 is directly visible to theta 3.
25.srt	00:09:09.159 --> 00:09:22.929	So, I have to compute del theta 4 del theta 3, where theta 3 is visible to theta 2.
25.srt	00:09:23.100 --> 00:09:38.139	So, I have to compute del theta 3, del theta 2, then del theta 2, del theta 1 and then finally, del theta 1 and del x.
25.srt	00:09:39.200 --> 00:09:54.220	So, you find that this chain of partial derivatives when multiplied together that actually gives you del o del x and del o del x as we said is nothing but the sensitivity of the output.
25.srt	00:09:54.689 --> 00:10:04.309	on the input x that is if I x if I change a x or perturb x slightly what is its effect on the final output.
25.srt	00:10:04.789 --> 00:10:27.439	That is what is given by this partial derivative and as we have seen here that when I have a sequence of functions from input to output I cannot directly compute this partial derivative rather I have to make use of the chain rule of differentiation to find out the partial derivative of output with respect to input.
25.srt	00:10:28.769 --> 00:10:36.490	So, in the back propagation learning algorithms, we have made use of these properties of the partial derivatives.
25.srt	00:10:37.429 --> 00:10:39.120	So, let us see that what we have done.
25.srt	00:10:39.909 --> 00:10:54.210	So, now, we will explain this back back propagation learning algorithm with an example and the example that I am going to take is on the network layer that is considering the neural network as a whole.
25.srt	00:10:56.090 --> 00:10:57.769	So we have explained this algorithm before.
25.srt	00:10:58.409 --> 00:11:05.549	We have had all the derivations, but I want to explain further and physically see practically see how does it work with the help of an example.
25.srt	00:11:06.830 --> 00:11:10.610	So, for this example I consider a two layer neural network.
25.srt	00:11:12.320 --> 00:11:26.100	So, MLP is a multi layer neural network out of that I am only considering two layer with one output layer, I have two nodes in the output layer, one hidden layer and one input layer.
25.srt	00:11:27.029 --> 00:11:34.340	And we had said earlier that the input layer nodes actually gives you the identity functions or identity mapping.
25.srt	00:11:35.049 --> 00:11:46.889	That means, whatever is the input to a node in the input layer that node simply outputs that input and fits it to the nodes in the next layer.
25.srt	00:11:48.870 --> 00:11:54.240	The hidden layer nodes as we seen earlier actually imposes the non-linearities.
25.srt	00:11:54.240 --> 00:12:03.009	So, as we increase the number of hidden layers, we can capture more and more complex form of non-linearity.
25.srt	00:12:03.009 --> 00:12:07.100	Then finally, at the output layer node which are actually classifying layer.
25.srt	00:12:08.240 --> 00:12:12.620	So, we can classifying nodes, it implements actually linear classifiers.
25.srt	00:12:13.120 --> 00:12:28.820	So, if we have the cases which are not linearlyseparable, the hidden layer nodes actually maps those non-linearly separable inputs non-linearly to a space where they are linearly separable.
25.srt	00:12:28.820 --> 00:12:36.170	And once they are linearly separable in a latent space, then I can have a linear classifier to classify them.
25.srt	00:12:36.170 --> 00:12:38.379	So, that is what the hidden layer does.
25.srt	00:12:39.129 --> 00:12:40.519	and we have seen that earlier.
25.srt	00:12:42.490 --> 00:12:53.700	So, we compute orwe consider that we have 2 sets of weights which later we will see that we will represent these as weight matrices.
25.srt	00:12:54.409 --> 00:13:03.120	One set of weights connecting the input layer to the hidden layer and another set of weights connecting the hidden layer to the output layer.
25.srt	00:13:04.120 --> 00:13:12.549	So, those weights connecting the input layer to the hidden layer are given by W 0 1 1 because the convention that we said we are following is.
25.srt	00:13:13.309 --> 00:13:16.250	as I have I am considering a two layer network.
25.srt	00:13:16.799 --> 00:13:27.379	So, the output layer is termed as layer 2, the hidden layer which is before the output layer is termed as layer 1 and the input layer is termed as layer 0.
25.srt	00:13:43.190 --> 00:13:53.310	And we have considered earlier that a node say ith node from K plus say an ith node from k minus first layer is connected to the jth node of the kth layer through a connection weight which is given by W ijk.
25.srt	00:13:54.040 --> 00:14:13.379	So, following the same convention at the input layer from the input layer to the hidden layer the connection weights or the weight values are W 0 1 1 similarly W 0 2 1 these are the weights which connect the 0th node at the input layer.
25.srt	00:14:14.039 --> 00:14:37.990	2 1 1 and W 2 2 1, they connect the second node of the hidden layer to the first and second nodesecond node of the input layer to the first and second node of the hidden layer respectively ok. And the same the same convention is also followed for the connection weights between the hidden layer to the output layer.
25.srt	00:14:45.600 --> 00:14:48.100	And in this casein this particular figure as I am considering are two category case.
25.srt	00:14:48.330 --> 00:14:57.770	So, my outputs are actually x 1 2 and x 2 2.
25.srt	00:14:58.430 --> 00:15:03.080	So, these are the outputs which will be available from this neural network.
25.srt	00:15:04.420 --> 00:15:08.500	So, that example that I am going to consider here isthis.
25.srt	00:15:09.650 --> 00:15:18.230	I consider a set ofconnection sets between the input layer to the hidden layer and hidden layer to the output layer.
25.srt	00:15:18.510 --> 00:15:19.800	at random initially.
25.srt	00:15:20.910 --> 00:15:48.100	So, the connection weights that we given as W 0 1 1 is 0.5, W 1 1 1 is 1.5, W 2 1 1 is 0.8, then W 0 2 1 is 0.8 again, W 1 2 1 is 0.2 and W 2 2 1 is 0.8.
25.srt	00:15:49.520 --> 00:15:50.860	is minus 1.6.
25.srt	00:15:50.860 --> 00:15:58.430	So, these are the connection weights from the input layer nodes to the hidden layer nodes.
25.srt	00:15:58.430 --> 00:16:00.610	So, that is why we use the superscript which is 1.
25.srt	00:16:00.610 --> 00:16:19.550	Similarly, I take another set of weights W 0 1 2 which is 0.9, W 1 1 2 which is minus 1.7, W 2 1 2 which is 1.6, W 0 2 2 which is 1.2, W 1 2 2 which is 2.1.
25.srt	00:16:21.600 --> 00:16:25.740	2 and W 2 2 2 which is minus 0.2.
25.srt	00:16:25.740 --> 00:16:51.270	These are the connection weights from the hidden layer nodes to theoutput layer nodes ok. And I also consider an input vector which is a two dimensional vector as given as 0.7 and 1.2.
25.srt	00:16:51.630 --> 00:16:54.030	So, these are the components of the input vector.
25.srt	00:16:55.470 --> 00:17:00.460	And, I assume that this input vector belongs to category 1.
25.srt	00:17:02.050 --> 00:17:12.660	So, as I assume this belongs to category 1 that means, the output from the output layer nodes the output of the first node will be equal to 1 because my input is category 1.
25.srt	00:17:13.980 --> 00:17:21.769	And, the output of the second node in the output layer should be equal to 0 because my input belongs to category 1.
25.srt	00:17:21.769 --> 00:17:23.900	So, output of the first node should be equal to 1.
25.srt	00:17:26.220 --> 00:17:33.250	So, as a result the target that I have is the target vector which should be 1 0.
25.srt	00:17:35.210 --> 00:17:51.620	So, the back propagation learning should try to adjust the weights in such a way that the output that I get should be equal to 1 0 or should be close to 1 0 when the learning is complete or when the input vector is correctly classified by this neural network.
25.srt	00:17:53.820 --> 00:17:56.560	So, let us see how this is done .
25.srt	00:17:58.630 --> 00:18:02.440	So, first let us see what happens in the forward pass or in the feed forward pass.
25.srt	00:18:02.600 --> 00:18:19.660	In the feed forward pass whatever you are feeding to the input as we have seen before it is processed at different layers in different hidden layers finally, goes to the output layer and output layer gives you the final output.
25.srt	00:18:21.030 --> 00:18:27.730	So, I am representing the connection weights from the input layer to the hidden layer.
25.srt	00:18:28.110 --> 00:18:31.470	layer by an weight matrix W 1 over here.
25.srt	00:18:32.940 --> 00:18:40.430	So, this weight matrix W 1 represents the connection weights from the input layer to the hidden layer.
25.srt	00:18:40.730 --> 00:18:46.110	So, these are the connection weights which is represented by weight matrix W 1.
25.srt	00:18:46.620 --> 00:18:58.310	And, simply similarly another matrix W 2 which is given this is represented by W 2 which is representing the connection weights from the hidden layer to the output layer.
25.srt	00:19:00.040 --> 00:19:07.970	So, given these two now you see that how this computation is done in the feed forward pass.
25.srt	00:19:09.390 --> 00:19:16.660	We said that we have the input vector which is a two dimensional vector having values 0.7 and 1.2.
25.srt	00:19:16.660 --> 00:19:27.090	So, this is 0.7 and 1.2 and as we said earlier that we append an additional component in this input vector.
25.srt	00:19:29.440 --> 00:19:30.720	which is equal to 1.
25.srt	00:19:32.360 --> 00:19:45.220	The whole purpose of doing this that I can have an unified representation that is the bias term which is W 0 can be considered as part of weight vector only right.
25.srt	00:19:45.660 --> 00:19:50.870	So, that it is W 0 plus W 1 times x 1 plus W 2 times x 2.
25.srt	00:19:52.630 --> 00:20:01.700	So, to have this unified representation we include an additional component in in the input vector x which is equal to 1.
25.srt	00:20:03.290 --> 00:20:21.440	So, given this the computation at the input layer can be done like this that the output of as we said earlier that every node in the in the neural network computes two parts.
25.srt	00:20:22.970 --> 00:20:33.040	The one part computes weighted sum of the inputs which is given by w i x i summation over all i.
25.srt	00:20:34.590 --> 00:20:42.620	And, the second part computes a non-linear function f on sum of w i x i .
25.srt	00:20:45.970 --> 00:20:50.250	So, this non-linear function f that we are considering a sigmoidal function over here.
25.srt	00:20:50.250 --> 00:21:05.610	And, we are representing this weighted sum of the inputs as a different parameter or with a different variable which is theta j or which is theta j indicates from which node it comes out .
25.srt	00:21:08.050 --> 00:21:20.530	So, given this now you find that weighted sum of these two nodes in the hidden layers node 1 and node 2 will be simply given by the matrix multiplication.
25.srt	00:21:20.930 --> 00:21:35.930	I have this weight matrix W 1 multiply that or post multiply that with your input vector or augmented input vector and that gives you the weighted sum that you get.
25.srt	00:21:36.160 --> 00:21:38.940	at every node in the hidden layer.
25.srt	00:21:40.560 --> 00:21:48.170	So, node 1 at node 1 in the hidden layer your weighted sum theta 1 1 is coming as 2.51.
25.srt	00:21:48.450 --> 00:21:54.450	If you simply do this multiplication the first row with this column vector you get 2.51.
25.srt	00:21:54.450 --> 00:22:02.790	Similarly, the weighted sum that you get from the second node in the hidden layer is minus 9.8.
25.srt	00:22:08.270 --> 00:22:14.870	If you multiply this row second row of the weight matrix W 1 with this input vector I get minus 9.8.
25.srt	00:22:14.870 --> 00:22:18.010	So, these are these are actually the intermediate values.
25.srt	00:22:18.010 --> 00:22:30.480	And final output value is after application of nonlinearity and as I said that the nonlinearity that I am considering in this case is a sigmoidal non nonlinearity.
25.srt	00:22:30.480 --> 00:22:38.910	So, the output from the first node x 1 1 will be sigmoidal function of theta 1 1.
25.srt	00:22:40.650 --> 00:22:48.040	At sigmoidal function is nothing, but this that is 1 upon 1 plus e to the power minus theta j 1.
25.srt	00:22:48.460 --> 00:22:59.300	You remember that the superscript 1 is being used that I am doing this computation at the hidden layer which is layer 1 in our case.
25.srt	00:23:00.780 --> 00:23:08.600	So, with this the output of the first node after applying nonlinearity which is x 1 1.
25.srt	00:23:10.830 --> 00:23:23.660	So, this is nothing, but x 1 1 plus So, this x 1 1 will become 0.92 and x 2 1 that is the output of the second load in the hidden layer will be 0.27.
25.srt	00:23:23.840 --> 00:23:38.410	And these are the values which are intermediate vector obtained after applying a non-linear function in the hidden layer is fed to the final output layer.
25.srt	00:23:42.780 --> 00:23:55.010	So, this vector along with So, this vector comes out over here appended with 1 as before to take care ofthe bias term as part of the weight vector.
25.srt	00:23:56.290 --> 00:24:01.090	So, this is the vector which is actually fed to the input of the output layer.
25.srt	00:24:02.900 --> 00:24:10.570	And the connection weights or the weight matrix between the hidden layer to the output layer is given by W 2 which is nothing but this.
25.srt	00:24:13.560 --> 00:24:42.470	And in the same manner The weighted sum of the inputs as given by the nodes in the output layer which is W i j 2 into x i 1, x i 1 means it is the output of the ith node in the first layer which is hidden layer and W i j 2 is the connection weight from the ith node in the hidden layer which is layer 1 to the jth node in the output layer which is layer 2.
25.srt	00:24:42.760 --> 00:24:44.020	So, if I compute this .
25.srt	00:24:44.190 --> 00:24:46.950	1 2 and this is theta 2 2.
25.srt	00:24:47.720 --> 00:24:57.460	Final output from this output layer is sigmoidal functions of these two quantities which comes out to be 0.44 and 0.95.
25.srt	00:24:57.460 --> 00:25:05.230	So, now, you find how what is the concept of error?
25.srt	00:25:05.230 --> 00:25:14.490	We said that this vector x which is 0.7 1.2, we have taken this vector x from class 1 or category 1.
25.srt	00:25:16.960 --> 00:25:27.140	And, because this vector x is taken from category 1, my target vector is actually 1 0 because it is taken from category 1.
25.srt	00:25:27.470 --> 00:25:32.860	So, the output of the first node that should be 1 and output of the second node that should be 0 ideally.
25.srt	00:25:34.000 --> 00:25:48.000	Or in other words output of the first node should be near to 1, very close to 1 and output of the second node should be very close to 0 if this x is correctly classified by this neural network.
25.srt	00:25:49.580 --> 00:26:02.080	But, in contrast with this arbitrary or randomly chosen weight vectors, the actual output which is given by this neural network is 0.44 and 0.95.
25.srt	00:26:02.080 --> 00:26:08.560	So, obviously, the output of the second node is much higher than the output of the first node.
25.srt	00:26:08.560 --> 00:26:10.790	So, clearly it is a misclassification.
25.srt	00:26:11.100 --> 00:26:18.640	I should actually try to get 1 0, but rather I am getting 0.44 and 0.95.
25.srt	00:26:20.520 --> 00:26:35.320	So, the difference between these two vectors is what is my error and the back propagation learning algorithm tries to minimize this error by adjusting the connection weights by propagating the error terms in the backward direction.
25.srt	00:26:37.570 --> 00:26:42.460	So, now, let us see that how that can be done or how the network does it.
25.srt	00:26:50.680 --> 00:26:58.070	So, these are things which we said before by that is the first component of the target was 1 and the first component of the output that I was getting is 0.44.
25.srt	00:26:58.070 --> 00:27:04.840	So, clearly there is a difference and that is what is the first component of the error vector.
25.srt	00:27:04.840 --> 00:27:17.200	Similarly, for j equal to 2 that is output of the second neuron over here, we actually got 0.95 whereas, ideally it should be 0.
25.srt	00:27:17.200 --> 00:27:23.500	So, 0.95 minus 0 that is the second component of the error vector.
25.srt	00:27:25.260 --> 00:27:30.660	If, squared these two error components add them together that gives you sum of squared error.
25.srt	00:27:31.110 --> 00:27:42.320	I put a multiplication factor half because as I am taking sum of squared error I have a squared term when I take the derivative this squared term becomes 2 and 2 and half gets cancelled.
25.srt	00:27:42.740 --> 00:27:53.540	So, that is the reason I have half over here and that is what is my loss function, the loss function that I want to minimize by using .
25.srt	00:27:55.930 --> 00:28:01.050	learning algorithm or back propagation algorithm.
25.srt	00:28:01.050 --> 00:28:12.500	Again over here you find that this x j 2 I want to minimize this with respect to different weight vectors.
25.srt	00:28:12.920 --> 00:28:26.190	So, I have to go for the chain rule x j 2 is defined in terms of theta j 2 which is an intermediate variable and theta j 2 is defined.
25.srt	00:28:26.440 --> 00:28:33.100	with respect to weight vectors and the output from the first layer nodes of the hidden layer nodes that you get.
25.srt	00:28:34.790 --> 00:28:49.290	My aim is that I should adjust the weight components W ij 2 that is the weights which are connecting the nodes in the first layer to the output layer by using back propagation algorithm.
25.srt	00:28:50.440 --> 00:28:58.390	So, for doing that what I have to do is I have to get the derivative of this error with respect to ij 2 and then I follow.
25.srt	00:28:58.740 --> 00:29:00.320	the gradient descent procedure.
25.srt	00:29:02.180 --> 00:29:06.130	So, I have to take the gradient of the error with respect to the weight vectors.
25.srt	00:29:07.460 --> 00:29:31.330	And again here here what we have done before this is not new we have discussed this before that I have to compute del a del e del w i j 2 and following chain rule this becomes del e del x j 2 because e is directly visible to x j then del x j 2 del theta j 2 because x j 2 is a function of theta j 2.
25.srt	00:29:31.400 --> 00:29:40.190	2 and then del theta j 2 del w i j 2 because theta j 2 is a function of w i j 2.
25.srt	00:29:41.480 --> 00:30:02.150	And if you do this each of these terms del E del x j 2 is x j minus T j del x j 2 del theta j 2 is x j 2 into 1 minus x j 2 and del theta j 2 del w i j 2 is nothing, but .
25.srt	00:30:02.840 --> 00:30:04.280	x i 1.
25.srt	00:30:06.320 --> 00:30:32.630	And if you remember what we did before is we have defined this term this part that is x j 2 into 1 minus x j 2 into x j 2 minus T j as delta j 2 because this is a term which will be passed backward.
25.srt	00:30:33.670 --> 00:30:56.450	W ij 2 minus eta times del E del W ij 2 or this is nothing, but del E eta times delta j 2 x i 1 where this eta is an hyper parameter which controls the rate of learning or the rate of convergence.
25.srt	00:30:58.610 --> 00:31:04.850	So, in this lecture let us stop here today, we will continue with this in our next lecture.
25.srt	00:31:05.390 --> 00:31:05.760	Thank you.
31.srt	00:00:00.610 --> 00:00:17.820	Hello, welcome to the NPTEL online certification course on deep learning.
31.srt	00:00:31.550 --> 00:00:55.289	In previous few lectures, we are discussing about the autoencoders and we have seen that autoencoder is an algorithm which tries to learn a compressed domain representation of the input data or it tries to learn the structure present in the input data.
31.srt	00:00:56.370 --> 00:01:00.759	And in order to do that, what you do is given an input data.
31.srt	00:01:01.229 --> 00:01:17.159	you pass it through a neural network which is obviously, a multi layer neural network where you try to reconstruct whatever input you are feeding the same signal the same data you try to reconstruct at the output.
31.srt	00:01:17.859 --> 00:01:27.039	But while this information the data passes from the input to the output layer it passes through one or more hidden layers.
31.srt	00:01:34.579 --> 00:01:48.420	So, in the basic configuration we have seen that an autoencoder consists of one hidden layer, where the number of nodes in the hidden layer is much less than the number of nodes in the input layer that is a configuration which is known as under complete autoencoder.
31.srt	00:01:49.579 --> 00:02:08.129	So, as it passes through a hidden layer which is also known as bottleneck layer, the information which while it passes through the hidden layer having a lesser number of nodes than the input layer, the network learns a compressed domain representation.
31.srt	00:02:09.489 --> 00:02:19.229	What will happen if the hidden layer contains the same number of nodes as the input layer or the number of nodes which is even larger than the input layer.
31.srt	00:02:19.989 --> 00:02:38.889	Later on of course, we will see other configurations of the autoencoder where such thing is also possible, but in such cases the autoencoder will learn a compressed domain representation by introducing some constraint which we will term as sparsity constraint.
31.srt	00:02:39.479 --> 00:02:46.409	We will come to that later, but so far what we have discussed is what is known as under complete autoencoder.
31.srt	00:02:46.860 --> 00:03:00.699	So, there if we assume that your number of nodes in the hidden layer is same as the number of nodes in the input layer and obviously, the same as number of nodes in the output layer and or even more than that.
31.srt	00:03:01.120 --> 00:03:18.120	In that case it is possible that autoencoder will simply try to memorize the input data and the function that it will learn is a simply identity function, whereby wherever is there at the input the same will be reproduced at the output.
31.srt	00:03:19.149 --> 00:03:43.429	But, by putting a hidden layer having limited number of nodes known as bottleneck layer as we have just said, the network is forced to learn a compressed domain representation or the network is forced to learn the salient features which are present in the input data and that is the purpose of an autoencoder.
31.srt	00:03:43.669 --> 00:03:48.209	Reconstruction of the input signal is not the purpose of autoencoder.
31.srt	00:03:48.599 --> 00:04:05.299	But, the purpose of autoencoder is that it learns a compressed domain representation or it learns the salient features in the input data and using this salient features the decoder side should be able to reconstruct your original data.
31.srt	00:04:05.759 --> 00:04:11.409	So, we are actually interested when it comes to the application of autoencoder we will come to that a bit later.
31.srt	00:04:12.389 --> 00:04:20.069	We are actually interested in the output of the hidden layer or the bottleneck layer which is a compressed domain representation.
31.srt	00:04:21.259 --> 00:04:31.059	So, we have also seen that as we are talking about the compressed domain representation, this is also nothing, but what is known as dimensionality reduction.
31.srt	00:04:31.889 --> 00:04:49.819	So, if your number of nodes in the hidden layer is much less than the number of nodes in the input layer, then in the compressed domain representation the dimensionality of the latent variable which is mapped from the input data, the dimensionality of the latent space data.
31.srt	00:04:50.499 --> 00:04:59.259	is much less than the dimensionality of the input data, but still the decoder should be able to reconstruct the input from that reduced data.
31.srt	00:04:59.789 --> 00:05:01.769	So, this is what is dimensionality reduction.
31.srt	00:05:02.679 --> 00:05:16.439	And we have also discussed in our previous lecture that when we talk about dimensionality reduction, traditionally a very popular method for dimensionality reduction is what is known as principal component analysis.
31.srt	00:05:21.089 --> 00:05:25.500	That is the input data is projected onto the eigenvectors into the eigen space.
31.srt	00:05:25.589 --> 00:05:45.419	And if the input data is projected into the eigenvectors obviously, if you have a set of data which is of dimension d the number of eigenvectors will be d number of eigenvectors, but for every eigenvector there be a corresponding eigenvalue.
31.srt	00:05:46.519 --> 00:05:52.169	So, when you form the transformation matrix, you form the transformation matrix.
31.srt	00:05:52.449 --> 00:05:56.939	using the eigenvectors as rows in the transformation matrix.
31.srt	00:05:57.629 --> 00:06:15.789	And when you form this transformation matrix as we have seen in your previous lecture that the first row in the transformation matrix will be the eigenvector corresponding to the maximum eigenvalue and the last row in the transformation matrix will be the eigenvector corresponding to minimum eigenvalue.
31.srt	00:06:16.759 --> 00:06:26.569	And in between all the rows are formed by eigenvectors arranged in descending order of the corresponding eigenvalues.
31.srt	00:06:27.879 --> 00:06:36.000	So, now for transformation purpose if we retain only few number of rows in the transformation matrix from the top.
31.srt	00:06:36.610 --> 00:06:38.110	So, we retain only one row.
31.srt	00:06:39.279 --> 00:06:50.740	In that case your d dimensional data is transformed into a one dimensional data which is nothing but projection onto the eigenvector having my maximum eigenvalue.
31.srt	00:06:51.849 --> 00:06:59.959	If we retain only two eigenvectors then the d dimensional input data will be transformed into two dimensional data.
31.srt	00:07:00.660 --> 00:07:03.129	principal components in eigen space.
31.srt	00:07:04.069 --> 00:07:10.779	And we have also seen through reconstruction with examples of reconstruction that the power of such principal components.
31.srt	00:07:11.019 --> 00:07:22.339	So, we have seen with examples that even with oneprinciple component it is possible to reconstruct most of the information present in the input data.
31.srt	00:07:22.379 --> 00:07:31.100	And there we have compared the principal component analysis PCA with autoencoders.
31.srt	00:07:31.449 --> 00:07:47.599	And, we have seen that in case of autoencoder if we do not impose any nonlinearity in the neural in the neurons in the neural network, then your principal components and the autoencoder outputs they almost coincide.
31.srt	00:07:47.889 --> 00:08:07.719	But, we have also discussed that autoencoders are much more powerful than principal components because of the presence because the neural neurons in the neural network are capable of imposing or implementing nonlinear functions.
31.srt	00:08:08.780 --> 00:08:21.100	So, as principal component analysis is a linear transformation from the input space to the eigen space, auto encoders can give you a non-linear transformation.
31.srt	00:08:21.100 --> 00:08:34.360	So, as because auto encoders can give us non-linear transformation, we can even represent non-linear manifolds using the auto encoders which is not possible using principal components.
31.srt	00:08:40.459 --> 00:08:52.589	So, we have seen that if we do not impose the nonlinearity the nonlinearity in the neurons or if the activation function of the neurons are linear then autoencoder and principal component analysis they become almost identical.
31.srt	00:08:53.919 --> 00:09:06.609	However, because of the presence of nonlinearity autoencoder gives us much better representation in lower dimensional space than in case of principal components.
31.srt	00:09:06.609 --> 00:09:11.249	So, that is what we have discussed in our previous lectures.
31.srt	00:09:13.870 --> 00:09:17.130	So, today what we are going to discuss about is how do you train a deep autoencoder.
31.srt	00:09:17.130 --> 00:09:20.520	So, we are talking about deep autoencoder training.
31.srt	00:09:21.180 --> 00:09:32.430	Then subsequently we will talk about other versions of autoencoders like sparse autoencoder, denoising autoencoder, contactive autoencoder and so on.
31.srt	00:09:32.970 --> 00:09:44.870	And after few lectures we will also talk about convolution autoencoder, but I will come to that topic after we discuss about convolution and convolution neural network.
31.srt	00:09:46.090 --> 00:09:51.030	So, let us start with how do we learn a deep autoencoder.
31.srt	00:09:51.890 --> 00:10:05.510	So, as we told before that in case of deep autoencoder and instead of having only one hidden layer, we have stacks of hidden layers placed one after another.
31.srt	00:10:16.210 --> 00:10:25.320	So, that is what is nothing but stacking of different autoencoder layers and the depth of the network depends upon how many such autoencoder layers you have in your autoencoder neural network.
31.srt	00:10:25.320 --> 00:10:29.100	So, a typical figure of a deep autoencoder is something like this.
31.srt	00:10:29.760 --> 00:10:34.830	So, here you find that we have our this input layer.
31.srt	00:10:35.810 --> 00:10:38.160	So, this is the layer which is input layer.
31.srt	00:10:40.020 --> 00:10:43.320	So, you are feeding your input data x to this input layer.
31.srt	00:10:43.920 --> 00:10:46.050	So, obviously, the number of nodes in the input layer.
31.srt	00:10:46.360 --> 00:10:55.400	we have also told that before is same as the number of elements in vector x plus 1, why that additional one?
31.srt	00:10:55.900 --> 00:11:00.740	Because we also wants to incorporate the bias term in the same layer.
31.srt	00:11:01.700 --> 00:11:09.540	So, if the dimensionality of the input vector x is d, number of nodes in the input layer will be d plus 1.
31.srt	00:11:10.210 --> 00:11:12.010	So, this is what we have discussed before.
31.srt	00:11:13.210 --> 00:11:16.730	And then you find that we have a number of autoencoders.
31.srt	00:11:17.610 --> 00:11:30.740	So, I can call this one as say the first autoencoder, autoencoder 1, this is the autoencoder 2, this is autoencoder 3 and so on.
31.srt	00:11:31.360 --> 00:11:44.980	And here in this configuration I get the coded output or the reduced dimensional representation which is also known as latent space representation at the output of autoencoder 3.
31.srt	00:11:45.740 --> 00:11:54.160	Of course, each of these autoencoders will give a reduced dimensional representation for the same input, but at different levels.
31.srt	00:11:54.910 --> 00:12:10.820	So, output of autoencoder 1 what you get here is also a coded version of input vector x, output of autoencoder 2 is also a coded version of input vector x, here this is also a coded version of the input vector x right.
31.srt	00:12:11.040 --> 00:12:14.870	So, this is where we get maximal dimensionality reduction.
31.srt	00:12:15.970 --> 00:12:27.270	And once I have this coded output, the coded output is decoded by this decoding layers, then I have a number of decoding layers to get my reconstruction.
31.srt	00:12:27.720 --> 00:12:29.940	or the reconstructedsignal x hat.
31.srt	00:12:30.000 --> 00:12:57.930	So, in case of autoencoder what we said is we try to reduce the error between x and x hat or the loss function in this case is L x x hat which we have also said that the loss function that can be defined is sum of squared error that is what is the error in the construction of x hat when you compare that with input x.
31.srt	00:12:58.800 --> 00:13:10.590	And, training of the autoencoder or deep autoencoder will try to reduce this error the sum of squared error to a minimum value.
31.srt	00:13:10.590 --> 00:13:15.320	So, you find that in case of autoencoder we have also said before that I have an encoding part.
31.srt	00:13:15.470 --> 00:13:24.610	So, this is a portion which is encoding and this is a part of the autoencoder which is decoding.
31.srt	00:13:25.690 --> 00:13:30.810	So, I have an encoding portion and I have a decoding portion.
31.srt	00:13:31.340 --> 00:13:47.490	And, these two taken together forms an autoencoder and the depth or the number of layers that you have auto that you have within this one autoencoder that tells you that what is the power of the autoencoder ok.
31.srt	00:13:48.850 --> 00:14:01.430	So, given this that as we said that for training such autoencoder I want to minimize the loss or minimize the error between the input vector x and the reconstructed vector x hat .
31.srt	00:14:02.120 --> 00:14:09.220	So, what I want ideally is the reconstructed x hat should be identical with my input vector x.
31.srt	00:14:11.210 --> 00:14:18.480	And that has to be done using the back propagation learning algorithm that we have talked about earlier.
31.srt	00:14:19.760 --> 00:14:34.510	Now, you find that the number of weight vectors or number of weight matrices or the number of elements weight elements that you have to determine by training of the autoencoder is tremendous.
31.srt	00:14:35.030 --> 00:14:51.480	So, I have weightmatrix W 1, I have weightmatrix W 2, I have weightmatrix W 3 on the encoder side on the decoder side I have weightmatrix W 3 hash, W 2 hash and W 1 hash.
31.srt	00:14:53.060 --> 00:15:04.920	And the number of weight matrices will go on increasing with the depth of the auto encoder that is the deeper the network is the number of such weight matrices will go on increasing.
31.srt	00:15:06.440 --> 00:15:36.630	So, if I try to train this entire autoencoder end to end that is given the full autoencoder architecture, I have the state of training vectors given to the input, I have x hat xhat as the output and by reducing the error between x and x hat, if I try to train this autoencoder then I have to deal with so many weight matrices simultaneously and that leads to a problem.
31.srt	00:15:37.020 --> 00:15:42.310	One is obviously, the memory problem that I have to save so many weight elements into into the memory.
31.srt	00:15:43.100 --> 00:15:55.410	The other problems are that if the weights that you have is close to the solution weights, the convergence of the learning algorithm is quite easy.
31.srt	00:15:56.820 --> 00:16:01.960	But if the weight elements are too large, then finding a global minimum becomes a difficulty.
31.srt	00:16:03.710 --> 00:16:08.930	And on the other hand, if the weight elements because initially all of them are chosen at random.
31.srt	00:16:09.370 --> 00:16:15.450	So, if the weight elements becomes too low in that case the convergence of the learning algorithm becomes very slow.
31.srt	00:16:16.710 --> 00:16:39.550	So, to avoid this problem the kind of approach for training a deep autoencoder can be that you go for a stage called pre-training which will be finally, refined with end to end training mechanism, but before going for that to reduce your complexity you go for a pre-training.
31.srt	00:16:40.880 --> 00:16:47.830	and this p training is done layer by layer that means, while pre training you deal with lesser number of weight matrices.
31.srt	00:16:48.570 --> 00:16:51.090	So, let us see that how we how it is actually done.
31.srt	00:16:52.410 --> 00:16:56.930	So, we are talking about the layer by layer p training mechanism.
31.srt	00:16:57.830 --> 00:17:03.270	So, while doing this you I take only one layer of autoencoder at a time.
31.srt	00:17:04.910 --> 00:17:10.670	So, as before I have this input layer where the input vector x is applied.
31.srt	00:17:11.410 --> 00:17:29.370	And, I take initially only one autoencoder say autoencoder layer 1 and then I put a decoder which decodes the coded output from autoencoder 1.
31.srt	00:17:30.840 --> 00:17:38.860	So, because I have only one layer this decoder output should besame as reconstructed X.
31.srt	00:17:39.010 --> 00:17:40.600	So, I call it X hat.
31.srt	00:17:49.220 --> 00:18:02.270	And, while training this first autoencoder or while trying to determine what will be the value of W 1, I you go for back propagation and this back propagation will try to minimize the error between x and x hash x and x hat and while doing so it learns the weight vectors w 1.
31.srt	00:18:03.590 --> 00:18:19.710	And once this weight vector w 1 is learned then you discard the first level of decoder that we have used and discarding this now I put a second autoencoder.
31.srt	00:18:20.410 --> 00:18:29.940	Now, before that you find that say output of the autoencoder which is an which encodes X is say a latent space vector Z 1.
31.srt	00:18:30.840 --> 00:18:35.740	So, the next level of autoencoder will try to encode this Z 1.
31.srt	00:18:36.520 --> 00:18:47.720	So, I put the second autoencoder and let me call this second autoencoder as A e 1 A e 2 sorry.
31.srt	00:18:47.720 --> 00:18:51.120	So, this A e 2 will try to encode Z 1.
31.srt	00:18:51.560 --> 00:18:57.580	And, while doing so it will try to learn the weight W 2 or weight matrix W 2.
31.srt	00:18:58.740 --> 00:19:10.840	So, to train a E 2 now what I do is I put another decoder of course, these decoders I am putting they are all intermediate finally, these decoders will not be there.
31.srt	00:19:11.990 --> 00:19:18.260	So, I put another decoder and this decoder tries to decode the output of autoencoder 2.
31.srt	00:19:19.580 --> 00:19:28.050	That means, it will try to reconstruct Z 1 which is input to input to autoencoder 2.
31.srt	00:19:28.630 --> 00:19:44.330	And, I call this Z 1 hat and for this learning the back propagation learning it will consider only the auto encoder 1, auto encoder 2 and the decoder that we have used.
31.srt	00:19:46.670 --> 00:19:54.270	And, while training this it will try to minimize the error between Z 1 and Z 1 hash and Z 1 hat.
31.srt	00:19:55.190 --> 00:19:58.920	And once that training is complete that learning is complete.
31.srt	00:19:59.320 --> 00:20:02.420	what we have learnt is the weight matrix W 2.
31.srt	00:20:03.760 --> 00:20:18.000	And once weight matrix W 2 is learnt you remove this second decoder that we have placed and there the autoencoder 2 let me assume the output of the autoencoder 2 is Z 2.
31.srt	00:20:19.660 --> 00:20:31.180	And after I got this I put the third autoencoder say A e 3 this is third autoencoder A e 3 .
31.srt	00:20:32.530 --> 00:20:40.250	So, now we have to train this third on at autoencoder that means, we have to find out that what are the weight what is the weight matrix W 3.
31.srt	00:20:42.000 --> 00:20:56.370	So, again for training this I put another decoder over here and this decoder will decode the output of autoencoder 3.
31.srt	00:20:56.880 --> 00:21:01.930	So, you find that the input to autoencoder 3 was Z 2 which was the output of autoencoder 2.
31.srt	00:21:02.780 --> 00:21:13.660	So, this last decoder that we are talking about this decoder will try to decode this Z 2 ordered by autoencoder 3 to give you Z 2 hat.
31.srt	00:21:14.660 --> 00:21:28.750	And for doing this the layers which are involved is only these layers and it will try to minimize the error or the loss function between Z 2 and Z 2 hat or L Z 2 Z 2 hat.
31.srt	00:21:32.820 --> 00:21:38.040	And once that is trained so, you find that we have the pre trained values of W 1, W 2 and W 3.
31.srt	00:21:39.260 --> 00:21:49.490	And if I assume that this is the last autoencoder layer that we had in our dipautoencoder, then the next part comes is the decoder part.
31.srt	00:21:50.990 --> 00:21:59.050	So, to set the decoder, so what I have to do is I have to again remove this autoencoder, I have to have a decoder part.
31.srt	00:21:59.890 --> 00:22:02.440	So, the decoder that you put is .
31.srt	00:22:03.280 --> 00:22:16.390	this by wrapping the encoder side and by taking the corresponding weights in the decoder side you take the transposes of the encoder weights.
31.srt	00:22:17.370 --> 00:22:27.480	So, this forms the total autoencoderor the encoder decoder pair which forms the total autoencoder.
31.srt	00:22:28.810 --> 00:22:35.730	So, here you find that W 1, W 2 and W 3 they were pre trained by using layer by layer mechanism.
31.srt	00:22:36.380 --> 00:22:38.370	layer by layer learning mechanism.
31.srt	00:22:39.740 --> 00:22:50.910	Now, I have this decoder also forming a full autoencoder and now you go for fine tuning or finer training of the weight vectors.
31.srt	00:22:51.740 --> 00:22:59.740	For that on the decoder side you initially assume that the weights are W 3 prime, W 2 prime and W 1 prime.
31.srt	00:23:00.790 --> 00:23:07.520	Now, you try to train this entire autoencoder chain using end to end training mechanism.
31.srt	00:23:08.000 --> 00:23:26.380	that is you feed your training vector x to the input, output of the autoencoder becomes x hat which is the reconstructed value of x and by back propagation learning you try to minimize the loss function between x and x hat which is L x x hat.
31.srt	00:23:27.360 --> 00:23:32.100	And here you find that because the encoder side was pre trained.
31.srt	00:23:39.310 --> 00:23:40.330	So, the values of the weight matrices W 1, W 2, W 3 are close to the actual values.
31.srt	00:23:42.920 --> 00:23:58.430	And while you go for this end to end training, now we have set of values which are very close to the actual the convergence of this training algorithm is much better than convergence of the algorithm if we try to train the entire network at a time.
31.srt	00:24:00.390 --> 00:24:04.540	So, this is what is layer by layer pre training.
31.srt	00:24:13.470 --> 00:24:34.340	So, what we have to do is after the pre training is complete, we have to introduce the decoder part and then for fine tuning of the pre trained weights I have to go for one or more iterations for end to end training giving the input as x and the output encoder output of the autoencoder x hat try to reduce the error between x and x hat using the gradient descent or back propagation learning mechanism.
31.srt	00:24:35.230 --> 00:24:44.150	So, that will ensure the convergenceto be faster and likely to attainthe global minimum of the loss function.
31.srt	00:24:45.940 --> 00:24:51.390	So, this is what isthe pre training the layer by layer pre training of autoencoder.
31.srt	00:24:52.759 --> 00:24:54.690	Now, suppose my autoencoder is trained.
31.srt	00:25:17.029 --> 00:25:18.559	So, what the autoencoder is giving me giving an input x the encoder side actually gives me say a function f of x that is my encoding function and say decoding let me call it a function g. So, this gives me decoding of f of x.
31.srt	00:25:20.759 --> 00:25:22.100	So, what is my x hat?
31.srt	00:25:22.660 --> 00:25:26.580	X hat is nothing, but g of f x.
31.srt	00:25:28.920 --> 00:25:43.529	So, the training mechanism try to minimize the error between f x and g of f x and that is how you try to find that x and x hat will be identical when the autoencoder is properly trained ok.
31.srt	00:25:43.690 --> 00:25:50.240	So, given this as we said before that we are not really interested in the reconstruction part I have input x.
31.srt	00:25:51.339 --> 00:26:07.019	do I do with x at that is not my aim, but my aim is actually the output of the auto encoder that is the latent space representation of the reduced space representation that I get from x.
31.srt	00:26:07.289 --> 00:26:20.210	And as we said that what I get at the output of the auto encoder say let me call this as output vector h which contains the stallion features present in x.
31.srt	00:26:21.549 --> 00:26:25.609	after discarding the redundancies or non salient features which are present in X.
31.srt	00:26:25.859 --> 00:26:29.519	So, H will contain the salient features and that is in the reduced dimension.
31.srt	00:26:30.079 --> 00:26:34.329	So, using H how I can go for further applications.
31.srt	00:26:35.629 --> 00:26:39.680	So, one of the applications that can be there are various applications.
31.srt	00:26:39.980 --> 00:26:43.460	So, one of the applications can be say classification.
31.srt	00:26:45.099 --> 00:26:49.690	So, what I have is I have input vector vector X ah.
31.srt	00:26:53.019 --> 00:26:54.609	So, this input vector X.
31.srt	00:26:55.319 --> 00:27:04.200	The output of the autoencoder gives me h and here this h can be fed to a classifier for classification.
31.srt	00:27:08.660 --> 00:27:18.670	It is not necessary that classifier this classifier has to be a neural network, it can be any classifier, it can be a support vector machine, it can be a base classifier or whatever which we have discussed earlier.
31.srt	00:27:20.150 --> 00:27:25.880	But let us assume that we have a neural network, we have talked about multi layer perceptron before.
31.srt	00:27:26.420 --> 00:27:31.750	So, I can feed a multi layer perceptron or MLP over here.
31.srt	00:27:32.450 --> 00:27:47.180	So, the input to MLP is H and output of the MLP is the class identification of H or eventually the class identification of the input vector X.
31.srt	00:27:49.210 --> 00:27:56.940	So, now, we find that what the autoencoder does is it gives a coded output H of X it does not give you what is.
31.srt	00:27:57.700 --> 00:28:02.269	the class belongingness of H or what is the class belongingness of X.
31.srt	00:28:03.579 --> 00:28:16.460	So, if for the training vectors the class belongingness of X is also known that is the training vectors are given in the form of X Y, where X isthe input vector and Y is the class.
31.srt	00:28:27.390 --> 00:28:44.680	Then again I can go for and end to end training fine with finer refining of the weight matrices W 1, W 2, W 3 and now this training this back propagation training will consider the output of this MLP or will consider the loss function with the output of the MLP that also we have seen before.
31.srt	00:28:45.610 --> 00:28:50.799	It can be cross entropy, it can be again sum of squared error.
31.srt	00:28:50.840 --> 00:28:54.180	So, various suchoutput error function.
31.srt	00:28:57.970 --> 00:29:12.130	So, the loss function can be defined which is defined at the output of the MLP depending upon whether the class say Y hash which is decided by this MLP taking this H that matches with Y or not.
31.srt	00:29:13.240 --> 00:29:23.410	If it matches with Y then there is no error or no training required, if it does not match then obviously, we have to train this inter neural network with that professional learning again.
31.srt	00:29:31.299 --> 00:29:31.830	And during that time also this W 1 to W 3 this encoder encoder weight matrices can be defined further.
31.srt	00:29:33.519 --> 00:29:34.680	This is one of the application.
31.srt	00:29:36.360 --> 00:29:43.930	The other application can be even I can go for say pixel classification or segmentation operation of an input image.
31.srt	00:29:44.750 --> 00:29:56.420	So, for that what I can do is suppose I have an image and input, you take various patches of this input image convert that into a vector and feed that to the input.
31.srt	00:30:01.759 --> 00:30:10.950	As we have seen before that output of the autoencoder will contain the salient features of each of these image blocks that is what the autoencoder is doing.
31.srt	00:30:12.170 --> 00:30:19.700	And then at the output again I put a classifier, what this classifier will do?
31.srt	00:30:19.920 --> 00:30:26.390	It will put this input matrix the input image or patch of the image into one of the classes.
31.srt	00:30:27.640 --> 00:30:38.180	And if that class and using that again I can form an error function or a loss function and the autoencoder can again be trained using this loss function.
31.srt	00:30:39.710 --> 00:31:01.960	And, finally, once the autoencoder is trained again now you feed an input image again feed all the different blocks of the input image to this autoencoder, the autoencoder will give a salient or the latent space representation of each of the blocks and the blocks can be classified by the trainedMLP.
31.srt	00:31:02.470 --> 00:31:07.519	So, thereby I can classify each and every block in the image.
31.srt	00:31:08.989 --> 00:31:10.709	which is nothing but a segmentation operation.
31.srt	00:31:12.159 --> 00:31:20.209	I can also consider this to be a pixel by pixel classification orthe semantic segmentation of the input image.
31.srt	00:31:21.209 --> 00:31:35.269	And for that what I can do is given and patch in the image whatever representation I am getting at the output I can consider that this is the salient features of the central pixel of this patch.
31.srt	00:31:35.419 --> 00:31:36.479	So, this is my center pixel.
31.srt	00:31:39.589 --> 00:31:49.569	So, this classifier output or the pixels in the of the input image are now classified into different class and all the pixels belonging to the same class that forms a particular segment.
31.srt	00:31:52.109 --> 00:32:09.269	So, today what we have discussed is that how you can train an autoencoder, we have talked about layer by layer training of the autoencoder and once the autoencoder is trained what can be possible applications of such autoencoder.
31.srt	00:32:10.339 --> 00:32:11.960	So, we will stop here today.
31.srt	00:32:12.799 --> 00:32:13.119	Thank you.
19.srt	00:00:00.610 --> 00:00:27.039	Hello, welcome to the NPTEL online certification course on deep learning.
19.srt	00:00:32.649 --> 00:00:37.780	In our previous lecture, we have talked about the various non-linearity functions.
19.srt	00:00:37.780 --> 00:00:43.640	In today's lecture what we are going to talk about is the neural network.
19.srt	00:00:43.640 --> 00:01:01.799	And when we talk about neural network, we will initially see that how differentlogic functions the simple functions like AND function OR function or XOR function can be implemented using the neural network.
19.srt	00:01:03.320 --> 00:01:18.689	Then, we will talk about the feed forward neural network or multi layer perceptron and we will also talk about the learning or the training mechanism of the feed forward neural network which is known as back propagation learning.
19.srt	00:01:20.170 --> 00:01:33.509	So, before we go to the neural network, let us quickly recapitulate that what are the different types of non-linearities or non-linear functions that we have discussed in our previous lecture.
19.srt	00:01:36.420 --> 00:01:57.120	So, we have talked about the very simple type of nonlinearity which is the threshold nonlinearity that is if y is a function of x, then y will be equal to 1 if x is greater than or equal to 0 and y will be equal to 0 if x is less than 0.
19.srt	00:01:57.909 --> 00:02:03.989	So, this is a simple threshold function or a nonlinear function where the threshold value is equal to 0.
19.srt	00:02:07.150 --> 00:02:12.599	I can also have a threshold where the threshold value can be non-zero maybe say I take the threshold value to be equal to 5.
19.srt	00:02:12.599 --> 00:02:22.189	So, in that case value of y will be 1 if x is greater than or equal to 5 and it will be 0 if x is less than5.
19.srt	00:02:22.189 --> 00:02:29.240	So, this is the simplest kind of non-linearity that I can have which which is a threshold function.
19.srt	00:02:29.240 --> 00:02:37.650	The other kind of non-linearity that we can have is what is known as sigmoidal function which is used in logistic regression.
19.srt	00:02:40.110 --> 00:03:10.120	So, the sigmoidal function is actually given by 1 by 1 upon e to the power minus s which is a sigmoidal function of the argument s. Now, in this case since we are talking about the classifications or machine learning techniques where we will be frequently talking about the dot product of two different vectors w and x where w is the weight vector and x is the sample vector.
19.srt	00:03:10.720 --> 00:03:15.100	Then, our argument S becomes W transpose X.
19.srt	00:03:16.220 --> 00:03:28.770	So, the sigmoidal nonlinearity or logistic regression will be given by sigma W transpose X is equal to 1 upon 1 plus e to the power minus W transpose X.
19.srt	00:03:29.560 --> 00:03:42.770	So, as you find in the right hand side, the sigmoidal function has been shown graphically and you see that at W transpose X equal to 0, the value of the sigmoidal function is half.
19.srt	00:03:43.610 --> 00:03:58.700	And, as W transpose X goes on increasing the sigmoidal function asymptotically reaches a value equal to 1 of course, it will never reach the value equal to 1, but asymptotically you can say that it reaches the value of 1.
19.srt	00:03:59.689 --> 00:04:15.840	And, as W transpose X becomes negative as it increases on the negative side or in other terms W transpose X goes on reducing on the negative side, then the sigmoidal function asymptotically reaches a value equal to 0.
19.srt	00:04:16.620 --> 00:04:37.980	So, this logistic regression actually gives an output a limit on the output where the output is limited between 0 and 1 and between 0 and 1 we have a smooth transition where at the center that is at the value of W transpose X equal to 0 the sigmoidal function passes through 0.5.
19.srt	00:04:37.980 --> 00:04:45.980	So, this is another type of nonlinearity which we will see that this can this is widely used in implementation of neutral network.
19.srt	00:04:47.949 --> 00:04:59.699	The other kind of nonlinearity is what is known as rectified linear unit or ReLU which is given by y is equal to maximum of 0 or x.
19.srt	00:05:00.279 --> 00:05:10.279	So, if x is greater than 0, then value of y is equal to x, if x is 0 or less than 0, then value of y will be equal to 0.
19.srt	00:05:11.459 --> 00:05:21.050	And the representation the graphical representation of this ReLU function is also shown on the right hand side in this figure.
19.srt	00:05:22.480 --> 00:05:33.780	So, ReLU is also a nonlinearity which is widely used in modern neural networks particularly when we talk about deep neural networks or deep learning.
19.srt	00:05:34.490 --> 00:05:41.410	So, we will come across all these different types of nonlinearity as weproceed in our discussion.
19.srt	00:05:41.410 --> 00:05:47.480	So, let us come to the neural network now.
19.srt	00:05:52.949 --> 00:06:03.430	The heart of the neural network is neuron So, when we talk about neural network, the concept of neural network is actually inspired from the way our we believe our brain works.
19.srt	00:06:03.800 --> 00:06:15.150	Of course, till now nobody has been able to say with certainty how the brain actually functions, but this is what till now what we believe how our brain actually functions.
19.srt	00:06:16.210 --> 00:06:25.580	So, in our brain we have a network of neurons and if you look at every neuron as is shown in thisfigure on .
19.srt	00:06:26.849 --> 00:06:33.399	The right hand side the neuron consists of a cell body, the cell body.
19.srt	00:06:33.810 --> 00:06:50.060	So, this is the center of this which is the cell body or the nucleus and the cell body collects information, it receives information through a number of sensors coming to the cell body which through a connectors which are known as dendrites.
19.srt	00:06:51.560 --> 00:06:56.449	Cell body processes this information and the information is outputted.
19.srt	00:06:56.829 --> 00:07:09.370	through a connection which is name known as action and action finally, it branches out and connects to other neurons through synaptic connections.
19.srt	00:07:11.089 --> 00:07:29.459	And it is believed that the information as it passes to actions and then finally, branches out and then it is passed on to other neurons in the network through a synaptic connections in this process there is a multiplicative interaction .
19.srt	00:07:30.420 --> 00:07:32.120	What is that multiplicative interaction?
19.srt	00:07:33.060 --> 00:07:53.000	If the signal outputted by the cell body is the x, then when it reaches the other neurons through this multiplicative interaction coming through the synapticconnections, the value which reaches the other neurons is W times x.
19.srt	00:07:54.069 --> 00:07:59.490	So, this is the kind of multiplicative interaction which is given in the neural network .
19.srt	00:08:00.160 --> 00:08:02.470	or in the network in the brain.
19.srt	00:08:03.710 --> 00:08:12.710	So, when you talk about neural network we will also see that the neural networks are derived from this particular concept.
19.srt	00:08:13.800 --> 00:08:15.410	So, what we have in neurons?
19.srt	00:08:16.650 --> 00:08:31.920	In neurons we have cells which receives signals through dendrites and it pass it passes these signals after processing.
19.srt	00:08:32.259 --> 00:08:35.639	to the other neurons in the network through synaptic connections.
19.srt	00:08:36.480 --> 00:08:49.440	So, the processing is done in an unit in the cell which is known as soma and action is the connecting path which transmits the signal from one neuron to another neuron.
19.srt	00:08:50.220 --> 00:08:54.899	So, this is what is the concept of a neuron in human brains.
19.srt	00:09:04.269 --> 00:09:13.909	So, when you talk about a neuron in our neural network you find that here also every neuron consists of a functional unit which is the cell body given by this unit.
19.srt	00:09:14.420 --> 00:09:23.529	This collects information x or the vector x through a number of inputs which are equivalent to dendrites.
19.srt	00:09:23.639 --> 00:09:35.940	And when these inputs are coming to the cell body they pass to a weighting function given by W or weight values given by the weight vector W .
19.srt	00:09:37.210 --> 00:09:53.970	And, the output of the neuron is of the form some function of W transpose X, where W is the weight vectors, X is the input vector and output Y of the neuron will be a function of W transpose X.
19.srt	00:09:54.820 --> 00:10:04.919	And, when you talk about neural network this function f in most of the cases is a non-linear function like the non-linear functions that we have discussed before.
19.srt	00:10:04.919 --> 00:10:09.500	So, we will come to the use of those non-linear functions in neural network.
19.srt	00:10:11.279 --> 00:10:13.909	inour discussions.
19.srt	00:10:15.870 --> 00:10:24.259	So, given this model of the neuron a neural network is nothing, but an interconnection of all those neurons.
19.srt	00:10:24.259 --> 00:10:46.950	So, here you find that in this figure what we have shown is we have a number of neurons which collects information x that is ourinformation vector or sample vector and in every level it is passed through or multiplied by an weight vector w .
19.srt	00:10:47.639 --> 00:10:50.279	So, I will have a set of weight vectors over here.
19.srt	00:10:52.000 --> 00:11:11.460	This processed information from every neuron is passed to the other neurons through say dendrites or synapses and while it passes through these dendrites or synapses while passing they are also multiplied by another set of weights or weight vectors w and it continues.
19.srt	00:11:12.379 --> 00:11:23.850	And finally, when you get the output the output of every neuron or every unit in this neural network is given by this function w transpose x.
19.srt	00:11:24.169 --> 00:11:33.519	and usually a non-linear function f of this W transpose X that is what is the output of every neuron right.
19.srt	00:11:34.019 --> 00:11:40.539	So, this is howis the architecture of a neural network looks like.
19.srt	00:11:40.539 --> 00:11:50.699	So, given this let us now see that how these neural networks can be used to implement various functions.
19.srt	00:11:55.180 --> 00:11:57.879	So, the first function which is a very simple function that we discuss is an AND function.
19.srt	00:11:59.009 --> 00:12:12.540	And the AND operation that we are going to consider which is a logical operation on two units or two inputs, the inputs are x 1 and x 2 and obviously, these inputs are binary inputs.
19.srt	00:12:13.960 --> 00:12:25.040	So, I have the input vector which is given by x 1 x 2 and my output function which is an AND function is given by y as shown in the table on the left hand side.
19.srt	00:12:26.259 --> 00:12:35.879	So, as you all know that if the input vector is 0 0, then given the function to be AND function the output is obviously 0.
19.srt	00:12:36.840 --> 00:12:43.670	If the input is 0 1, the output is also 0, if the input is 1 0, output is 0.
19.srt	00:12:44.350 --> 00:12:56.610	Only when input is 1 1 that is both the inputs both the variables on the input which are binary variables are 1, then only the output of the AND logic will be equal to 1.
19.srt	00:12:58.120 --> 00:13:15.629	So, if I consider this x 1 and x 2 which are inputs tothis AND gate to be the features or x 1 x 2 given together become a binary feature vector, then I have a feature space or a two-dimensional feature space.
19.srt	00:13:15.629 --> 00:13:27.730	So, if I plot these outputs in this two-dimensional feature space as given on the right hand side of this figure over here you see .
19.srt	00:13:28.830 --> 00:13:35.560	that, when x 1 is 1 and x 2 is 0, the output is 0 which is shown here.
19.srt	00:13:37.180 --> 00:13:41.810	If x 1 is 0 and x 2 is 1, then also output is 0.
19.srt	00:13:43.100 --> 00:13:51.530	If x 1 is 0, x 2 is 0, output is 0, only when both x 1 and x 2 they are 1, the output is 1.
19.srt	00:13:52.700 --> 00:13:59.220	So, this is how the functional values will be distributed in the feature space given by the features x 1 and x 2.
19.srt	00:14:00.330 --> 00:14:15.850	Now, I can consider this to be a classification problem that is when I am considering the input to be a binary feature vector, then I can consider the output to belong to one of the two classes or the input vectors belonging to one of the two classes.
19.srt	00:14:17.060 --> 00:14:21.110	In one class which is class 1 and the other class which is class 0.
19.srt	00:14:22.310 --> 00:14:29.230	So, all the feature vectors 0 0 0 1 and 0 they will belong to one class when the output should be equal to 0.
19.srt	00:14:29.780 --> 00:14:35.490	only when the feature vector is 1 1, it should belong to another class and output will be equal to 1.
19.srt	00:14:36.890 --> 00:14:46.190	And those distributions of the feature vectors are as shown in this plot on the right hand side.
19.srt	00:14:48.190 --> 00:14:59.230	Now, consider and now find that considering this to be a binary classification problem, I have to find out a classifying boundary or a classifier which classifies these two classes.
19.srt	00:15:00.480 --> 00:15:08.210	And, as you see that this is a linear problem as I can separate these two classes by using linear boundaries.
19.srt	00:15:09.390 --> 00:15:28.020	And, over here though there are multiple boundaries possible that is I can have this as a linear line which separates these two classes, this can also be a linear separator which is which separates these two classes .
19.srt	00:15:30.340 --> 00:15:39.840	But, one of the option is that as shown over here and you find that equation of the straight line in this two dimensional space is given by x 1 plus x 2 minus 1.5 equal to 0.
19.srt	00:15:39.840 --> 00:15:49.530	And as I said that this is one of the many possible linear boundaries that I can have between these two classes .
19.srt	00:15:51.060 --> 00:16:01.620	So, considering this now you find that I can consider this to be a feature vector where my feature vector is .
19.srt	00:16:01.970 --> 00:16:13.440	1 x 1 x 2 and I have an weight vector which is given by minus 1.511.
19.srt	00:16:13.870 --> 00:16:30.080	So, equation of this straight line in that case becomes W transpose X or X transpose W whichever way I put it because the value of W transpose X and X transpose W is same.
19.srt	00:16:33.500 --> 00:16:37.259	So, the equation of the straight line is given by W transpose X equal to 0 or X transpose W equal to 0.
19.srt	00:16:38.280 --> 00:16:47.840	And the feature vectors 0 0 0 1 and 1 0 that will fall on one side of the straight line and the feature vector 1 1 will fall on the other side of the straight line.
19.srt	00:16:48.710 --> 00:17:03.250	And incidentally if you analyze you find that this particular equation the classifier that I get this is nothing, but a two class support vector machine or a binary support vector machine.
19.srt	00:17:03.940 --> 00:17:06.009	because, it maximizes the margin.
19.srt	00:17:06.860 --> 00:17:16.259	And as I said that though there are many possible straight lines that I can draw for them the margin will be less than the margin which is given by this.
19.srt	00:17:16.450 --> 00:17:19.460	So, this is also a support vector machine.
19.srt	00:17:21.320 --> 00:17:26.800	Now, given this now let us see that how I can implement this using a neural network.
19.srt	00:17:29.240 --> 00:17:33.230	So, as I said before all the feature vectors taken together.
19.srt	00:17:33.690 --> 00:17:47.540	I can put that in the form of a matrix and we are also putting this in unified form that is I am adding in each of the feature vectors one additional element which will be equal to 1.
19.srt	00:17:48.960 --> 00:17:52.320	So, my feature vectors are 1 0 0.
19.srt	00:17:52.640 --> 00:17:58.200	So, 1 is added which is an additional element as we have shown over here.
19.srt	00:17:58.770 --> 00:18:05.030	So, this is one of the feature vector which is 1 0 0, 1 0 1 is another feature vector.
19.srt	00:18:05.510 --> 00:18:11.340	1 1 0 is another feature vector and 1 1 1 is the fourth feature vector.
19.srt	00:18:12.560 --> 00:18:35.850	And we also said, so all these feature vectors are represented are put together in the form of a matrix ok. And out of this we know that this first four feature vectors they belong to say class omega 1 for which output will be equal to 0 and for this it belongs to class omega 2 for which output will be equal to 1.
19.srt	00:18:37.070 --> 00:18:42.460	And, I also have this weight vector w which is minus 1.511.
19.srt	00:18:42.780 --> 00:18:53.040	So, given this representation representing all the feature vectors in the form of a matrix and the weight vector now how my classifier will work?
19.srt	00:18:53.040 --> 00:18:56.720	Let us see this one.
19.srt	00:18:56.720 --> 00:19:07.150	So, I can put it in the form of x transpose w where yeah I I just .
19.srt	00:19:07.600 --> 00:19:08.340	put it this way.
19.srt	00:19:09.130 --> 00:19:20.330	Here instead of writing this as x, I will write this as x transpose because whenever we talk about a vector, we usually talk the vector as a column vector.
19.srt	00:19:20.850 --> 00:19:27.860	So, this 1 0 0 which is rho over here, it is actually 1 0 0 that is a column vector.
19.srt	00:19:28.860 --> 00:19:32.800	So, instead of writing this matrix as x, let us put this as x transpose.
19.srt	00:19:32.800 --> 00:19:37.920	So, that every rho in this matrix is actually transpose of our feature vectors.
19.srt	00:19:39.230 --> 00:20:08.240	So, with this understanding you find that the way the classifier will actually work is if I compute W transpose Xsorry X transpose W where X is this matrix X transpose is this matrix and W is a weight vector which is this then the output of this multiplication this matrix multiplication is minus 1.5 then minus 0.5.
19.srt	00:20:09.490 --> 00:20:11.200	minus 0.5 and 0.5.
19.srt	00:20:11.200 --> 00:20:19.840	Now, if I pass it through a non-linearity, so you remember we said that this non-linearity is a non-linear functions are widely used in neural networks.
19.srt	00:20:19.840 --> 00:20:30.660	So, this vector that I get if I pass it through a non-linearity which is a threshold function my output becomes 0 0 0 1.
19.srt	00:20:30.700 --> 00:20:39.450	So, this threshold function is when the input is less than 0 the output should be equal to 0.
19.srt	00:20:40.620 --> 00:20:45.600	should be 0, if the input is greater than 0 then output will be 1.
19.srt	00:20:46.330 --> 00:20:51.070	So, in all these cases here it is minus 1.5 which is less than 0 obviously.
19.srt	00:20:51.070 --> 00:21:02.870	So, I will have an output 0, here here it is minus 0.5 again I will have an output 0, here it is minus 0.5 again I will have an output 0, here it is plus 0.5 which is greater than 0.
19.srt	00:21:02.870 --> 00:21:05.270	So, here I get an output equal to 1.
19.srt	00:21:05.270 --> 00:21:13.260	So, you find that this matrix multiplication followed by this threshold operations actually perform an AND operation.
19.srt	00:21:16.030 --> 00:21:20.620	which is a logical operation.
19.srt	00:21:20.620 --> 00:21:27.350	So, given this now how a neural network I can design a neuron to perform this particular task.
19.srt	00:21:28.800 --> 00:21:50.300	So, in case of neuron as it inputs the feature vectors and I say that the feature vectors are in inputted through the dendrites, one of the input I will put it as 1 because the feature vector x 1 x 2 we are converting that to 1 x 1 and x 2 .
19.srt	00:21:51.000 --> 00:21:57.250	we are adding an additional component and making that equal to 1 which is you know unified representation.
19.srt	00:21:57.960 --> 00:22:06.000	So, I have 1 over here, I have x 1 over here and I have x 2 over here which are my input vectors.
19.srt	00:22:07.200 --> 00:22:13.610	Then the weight vector I put it as minus 1.5 here it is 1 here it is 1.
19.srt	00:22:14.980 --> 00:22:20.820	So, this function of the neuron I can put it in two forms.
19.srt	00:22:21.750 --> 00:22:30.770	2parts, the first part computes W transpose X and what is this W transpose X?
19.srt	00:22:31.350 --> 00:22:36.930	W transpose X is nothing, but X 1 plus X 2 minus 1.5.
19.srt	00:22:36.930 --> 00:22:49.320	So, it becomes X 1 plus X 2 minus 1.5 and then the second part of the neuron that gives you the threshold function.
19.srt	00:22:55.230 --> 00:23:03.160	This threshold And, at the output what I get is function y is equal to f of W transpose X.
19.srt	00:23:03.920 --> 00:23:18.130	So, I can put this either in the form of W transpose X or I can also write it as W i x i, i varying from 0 to 2 and function of this.
19.srt	00:23:18.850 --> 00:23:24.950	And, in this particular case this function with these weight vectors will be an AND function.
19.srt	00:23:26.190 --> 00:23:38.920	So, this is one of the ways you find that I can implement an AND logic which I can pose as a classifier problem as a binary classifier problem with binary inputs.
19.srt	00:23:39.180 --> 00:23:47.170	So, we have two dimensional binary inputs x 1 and x 2 and that classifier can easily be implemented by a single neuron.
19.srt	00:23:47.170 --> 00:23:50.810	So, I do not need multiple number of neurons or a neural network for that purpose.
19.srt	00:23:51.360 --> 00:23:56.380	So, using a simple single neuron neuron having a threshold non-linearity.
19.srt	00:23:57.470 --> 00:23:59.600	can implement an AND logic.
19.srt	00:24:01.759 --> 00:24:09.620	In the same manner let us consider that whether I can have some other logical functions to be implemented in the same manner.
19.srt	00:24:11.280 --> 00:24:15.370	So, I consider here the other logical function which is an OR function.
19.srt	00:24:16.800 --> 00:24:25.650	Again in case of OR function I again consider the inputs to betwo-dimensional binary vectors having components x 1 and x 2.
19.srt	00:24:25.650 --> 00:24:31.460	So, my function will be if both one x 1 x 1 and x 2 then output should be 0.
19.srt	00:24:32.240 --> 00:24:32.269	So, I can 0.
19.srt	00:24:32.630 --> 00:24:43.170	In all other cases that is if the inputs areonly when x 1 and x 2 both of them are 0, then output should be 0 that is it belongs to one class.
19.srt	00:24:44.349 --> 00:25:01.960	And in all other cases that when x 1 x 2 is 0 1 or x 1 x 2 is 0 1 0 or x 1 x 2 is 1 1, then output should be equal to 1 indicating that these feature vectors belong to the other class.
19.srt	00:25:03.309 --> 00:25:18.940	Again, as before if I plot these feature vectors in the two dimensional feature space as given over here, you find that when x 1, x 2 both of them are 0 the output is 0.
19.srt	00:25:19.900 --> 00:25:22.359	In all other cases the output is 1.
19.srt	00:25:24.910 --> 00:25:28.240	Here again it becomes a linearly separable problem.
19.srt	00:25:36.130 --> 00:25:38.650	Again you can see that I can have multiple number of straight lines or infinite number of straight lines which separates these two different classes.
19.srt	00:25:39.740 --> 00:25:48.319	One of all these straight lines one of the straight lines is given by x 1 plus x 2 minus 0.5 which is equal to 0.
19.srt	00:25:48.319 --> 00:25:58.589	And here you can easily verify that both if both x 1 and x 2s are 0s then output becomes minus 0.5.
19.srt	00:25:58.589 --> 00:26:08.990	However, if any of or both x 1 and x 2 they are equal to 1 then output becomes output becomes plus 1.5.
19.srt	00:26:10.990 --> 00:26:19.109	clearly indicating that when it is 0 0 the output is negative in all other cases the output is positive ok.
19.srt	00:26:19.149 --> 00:26:27.599	So, when it when both x 1 and x 2 are 1 1 the output is 1.5, if one of them is 1 and the other one is 0 the output is 0.5.
19.srt	00:26:27.599 --> 00:26:30.730	However, in all these three cases the output is positive .
19.srt	00:26:30.730 --> 00:26:39.730	So, given this so, this becomes a simple linear classifier and when I have this simple linear classifier .
19.srt	00:26:41.740 --> 00:26:50.279	you find that a single straight line in this feature space can separate these two different classes.
19.srt	00:26:52.059 --> 00:26:54.259	How can I put it in the form of a neuron?
19.srt	00:26:54.609 --> 00:26:56.889	Can I how can I implement it in the form of a neuron?
19.srt	00:26:57.449 --> 00:27:12.299	So, here as we have shown before in the same manner I can do it as X transpose W where the matrix X is the matrix which is formed from all those two dimensional feature vectors .
19.srt	00:27:13.049 --> 00:27:20.309	W is the weight vector which indicates what is the separating planebetween the two different classes.
19.srt	00:27:20.529 --> 00:27:24.879	If I perform W transpose X, then this is the output vector that I get.
19.srt	00:27:25.189 --> 00:27:32.189	Again you pass through this threshold nonlinearity, so output becomes 0 1 1 1.
19.srt	00:27:32.559 --> 00:27:36.219	So, when my input vector is 0 0, output is 0.
19.srt	00:27:36.999 --> 00:27:43.249	When the input vector is 0 1, output is 1 1 0, again output is 1.
19.srt	00:27:43.709 --> 00:27:45.509	1 1 the output is 1.
19.srt	00:27:46.819 --> 00:27:50.499	So, this simple operation implements the OR logic.
19.srt	00:27:51.589 --> 00:27:53.869	And how do I implement it in neural network?
19.srt	00:27:54.219 --> 00:28:08.029	Again a very simple I put the input vector to be 1 x 1 x 2 and the weight vectors will be minus 0.5 1 1.
19.srt	00:28:08.419 --> 00:28:14.949	This neuron computes W transpose X .
19.srt	00:28:15.509 --> 00:28:30.749	x and I have this threshold nonlinearity which performs f of w transpose x, where this f is nothing but the threshold nonlinearity and at the output what I get is an OR function.
19.srt	00:28:31.969 --> 00:28:37.949	So, again you find that using a single neuron I can implement a OR function.
19.srt	00:28:39.249 --> 00:28:45.509	So, it has been possible to implement these logical functions using a single neuron.
19.srt	00:28:46.269 --> 00:28:56.259	because, the problem that have considered they are linearly separable problems, both and and or functions they are linearly separable.
19.srt	00:28:57.409 --> 00:29:11.049	But, if the problems becomes non separable what will be our situation and how we can solve those problems in neurons or neural networks that we will explain in our next lecture.
19.srt	00:29:11.859 --> 00:29:12.179	Thank you.
27.srt	00:00:00.610 --> 00:00:23.269	Hello, welcome to the online Certification course on Deep Learning.
27.srt	00:00:32.369 --> 00:00:38.500	So, we are discussing about the back propagation learning algorithms with some examples.
27.srt	00:00:39.549 --> 00:01:00.759	In the last class we have taken an example at the network level that is given a feed forward neural network, how to compute the error at the output node and then how do you propagate that error in the backward direction from output towards input layer.
27.srt	00:01:01.570 --> 00:01:01.670	layer.
27.srt	00:01:01.670 --> 00:01:09.090	And as you propagate the error from output layer to the input layer, how the weights in every layer areupdated.
27.srt	00:01:09.230 --> 00:01:27.469	The whole purpose of this back propagation algorithm and weight updation is that we want that output error that is the difference between the actual output that you get from the network and your target output that should be minimized.
27.srt	00:01:28.689 --> 00:01:31.750	So, in the previous class we have discussed this with respect to .
27.srt	00:01:32.150 --> 00:01:33.820	a network in the network level.
27.srt	00:01:34.760 --> 00:01:59.000	Today's lecture we will see that the same back propagation or the gradient propagation is applicable within a node itself because every element in a neural network is nothing, but a neuron or a node and within the node as the complexity of the node increases the node may also consist of a number of layers.
27.srt	00:01:59.360 --> 00:02:04.230	It is not necessarily that every node will compute in a single layer fashion.
27.srt	00:02:04.910 --> 00:02:16.600	So, I can have multiple layers within a node and today we will see that how this gradient can flow within a node from output of the node to the input of the node.
27.srt	00:02:17.830 --> 00:02:24.180	So, before we go into that let us just try to recapitulate what we have done in the previous class.
27.srt	00:02:25.670 --> 00:02:30.680	So, in the previous class we had taken a simple two layer neural network.
27.srt	00:02:31.580 --> 00:02:33.520	So, as is shown over here.
27.srt	00:02:34.350 --> 00:02:35.930	So, this neural network has .
27.srt	00:02:36.849 --> 00:02:48.120	an output layer having only two nodes and we also had an input layer which is also having two nodes that is node 1 and node 2.
27.srt	00:02:48.520 --> 00:02:55.750	In addition we had another node which gives you the bias term and we had an input layer.
27.srt	00:03:06.740 --> 00:03:23.099	So, this was the hidden layer and we had an input layer again consisting of two nodes because we had two dimensional feature vectors x 1 x 2, but the number of nodes in the in the input layer was also 3 because we wanted to augment these input vectors by an additional term by an additional component which is equal to 1 which takes care of the bias in every node.
27.srt	00:03:23.099 --> 00:03:27.290	And there we have seen that the error that you compute at the output.
27.srt	00:03:27.650 --> 00:03:37.469	So, we had an error energy which was given by half of say your actual output x g .
27.srt	00:03:37.930 --> 00:03:52.949	And, because this was a second layer, so we put it as x j 2 minus T j take the square of this and sum of this for j is equal to 1 to 2 .
27.srt	00:03:52.949 --> 00:03:58.280	So, that is the sum of squared error that you compute at the output.
27.srt	00:03:58.280 --> 00:04:07.170	And, you take the gradient of this with respect to the weights weights between the hidden layer and the output layer.
27.srt	00:04:08.200 --> 00:04:17.420	And, accordingly by gradient descent algorithm you go on updating the weights of thishidden layer to the output layer.
27.srt	00:04:18.590 --> 00:04:30.819	Then what we had seen is that whatever gradient that you get over here you remember one thing that we discussed about because this network is a multi layer network.
27.srt	00:04:39.009 --> 00:04:50.170	So, if my input is x I have a function say f 1 which works on x along with an weight matrix or set of weight values which are say w 1.
27.srt	00:04:52.400 --> 00:05:03.930	And this output this particular function is inputted to the next layer which computes say f 2 along with the corresponding weights w 2.
27.srt	00:05:05.590 --> 00:05:08.879	This again in turn inputted to the next layer.
27.srt	00:05:09.379 --> 00:05:17.139	which computes say f 3 along with the corresponding weights w 3 and this continues this goes on.
27.srt	00:05:18.540 --> 00:05:22.860	And this is the final output that we get assuming that it is a three layer network.
27.srt	00:05:23.439 --> 00:05:26.170	So, the output comes from the third layer which is f 3.
27.srt	00:05:27.100 --> 00:05:39.100	So, when I compute the error the error e is computed with respect to f 3 and our target output that is the target that we want to have.
27.srt	00:05:40.680 --> 00:05:51.110	So, here you find that this e or the error is actually available to f 3 or f 3 which is a function of let us call this argument as theta 3.
27.srt	00:05:53.900 --> 00:06:03.480	So, actually error is visible to theta 3, but error is not visible to which was output of the input layer which is a theta 1.
27.srt	00:06:04.780 --> 00:06:07.180	Similarly, this one I call as theta 2.
27.srt	00:06:09.800 --> 00:06:13.420	So, error is actually visible to theta 3, it is not visible to theta 1.
27.srt	00:06:14.069 --> 00:06:20.019	So, if I want to compute the gradient of error with respect to w 1, I cannot compute it directly.
27.srt	00:06:20.779 --> 00:06:45.949	So, what I have to do is, I have to compute the error with respect to theta 3gradient of error with respect to theta 3, then multiply that with the gradient of theta 3 with respect to theta 2, multiply that with the gradient of theta 2 with respect to theta 1, and multiply that with the gradient of theta 1 with respect to w. So, what I have to compute is if I want to compute del E.
27.srt	00:06:46.500 --> 00:06:57.089	say del W 1 let us put del W 1 ij because the W 1 over here is a matrix.
27.srt	00:06:58.560 --> 00:07:16.079	So, this will be del E del theta 3 into del E del theta 2 into sorry del theta 3 del theta 2 into del theta 2 .
27.srt	00:07:16.870 --> 00:07:26.020	1 into del theta 1 del W i j 1 .
27.srt	00:07:26.020 --> 00:07:45.980	So, here you find that this product that is del theta 3 del e del theta 3 into del theta 3 del theta 2 into del theta 2 del del theta 1, these are the gradients which are being back propagated from the output layer to this input layer.
27.srt	00:07:45.980 --> 00:07:47.040	And del theta 1.
27.srt	00:07:47.370 --> 00:07:50.820	del W ij 1 that is what is the local gradient.
27.srt	00:07:51.610 --> 00:08:01.700	So, to find out the gradient of the error with respect to W ij 1, I have two components.
27.srt	00:08:02.070 --> 00:08:09.480	One component is the propagated term which is this and the other component is the local gradient.
27.srt	00:08:10.610 --> 00:08:17.230	So, what we are doing is we are multiplying the propagated gradient with the local gradient to get the actual gradient.
27.srt	00:08:17.760 --> 00:08:17.970	ok.
27.srt	00:08:18.590 --> 00:08:41.590	So, this is the same concept which has been applied over here that whatever was gradient at the output the same gradient when it comes over here it is multiplied with the local gradient to find out how the error is propagated to the input side.
27.srt	00:08:49.100 --> 00:08:56.800	And you remember one more thing that every node in the hidden layer is feeding input to every node in the next layer and that input is fed through a corresponding weight value.
27.srt	00:08:56.950 --> 00:09:14.389	So, when we are propagating error or the gradient in the backward direction, the gradient which is propagated from here through this and the gradient which is propagated through this that will be weighted by the corresponding weight values and added over here.
27.srt	00:09:21.009 --> 00:09:27.620	And this summation is or the aggregate of the gradient which is collected at this hidden layer node, this is the total gradient which is available here through back propagation.
27.srt	00:09:28.330 --> 00:09:38.649	And this total gradient now has to be multiplied with the local gradient to find out what is the gradient of the output on this input weight.
27.srt	00:09:39.139 --> 00:09:45.700	And accordingly I have to adjust theseweight components and that is what we have discussed in our previous class.
27.srt	00:09:51.289 --> 00:09:55.080	So, now let us see that how the same concept x y into z.
27.srt	00:09:57.610 --> 00:10:01.500	So, this is a function that this node computes.
27.srt	00:10:02.889 --> 00:10:15.600	So, if I break or if I expand the particular node here in a hierarchical manner on or in a staged manner, how this node actually computes this function.
27.srt	00:10:16.080 --> 00:10:21.470	So, that every function is broken into a smaller primitive set of functions.
27.srt	00:10:23.000 --> 00:10:28.440	So, what I do is you find that there are a few hierarchical levels.
27.srt	00:10:29.500 --> 00:10:34.610	So, in the first level you compute x into y through a multiplier block.
27.srt	00:10:34.720 --> 00:10:43.289	So, this is a multiplier block which computes x into y, then I have an addition block which computes.
27.srt	00:10:53.399 --> 00:11:01.809	So, this intermediate variable x into y that is assigned to an intermediate variable say v, then I have a an adder block, f, which computes w plus x y or w plus v because v is the intermediate variable which is equal to x into y.
27.srt	00:11:03.129 --> 00:11:19.519	So, this w plus x y is assigned to another intermediate variable u and then finally, I compute f which is nothing but u into z or which is nothing but u into w plus x into y.
27.srt	00:11:20.750 --> 00:11:26.059	So, this is my total node structure and as we have discussed before.
27.srt	00:11:26.470 --> 00:11:32.290	that every back propagation learning algorithm is preceded by a forward pass.
27.srt	00:11:33.060 --> 00:11:59.170	The forward pass in which the functional value is computed or coming to a network layer given an input vector and whatever be the set of weights at different layers available at that point of time using that you go for a feed forward pass and in the feed forward pass you compute what is the output vector that you get.
27.srt	00:12:00.910 --> 00:12:05.930	And, this if this output vector matches with the target then I do not have any error.
27.srt	00:12:06.250 --> 00:12:17.009	So, that means, I do not have to go for back propagation, I do not have to I do not have anything to be adjusted because whatever output we get that is my desired output or the target output.
27.srt	00:12:18.040 --> 00:12:28.509	But in case of an error when the output does not match with the target then I have an error and the gradient of the error has to be back propagated for weight adjustment.
27.srt	00:12:30.870 --> 00:13:02.250	So, here I have to have a forward pass that means, whatever be the value of x y z and w using those values I have to compute what will be the value of f. And then if necessary that means, if the f that you get is not the desired value then I have an error and the gradient of that error has to be propagated in the backward direction for updation wherever it is required.
27.srt	00:13:04.180 --> 00:13:09.960	So, now let us see how this forward pass actually works.
27.srt	00:13:12.450 --> 00:13:17.750	So, to see how the forward pass works let us assign values to w x y and z.
27.srt	00:13:18.960 --> 00:13:28.670	So, we assume w has a value 5, x has a value 3, y has a value 2 and z has a value w z has a value 4.
27.srt	00:13:30.350 --> 00:13:34.110	So, accordingly you will have v which is equal to x into y.
27.srt	00:13:34.480 --> 00:13:44.509	that that gets a value 6, then u which is w plus v or in other words it is w plus x into y if you compute this it will be 11.
27.srt	00:13:45.530 --> 00:13:59.420	And then finally, f which is u into z or it is x w plus x y into z that will assume a value 44.
27.srt	00:14:05.710 --> 00:14:08.399	So, in the forward pass I get the output to be to have a value 44 right.
27.srt	00:14:09.710 --> 00:14:14.050	Now, let us see how the backward pass will work on this.
27.srt	00:14:37.440 --> 00:15:04.230	So, to work on backward pass see what I want to find out is what is the sensitivity of output f sensitivity of f on W, I want to compute what is what is the sensitivity of f on X what is the sensitivity of f on y, what is the sensitivity of f on z or in other words if I need any correction on f suppose my desired value of f was something like 33 whereas, I am getting a value of f which is 44 that means, value of f has to be reduced.
27.srt	00:15:06.019 --> 00:15:08.519	So, in order to reduce the value of f.
27.srt	00:15:09.170 --> 00:15:09.200	valuey.
27.srt	00:15:09.480 --> 00:15:19.440	Whether I should increase value of W or I should also reduce value of W?, whether I should increase value of X or I should reduce value of X?
27.srt	00:15:19.879 --> 00:15:24.480	Whether I should increase value of Y or I should reduce value of Y?
27.srt	00:15:24.759 --> 00:15:28.810	Whether I should increase value of Z or I should reduce value of Z?
27.srt	00:15:29.920 --> 00:15:40.270	that is what is the sensitivity of f on W or on X or on y or on z and this is what I need.
27.srt	00:15:41.270 --> 00:15:55.530	I do not need how f varies with u or how f varies with v that is not my concern, but my concern is how f varies with w x y and z .
27.srt	00:15:55.530 --> 00:16:10.960	But I cannot directly compute del f del w or del f del x the reason being f is not directly visible to w, f is not directly visible to x, f is not visible directly visible to y .
27.srt	00:16:12.030 --> 00:16:16.930	But, yes I can compute del f del z because f is directly visible to z.
27.srt	00:16:18.490 --> 00:16:28.240	So, now, let us see that how this gradient in this case in the backward direction can be computed again using the chain rule.
27.srt	00:16:29.950 --> 00:16:41.480	So, for doing this I assume say what the gradient that you get at the output is say 1, then assuming this how it is propagated.
27.srt	00:16:41.870 --> 00:16:55.820	f del f del w. And as we said because f is not directly visible to w, so I cannot really compute del f w del f del w directly.
27.srt	00:16:56.300 --> 00:17:00.440	So, for doing this I have to make use of the chain rule.
27.srt	00:17:01.399 --> 00:17:12.150	So, I have to make use of what is del f del u in this case that has to be multiplied by what is del u del.
27.srt	00:17:12.579 --> 00:17:24.899	w. So, this is what I was saying that del f del u is the back propagated gradient up to this point and del u del w is the local gradient.
27.srt	00:17:25.799 --> 00:17:42.669	So, you multiply the back propagated gradient with the local gradient to get what is del f del w. Now similarly over here I have to compute del f del v, but I cannot compute it directly because f is not .
27.srt	00:17:42.940 --> 00:17:55.569	to V. So, what I will compute is I will compute del f del u and then multiply with del u del v .
27.srt	00:18:13.209 --> 00:18:20.089	So, that is what gives me the sensitivity of V sensitivity of f with respect to V or the gradient of f with respect to V. Again over here when I compute del f del x, first I have to compute what is f del v and then I have to compute what is del v del x .
27.srt	00:18:20.859 --> 00:18:41.459	Similarly, over here I have to compute to in order to find out del f del y I have to compute what is del f del v and then multiply that with del v del y right.
27.srt	00:18:41.459 --> 00:18:42.909	So, here you find that .
27.srt	00:18:43.949 --> 00:18:55.149	your del f del u is equal to z and what is del u del w you come over here del u del w is equal to 1 right.
27.srt	00:18:55.589 --> 00:19:00.759	So, this will be simply the value of del f del u which is nothing but z.
27.srt	00:19:03.669 --> 00:19:06.519	Come over here what is del f del v?
27.srt	00:19:06.819 --> 00:19:14.659	Del f del v is del f del u into del u del v and what is del f del u?
27.srt	00:19:14.889 --> 00:19:28.079	del u is equal to z and what is del u del v right del u del v here you find that del u del v is again equal to 1.
27.srt	00:19:28.989 --> 00:19:32.449	So, this value will simply be equal to z again.
27.srt	00:19:34.369 --> 00:19:42.219	Coming over here del f del x equal to del f del v into del v del x and del v del x is nothing but y.
27.srt	00:19:42.929 --> 00:19:45.359	So, del f del x will be y into z.
27.srt	00:19:45.889 --> 00:19:48.169	So, this will be equal to y into z.
27.srt	00:19:50.159 --> 00:19:58.939	Similarly here as del f del v is equal to z and del v del y del v del y is equal to x.
27.srt	00:19:59.139 --> 00:20:04.189	So, this will be x into z .
27.srt	00:20:04.189 --> 00:20:18.089	So, you find that finally, following this back propagation and the chain rule I find I can find out what is del f del x, I can find out what is del f del y, I can find out what is del f del z, I can also find out what is del f del w .
27.srt	00:20:21.029 --> 00:20:30.859	So, let us see that how we can implement this in modern programming languages.
27.srt	00:20:31.639 --> 00:20:41.999	I will just put this because this is the kind of structureor the constructs which are given by modern languages meant for deep learning or machine learning implementations.
27.srt	00:20:43.289 --> 00:20:47.089	So, first what you do is you set the input values.
27.srt	00:20:47.449 --> 00:20:48.179	So, you find .
27.srt	00:20:48.739 --> 00:20:56.209	values we had set earlier was W is equal to 5 equal to x equal to 3, y is equal to 2 and z equal to 4.
27.srt	00:20:57.579 --> 00:21:00.299	Then what we have done is we have computed the forward pass.
27.srt	00:21:01.289 --> 00:21:09.159	In the forward pass V is equal to x into y, then u is equal to W plus V and then f is equal to u plus z.
27.srt	00:21:10.269 --> 00:21:15.279	So, this is what we are computing in the forward pass and then you have backward pass.
27.srt	00:21:15.989 --> 00:21:18.569	So, in the backward pass as we as we have .
27.srt	00:21:18.849 --> 00:21:26.319	seen earlier that you see what we have done in the backward pass.
27.srt	00:21:26.319 --> 00:21:38.529	Firstly, we have to compute del f del u, I have to compute del f del z and then following the chain rule finally I have to get what is del f del w, what is del f del x, del f del y and so on.
27.srt	00:21:40.319 --> 00:21:48.919	So, in the same manner here you find out what is del f del u which is nothing but z and del f del z which becomes equal to .
27.srt	00:21:49.479 --> 00:21:54.129	f del v into del v del x, where del v del x is equal to y right.
27.srt	00:21:54.129 --> 00:22:06.709	So, you simply come over here you can look over here that del v del x is equal to y.
27.srt	00:22:06.709 --> 00:22:22.119	So, that gives me del f del x or d f d x is equal to y times d f d v and in the same manner d f d y becomes x times d f d v. So, after this .
27.srt	00:22:23.539 --> 00:22:42.449	Now, we are ready with the sensitivity computation of sensitivity of the output with respect to the inputs to the node ok. And the kind of graph that we have computed this is what is known as computational graph.
27.srt	00:22:43.789 --> 00:22:53.289	So, all these which are shown in red over here they tell you that what is the sensitivity of f with respect to z.
27.srt	00:22:53.659 --> 00:23:02.629	what is the sensitivity of f with respect to w, the sensitivity of f with respect to x and sensitivity of output with respect to y.
27.srt	00:23:04.409 --> 00:23:05.259	So, how does it help?
27.srt	00:23:05.929 --> 00:23:07.149	Why we are doing all this?
27.srt	00:23:07.659 --> 00:23:18.079	One is we know that given a complicated function how it can be broken into simpler functions to give you a complete node function.
27.srt	00:23:18.629 --> 00:23:26.599	And then how we can write the back propagation algorithm as well as the feed forward algorithms using the modern .
27.srt	00:23:27.599 --> 00:23:33.959	deep learning languages programming deep learning tools that we have right.
27.srt	00:23:34.689 --> 00:23:41.209	So, this is simply same computation with the examples that we have shown earlier.
27.srt	00:23:41.679 --> 00:23:54.879	So, here you find that your del f del w actually tells you that how f varies with w. So, if I increment w by say small amount say for example, 0.001.
27.srt	00:23:54.879 --> 00:24:00.509	So, we had fed input w to be 5, now we make w to be 5.005.
27.srt	00:24:03.109 --> 00:24:23.869	And, as a result you find that f has increased in initially value of f was 44, now f has increased to 44.004 that says that by whichever amount we have incremented w f has been incremented by 4 times of that.
27.srt	00:24:23.869 --> 00:24:33.419	That means, if I want to reduce w by varying reduce f by varying w then w has to be incremented and the same thing becomes true.
27.srt	00:24:34.009 --> 00:24:36.389	with all x y and z.
27.srt	00:24:37.879 --> 00:24:52.439	And this graph is what is known as a computational graph and now you find that what is the use of the computational graph or how the computational graph helps you in writing such back propagational problems right.
27.srt	00:24:54.589 --> 00:25:05.479	We have few more examples in the same manner, but I tell you that simple some simples that circuits elementary circuits.
27.srt	00:25:06.099 --> 00:25:15.719	using which you form or you design the complicated nodes, one is add, one is multiply and otherwise max .
27.srt	00:25:15.719 --> 00:25:36.929	So, in the back propagation the multiply operation as we have seen before that if the output is say product x into y, then in the back propagation if the gradient up to this output is g, what you pass to the side of x is actually g into y .
27.srt	00:25:37.619 --> 00:25:40.829	and what you pass to the side of y is actually g into x.
27.srt	00:25:42.009 --> 00:25:49.659	Similarly, if it is summation node, then whatever is the gradient at the output side, it is simply copied to both the inputs.
27.srt	00:25:51.409 --> 00:26:02.509	Similarly, if it is max, then whatever is the gradient at the output, the gradient is simply passed to the node of the variable which has maximum value.
27.srt	00:26:02.739 --> 00:26:08.299	So, if x was maximum of the two x and y, gradient g was passed towards x.
27.srt	00:26:08.589 --> 00:26:11.619	If y was maximum, then gradient g would have to be maximum.
27.srt	00:26:11.809 --> 00:26:12.749	passed to y.
27.srt	00:26:14.269 --> 00:26:27.759	And using this we can havewe can represent complicatednode functions using simpler partial differentiation or gradient operations.
27.srt	00:26:28.929 --> 00:26:40.629	And that helps us to writethe functions in a much simpler way and that helps ultimately helps us to code the complicated functions.
27.srt	00:26:43.689 --> 00:27:11.609	I will So, this is the same thing I will just skip thatthis is again an example using that multiply add and max operation and we hadyou can easily verify that how the forward passinformation is propagated from input to output to get the final output and then in the backward pass we can compute the gradients following the same gradient descent procedure.
27.srt	00:27:15.289 --> 00:27:23.079	And, I want to emphasize one more point over here that in every case the gradient computation at a node is highly local in nature.
27.srt	00:27:24.039 --> 00:27:43.569	As long as your gradient till the previous nodeprevious layer is computed and that is fed to the current layer, in the current layer you can make use of the gradient which has been propagated to current layer and all the computations in the current layer are highly parallel in nature.
27.srt	00:27:43.739 --> 00:27:50.099	The computation of gradient of one node in the current layer is independent of the gradient computation in the other node.
27.srt	00:27:50.829 --> 00:27:57.809	So, as a result this entire function can be implemented in a parallel machine.
27.srt	00:27:57.889 --> 00:28:05.519	If I have a parallel machine then all the gradient computations or the back propagation learning can be implemented using parallel operations.
27.srt	00:28:06.619 --> 00:28:17.529	So, I will stop here today and as we said now onwards I will not consider the gradient learning anymore or the gradient propagation or back propagation learning anymore.
27.srt	00:28:17.579 --> 00:28:24.069	For any application subsequently I will simply use the term that the machine is turned is learnt.
27.srt	00:28:24.219 --> 00:28:28.609	or trained using back propagation algorithm ok.
27.srt	00:28:28.989 --> 00:28:29.319	Thank you.
26.srt	00:00:00.610 --> 00:00:28.640	Hello, welcome to the NPTEL online certification course on deep learning.
26.srt	00:00:32.759 --> 00:00:41.289	You remember in the previous class we were discussing about the back propagation learning with respect to some examples.
26.srt	00:01:02.359 --> 00:01:23.780	So, what I wanted to do is I wanted to explain how the back propagation learning algorithm works with the help of example to have a clear understanding of the back propagation learning and the point till which we completed was this that when you go for back propagation of the error at the output layer that means, now I want to update the weight vectors connecting the nodes from the hidden layer to the output layer.
26.srt	00:01:24.039 --> 00:01:31.019	The example that we are considering is a two layer neural network or two layer feed forward neural network.
26.srt	00:01:33.190 --> 00:01:40.230	So, when you go for updation of the connection weights as the error can be computed only at the output.
26.srt	00:01:40.230 --> 00:01:53.240	I cannot compute an error at the output of the any of the hidden layer nodes because I do not know what are the targets or what are the target vectors at the outputs of the hidden layer nodes.
26.srt	00:01:54.189 --> 00:02:03.530	But given the class belongingness of the training vector I have what is or I know what should be my target output.
26.srt	00:02:04.380 --> 00:02:11.420	So, any deviation of the output that you get from the network from the target output that is my error.
26.srt	00:02:11.820 --> 00:02:23.819	So, the back propagation learning algorithm tries to adjust the weight vectors, so that the error is reduced or the error is minimized and for that you start from the output layer node.
26.srt	00:02:24.780 --> 00:02:34.650	So, in the previous class what we have discussed is that how do you adjust the weights at the output layer nodes using .
26.srt	00:02:35.210 --> 00:02:49.030	the error information or by back propagating the derivative of the error information with respect to the weightvectors or the weight components from the hidden layer node to the output layer node.
26.srt	00:02:50.270 --> 00:02:57.840	So, for that we had defined these various terms as is shown in this particular diagram .
26.srt	00:02:57.910 --> 00:03:08.530	Now, you also remember that in the forward pass we have computed the outputs of every node in the hidden layer .
26.srt	00:03:09.070 --> 00:03:14.580	layer, we have also computed the outputs of every node in the output layer.
26.srt	00:03:14.810 --> 00:03:17.620	In fact, that is from there only I know what is my error.
26.srt	00:03:19.160 --> 00:03:35.210	So, the outputs of the nodes in the hidden layer are as given here that x 1 1 is 0.92.
26.srt	00:03:36.690 --> 00:03:38.740	So, this is x 1 1.
26.srt	00:03:38.990 --> 00:03:42.020	1 1 which is the output of the hidden layer node.
26.srt	00:03:43.500 --> 00:03:52.219	And similarly x 2 1 which is output of the second node in the hidden layer is 0.27.
26.srt	00:03:52.340 --> 00:04:02.129	And I said that I cannot compute the error in the hidden layer because though I know from the forward pass that what are my outputs, but I do not know what are the targets right.
26.srt	00:04:02.580 --> 00:04:05.030	So, I cannot compute error in the hidden layer.
26.srt	00:04:06.160 --> 00:04:11.200	And in the same manner I have computed output of the output layer nodes.
26.srt	00:04:11.930 --> 00:04:31.050	So, this is my x 1 2 that is the output of the first node in the output layer which is 0.44 and 0.95 is x 2 2 which is the output of the second node in the output layer.
26.srt	00:04:31.050 --> 00:04:39.780	And we also said that the vector 0.7, 0.1, 0.2 that we considered this vector is taken from category 1.
26.srt	00:04:39.819 --> 00:04:43.900	So, as a result my target is nothing but 1, 0.
26.srt	00:04:46.600 --> 00:04:49.910	This is my target vector, but this is the actual vector that I got.
26.srt	00:04:50.960 --> 00:04:56.100	So, the difference between the target vector and the actual vector that gives me an error.
26.srt	00:04:56.790 --> 00:05:01.920	And by using the backward learning mechanism we have to reduce or minimize this error.
26.srt	00:05:01.980 --> 00:05:14.200	That means, this output should be as close as possible to the target output and that is what we are doing using the backward learning algorithm.
26.srt	00:05:14.200 --> 00:05:15.940	So, now let us see.
26.srt	00:05:15.940 --> 00:05:17.630	So, as we have seen before that.
26.srt	00:05:18.060 --> 00:05:21.000	how this backward learning algorithms.
26.srt	00:05:21.300 --> 00:05:29.650	So, I need to compute these terms del J 2 that is for J equal to 1 and 2.
26.srt	00:05:29.710 --> 00:05:35.660	So, I have to compute del 1 2 x 1 1.
26.srt	00:05:36.130 --> 00:05:46.470	So, for various combinations of J and I, I have to compute this derivative of E with respect to the connection weights.
26.srt	00:05:47.220 --> 00:05:48.170	And for this.
26.srt	00:05:49.010 --> 00:05:53.080	j I compute delta 1 2.
26.srt	00:05:53.870 --> 00:06:01.510	So, delta 1 2 is nothing, but x 1 2 into 1 minus x 1 2 into x 1 2 minus t 1.
26.srt	00:06:02.920 --> 00:06:19.250	And as we have just seen that what is my x 1 2, x 1 2 is 0.44 as is obvious from here, x 1 2.
26.srt	00:06:19.880 --> 00:06:22.860	is 0.44 and x 2 2 is 0.95.
26.srt	00:06:22.860 --> 00:06:52.280	So, by using this I go for this computation that delta 1 2 is equal to x 1 2 into 1 minus x 1 2 into x 1 2 minus t 1, x 1 2 is 0.44 and t 1 is 1 because the input vector that I am considering I am considering that to belong to plus 1.
26.srt	00:06:52.280 --> 00:06:53.490	So, t 1 equal to 1.
26.srt	00:06:54.970 --> 00:07:04.380	So, as a result when you compute this delta 1 2 it simply becomes minus 1.38 just this computation will give you.
26.srt	00:07:04.380 --> 00:07:14.910	And in the same manner when I compute delta 2 2 which is x 2 2 into 1 minus x 2 2 into x 2 minus t 2.
26.srt	00:07:14.910 --> 00:07:23.620	So, you remember that my x 2 2 was 0.95 and t 2 is equal to 0 because the input vector belongs to class.
26.srt	00:07:24.700 --> 00:07:25.200	1.
26.srt	00:07:25.520 --> 00:07:30.060	So, my T 1 is 1 in the target vector and T 2 is 0 in the target vector.
26.srt	00:07:31.080 --> 00:07:40.750	So, accordingly as X 2 2 is equal to 0.95, when I compute delta 2 2 delta 2 2 comes out to be 0.045.
26.srt	00:07:41.050 --> 00:07:54.810	So, simply by gradient descent algorithm the updated delta 1 1 2 is nothing, but delta 1 1 2 .
26.srt	00:07:56.530 --> 00:08:11.270	minusthe updated W 1 1 2 is nothing, but W 1 1 2 minus some eta times del E del W 1 1 2.
26.srt	00:08:12.280 --> 00:08:18.050	And as I have computed delta 1 2 as minus 0.138.
26.srt	00:08:18.050 --> 00:08:27.820	So, del E del W 1 1 2 it is simply delta 1 2 into x 1 1.
26.srt	00:08:28.600 --> 00:08:32.940	1 that is the output of the first node in the hidden layer that is x 1 1.
26.srt	00:08:33.750 --> 00:08:46.540	So, del E del W 1 1 2 which is delta 1 2 into x 1 1 which is nothing but minus 0.126.
26.srt	00:08:46.540 --> 00:08:48.670	So, what is x 1 1?
26.srt	00:08:48.670 --> 00:08:58.760	Again x 1 1 we have computed in the forward pass as you see from here that x 1 1 is nothing but .
26.srt	00:08:59.640 --> 00:09:04.940	this value 0.92 and x 2 1 is 0.27.
26.srt	00:09:05.070 --> 00:09:09.720	So, using these values I am computing these quantities.
26.srt	00:09:09.720 --> 00:09:24.520	So, this del E del W 1 1 2 is delta 1 2 delta 1 2 is minus 0.138 multiplied by x 1 1 that gives you minus 0.126.
26.srt	00:09:29.270 --> 00:09:38.370	And in the same manner e del W 1 2 2 which is delta 2 2 times X 1 1 which becomes 0.04.
26.srt	00:09:38.370 --> 00:10:00.950	So, as a result the updated weights that is W 1 1 2 which is the connection weight from the first node in the hidden layer to the first node in the output layer that simply becomes W 1 1 2 plus eta which is a hyper parameter indicating the learning rate.
26.srt	00:10:01.970 --> 00:10:04.180	eta times 0.126.
26.srt	00:10:04.180 --> 00:10:09.270	You find that del E del W 1 1 2 was negative.
26.srt	00:10:09.270 --> 00:10:22.780	My learning algorithm the or updation rule is actually W 1 1 2 minus eta times del E del W 1 1 2 as W 1 1 2 is negative.
26.srt	00:10:22.780 --> 00:10:31.130	So, this del E del W 1 1 2 absolute value of that is being added to W 1 1 2.
26.srt	00:10:33.730 --> 00:10:45.910	Similarly, W 1 2 2 which is the connection weight from the first node in the hidden layer to the second load of the output layer that becomes W 1 2 2 minus eta times 0.04.
26.srt	00:10:45.910 --> 00:11:03.050	Now, you note an interesting point over here that is after updation W 1 1 which is the connection weight from first node in the hidden layer to the first node in the output layer that is being increased.
26.srt	00:11:04.700 --> 00:11:12.660	Whereas, the connection weight from the first node in the hidden layer to the second node in the output layer is being decreased.
26.srt	00:11:14.890 --> 00:11:27.320	And you remember that my target vector was 1 0, whereas the output that actually I have obtained after this forward pass is 0.44 and 0.95.
26.srt	00:11:35.850 --> 00:11:43.970	So, that clearly says that I should update the weights in such a way that the first component 1 2 is the connection weight from the same hidden layer node which is the first node in the hidden layer to the second node in the output layer.
26.srt	00:11:45.110 --> 00:11:57.380	So, if I increase W 1 1 then effectively I am adding more values to the output of W 1 to the output of the first node in the output layer.
26.srt	00:11:59.050 --> 00:12:08.080	And if I reduce W 1 2 as this is waiting at this as this is multi being multiplied with the output of the first node in the hidden layer.
26.srt	00:12:08.470 --> 00:12:10.310	So, the effective contribution.
26.srt	00:12:11.260 --> 00:12:19.930	as the weight is reduced effective contribution to the output of the second node ofthe output layer that is being reduced.
26.srt	00:12:41.570 --> 00:12:44.470	So, effectively what we are trying to do is we are trying to increase by doing this we are trying to increase this value this is we are trying to increase and this value we are trying to reduce that means, we are trying to move more our target vectors.
26.srt	00:12:46.670 --> 00:12:49.340	So, this is how it is done in the output layer.
26.srt	00:12:51.110 --> 00:13:12.740	Similarly, in the same manner I can compute what is W 2 1 or the updation of W 2 1 2 that means, the connection weight from the second node second node of the hidden layer to the first node in the output layer this is what is .
26.srt	00:13:13.200 --> 00:13:23.480	W 2 1 2 and also W 2 2 2 which is the connection weight from the second node in the hidden layer to the second node in the output layer.
26.srt	00:13:24.230 --> 00:13:43.570	So, in the same manner by computing this delta 1 2 I can and delta 2 2 and making use of the outputs of the previous layer nodes or hidden layer nodes I can compute what is del E.
26.srt	00:13:43.759 --> 00:13:50.529	W 2 1 2, I can also compute what is del E del W 2 2 2.
26.srt	00:13:51.450 --> 00:14:02.840	And here again you find that del E del W 2 1 2 comes out to be negative which is minus 0.037.
26.srt	00:14:03.190 --> 00:14:16.710	And also del E del W 2 2 2 that is the connection weight from the second node in the hidden layer to the second load to the output layer that is also positive.
26.srt	00:14:19.200 --> 00:14:26.850	So, the connection weight to the first node in the output layer is negative, connection weight to the second node of the output layer is positive.
26.srt	00:14:27.400 --> 00:14:39.770	That means, when you go for weight updation W 212 will be incremented by a factor by a value which is eta times 0.037.
26.srt	00:14:40.420 --> 00:14:46.450	This is the amount which will be added to W 212.
26.srt	00:14:52.690 --> 00:15:00.320	And similarly, when you update W 222, you eta times 0.012 will be subtracted from W 2 2 2.
26.srt	00:15:00.320 --> 00:15:08.770	That means, the value of W 2 2 2 will be reduced whereas, value of W 2 1 2 will be increased.
26.srt	00:15:08.800 --> 00:15:14.780	So, this is a vector which will be increased whereas, this is a vector which will be reduced.
26.srt	00:15:14.780 --> 00:15:22.760	So, again as we have explained before that this increment of W 2 1.
26.srt	00:15:23.530 --> 00:15:39.090	And, reduction of W 2 2 tries to make the output of the first node higher and the output of the second node lower and that is what we should do to reach our target vector which is 1 0.
26.srt	00:15:41.240 --> 00:15:54.050	In the same manner the bias term bias is nothing but W 0 1 2 which is the bias of the first node in the second layer.
26.srt	00:15:54.430 --> 00:16:01.600	or in the output layer and W 0 2 2 this is the bias of the second node in the output layer.
26.srt	00:16:03.400 --> 00:16:20.380	So, in the same manner you find that del E del W 0 1 2 that is also negative that is minus 1.38 and del E del W 0 2 2 that is positive which is 0.045.
26.srt	00:16:20.690 --> 00:16:24.140	So, all these values will come based on .
26.srt	00:16:24.690 --> 00:16:26.950	the computations that we have done in the forward pass.
26.srt	00:16:28.129 --> 00:16:37.750	So, this also says the bias term that is W 0 1 once it is updated, it will be incremented by an amount eta times 1.38.
26.srt	00:16:37.750 --> 00:16:45.490	Whereas, W 0 2 2 will be decremented by amount eta times 0.45.
26.srt	00:16:55.530 --> 00:17:08.480	So, this again tries to increase the output of the first node of the output layer and tries to reduce the output of the second node of the output layer because W 0 1 is being incremented by eta times 1.38 whereas, W 0 2 is reduced by 0.045 ok.
26.srt	00:17:08.720 --> 00:17:17.950	So, this is how the nodes in the or the weights in the output layer will be updated.
26.srt	00:17:17.950 --> 00:17:28.340	And while doing so we have propagated the effect of error computed at the output in the backward direction.
26.srt	00:17:30.850 --> 00:17:39.250	Now, this error has to be propagated further inside to update the weights from the input layer to the hidden layer.
26.srt	00:17:40.740 --> 00:17:48.770	And when you do that you find that coming to a particular node you are propagating the weight from the first node you are also propagating the weight from the second node.
26.srt	00:17:49.780 --> 00:17:54.890	So, these twopropagating the error from the first node and propagating error from the second node.
26.srt	00:17:59.580 --> 00:18:08.360	So, these two error terms are to be added together to consider what is the total back propagated error term at every node in the hidden layers.
26.srt	00:18:08.360 --> 00:18:33.180	So, for that again we have seen before that how this is done we had defined an additional term if you remember that when we discussed about the back propagation algorithm that for every kth layer node we have defined an back propagated error term which is given by delta i k.
26.srt	00:18:34.070 --> 00:18:40.410	i k which was o i k sorry in this particular case our we are considering o i to be x i.
26.srt	00:19:04.970 --> 00:19:06.970	So, please read this as o i has to be x i o i k has to be x i k. So, please read this as x i k. So, my delta i k will be x i k into 1 minus x i k into sum of delta j k plus 1 W ij k plus 1.
26.srt	00:19:07.190 --> 00:19:19.100	So, you remember that this W ij k plus 1 is the connection weight from the ith node in the kth layer to the jth node in the k plus 1 layer.
26.srt	00:19:20.850 --> 00:19:27.780	And this delta j k plus 1 is the error term which is propagated up to the jth node of the k plus 1 layer.
26.srt	00:19:28.450 --> 00:19:34.200	So, this is being weighted by the corresponding weight and you are adding them together.
26.srt	00:19:35.740 --> 00:19:40.640	So, to consider to find out what is the propagated error at the ith node.
26.srt	00:19:41.330 --> 00:19:55.450	And for doing this all the nodes to which the ith node has fed the input that means, all the j s from all of them now you are accumulating the error by weighting them by the corresponding connection weight and adding them together.
26.srt	00:19:57.340 --> 00:20:04.400	And then multiplying that with a local derivative, local derivative of the output of the ith node.
26.srt	00:20:04.860 --> 00:20:08.950	which is x i k into 1 minus x i k right.
26.srt	00:20:10.170 --> 00:20:21.130	So, once you have this you define it with respect to k. Now, this k in our case because we are considering a two layer network the value of k is equal to 1.
26.srt	00:20:21.500 --> 00:20:33.620	So, what we have to find out is what is delta i 1 and as per this definition this delta i 1 is nothing, but x i 1 into 1 minus x i 1.
26.srt	00:20:36.230 --> 00:20:39.480	So, this x i 1 is the output of the ith node in the hidden layer.
26.srt	00:20:41.920 --> 00:20:56.320	So, this x i 1 into 1 minus x i 1 into sum of all the back propagated errors from all the nodes to which the ith node has fed the input.
26.srt	00:20:56.350 --> 00:20:58.840	So, that is what gives us delta i 1.
26.srt	00:21:00.010 --> 00:21:08.050	So, given this and all the pre computed values all the computed values that we have computed during the forward pass, I can find out what is delta 1 1.
26.srt	00:21:08.490 --> 00:21:11.319	1, because I know what is x 1 1 from the forward pass.
26.srt	00:21:12.390 --> 00:21:26.269	I know what is delta 1 1 2, I know what is delta 1 1 1 2 2, because that is what we had initialized or in any intermediate stage in any step of our iteration these are the updated weights those are also known.
26.srt	00:21:27.259 --> 00:21:36.120	I also know what is delta 1 2 that is the back propagated error from the next node, the nodes in the next layers.
26.srt	00:21:37.340 --> 00:21:39.670	Similarly, I also know what is delta 2 2.
26.srt	00:21:39.799 --> 00:21:44.879	1 that is the what is the back propagated error up to again unknown in the next layer.
26.srt	00:21:45.649 --> 00:21:54.970	So, if you compute this you will find that delta 1 1 1 delta 1 1 that comes out to be 0.24.
26.srt	00:21:55.149 --> 00:22:04.839	And in the same manner you will find that delta 2 1 that comes out to be minus 0.02 right.
26.srt	00:22:04.980 --> 00:22:09.379	So, these are the back propagated errors.
26.srt	00:22:11.460 --> 00:22:15.750	to the first node in the hidden layer and to the second node in the hidden layer.
26.srt	00:22:16.000 --> 00:22:24.069	So, this is the back propagated error to the first node in the hidden layer and this is the back propagated error to the second node in the hidden layer.
26.srt	00:22:25.149 --> 00:22:36.940	So, using this now I can go for updation of the weight vectors from the input layer nodes to the hidden layer nodes.
26.srt	00:22:37.889 --> 00:22:43.019	So, how do I do it?
26.srt	00:22:43.209 --> 00:22:49.769	by using the same expressions your del E del W 1 1 1.
26.srt	00:22:49.769 --> 00:22:52.740	What is del W 1 1 1?
26.srt	00:22:53.319 --> 00:23:02.949	It is the connection weight from the first node, the connection weight from the first node in the input layer to the first node in the hidden layer.
26.srt	00:23:03.119 --> 00:23:04.889	So, that is W 1 1 1.
26.srt	00:23:05.279 --> 00:23:05.990	So, this is the one.
26.srt	00:23:07.199 --> 00:23:14.399	So, I can compute del E del W 1 1 1 as delta 1 1.
26.srt	00:23:14.750 --> 00:23:17.369	times x 1 0, what is x 1 0?
26.srt	00:23:17.719 --> 00:23:23.879	x 1 0 is supposed to be the output of the first node in the 0th layer.
26.srt	00:23:25.149 --> 00:23:36.259	And in our case in this case the 0th layer is the input layer and what we said earlier is that every node in the input layer gives you an identity function.
26.srt	00:23:36.619 --> 00:23:40.240	That means, whatever is the input it simply passes that to the output.
26.srt	00:23:46.749 --> 00:23:55.739	So, this x 1 0 is nothing but the first component of the input vector which is x 1 because that is the input vector the first component of the input vector.
26.srt	00:23:56.439 --> 00:24:01.619	So, this first component of the input vector if you remember we considered that to be 0.7.
26.srt	00:24:01.619 --> 00:24:10.659	So, my input vector was 0.7 and 1.2 that was the input vector.
26.srt	00:24:17.129 --> 00:24:28.969	So, using this I can compute what is del E del W 1 1 1, I can compute what is del E del W 2 1 1 which comes out to be minus 0.014.
26.srt	00:24:49.179 --> 00:25:03.479	I can compute what is del E del W 2 1 1 which comes out to be 0.288, I can compute del E del W 2 2 1 which comes out to be minus 0.24, I can compute what is del E del W 2 011, now del 011 del E del W 011, W 011 if you remember it is representing the bias of the first node in the input layer.
26.srt	00:25:05.229 --> 00:25:15.279	So, which comes out to be again 0.24, I can also compute del E del W 021, W 021 is the bias to the second node.
26.srt	00:25:15.279 --> 00:25:22.719	So, I can also compute del E del W 021 which comes out to be minus 0.02 .
26.srt	00:25:23.749 --> 00:25:43.259	And, once once I compute all these my updation rule weight updation rule is as before del ij 1 getsW ij 1 simply gets W ij 1 minus eta times del E del W ij 1 right.
26.srt	00:25:43.589 --> 00:25:54.159	So, you find that by forwarding the backward direction by back propagation of the error terms from the output layer.
26.srt	00:25:55.119 --> 00:26:02.659	layer, I can update the weight vectors even in between the hidden layers and this can proceed further.
26.srt	00:26:02.939 --> 00:26:20.359	So, instead of two layer network if I take a three layer network again the error will be propagated from the second hidden layer to the first hidden layer and it can be used in a similar similar manner for multi layer networks.
26.srt	00:26:22.299 --> 00:26:29.299	So, here you find that what we have done we have just illustrated with the help of examples that in the network layer.
26.srt	00:26:29.739 --> 00:26:39.669	at the network level how the back propagation algorithm is can be implemented to update the weight vectors.
26.srt	00:26:40.769 --> 00:26:52.329	And, you find that when you use this back propagation algorithm the values that you are using at every layer are actually computed in the forward layeractually computed in the forward pass.
26.srt	00:26:53.169 --> 00:27:01.279	So, it will be wise if you save all the values that you have computed in the forward pass for reducing the computation.
26.srt	00:27:01.769 --> 00:27:03.279	during the back propagation learning work.
26.srt	00:27:04.139 --> 00:27:10.809	And each of these works that you have done that independent every node is independent of the other nodes.
26.srt	00:27:10.809 --> 00:27:12.219	So, it is highly parallelizable.
26.srt	00:27:14.109 --> 00:27:22.189	So, I will stop here todaywe will continue with these discussions even at the node level in our next lectures.
26.srt	00:27:22.929 --> 00:27:23.209	Thank you.
7.srt	00:00:00.160 --> 00:00:28.070	Hello, welcome to the NPTEL online certification course on deep learning.
7.srt	00:00:32.159 --> 00:00:43.179	You remember that in the previous class we had started our discussion on discriminant function and the boundary between different classes.
7.srt	00:00:44.340 --> 00:00:51.329	So, in the previous class we talked about the discriminant function under multivariate normal distribution.
7.srt	00:00:52.609 --> 00:01:03.120	And in today's class we are going to continue with our previous discussion and we will talk about we will see that how the decision boundary.
7.srt	00:01:03.490 --> 00:01:10.549	under different classes under various conditions of the covariance matrix we can have.
7.srt	00:01:11.430 --> 00:01:21.609	So, we can have linear boundaries, we can also have non-linear boundaries or quadratic boundaries and this will also illustrate with the help of some examples.
7.srt	00:01:21.640 --> 00:01:32.439	So, let us justtry to start with what we had done in our previous class.
7.srt	00:02:05.720 --> 00:02:30.040	So, in the previous class we have said that the multivariate normal distribution is given by P of x as 1 over 2 pi to the power d by 2 then sigma determinant to the power half and then exponential minus half x minus mu transpose sigma inverse into x minus mu .
7.srt	00:02:36.850 --> 00:03:02.140	So, this was the normal distribution under case, where this covariance matrix sigma is nothing, but x minus mu into x minus mu transpose and the expectation value of this that is what is the covariance matrix and mu is the mean of all the samples all the vectors that we have.
7.srt	00:03:03.840 --> 00:03:12.370	So, now if I want to have represent this as class conditional probability density function multivariate normal density function.
7.srt	00:03:13.450 --> 00:03:32.530	Then, what I have to do is I have to get p of x given omega i which will be 1 upon 2 pi to the power d by 2 and as we said in our previous class that d is the dimensionality of the vector.
7.srt	00:03:34.300 --> 00:03:44.090	And then sigma now becomes sigma i because it is the covariance matrix of all the samples taken from class omega i.
7.srt	00:03:45.870 --> 00:04:04.520	And, the other part remains exponential minus half x minus now mu becomes mu i because this is mean of the vectors taken from class omega i sigma becomes sigma i.
7.srt	00:04:04.700 --> 00:04:11.530	So, this is sigma i inverse this of course, transpose into x minus mu i.
7.srt	00:04:15.730 --> 00:04:17.990	So, this is the class conditional normaldistribution.
7.srt	00:04:46.410 --> 00:04:51.590	So, using this we have in our previous class found out the discriminant function for the ith class or the discriminant function was obtained as g i x that is the discriminant function for the ith class which was w i transpose x plus w i naught where what is this w i?
7.srt	00:04:52.389 --> 00:05:13.449	We had seen that this w i is nothing, but 1 upon sigma square intomu i and w i naught was minus 1 upon 2 sigma square mu i transpose.
7.srt	00:05:16.990 --> 00:05:23.220	mu i plus log of p of omega i.
7.srt	00:05:24.530 --> 00:05:47.570	And this is the expression we have obtained under the assumption that sigma i that is the covariance matrix for all the classes is same and which is of the form sigma square i which indicates that the covariance matrix is a diagonal matrix where all the off diagonal limits are 0.
7.srt	00:05:48.620 --> 00:05:54.020	and all the diagonal elements of the covariance matrix is same as sigma square.
7.srt	00:05:55.189 --> 00:05:56.430	What does it physically mean?
7.srt	00:05:56.990 --> 00:06:18.930	It physically means that the different components of the feature vector that we have those components are statistically independent and every component has the same variance that is the variance of x 1 the first component is same as the variance of x 2 which is the second component like this and every component.
7.srt	00:06:19.390 --> 00:06:22.710	the variance is same which is nothing, but sigma square.
7.srt	00:06:23.970 --> 00:06:44.900	This indicates that the way the training vectors the vectors are distributed in the feature space is like a circle in case of two dimension, it is a sphere in three dimension and it is hypersphere in multi dimension.
7.srt	00:06:51.920 --> 00:06:53.580	Where of course, at the center the density is maximum and as you move away from the center the density goes on reducing.
7.srt	00:06:54.280 --> 00:07:12.550	So, this is the physical significance of this short of distribution where sigma i is of the form sigma square i where this i is nothing but our unity matrix .
7.srt	00:07:22.889 --> 00:07:26.889	So, under this situation we have also stated in the previous class that if I have feature vectors descriptors coming from two different classes the i th class and j th class.
7.srt	00:07:27.649 --> 00:07:32.740	I can find out g i x that is the discriminant function for the i th class.
7.srt	00:07:32.740 --> 00:07:37.899	I can also find out g j x which is the discriminant function corresponding to the j th class.
7.srt	00:07:38.699 --> 00:07:54.689	And given this if I want to find out what is the boundary the decision boundary between these two classes that is we say that if the feature vectors falls on one side of the boundary it belongs to one class and it and if it belongs to falls on the other side of the boundary.
7.srt	00:07:54.980 --> 00:07:57.000	it belongs to some other class.
7.srt	00:07:58.020 --> 00:08:03.329	So, I can find out an expression of the boundary which separates these two classes.
7.srt	00:08:04.129 --> 00:08:23.750	And the expression of the boundary will be simply given by g x which is nothing but g i x minus g j x and because on the boundary g i x and g j x both of them will be equal.
7.srt	00:08:24.330 --> 00:08:26.050	So, this has to be equal to .
7.srt	00:09:29.379 --> 00:09:34.000	So, our expression will be g x is equal to g i x minus g j x which will be equal to 0 and this just from the expression of g i x that we have obtained you can find that g i x minus g j x this will be simply given as 1 upon sigma square into mu i minus g i mu j transpose x minus 1 upon sigma square mu i transpose mu i minus mu j transpose mu j plus log of p omega i upon p omega j that will be equal to 0.
7.srt	00:10:34.750 --> 00:11:02.250	This can simply be put in the form mu i minus mu j transpose X minus this there has to be a half right half of mu i minus mu j transpose into mu i plus mu j plus sigma square log of p omega i upon p omega j that has to be equal to 0 and after simplification you can find that this expressions can simply be written as W transpose X minus X naught that has to be equal to 0, where this W will be simply mu i minus mu j and X naught will be given by half of mu i plus mu j .
7.srt	00:11:04.129 --> 00:11:23.699	j minus sigma square upon mu i minus mu j mod square log of p omega i upon p omega j into mu i minus mu j.
7.srt	00:11:23.699 --> 00:11:34.250	So, you see what is the significance of this particular expression?
7.srt	00:11:35.409 --> 00:11:51.019	It says the equation of the boundary between the two classes i th class and j th class is given by W transpose X minus X naught equal to 0, which simply indicates that this boundary is a linear boundary.
7.srt	00:11:51.919 --> 00:11:57.689	In case of three dimension it is a plane, in case of multi dimension it is a hyper plane.
7.srt	00:12:08.759 --> 00:12:20.750	For the vector W is given by mu minus mu i minus mu j, which is nothing but a vector drawn from mu i to mu j, where mu i is the mean of the vectors taken from class omega i and mu j is the mean of the vectors taken from class omega j.
7.srt	00:12:22.419 --> 00:12:29.789	And the expression for x naught and it says that because W transpose x minus x naught equal to 0.
7.srt	00:12:30.429 --> 00:12:41.309	So, the decision surface is obviously perpendicular orthogonal to the vector W and as W is the vector drawn from omega i to omega j.
7.srt	00:12:41.659 --> 00:13:12.889	So, the decision surface is orthogonal to the line joining mu i and mu j and it passes to the point x naught and here if you look at the expression for x naught and particularly under the case if I consider that mu p of omega i is equal to p of omega j if I use if I consider this condition that is both the classes omega i and omega j.
7.srt	00:13:13.200 --> 00:13:21.990	they are equally probable the afterey probability is same under this case log of p omega i upon p omega j will be equal to 0.
7.srt	00:13:22.559 --> 00:13:32.149	So, this term will be equal to 0 and in which case your x naught simply becomes half of mu i plus mu j.
7.srt	00:13:32.990 --> 00:13:41.519	That means, x naught is a point which is at the middle of the vector the line joining mu i and mu j.
7.srt	00:13:44.220 --> 00:13:55.370	So, under such circumstances where the a priori probabilities of the two classes are same your decision surface becomes an orthogonal bisector of the line joining mu i and mu j.
7.srt	00:13:56.310 --> 00:14:14.330	And obviously, the kind of decision that you take in this case that given an unknown vector whether the vector should belong to class omega i or the vectors should belong to class omega j that decision will be taken by simply taking the distance.
7.srt	00:14:15.019 --> 00:14:18.860	of that unknown vector from the mean vectors mu i and mu j.
7.srt	00:14:19.299 --> 00:14:27.429	So, whichever mean is nearest to this unknown vector x the unknown vector will be classified to that corresponding class.
7.srt	00:14:28.549 --> 00:14:37.870	And obviously, if p of omega i and p of omega j they are different that is a priori probabilities are different that will give a bias in the decision.
7.srt	00:14:38.699 --> 00:14:44.549	So, if a priori probability for omega i is greater than a priori probability for omega j.
7.srt	00:14:44.820 --> 00:14:58.840	Then, your decision surface though it will be orthogonal to the line joining mu i and mu j, but it will be shifted towards mu j indicating that more space is allocated to class omega i.
7.srt	00:15:00.120 --> 00:15:14.899	Similarly, if mu j p of omega j is greater than p of omega i in that case x naught will be shifted towards mu i indicating that more of space will be allocated to class omega i.
7.srt	00:15:15.169 --> 00:15:21.149	in which case your decision will be biased in favor of classbiased in favor of class omega j.
7.srt	00:15:21.200 --> 00:15:33.169	So, now let us try to see an example that how this really works .
7.srt	00:15:33.169 --> 00:15:41.179	So, to illustrate this I take a set of points both from class omega 1 and class omega 2.
7.srt	00:15:41.179 --> 00:15:44.559	So, first I take a point say 12 4.
7.srt	00:15:44.590 --> 00:15:46.879	So, I am considering a two dimensional feature space.
7.srt	00:15:47.220 --> 00:15:49.429	and the features are say x 1 and x 2.
7.srt	00:15:50.450 --> 00:16:05.990	So, first I consider a point 12 4, then I consider a point 12 8, then I consider a point 10 6 and say 14 6 and I assume that these are the points which are taken from class omega 1.
7.srt	00:16:07.049 --> 00:16:18.389	Similarly, I also consider another set of points say 9 10, 9 14, 7 12 and 11 12.
7.srt	00:16:19.129 --> 00:16:22.440	And, I consider these points to be taken from class omega 2.
7.srt	00:16:23.379 --> 00:16:36.720	And, these are the points we call as training samples because using these feature vectors using these feature vectors I am going to train my classifier and that is where what is the learning in this particular case.
7.srt	00:16:37.769 --> 00:16:46.000	So, I have a set of points from one class omega 1 and another set of points from class omega 2.
7.srt	00:16:49.939 --> 00:17:05.460	Now, given this set of points first I consider the points taken from class omega 1, I compute the mean vector mu 1 which is simply average or mean of all these vectors taken from class omega 1 and the that mean vector comes out to be 12 6.
7.srt	00:17:06.359 --> 00:17:20.710	And once I have this mean vector then I have to compute the covariance matrix and as we said that covariance matrix is nothing but the expectation value of X minus mu.
7.srt	00:17:21.180 --> 00:17:22.930	into X minus mu transpose.
7.srt	00:17:24.159 --> 00:17:33.109	So, if I consider the first vector I call it say X 1 that is vector 12 4, I subtract the mean 12 6 from this.
7.srt	00:17:33.769 --> 00:17:38.089	So, 12 4 minus 12 6 simply becomes 0 minus 2.
7.srt	00:17:39.779 --> 00:17:51.389	So, a part of the partial covariance matrix simply X minus mu 1 into X minus mu 1 transpose in this case as is shown here.
7.srt	00:17:51.869 --> 00:17:58.859	x minus mu 1 into x minus mu 1 transpose simply becomes 0 0 0 4.
7.srt	00:17:59.559 --> 00:18:08.490	So, this 0 minus 2 as column vector is my x minus mu 1 and 0 minus 2 as row vector is x minus mu 2.
7.srt	00:18:22.389 --> 00:18:27.379	In the same manner I also compute x 2 minus mu 1 into x 2 minus mu 1 transpose which is M 2 that again comes out to be 0 0 0 4.
7.srt	00:18:29.000 --> 00:18:39.329	I also compute X t minus mu 1 into X t minus mu 2 transpose mu 1 transpose and that comes out to be 4 0 0 0.
7.srt	00:18:40.480 --> 00:18:52.119	Similarly, M 4 which is X 4 minus mu 1 into X 4 minus mu 1 transpose and that comes out to beagain 4 0 0 0.
7.srt	00:18:53.669 --> 00:19:03.839	So, once I have these four matrices, now the covariance matrix is nothing but the mean of all these four matrices.
7.srt	00:19:04.859 --> 00:19:16.539	So, the covariance matrix from class for class omega 1 which is sigma 1 is simply 1 upon 4 into M 1 plus M 2 plus M 3 plus M 4.
7.srt	00:19:17.319 --> 00:19:22.649	And if you compute this, it will simply come out to be 2 0 0 2.
7.srt	00:19:23.279 --> 00:19:32.460	which is nothing butmatrix of the form 2 into i where this i is an unity matrix.
7.srt	00:19:34.259 --> 00:19:38.539	So, this is what I get for class omega 1.
7.srt	00:19:39.419 --> 00:19:51.250	Similarly, for class omega 2 I consider all those feature vectors that have taken from class omega 2 which you remember that the feature vectors were 9 10, 9 14, 7 12 and 11 12.
7.srt	00:19:53.809 --> 00:20:02.299	So, using this 4 feature vectors, I compute the mean of the vectors belonging to class omega 2 and which in this case comes out to be 9, 12.
7.srt	00:20:03.789 --> 00:20:24.339	And once I have this mean vectors in the same manner as I have done previously I am not repeating all those calculations, you can calculate the same way and you can find out that the covariance matrix for class omega 2 will come out to be sigma 2 which is nothing but 2 i, again i is the unity matrix.
7.srt	00:20:26.009 --> 00:20:37.180	So, here you find that if you remember that for class omega 1 we had sigma 1 which was 2 i and for class omega 2 I have sigma 2 which is also 2 i.
7.srt	00:20:37.970 --> 00:20:50.759	So, this is a case where as we said earlier that sigma i is equal to i sigma square i .
7.srt	00:20:50.759 --> 00:20:55.250	So, it is this same condition and under which case we have seen that.
7.srt	00:20:56.060 --> 00:21:06.140	the discriminant functions will be linear and not only that the decision boundary between the two classes omega i and omega j that will also be linear.
7.srt	00:21:07.590 --> 00:21:21.540	So, this is a perfect case of that where I have sigma 1 and sigma 2 to be equal and that is 2 into i which is of the form sigma square i and what is sigma square?
7.srt	00:21:22.070 --> 00:21:24.360	Sigma square in this case is 2.
7.srt	00:21:24.730 --> 00:21:26.610	So, sigma is square root of 2 .
7.srt	00:21:28.970 --> 00:21:33.870	So, given this calculations now let us see how the decision boundary will look like.
7.srt	00:21:35.470 --> 00:21:48.470	So, come to the same set of points as we shown earlier that these points were belonging to class omega 2 and these were the set of points which were taken from class omega 1.
7.srt	00:21:50.090 --> 00:22:00.269	And we just shown earlier that when the covariance matrix sigma i is of the form sigma square i for all the classes.
7.srt	00:22:00.869 --> 00:22:35.909	The decision boundary takes the form W transpose X minus X naught equal to 0, where W is nothing but mu 2 minus mu 1 that is the vector drawn from omega 2 to omega 1 right or omega 1 to omega 2 if I compute the other way that is g 1 X minus g 2 X here the computation was g 2 X minus g 1 X and the middle point will be given by there is a mistake it is not mu 1 minus mu 2 that it, but it should be mu 1 plus mu 2.
7.srt	00:22:36.000 --> 00:22:36.039	2.
7.srt	00:22:37.920 --> 00:22:57.160	And the midpointthe point on this decision boundary is given by X naught is equal to half of mu 1 plus mu 2 minus sigma squared mu 1 minus mu 2 square into log of p of omega 1 upon p of omega 2 into mu 1 minus mu 2.
7.srt	00:22:59.059 --> 00:23:15.960	So, if you look at this if I consider the case that p of omega 1 and p of omega 2 that is the aft priority probabilities to be equal then this term will be equal to 0 and X naught will be half of mu 1 plus mu 2 which is nothing but the midpoint of the line joining mu 1 and mu 2.
7.srt	00:23:17.230 --> 00:23:37.789	And, the decision surface being orthogonal to W which is nothing but a line joining mu 1 and mu 2 or vector drawn from mu 1 to mu 2, my decision surface will be orthogonal bisector of the line joining mu 1 and mu 2 and that is what is this one.
7.srt	00:23:38.899 --> 00:23:48.549	You have this blue line that is this which is the line joining mu 1 and mu 2 here this was mu 1.
7.srt	00:23:48.599 --> 00:24:01.659	2 and this was mu 2 and this red dotted line which is an orthogonal bisector of this blue line is the decision boundary between the two classes omega 1 and omega 2.
7.srt	00:24:02.980 --> 00:24:09.659	And as I said that as p as I am assuming p omega 1 and p omega 2 to be equal.
7.srt	00:24:10.019 --> 00:24:16.889	So, this X naught is nothing but midway between mu 1 and mu 2.
7.srt	00:24:19.219 --> 00:24:32.909	So, given this if I have any point x which is falling on this side of the boundary the x will be classified to class omega 2 because I am considering these to bethe vectors taken from class omega 2.
7.srt	00:24:33.389 --> 00:24:40.959	Whereas, if I have an unknown vector y falling on this side of the boundary this unknown vector will be classified to class omega 1.
7.srt	00:24:42.359 --> 00:24:50.909	And as it is clear very clear from here the kind of classification rule that we have is nothing but a minimum distance classification rule.
7.srt	00:24:51.000 --> 00:24:59.319	2, because for any point on this side of the boundary its distance from mu 1 will be less than its distance from mu 2.
7.srt	00:25:00.579 --> 00:25:07.420	Similarly, for any point on this side of the boundary its distance from mu 2 will be less than its distance from mu 1.
7.srt	00:25:07.980 --> 00:25:12.309	So, the kind of classification rule that you have is a minimum distance classification.
7.srt	00:25:13.509 --> 00:25:22.450	So, this is what we get for a simple case when I have a situation.
7.srt	00:25:22.579 --> 00:25:25.609	that mu i is equal to sigma square i.
7.srt	00:25:27.549 --> 00:25:46.769	Now, let us go to the next case that when I have a situation that mu i a sigma i is equal to sigma, but this may not be of the form sigma square i.
7.srt	00:25:47.910 --> 00:25:48.559	What does it mean?
7.srt	00:25:49.099 --> 00:25:54.480	It means that the covariance matrix of the samples belonging to all the classes are same.
7.srt	00:25:55.349 --> 00:26:07.929	0, but the components of the vectors may not be statistically independent or in other words the off diagonal elements of this covariance matrix may not be 0.
7.srt	00:26:09.019 --> 00:26:15.759	Whereas, in our earlier simplified case we have we had assumed that the off diagonal elements were 0 right.
7.srt	00:26:27.199 --> 00:26:45.119	So, given this situation my g i x if I compute from here So, as before the g i y x was minus half log of 2 pi minus half log of mod of sigma i, but now sigma i is equal to sigma.
7.srt	00:26:57.259 --> 00:27:02.709	So, it becomes minus half log of determinant of sigma minus half x minus mu mu i transpose sigma i inverse.
7.srt	00:27:02.789 --> 00:27:04.339	Now, sigma i is equal to sigma.
7.srt	00:27:04.389 --> 00:27:11.659	So, it simply becomes sigma inverse into X minus mu i plus log of p of omega i.
7.srt	00:27:12.499 --> 00:27:25.149	Again if I simplify this you find that this is independent of the class, this is independent of the class.
7.srt	00:27:25.509 --> 00:27:28.679	So, these two do not participate in discrimination.
7.srt	00:28:04.359 --> 00:28:20.959	So, my g i x now becomes same as minus half x minus mu i transpose sigma inverse x minus mu i plus log of p of omega i and if you expand this it simply becomes minus half x transpose sigma inverse x minus 2 mu i transpose X plus mu i transpose mu i plus log of p of omega i .
7.srt	00:28:20.959 --> 00:28:30.229	As before you find that this X transpose sigma inverse X this is class independent because sigma is same for all the classes.
7.srt	00:28:30.229 --> 00:28:34.469	So, I can ignore this I can remove this from the discriminant function .
7.srt	00:28:35.039 --> 00:28:58.269	So, the discriminant function now simply becomes mu i transpose sorry here it should be there is a mistake this should be 2 mu i transpose sigma inverse x plus mu i transpose sigma inverse mu i .
7.srt	00:28:58.459 --> 00:29:00.979	So, what I get is mu i transpose .
7.srt	00:29:38.899 --> 00:30:05.229	sigma inverse x minus half mu i transpose sigma inverse mu i plus log of p of omega i ok. And this you find that this is again of the form w i transpose x plus w i naught And, this equation is again a linear equation, where this w i will now be sigma inverse mu i and w i naught will be minus half mu i transpose sigma inverse mu i plus log of p of omega i.
7.srt	00:30:06.749 --> 00:30:10.599	So, I will stop in this stop here in this particular lecture.
7.srt	00:30:10.599 --> 00:30:12.659	So, here we have what we have seen is.
7.srt	00:30:13.329 --> 00:30:29.869	starting from the discriminant function which we have seen that both in the case where sigma i is of the form of sigma square i, whereas and also sigma i is equal to sigma our decision or discriminant functions are linear.
7.srt	00:30:31.709 --> 00:30:42.669	In case of sigma i is equal to sigma square i, we have seen that the decision surface is also linear and the decision surface is orthogonal to the line joining mu i and mu j.
7.srt	00:30:43.609 --> 00:30:54.509	And, in case the a priori probabilities are equal that this is decision surface becomes an orthogonal bisector of the line joining mu i and mu j.
7.srt	00:30:55.489 --> 00:31:12.869	And, in the other case where my covariance matrix may not be a diagonal matrix and all the variances variances of all different components may not be equal, but even in that case the discriminant function g i x is a linear discriminant function.
7.srt	00:31:13.759 --> 00:31:17.339	So, we will stop here today in our next lecture we will start from this point.
7.srt	00:31:17.869 --> 00:31:18.179	Thank you.
6.srt	00:00:00.610 --> 00:00:29.449	Hello, welcome to the NPTEL online certification course on deep learning.
6.srt	00:00:31.899 --> 00:00:45.609	In, the previous class we have talked about topics like different types types of classifiers like Bayes minimum error classifier and Bayes minimum risk classifier.
6.srt	00:00:46.570 --> 00:01:01.399	And, we have also seen that Bayes minimum risk classifier under a specific case of 0 1 loss that is when the loss function for a correct decision is taken to be 0.
6.srt	00:01:01.859 --> 00:01:14.099	And, the lost function for an incorrect decision is taken to be 1 under that situation Bayes minimum risk classifier and Bayes minimum error classifier they are identical.
6.srt	00:01:15.329 --> 00:01:26.560	So, in today's lecture we will talk about we will start from those Bayes classifiers and then we will move on to what is known as discriminant function.
6.srt	00:01:27.189 --> 00:01:34.780	And then using the discriminant function we will also try to derive and we will also try to demonstrate.
6.srt	00:01:35.489 --> 00:01:40.170	the decision boundary between different classes.
6.srt	00:02:07.829 --> 00:02:27.170	So, when we talk about discriminant function, you remember from the previous class in case of Bayes minimum risk classifier or Bayes minimum error classifier, what we said is that for Bayes minimum error classifier, if p of say omega i given x is greater than p of omega j given x where omega i and omega j are two different classes and x is the unknown input vector in that case we classify the x to thisclass omega i.
6.srt	00:02:37.599 --> 00:02:46.650	And if I expand this p of omega i given x is nothing but p of 1, X given omega i multiplied by the a priori probability P of omega i.
6.srt	00:02:47.840 --> 00:03:07.930	Where P of X given omega i is what is known as the class conditional probability density, P of omega i is the a priori probability and P of omega i given X is the a posteriori probability based on which we make the decision.
6.srt	00:03:08.449 --> 00:03:16.810	that whether this unknown vector x should be classified to class omega i or it should be classified to class omega j.
6.srt	00:03:17.449 --> 00:03:30.659	So, obviously, if p of omega i given x is greater than p of omega j given x, then it is more likely or more probable that your unknown feature vector belongs to class omega i.
6.srt	00:03:31.719 --> 00:03:40.569	And this is what we had derived in our previous lectures using Bayes minimum error classification rule.
6.srt	00:03:41.989 --> 00:04:10.919	And, then base minimum risk classification what we had said is for an unknown feature vector x if we take an action alpha i then the risk involved is given by R of alpha i given x and which we said that this is nothing, but lambda alpha i given omega j .
6.srt	00:04:11.629 --> 00:04:24.629	into p of omega j given x, you take the summation over this for all the classes omega j .
6.srt	00:04:24.629 --> 00:04:31.139	So, for every action alpha i if I have say c number of actions.
6.srt	00:04:31.139 --> 00:04:49.139	So, i varies from 1 to c. So, for every such action I have to compute this risk function and for whichever action the risk the estimated risk r of alpha i given x is minimum I have to take that corresponding action .
6.srt	00:04:50.300 --> 00:05:20.040	And, as we said that under a specific case when this lambda of alpha i given omega j is equal to 0 for i is equal to j and if I take this equal to 1 whenever i is not equal to j that means, for every correctdecision the loss incurred is 0.
6.srt	00:05:20.570 --> 00:05:35.129	And, for every incorrect decision the loss incurred is 1 under that situation we had shown in the previous class that Bayes minimum risk classifier and Bayes minimum error classifier they turn out to be identical.
6.srt	00:05:36.660 --> 00:05:53.610	Now, starting from here we can define something called discriminant function because every time you find that whether I go for Bayes minimum error classification or Bayes minimum risk classification in case of Bayes minimum error classification.
6.srt	00:05:54.120 --> 00:06:06.010	For every class I am computing p of omega i given x where i varies from z 1 to c where c is the number of classes that I have.
6.srt	00:06:07.120 --> 00:06:15.070	And for whichever i p of omega i given x turns out to be maximum I classify x to that corresponding class.
6.srt	00:06:15.920 --> 00:06:23.920	Similarly in case of Bayes minimum risk classification for every class I compute r of alpha i given x.
6.srt	00:06:24.340 --> 00:06:39.780	And, then for whichever class R of alpha i given X is minimum that is for whichever class of for whichever action the risk involved is minimum I am taking the corresponding action or I am classifying X to that to that corresponding class.
6.srt	00:06:41.060 --> 00:06:54.770	And, I can say that in each of this case I am taking an action based on certain maximum criteria that is in case of base minimum error classification.
6.srt	00:06:55.150 --> 00:07:03.520	for whichever class the a posteriori probability is maximum, I am taking that corresponding action or classifying X to that corresponding class.
6.srt	00:07:04.090 --> 00:07:12.100	Similarly, for Bayes minimum risk classification for whichever class R of alpha i given X.
6.srt	00:07:12.100 --> 00:07:26.120	So, for whichever value of i R all R of alpha i given X turns out to be minimum or in other case I can say that instead of considering R of alpha i given X, I will consider.
6.srt	00:07:26.580 --> 00:07:31.610	minus r of alpha i given x.
6.srt	00:07:33.740 --> 00:07:42.100	So, if r of alpha i given x is minimum then obviously, r of alpha i given xminus r of alpha i given x will be maximum.
6.srt	00:07:42.960 --> 00:07:55.040	So, for whichever action this negative of the risk value turns out to be maximum I am taking that corresponding decision or I am classifying x to that corresponding class.
6.srt	00:07:55.980 --> 00:08:00.170	So, or in other words I can say that I can define a function.
6.srt	00:08:00.860 --> 00:08:07.450	say g i x for class say omega i.
6.srt	00:08:08.770 --> 00:08:33.220	So, here x is the unknown feature vector and for every class i every class omega i, I am computing a function g i x and for whichever i this g i x turns out to be maximum, I take decision in favor of that particular class or that particular omega i.
6.srt	00:08:34.270 --> 00:08:53.700	So, what I am doing is for an unknown feature vector x, I will compute g 1 of x, I will compute g 2 of x, I will compute g i of x and if there are c number of classes, I will compute g c of x.
6.srt	00:08:55.030 --> 00:09:03.040	And then I will try to find out that out of all these functional values whichever is maximum.
6.srt	00:09:03.950 --> 00:09:07.150	So, I take maximum of all of this.
6.srt	00:09:07.990 --> 00:09:15.100	And, for whichever i this turns out to be maximum I classify x to that corresponding class omega i.
6.srt	00:09:17.080 --> 00:09:23.230	So, this is a function that g i x I want to design for every class omega i.
6.srt	00:09:23.510 --> 00:09:27.190	So, what are the possible options that I can have g i x?
6.srt	00:09:28.160 --> 00:09:38.630	One of the option is obviously I can have g i x to be is equal to p of omega i given x that is straight forward.
6.srt	00:09:39.470 --> 00:09:50.760	which is nothing, but p of x given omega i into afterey probability p of omega i .
6.srt	00:09:50.760 --> 00:10:07.050	So, this is a straight forwarddefinition of g i x or I can also say that I will use g i x to be minus r of alpha i given x .
6.srt	00:10:09.800 --> 00:10:16.000	So, here also if g i x is maximum, then I I take that corresponding decision here also if g i x is maximum I take that corresponding decision.
6.srt	00:10:17.050 --> 00:10:34.430	So, out of these two options possible options because there might be other options as well out of these two we will try to explore this that is based on Bayes minimum error classification rule.
6.srt	00:10:37.330 --> 00:10:40.500	So, I will assume that.
6.srt	00:10:40.740 --> 00:11:10.060	we will use this discriminant function g i x where this discriminant function is defined as p of omega i given x or it is also possible that instead of p of omega i given x if I use a function of p of omega i given x where this function f has to be a monotonically increasing function.
6.srt	00:11:12.320 --> 00:11:38.020	That means If p i given x is greater than p of omega j given x, this should imply that f of p of omega i given x should be greater than f of p of omega j given x.
6.srt	00:11:41.080 --> 00:11:42.300	Let me rewrite this.
6.srt	00:11:43.310 --> 00:12:00.750	So, this implies f of p of omega i given x has to be greater than f of p of omega j given x .
6.srt	00:12:00.750 --> 00:12:06.250	So, that is f has to be a monotonically increasing function .
6.srt	00:12:15.740 --> 00:12:23.080	Then this form that is g i x as f of p of omega i given x that can also be used as a dis schematic function because, whenever g i x is maximum f of p of omega i x will also be maximum.
6.srt	00:12:24.600 --> 00:12:33.470	So, given this you will find that one very convenient function that can be used is logarithmic function.
6.srt	00:12:33.570 --> 00:12:38.930	So, or I can use natural logarithm ln what is the advantage?
6.srt	00:12:46.759 --> 00:13:18.310	The advantage is because p of omega i given x is nothing, but P of X given omega i which is the class conditional probability density function that can be estimated experimentally into P of omega i which is the probability of class omega i that is also precomputed and now if this f the function I used as the logarithmic function L n then the advantage that I get is.
6.srt	00:13:18.730 --> 00:13:37.379	L n p of omega i given x turns out to be L n p of x given omega i plus log of p of omega i .
6.srt	00:13:37.379 --> 00:13:47.580	So, this multiplication straight way is converted to an addition operation and which is very very advantageous in many computational purposes.
6.srt	00:13:48.710 --> 00:14:08.769	So, I will use this particular form that g i x is nothing, but log of p of x given omega i plus log of a priori probability p of omega i.
6.srt	00:14:09.639 --> 00:14:19.029	So, this is the discriminant function form that we will use in the remaining part of this lecture right.
6.srt	00:14:20.840 --> 00:14:37.560	So, given this let us try to see that if I assume a particular form or a particular distribution function probability density function which usually we use as a normal probability density function.
6.srt	00:14:38.430 --> 00:14:48.340	Then what form of expression of the discriminant function that we get or what form of the decision boundary between classes that we get.
6.srt	00:14:51.600 --> 00:14:58.820	So, let us talk about this discrete function under multivariate normal distribution.
6.srt	00:15:22.490 --> 00:15:30.399	So, we all know that the normal distribution if I have a single variable say p x is given by 1 over square root of 2 pi sigma e to the power minus x minus mu square upon 2 sigma square .
6.srt	00:15:30.399 --> 00:15:49.759	This is the normal density in case of a single variable x or scalar variable x where this sigma is nothing, but standard deviation and sigma squared is the variance and mu is the mean .
6.srt	00:15:53.320 --> 00:16:16.490	And you all know that the typical form of this is So, if I plot x and p x the typical form is like this, but this is what is your the mean of x that is mu and the spread of this envelope depends upon the value of sigma or sigma square.
6.srt	00:16:17.290 --> 00:16:23.820	So, if sigma is low or the sigma square is low then I will have a distribution something like this .
6.srt	00:16:25.140 --> 00:16:29.900	If the sigma square is high then the distribution will be flat of this form.
6.srt	00:16:31.080 --> 00:16:39.340	So, this is the form that I get when x is a single variable or it is a scalar variable.
6.srt	00:16:39.340 --> 00:16:56.750	But in our case since we are talking about feature vector which describes an object and the feature vector consists of multiple number of features where every feature captures some property or some attribute of the object.
6.srt	00:16:57.450 --> 00:17:17.480	So, those features may be computed from the shape of the object, they might be computed from the color of the object, they might be computed from the intensity of the object, they might be computed from the texture of the object and various such different properties are put together in the form of a vector or a feature vector.
6.srt	00:17:18.580 --> 00:17:28.800	So, the type of distribution that is important in our case is not a single variate distribution, but it is a multivariate distribution.
6.srt	00:17:29.830 --> 00:17:49.590	So, in our case I have a feature vector x and let me assume that the dimension of the feature vector is d. So, it is a d dimensional feature vector where d is the number of components or the number of features which are packed into this feature vector x.
6.srt	00:18:00.290 --> 00:18:12.720	So, given this the multivariate pro-emptive density is now given by P of x which is 1 over 2 pi to the power d by 2, then instead of variance now I have multiple variables.
6.srt	00:18:13.030 --> 00:18:16.230	So, what I have is a covariance matrix.
6.srt	00:18:16.800 --> 00:18:18.770	So, sigma is the covariance matrix.
6.srt	00:18:18.800 --> 00:18:29.870	You take the determinant of that and square root of the determinant into exponential minus half, minus half.
6.srt	00:18:31.150 --> 00:18:43.330	x minus mu transpose sigma inverse into x minus mu .
6.srt	00:18:43.330 --> 00:18:54.900	That is what is the normal distribution form of normal distribution in case of multivariates or in case of vectors .
6.srt	00:19:00.360 --> 00:19:06.480	Now, what we are interested in or the expression that we have that contains x given omega i that is the class conditional probability density.
6.srt	00:19:07.940 --> 00:19:16.150	And we said earlier that we get this class conditional probability density by taking the feature vectors x from class omega i.
6.srt	00:19:17.319 --> 00:19:20.289	So, when I take feature vectors x from class omega i.
6.srt	00:19:20.490 --> 00:19:29.289	So, for those feature vectors the mean that I will get is class dependent and I will represent that by mu i.
6.srt	00:19:29.920 --> 00:19:34.430	Similarly, the covariance sigma the covariance matrix sigma that I compute.
6.srt	00:19:34.809 --> 00:19:39.809	will also be on for that particular class omega i.
6.srt	00:19:39.990 --> 00:19:44.170	So, I will also represent this as covariance matrix sigma i.
6.srt	00:19:45.430 --> 00:19:57.509	So, what I will do is I will put this class conditional probability density function express it in the form 2 pi to the power d by 2.
6.srt	00:19:58.440 --> 00:20:04.740	Now, this sigma actually becomes sigma i because this is for class omega i.
6.srt	00:20:06.230 --> 00:20:16.560	square root of that into exponent minus half x minus.
6.srt	00:20:16.640 --> 00:20:25.030	Now, this mu becomes mu i it is for ith class transpose sigma becomes sigma i.
6.srt	00:20:25.340 --> 00:20:30.100	So, it is sigma i inverse into x minus mu i.
6.srt	00:20:34.720 --> 00:20:36.030	So, this is my multivariate.
6.srt	00:20:36.600 --> 00:20:51.600	to a pre-tensity function where sigma i is the covariance matrix computed over all the feature vectors which we call as training vectors because using their using those vectors I am computing sigma i and mu i.
6.srt	00:20:51.600 --> 00:21:03.850	So, it is the covariance matrix computed using those feature vectors taken from class omega i mu i is the mean of those feature vectors taken from class omega i.
6.srt	00:21:03.910 --> 00:21:05.980	Now, given this.
6.srt	00:21:08.120 --> 00:21:28.380	So, the way we have defined g i x is equal to log of p omega i given x plus log of a priory probability p of omega i .
6.srt	00:21:28.380 --> 00:21:37.070	Now, you find that p of omega i given x is nothing but 1 over 2 pi .
6.srt	00:21:39.870 --> 00:22:09.590	to the power d by 2, then sigma i square root of this exponential minus half x minus mu i transpose .
6.srt	00:22:09.590 --> 00:22:10.420	So, this is what is .
6.srt	00:22:10.780 --> 00:22:13.900	p of omega i given x .
6.srt	00:22:41.440 --> 00:23:02.370	So, once I use this logarithm then my g i x it simply becomes minus d by 2 log of 2 pi minus half log of sigma i minus half of x minus mu i transpose sigma i inverse x minus mu i ok plus of course, I have this log of p of omega i.
6.srt	00:23:11.440 --> 00:23:11.610	From here you find that d by 2 log of 2 pi term.
6.srt	00:23:11.610 --> 00:23:20.200	This particular term is independent of the class because there is no term like subscript i over here.
6.srt	00:23:21.460 --> 00:23:33.550	So, this minus d by 2 log of 2 pi this does not differentiate between an ith class and a jth class.
6.srt	00:23:34.770 --> 00:23:42.470	So, easily I can conveniently ignore this particular term minus d by 2 log of 2 pi.
6.srt	00:23:42.640 --> 00:23:42.900	2 pi.
6.srt	00:23:44.350 --> 00:24:14.010	So, that simplifies my g i x as minus half log of p sigma i minus half x minus mu i transpose.
6.srt	00:24:14.600 --> 00:24:28.640	sigma i inverse x minus mu i plus log of a priori probability p of omega i .
6.srt	00:24:28.640 --> 00:24:34.550	Now here I can have different cases.
6.srt	00:24:46.700 --> 00:24:56.910	So, for example, this covariance matrix sigma i in a particular case in a specific case if all the components the components of the feature vector x they are statistically independent, then covariance matrix that we get will be a diagonal matrix.
6.srt	00:24:58.340 --> 00:25:13.240	And if every component has same variance, then this covariance matrix sigma i will be of the form sigma squared i .
6.srt	00:25:13.240 --> 00:25:17.370	So, what I am assuming here that for all the classes.
6.srt	00:25:18.880 --> 00:25:25.220	The feature vectors that you obtain the components of the feature vectors are statistically independent.
6.srt	00:25:26.120 --> 00:25:37.250	So that means, if I try to compute the variance involving say ith component and jth component because they are statistically independent.
6.srt	00:25:37.250 --> 00:25:50.070	So, that variance will be equal to 0 which leads to the covariance matrix to be a diagonal matrix where only I will have diagonal elements to be non-zero and all the off diagonal elements will be 0.
6.srt	00:25:51.910 --> 00:26:03.480	And, then again if I assume that all those components for all those components the variance is same in that case all the diagonal elements which are nonzero they will be equal.
6.srt	00:26:04.350 --> 00:26:22.700	So, that ultimately leads to the covariance matrix to be of the form this sigma square i and I am assuming this to be same for all the classes that means, for every sigma i I have this covariance matrix for every omega i.
6.srt	00:26:22.940 --> 00:26:26.390	the covariance matrix sigma i is of the form sigma square i.
6.srt	00:26:26.840 --> 00:26:33.480	So, the sigma square is again same for all the features across the classes.
6.srt	00:26:34.000 --> 00:26:38.930	So, that is one of the simplified assumption that I can make.
6.srt	00:26:40.990 --> 00:26:49.610	The other assumption that can be used is where sigma i is of the form sigma.
6.srt	00:26:53.560 --> 00:27:14.009	So, in this case, It is not necessary that the different components of the feature vector will be statistically independent, not even necessary that every component will have the same variance, but what I am assuming is that whatever is the covariance matrix the same covariance matrix is valid for all the classes.
6.srt	00:27:15.290 --> 00:27:19.740	So, this is a simplified condition condition 2.
6.srt	00:27:21.400 --> 00:27:25.140	And the third one where I have the most general case.
6.srt	00:27:25.600 --> 00:27:37.059	that every class will have its own covariance matrix that is the covariance matrix of one class need not be same as covariance matrix of other classes.
6.srt	00:27:37.390 --> 00:27:40.190	So, that is the most general case which is case 3.
6.srt	00:27:42.620 --> 00:27:56.549	So, initially I will try to see that how this discriminant function look like when I assume the first case that is covariance matrix of every class is of the form sigma square i.
6.srt	00:27:58.529 --> 00:27:59.890	So, let us see this.
6.srt	00:28:27.710 --> 00:28:33.340	So, what I have is g i x is equal to minus half log of sigma i minus half x minus mu i transpose sigma i inverse x minus mu i plus log of p of omega i.
6.srt	00:28:34.819 --> 00:28:41.130	So, here as I am assuming that this sigma i the covariance matrix is same for all the classes.
6.srt	00:28:41.789 --> 00:28:53.430	So, this minus half log of determinant sigma i again this does not have any role in discriminating among different classes.
6.srt	00:28:53.430 --> 00:28:59.920	So, I can simply ignore this term from the function of from the expression of the discriminant function.
6.srt	00:29:00.640 --> 00:29:15.630	So, my g i x now simply becomes minus half x minus mu i transpose and sigma i because it is sigma square i.
6.srt	00:29:15.849 --> 00:29:22.309	So, this sigma i is of the form sigma square i.
6.srt	00:29:22.930 --> 00:29:25.759	So, this sigma i inverse is simply 1 upon sigma square.
6.srt	00:29:26.480 --> 00:29:29.980	So, what I will do is I simply put it as 1 upon 2 sigma square.
6.srt	00:29:30.579 --> 00:29:46.589	x minus mu i transpose into x minus mu i plus log of p of omega i which simply becomes minus 1 upon 2 sigma square.
6.srt	00:29:47.639 --> 00:30:00.659	If I expand this it becomes x transpose x minus twice mu i transpose x plus.
6.srt	00:30:02.019 --> 00:30:14.919	mu i transpose mu i plus log of p of omega i .
6.srt	00:30:14.919 --> 00:30:22.459	In this expression again this X transpose X is class independent right.
6.srt	00:30:22.459 --> 00:30:27.239	So, again this term does not contribute to discrimination.
6.srt	00:30:27.239 --> 00:30:31.379	So, I further simplify this as minus 1 by 2 .
6.srt	00:30:31.809 --> 00:30:55.329	sigma square what I have within the bracket is minus 2 mu i transpose X plus mu i transpose mu i plus log of p omega i.
6.srt	00:31:37.179 --> 00:32:01.289	You simplify this it simply becomes mu i 1 upon sigma square mu i transpose X minus 1 upon 2 sigma square mu i transpose mu i plus log of p of omega i which I can write in the form w i transpose X plus w i naught where this w i is nothing but 1 upon sigma squared mu i and w i naught is 1 upon 2 sigma squaredminus 1 upon 2 sigma squared mu i transpose mu i plus log of p of omega i.
6.srt	00:32:02.500 --> 00:32:07.230	So, you find that the expression that you get is a linear expression.
6.srt	00:32:40.849 --> 00:32:59.119	That means, under the simplified case when all the components all when the components of the feature vectors are statistically independent, all the components have the same variance sigma square and this is same for all the classes or in this particular case I am not assuming it is same for all the classes, but I am considering only a particular class omega The g i x is simply of the form of w transpose x plus w i transpose x plus w i naught which is a simply a linear expression right.
6.srt	00:33:00.430 --> 00:33:10.109	So, from here I can try to find out that what isthe boundary between two different classes.
6.srt	00:33:10.500 --> 00:33:12.990	omega i and omega j.
6.srt	00:33:14.289 --> 00:33:20.340	So, in order to do that let me again try to find out.
6.srt	00:33:21.170 --> 00:33:40.799	So, that boundary I can simply defined as g x and on a boundary I must have g i x is equal to g j x that is the discriminant functional value for ith class and for jth class they should be same on the boundary.
6.srt	00:33:41.980 --> 00:33:56.570	So, the equation of the boundary can simply be written as g x is equal to g i x minus g j x which is equal to 0.
6.srt	00:33:58.509 --> 00:34:04.430	So, this is simply the equation of the boundary between two classes omega i and omega j.
6.srt	00:34:16.739 --> 00:34:41.909	And what we have seen is that for g i x under this simplified assumption we have seen that g i x is nothing, but minus 1 upon 2 sigma square into x minus mu i transpose x minus mu i plus log of p of omega i .
6.srt	00:35:52.250 --> 00:36:23.420	Similarly, for g j x I will also have the case that it is minus 1 upon 2 sigma squared into x minus now it will be mu j transpose x minus mu j plus log of p of omega j and if I equate these two if I met make g x is equal to g i x minus g j x to be equal to 0, then we will find that by putting g i x this expression and in place of g j x this expression, you will find that this g i x equal to 0, this will take a form w transpose x minus x naught is equal to 0, where you will find that this w is nothing but mu 1 minus mu 2 and x naught will be same as half of mu 1 plus mu 2 minus sigma square upon mod of mu 1 minus mu 2 square into log of p omega 1 upon p omega 2 into mu 1 .
6.srt	00:36:23.949 --> 00:36:24.659	2.
6.srt	00:36:25.279 --> 00:36:35.599	So, this is the expression that I will get for the boundary between the two different classes.
6.srt	00:36:37.329 --> 00:36:44.519	So, I will derive the expression of this boundary under this simplified case in our next lecture.
6.srt	00:36:45.589 --> 00:36:45.969	Thank you.
4.srt	00:00:00.610 --> 00:00:26.620	Hello, welcome to the NPTEL online certification course on deep learning.
4.srt	00:01:01.950 --> 00:01:11.289	You recall in the previous class what we did is we discussed about the different descriptors or the features that can be extracted from a given signal, whether the signal is a visual signal like an image or what we can see around the world or it can also be a voice signal like speech signal and the applications are in the object recognition, object classification, understanding the world, speech identification, speaker identification, then speech to text conversion and many such applications.
4.srt	00:01:12.420 --> 00:01:28.769	So, what we talked about in the previous two lectures is that given any such signal we can extract the descriptors or the features from that signal which represent that particular signal whether it is visual or auditory signals.
4.srt	00:01:33.009 --> 00:01:40.679	And once you represent a signal using a number of features or a number of descriptors, those features can be represented in the form of a vector.
4.srt	00:01:41.669 --> 00:01:54.839	So, if I extract say three features from any given signal, the features may be obtained from the shape or may be obtained from the region like its intensity its color or its texture.
4.srt	00:01:56.079 --> 00:02:04.359	So, those three different features if I put in the form of a vector, it becomes a vector in one dimension having three different components.
4.srt	00:02:05.469 --> 00:02:15.679	Or in other words the signal is represented by a point in a three dimensional feature space or by a vector in a three dimensional feature space.
4.srt	00:02:16.739 --> 00:02:23.069	So, in general for a given signal you extract a number of such features.
4.srt	00:02:23.319 --> 00:02:36.810	So, you extract d number of such features or d number of such descriptors and put those descriptors in a particular order to get a vector having d number of elements or a d dimensional vector .
4.srt	00:02:37.909 --> 00:02:39.809	So, once I have a d dimensional vector.
4.srt	00:02:39.809 --> 00:02:55.729	So, effectively what I am doing is I am transforming my signal into a feature space or a vector space, where in that d dimensional vector space a signal will be represented by a particular vector.
4.srt	00:03:07.519 --> 00:03:13.449	And once I represent the signal by a particular vector which is nothing, but a point in my d dimensional space and if I have multiple number of such signals then for each of those signals I will have a corresponding point or a corresponding vector in a d dimensional space.
4.srt	00:03:14.299 --> 00:03:31.479	So, once I have this feature representation or vector representation, then just to measure whether two different signals are similar or two different signals are dissimilar, I can simply try to find out what is the distance between those two vectors or what is the difference of those two vectors.
4.srt	00:03:32.319 --> 00:03:41.149	So, if the difference is very high or the distance between two vectors is very high, in that case I can infer that the signals are not similar.
4.srt	00:03:41.949 --> 00:03:52.619	Whereas, if the distance is very small that means, the points are very close to each other then I can infer that those two signals are very close or they are similar.
4.srt	00:03:54.319 --> 00:04:04.859	So, in today's lecture what we will discuss is we will have the concept of features based representation of any given signal.
4.srt	00:04:04.859 --> 00:04:12.419	Then to understand or to recognize those signals we will discuss about Bayes rule.
4.srt	00:04:14.059 --> 00:04:25.039	Then, we will have two types of classifiers or two types of recognizers, one is Bayes minimum error classifier, the other one is Bayes minimum risk classifier.
4.srt	00:04:26.359 --> 00:04:30.149	So, let us see what this feature space representation means.
4.srt	00:04:32.559 --> 00:04:40.599	So, for the time being let us assume that a signal and to demonstrate this we will mostly take visual signals.
4.srt	00:04:49.139 --> 00:04:57.009	So, let us assume that the visual signal is represented by a two dimensional feature vector having components x 1 and x 2 or in other words we have extracted let us assume that we have extracted only two features.
4.srt	00:04:57.629 --> 00:05:05.829	One feature may be from the shape of the object, the other feature might have been obtained from the intensity of that particular object.
4.srt	00:05:06.269 --> 00:05:10.719	So, I have two different features one is feature x 1 the other one is feature x 2.
4.srt	00:05:11.989 --> 00:05:19.969	So, given these two features now let us assume that I have visual signals or have images or birds.
4.srt	00:05:20.129 --> 00:05:23.919	I have images of cars, I have images of dogs and so on.
4.srt	00:05:25.099 --> 00:05:36.669	So, if I get one image of a bird as we said that this image of this signal will be represented by a vector or a point in my feature space.
4.srt	00:05:38.279 --> 00:05:55.849	So, obviously, here you can see that to represent that image of a bird just two dimensional feature vector is not sufficient, because the birds have different shapes, the birds have different colors, they have different intensity levels, a bird may be obtained from various orientations.
4.srt	00:05:56.049 --> 00:05:58.599	it may might have been observed from various orientations.
4.srt	00:05:58.909 --> 00:06:03.649	So, accordingly I have to have a large number of features to describe a bird.
4.srt	00:06:04.619 --> 00:06:18.809	But since I cannot show any dimension on a paper of more than 2, so I am taking a simplistic case that I am assuming that this bird is represented by two dimensional feature vector.
4.srt	00:06:20.329 --> 00:06:29.779	So, given that I if I take one picture that picture is represented over here in my feature vector space which is given by x 1 and x 2.
4.srt	00:06:31.379 --> 00:06:45.849	If, I take another image of some other bird you find that here this bird or this picture is also placed at a vector location which is very close to the previous location of the bird.
4.srt	00:06:47.149 --> 00:06:55.749	But, you notice that these two locations of these two vectors are not identical because the images are not identical.
4.srt	00:07:01.269 --> 00:07:03.809	Similarly, if I take another one I will again get another which is close to the previous two vectors.
4.srt	00:07:05.689 --> 00:07:18.099	Now, if I take image of a car you find that the a car is represented by a vector over here which is far away from the vector representation of the birds.
4.srt	00:07:18.709 --> 00:07:32.989	And now if I find out the distance or the difference of this vector representing a car and a vector representing a bird the modulus of the vector difference will will be quite high or in other words the distance between these two will be quite high.
4.srt	00:07:33.699 --> 00:07:43.689	which is again an indication that these two images are not similar or a car or a bird neither in terms of shape nor in terms of color they are similar.
4.srt	00:07:45.039 --> 00:07:53.699	Again if I take a second car I get a vector over here vector representation, but again it is not identical to the previous location of the car.
4.srt	00:07:54.139 --> 00:08:03.489	The reason being the images are not identical I can can have I can have cars of various colors of various shapes of various sizes.
4.srt	00:08:03.789 --> 00:08:07.309	the card images may have been obtained from various orientations.
4.srt	00:08:07.399 --> 00:08:14.809	So, accordingly their appearance will change and the descriptors or the features that we compute that will also be changed.
4.srt	00:08:16.199 --> 00:08:22.689	If I take image of a dog you find that a dog may be represented by a vector somewhere in this location.
4.srt	00:08:23.959 --> 00:08:30.449	If I take another dog this dog is also represented by a vector in this location in my feature space.
4.srt	00:08:31.189 --> 00:08:34.369	So, like this and again you find that the distance between the.
4.srt	00:08:34.589 --> 00:08:59.499	first dog and that is and the second dog this distance is smaller than the distance between the dog and the bird and the distance between dog and the car, which again indicates that this first image the image of the first dog and this second dog image they are very similar, whereas this dog image and the car image or the dog image and the bird they are dissimilar.
4.srt	00:09:06.959 --> 00:09:19.419	So, I can continue like this and you find that for a large number of images of birds or a large number of images of cars or a large number of images of dogs each of these vectors they represent a cluster of vectors.
4.srt	00:09:20.269 --> 00:09:36.559	So, all the images of dogs that forms a cluster, all the images of cars that forms a cluster in my vector space, all the images of birds form another cluster in my vector space or feature space.
4.srt	00:09:37.859 --> 00:09:54.619	And, obviously as I said that all of them will not be represented by the same vector, all these bird images are not represented by the same vector, but the because of variation in the images I can have images of different birds of different colors, they may have different intensity values.
4.srt	00:09:54.879 --> 00:09:58.309	So, there will be always be a variation in the vector representation.
4.srt	00:09:58.949 --> 00:10:08.229	Similarly, there will always be a variation in the vector representation of cars, there will always be a variation in the vector representation of the dogs.
4.srt	00:10:09.159 --> 00:10:18.539	So, as a result what we get is given images of the signals belonging to I can call that this is a class of signals, ok.
4.srt	00:10:18.569 --> 00:10:28.129	Similarly, this is another class of signals which represents the class car, this is another class of signals which represent the class dog, right.
4.srt	00:10:28.879 --> 00:10:39.859	So, you find that the vectors coming from a particular class that forms a cluster of feature vectors or a cluster of points in my feature space.
4.srt	00:10:40.279 --> 00:10:47.369	The same is true in case of bird, the same is true in case of cars, the same is true in case of dogs.
4.srt	00:10:48.399 --> 00:10:53.919	And naturally there is a distribution of these points in the feature space right.
4.srt	00:10:54.849 --> 00:11:05.839	So, what we have if I put in the other way every such image represented by a point or by a vector in the feature space, I can put this image in this form.
4.srt	00:11:06.739 --> 00:11:11.279	So, here you find that over here.
4.srt	00:11:11.959 --> 00:11:14.829	this represents one cluster of points.
4.srt	00:11:15.469 --> 00:11:22.289	Similarly, this represents another cluster of points or cluster of feature vectors, this represents another cluster of points.
4.srt	00:11:42.999 --> 00:11:55.249	And when I have these different cluster of points, every cluster is represented by a distribution and that distribution if you look at these figures, the density of the feature vectors at the center is very high as you move away from the center as the distance between the center and the other point increases you find that the density goes on goes on decreasing.
4.srt	00:11:56.229 --> 00:12:08.749	Similarly, over here at the center the density is high which is actually mean location mean of the cluster of vectors and as I move away from the center the density goes on reducing.
4.srt	00:12:09.419 --> 00:12:14.679	Similarly, in this case at the center the density is high as you move away from the center.
4.srt	00:12:15.519 --> 00:12:16.769	the density goes on reducing.
4.srt	00:12:17.869 --> 00:12:25.219	So, this indicates that all these feature vectors follow a particular probability density function.
4.srt	00:12:27.079 --> 00:12:37.019	And in this particular case in this diagram as I have shown it in a two-dimensional feature space, this probability density is elliptic distribution.
4.srt	00:12:37.019 --> 00:12:43.329	In one case it is circular, in other two cases those are elliptic.
4.srt	00:12:49.179 --> 00:12:52.699	If I go for three-dimensional then this will be represented by spherical distributionor ellipsoidal distribution.
4.srt	00:12:53.299 --> 00:13:11.449	When the dimension becomes even more more than 3 which I cannot possibly draw on a two-dimensional plane, I represent those as or term those as hyper spherical or hyper ellipsoidal.
4.srt	00:13:11.449 --> 00:13:15.879	So, what are these spheres or the ellipsoids mean?
4.srt	00:13:19.819 --> 00:13:27.849	See for example, here If I take a contour of equal probability density functions that becomes a circle.
4.srt	00:13:28.909 --> 00:13:36.269	Similarly, in this case if I take a contour of equal probability density values it becomes an ellipse.
4.srt	00:13:37.799 --> 00:13:44.479	And as I move away from the center the value of the probability density goes on reducing.
4.srt	00:13:44.839 --> 00:13:48.659	So, that is what is meant by these different diagrams.
4.srt	00:13:51.699 --> 00:13:59.779	Now, if I go further in a three dimensional representation those densities can be represented by surface plots.
4.srt	00:14:00.769 --> 00:14:15.729	So, as you see over here this one may represent the probability density or distribution of the vectors coming from a particular class of objects.
4.srt	00:14:22.459 --> 00:14:36.879	This class may be the class of birds, this distribution may be coming from a class of dogs, this distribution may be coming from a class of cars, this distribution may be coming from a class of bicycles and so on.
4.srt	00:14:38.609 --> 00:14:48.419	So, this diagram through this diagram what I wanted to show that the distribution that you get is dependent on the class.
4.srt	00:14:49.009 --> 00:14:51.989	So, if I take any value of x.
4.srt	00:14:54.209 --> 00:15:05.099	So, what I get is that what is if I take any feature vector from a class of say dogs, what is the probable value of X?
4.srt	00:15:06.279 --> 00:15:13.999	If I take a feature vector from a class of cars, what is the probable value of that feature vector X?
4.srt	00:15:14.319 --> 00:15:16.989	So, that is the distribution which is given by this figure.
4.srt	00:15:17.609 --> 00:15:24.329	So, or in other words what I get is I get a class conditional probability density function which is known as X.
4.srt	00:15:24.759 --> 00:15:31.609	P of X given omega i, this omega i I represent as i th class.
4.srt	00:15:33.209 --> 00:15:42.129	So, as I said that this class may be class of dogs, this class may be class of birds, this class may be class of cars and so on.
4.srt	00:15:43.689 --> 00:15:51.419	So, what I have is a class conditional probability density function and how do you get this class conditional probability density function?
4.srt	00:15:52.679 --> 00:15:53.939	This is a part of training.
4.srt	00:15:56.429 --> 00:16:05.399	What I take a large number of images belonging to bird and for all those images I compute what is the feature vector x.
4.srt	00:16:06.519 --> 00:16:12.409	And then I find out what is the distribution of those feature vectors x in my feature space.
4.srt	00:16:13.649 --> 00:16:19.609	And because all these feature vectors I obtained from images from the class birds.
4.srt	00:16:19.979 --> 00:16:24.779	So, this distribution is for the feature vectors coming from the class bird.
4.srt	00:16:26.689 --> 00:16:35.069	So, I get P of the feature vector x given omega i, where this particular omega i is nothing but class parts.
4.srt	00:16:36.120 --> 00:16:51.459	Similarly, if I take a large number of images from of cars, find out the corresponding feature vectors and find out the distribution of all those feature vectors again in the feature space.
4.srt	00:16:52.470 --> 00:16:57.549	So, in this case the class of cars I write as say class omega j .
4.srt	00:16:57.790 --> 00:17:03.710	which indicates cars .
4.srt	00:17:03.710 --> 00:17:15.569	So, the distribution of the feature vectors that I get in this particular case is nothing, but the probability density of the feature vector x given the class as cars .
4.srt	00:17:15.569 --> 00:17:28.069	So, these are all the class conditional probability density functions which I have to compute from a large number of signals or large number of images with the examples that we are taking .
4.srt	00:17:28.419 --> 00:17:31.009	from a particular class.
4.srt	00:17:31.009 --> 00:17:58.210	So, I represent this as this class conditional probability density function and once I have this then given an unknown image if I want to recognize that what that image is then I have to make use of this class conditional probability density function to find out that given a signal.
4.srt	00:17:58.919 --> 00:18:12.960	which class it belongs to that is given by class conditional probability density functions p of omega j or p of omega i .
4.srt	00:18:12.960 --> 00:18:28.889	So, what I have is p of x given omega i or p of x given omega j where x is feature vector and omega i or omega j is the class.
4.srt	00:18:36.049 --> 00:18:50.619	During classification what I want to have is or what I need to do is that given an unknown feature vector vector, I have to identify whether this unknown feature vector is coming from a bird or this unknown feature vector corresponds to a car or this unknown feature vector corresponds to a dog.
4.srt	00:18:51.599 --> 00:18:58.769	So, what I need to compute is what is P of omega i given x.
4.srt	00:19:00.059 --> 00:19:08.699	So, what I have during training is P of x given omega i and what I need to compute is P of omega i given x.
4.srt	00:19:10.609 --> 00:19:13.109	In addition to this there is another concept.
4.srt	00:19:13.109 --> 00:19:21.480	So, this is what is known as class conditional probability density function and this is what is known as a posteriori probability density function.
4.srt	00:19:23.009 --> 00:19:41.009	In addition to this there is another concept of a priori probability of classes that means, what is the probability that in a given domain a sample will belong to the class omega i or p of omega i which is the priori probability.
4.srt	00:19:42.099 --> 00:19:46.409	So, as an example just to give you an example that how this may occur.
4.srt	00:19:47.490 --> 00:20:11.709	See if I go to a forest and I see an object, then after looking at the object if I have to infer whether that object or that animal or whatever I am seeing in the forest should be a car or it should be a bird and it is quite obvious.
4.srt	00:20:12.349 --> 00:20:29.889	that, if I am visiting a forest it is more likely to see a bird than to see a car because you cannot expect a car to enter a forest until until and unless there is a motorable road whereas, the birds are abundant in the forest.
4.srt	00:20:31.349 --> 00:20:42.779	So, given any object the a priori probability or the probability that that object of thewhat I am seeing will be a bird if I have to compare between bird and a car.
4.srt	00:20:43.259 --> 00:20:53.569	that the a priori probability that it will be a bird is more than the probability that will be that it will be a car and that is what is this p omega i or a priori probability.
4.srt	00:20:55.519 --> 00:21:10.789	Now given this I want to go for how the classification of the objects or the signals can be done given the feature vectors belonging to different objects.
4.srt	00:21:14.109 --> 00:21:16.759	So, for that what I will have is Bayesian learning.
4.srt	00:21:18.609 --> 00:21:25.559	So, before we go for what is Bayesian learning, let us just recapitulate probability rule.
4.srt	00:21:43.869 --> 00:22:00.159	That the probability says that if I have two events say event A and event B, the probability of event A and B can be probability of a given b into probability of b which is also same as probability of b given a into p of a .
4.srt	00:22:00.159 --> 00:22:08.199	So, the Bayes rule or the Bayes decision Bayes decision theory is based on this probability rule .
4.srt	00:22:08.199 --> 00:22:15.490	So, in this case we can say that this x is my feature vector a is my feature vector x .
4.srt	00:22:16.019 --> 00:22:19.809	and B is a class omega i.
4.srt	00:22:21.419 --> 00:22:22.189	So, what does it mean?
4.srt	00:22:22.990 --> 00:22:36.609	That if I have been given a feature vector of an object or of an image belonging to class omega i, then what is the probability that both of them occur together?
4.srt	00:22:46.149 --> 00:23:07.689	So, which is nothing, but P of X given omega i into p of omega i which is the a priori probability of class omega i and that is also same as p of omega i given x into a priori probability p of x .
4.srt	00:23:16.069 --> 00:23:18.419	So, you recall that what I said just few minutes ago that through training what I compute is P of X given omega i.
4.srt	00:23:19.059 --> 00:23:40.239	That means, if I take a large number of images of birds and I compute the distribution of the feature vectors computed from all those bird images, then actually what I am computing is P of X given the class of objects as birds.
4.srt	00:23:46.609 --> 00:24:02.979	Similarly if I take a large number of images of cars and compute the feature vectors from those images and find out what its distribution I compute what is what is the distribution of those feature vectors computed from images of cars.
4.srt	00:24:03.419 --> 00:24:17.569	What I am actually computing is the class conditional probability P of x given cars, where this x is the feature vector and cars are my class.
4.srt	00:24:18.129 --> 00:24:19.169	or class of objects.
4.srt	00:24:19.959 --> 00:24:24.829	So, what I have computed is basically class conditional probability density function.
4.srt	00:24:26.199 --> 00:24:42.269	In addition to that in that particular situation or in a given situation, I also have the aftere probability of birds and I also have aftere probability of cars.
4.srt	00:24:43.989 --> 00:24:44.849	So, what does it mean?
4.srt	00:24:45.829 --> 00:24:49.849	If my domain is a forest that means, I have visited a forest.
4.srt	00:24:50.439 --> 00:25:03.229	So, I And, there what is the probability that an object that you see is a car or it is a bird then those are the a priori probabilities P of birds and P of cars.
4.srt	00:25:21.169 --> 00:25:27.709	So, given these two now using that probability theory I can say that P of X given omega i into P of omega i is equal to P of of omega i given x into p of x.
4.srt	00:25:29.709 --> 00:25:47.719	So, this p of x given omega i, this is the class conditional probability that I have computed p of omega i is the a priori probability, but what I need to compute is p of omega i given x that is a posti a posti probability.
4.srt	00:25:55.149 --> 00:26:12.069	So, this computation p of omega i given x is nothing, but p of x given omega i into p of omega i upon p of x .
4.srt	00:26:12.069 --> 00:26:23.559	So, if I compute the same suppose omega i is the class of birds and I have another class omega j which is the class of cards.
4.srt	00:26:24.369 --> 00:26:38.709	This is nothing, but p of x given omega j into p of omega j that is a priori probability upon p of x .
4.srt	00:26:38.709 --> 00:26:41.289	Where what is this p of x?
4.srt	00:26:41.319 --> 00:26:56.129	p of x is nothing, but p of x given omega i into a priori probability omega i take the summation over all i .
4.srt	00:26:56.129 --> 00:26:58.499	And if you look at these two expressions .
4.srt	00:26:58.869 --> 00:27:08.139	out of these two whichever is more I will classify or I will associate this input vector X to that corresponding class.
4.srt	00:27:09.019 --> 00:27:25.759	So, if I find that P of omega i given X is greater than P of omega j given X, then obviously, my interpretation will be that X belongs to class omega i.
4.srt	00:27:27.289 --> 00:27:28.969	This is the interpretation that I will have.
4.srt	00:27:31.309 --> 00:27:42.529	So, given these two expressions of P of omega i given x and P of omega j given x, you find that this P x appears in the denominator both of them.
4.srt	00:27:43.659 --> 00:27:49.539	So, this P x does not contribute anything in discrimination.
4.srt	00:27:50.339 --> 00:27:59.499	So, I can simply compute P of omega i given x is equal to P of omega j.
4.srt	00:27:59.809 --> 00:28:22.729	X given omega i into a priori probability omega i and P of omega j given X is equal to P of X given omega j into a priori probability P of omega j .
4.srt	00:28:22.729 --> 00:28:30.569	So, I can simply compute this which is an approximation of P of omega i given X because I have ignored the denominator which is P of X .
4.srt	00:28:31.559 --> 00:28:39.039	And, out of these two whichever is larger I will associate my input vector to that corresponding class.
4.srt	00:28:40.729 --> 00:28:57.299	And, you find that given an x if I have P of omega i given x to be greater than P of omega j given x I still have.
4.srt	00:28:57.299 --> 00:29:00.909	So, I am deciding that x is associated with class omega i.
4.srt	00:29:01.519 --> 00:29:09.319	1, but I still have a finite probability that X may belongs to class omega j and that is what is my probability of error.
4.srt	00:29:10.609 --> 00:29:23.329	But I am taking decision in favor of that particular class for which a posteriori probability is more and my probability of error is the probability of X belonging to the other class.
4.srt	00:29:23.329 --> 00:29:31.459	So, in this particular case the probability of error is the probability p of omega j given X which is minimum of the two.
4.srt	00:29:32.279 --> 00:29:39.609	So, this particular classifier that we have discussed today is what is known as Bayes minimum error classifier.
4.srt	00:29:41.209 --> 00:29:55.929	So, in this lecture what we have done is we have talked about the vector representation of the different signals and then we have talked about the Bayes rule and discussed about the Bayes minimum error classifier.
4.srt	00:29:57.159 --> 00:30:02.369	So, in the next class we will talk about Bayes minimum risk classifier .
4.srt	00:30:02.989 --> 00:30:04.639	And, we will continue further.
4.srt	00:30:05.459 --> 00:30:05.749	Thank you.
5.srt	00:00:00.610 --> 00:00:29.500	Hello, welcome to the NPTEL online certification course on deep learning.
5.srt	00:00:34.240 --> 00:00:52.079	You remember that in the previous lecture we have talked about the feature distribution in the feature vector space and we have shown that this distribution because the different objects that we get from the same class all of them may not be identical.
5.srt	00:00:53.350 --> 00:01:04.159	The reason that they may not be identical is that the variation among the objects whether it is shape or color or texture or illumination or orientation whatever .
5.srt	00:01:06.329 --> 00:01:24.500	So, when you get multiple instances of the objects belonging to the same class, it is hardly possible that the feature vectors that we compute given two instances of the objects belonging to the same class, those feature vectors will be identical.
5.srt	00:01:26.030 --> 00:01:39.199	And because of this variation, when I have large number of objects belonging to a particular class and I compute the feature vectors of all those different objects belonging to the same class, all these feature vectors are not identical.
5.srt	00:01:39.920 --> 00:01:44.780	Rather in the feature space they will form a sort of distribution.
5.srt	00:01:46.939 --> 00:02:01.379	So, in today's class in the previous class what we have talked about this feature space representation, then we have talked about the Bayes rule and then we have also talked about the Bayes minimum error classifier.
5.srt	00:02:03.489 --> 00:02:10.280	So, today we will further analyze the remaining part of Bayes minimum error classifier.
5.srt	00:02:10.870 --> 00:02:27.110	Then, we will go to what is known as Bayes minimum risk classifier and I will also try to discuss whether there is any relation between Bayes minimum error classifier and Bayes minimum risk classifier we will try to see that.
5.srt	00:02:28.590 --> 00:02:42.990	So, this is what we have shown in the previous class that is given images from the same class, but multiple number of images belonging to the same class over here.
5.srt	00:02:42.990 --> 00:02:48.930	So, we had considered three different classes the class of birds, the class of dogs and the class of cars.
5.srt	00:02:49.270 --> 00:02:58.080	you find that all theserepresentations of these objects in the feature space that forms a cluster or a distribution.
5.srt	00:02:59.360 --> 00:03:04.480	So, we had shown in the other figure in 3D how this distribution looks like.
5.srt	00:03:05.380 --> 00:03:16.300	And we have said that because we are computing thedistribution of the feature vectors belong from objects belonging to a particular class.
5.srt	00:03:19.690 --> 00:03:31.510	So, this tells us what is the class conditional probability density function or p of x given omega i, where omega i is the class and x is the feature vector that we have computed.
5.srt	00:03:32.520 --> 00:03:39.950	So experimentally by collecting large number of objects from different classes, I compute this p of x given omega i.
5.srt	00:03:40.980 --> 00:03:49.080	And at the same time I also have an probability that is what is the probability of occurrence of class omega i.
5.srt	00:03:49.690 --> 00:04:19.860	So, I have two concepts p of x given omega i and the a priori probability p of omega i and from this for classification or for recognition the what I have to compute is what is p of omega i given x and we have shown using Bayes rule that this is nothing but p of x given omega i into a priori probability.
5.srt	00:04:20.240 --> 00:04:20.639	omega i.
5.srt	00:04:50.649 --> 00:05:04.519	So, given two classes say birds and cars I have to compute given an unknown feature vector what is p of say car given x and I also have to compute the probability of what is p of bird given the same x and this p of car given x is nothing, but P of X given car which we have already computed through experiments that is our cross conditional probability density multiplied by the appare probability what is P of car.
5.srt	00:05:06.199 --> 00:05:18.889	Similarly, in this case we will compute what is P of X given bird into appare probability what is P of bird.
5.srt	00:05:23.259 --> 00:05:34.810	So, these are my class conditional probability densities, these are the a priori probabilities and from this we compute the a posteriori probability p of car given x and p of bird given x.
5.srt	00:05:35.540 --> 00:05:40.589	So, out of these two whichever is more for a given unknown x feature vector.
5.srt	00:05:40.860 --> 00:05:55.870	So, if I find that p of car given x is greater than p of bird given x, then my inference will be that this feature vector x belongs to car or the object from which this feature vector x has been computed.
5.srt	00:05:56.300 --> 00:05:59.950	that object is nothing, but a card nothing, but, but a car.
5.srt	00:06:01.330 --> 00:06:23.550	So, what we are computing is P of omega i given x if it is greater than P of omega j given x then my interpretation is x belongs to omega i.
5.srt	00:06:27.639 --> 00:06:35.209	If P of omega j given x is greater than p of omega i given x, then my interpretation will be the other ways that is x belongs to omega j.
5.srt	00:06:37.029 --> 00:06:49.660	Now, even in this case you find that if I plot these two in one dimension say p of omega i given x may be a plot something like this.
5.srt	00:06:49.800 --> 00:06:58.129	So, here what I have is my feature vector x and in this direction what I have is p of omega i given x.
5.srt	00:06:59.639 --> 00:07:23.259	So, if my omega i is barred then I can have this sort of a posteriori probability density whereas, for car maybe p of car given x is having some density something like this.
5.srt	00:07:29.399 --> 00:07:29.670	So, this is my say omega i, this is my j.
5.srt	00:07:31.040 --> 00:07:45.790	So, given any unknown x say x vector is somewhere over here, you find that for this x p of car given x is more than p of bird given x.
5.srt	00:07:46.250 --> 00:07:52.569	So, as a result I am deciding that this x belongs to car, it does not belong to bird.
5.srt	00:07:53.410 --> 00:08:01.100	But still there is a finite probability that x may belong to bird also.
5.srt	00:08:01.949 --> 00:08:03.519	error and that is what is my probability of error.
5.srt	00:08:04.849 --> 00:08:08.189	So, in this case what is the probability of error that I have?
5.srt	00:08:08.959 --> 00:08:13.699	The probability of error is nothing but the minimum of the two.
5.srt	00:08:14.310 --> 00:08:36.569	So, p error if I put it write it like this p of error given x is nothing but .
5.srt	00:08:37.370 --> 00:08:52.259	minimum of p of omega i given x and p of omega j given x .
5.srt	00:08:52.290 --> 00:09:03.680	So, as I am taking the decision which minimizes the error because it is minimum of these two quantities p of omega i given x and p of omega j given x.
5.srt	00:09:07.090 --> 00:09:09.570	So, the classifier that we design is what is known as Bayes minimum error classifier.
5.srt	00:09:10.750 --> 00:09:12.740	And what is the total error in this case?
5.srt	00:09:12.960 --> 00:09:20.580	Total error of classification is nothing but the error or the area under this curve.
5.srt	00:09:37.150 --> 00:09:51.220	So, which is nothing but if I integrate this area minimum of these two over x varying from minus infinity to infinity, then what is what I get is the total error of this classification rule that is given by this minimum error classifier, ok.
5.srt	00:09:51.410 --> 00:09:59.290	Given this now I go to the next type of classifier which is Bayes minimum risk classifier.
5.srt	00:10:01.100 --> 00:10:07.230	So, this minimum risk classifier is more general from Bayes minimum error classifier.
5.srt	00:10:07.990 --> 00:10:14.660	In the sense that in case of B S minimum error classifier, we have considered only the classes.
5.srt	00:10:14.960 --> 00:10:38.770	See if I have c number of classes, then I have classes omega i, i varying from 1 to c. So, I take if I take c number of classes omega i, where this i varies from 1 to c. See if I have c number of classes.
5.srt	00:11:12.030 --> 00:11:13.130	In case of Bayes minimum risk classifier, we consider this omega i to be the states of nature which are nothing but classes for our classification problem and we also have a set of actions say alpha i where or alpha j set of actions alpha j where j varies from say 1 to capital K. So, I have seen number of 2 states of nature.
5.srt	00:11:42.030 --> 00:11:48.460	I have k number of actions alpha i as before I consider the feature x to be a d dimensional feature vector, but what makes Bayes minimum risk classifier more general than Bayes minimum error classifier is introduction of a loss function.
5.srt	00:11:49.590 --> 00:11:58.730	So, this loss function is introduced loss function lambda which is alpha i given omega j.
5.srt	00:12:13.610 --> 00:12:16.190	That means, if I take an action alpha i where the true state of nature is omega j or the true class is omega j, then the loss that we incur is lambda alpha i given omega j.
5.srt	00:12:18.080 --> 00:12:24.510	So, given this the base minimum risk classifier works in this fashion.
5.srt	00:12:26.160 --> 00:12:36.700	In our classification problem, our problem is that given an unknown feature vector x, we told earlier that any input signal now will consider to be of feature vector in my feature space.
5.srt	00:12:45.510 --> 00:12:51.680	So, my classification problem is that given any unknown feature vector x, I have to compute or I have to predict to which class omega i that feature vector belongs.
5.srt	00:12:51.850 --> 00:12:53.580	So, that is my classification problem.
5.srt	00:12:55.370 --> 00:13:10.880	In case of Bayes minimum risk classifier, it is assumed that for every such action you take or for every such prediction that x belongs to a particular class, you have a risk involved in it.
5.srt	00:13:11.700 --> 00:13:17.330	So, you compute the risk, the value of the risk for every decision that you are taking.
5.srt	00:13:17.880 --> 00:13:22.480	And, the decision that gives you the minimum risk you have to take the corresponding decision.
5.srt	00:13:23.620 --> 00:13:24.590	So, it is like this.
5.srt	00:13:25.870 --> 00:13:34.440	So, again I assume that I have a given feature vector x and on this x I take an action alpha i.
5.srt	00:13:36.010 --> 00:13:50.960	So, the risk involved in taking action alpha i given x can be computed as if the true state of nature is say omega g.
5.srt	00:13:51.440 --> 00:14:04.200	Then, we said that we incur a loss lambda alpha i given omega j because alpha i is the action that I am taking whereas, two state of nature is omega j it should have been omega j.
5.srt	00:14:04.830 --> 00:14:08.070	So, for while taking this action I incur some loss.
5.srt	00:14:08.410 --> 00:14:23.520	So, that is my loss function lambda omega i given lambda alpha i given omega j into what is the probability p of sorry let me rewrite.
5.srt	00:14:25.030 --> 00:14:29.770	So, I have been given vector x and I take an action alpha i.
5.srt	00:14:30.450 --> 00:14:54.560	So, I compute the risk r of alpha i given x which is nothing, but the risk involved for taking action alpha i if the true state of nature is omega j multiplied by a posteriori probability p of omega j is given x.
5.srt	00:14:56.130 --> 00:15:15.580	And, you take the sum of this over all j, why over all j because I am taking action alpha i, maybe the actual true the true state of nature is omega 1, the signal actually belongs to class omega 1.
5.srt	00:15:16.100 --> 00:15:17.420	So, for that what is the risk?
5.srt	00:15:20.330 --> 00:15:24.030	It may actually belong to class omega 2 for that what is the risk?
5.srt	00:15:25.930 --> 00:15:30.280	And likewise, may actually belong to class omega c and therefore, they for that what is the risk.
5.srt	00:15:30.980 --> 00:15:42.700	And if I add all these risks then I get the overall risk for taking action alpha i given my feature vector x right.
5.srt	00:15:44.280 --> 00:15:45.550	So, this I have to take.
5.srt	00:15:45.660 --> 00:15:57.750	So, I have to compute this R of alpha i given x for all i we said that we have k number of actions.
5.srt	00:15:58.070 --> 00:16:13.120	So, for all i varying from 1 to k and out of all these for whichever r of alpha i given x is minimum, I have to take that corresponding action.
5.srt	00:16:14.290 --> 00:16:23.370	So, that is why it is Bayes minimum risk classification that is I want to take that particular action for which my risk is minimum.
5.srt	00:16:30.450 --> 00:16:35.040	Unlike in case of Bayes minimum error classification, there you decided x to belong to a particular class which minimized your error.
5.srt	00:16:36.370 --> 00:16:39.380	So, now it is minimization of risk.
5.srt	00:16:41.260 --> 00:16:49.740	Now, let us see whether I can establish any relation between this minimum risk classification and minimum error classification.
5.srt	00:17:01.530 --> 00:17:08.920	Let us assume that we have an 1 0 loss function that is I assume that lambda alpha i given omega j, let me represent this in short as lambda i j.
5.srt	00:17:11.400 --> 00:17:25.210	So, if i is equal to j that means I am correcting, I am taking the correct action, it belongs to class omega j and I am saying that and I am my decision is it belongs to class omega j and it actually belongs to class omega j.
5.srt	00:17:26.110 --> 00:17:33.910	So, in that case the loss function, the loss that I incur is 0.
5.srt	00:17:34.170 --> 00:17:49.510	So, that this lambda the loss function is equal to 0 if i is equal to j and I also assume that this is equal to 1 if i is not equal to j.
5.srt	00:17:50.260 --> 00:18:05.770	So, that is for every incorrect action you incorporate a unity loss and which is same for all incorrect decisions, but if your decision is correct obviously you are not incurring any loss.
5.srt	00:18:06.050 --> 00:18:07.600	So, lambda i j is equal to 0.
5.srt	00:18:09.660 --> 00:18:36.470	So, given this now if I compute the risk involved in taking an action alpha i given x which we have said that this is nothing but lambda i j that is lambda of alpha i given omega j into p of omega j given x and sum of this.
5.srt	00:18:37.410 --> 00:18:39.880	over all j.
5.srt	00:18:42.430 --> 00:18:57.940	And now coming taking these values of lambda i j you find that we have defined that wherever i is equal to j lambda i j is equal to 0 and wherever i is not equal to j lambda i j is equal to 1.
5.srt	00:19:07.920 --> 00:19:21.530	So, this expression simply becomes p of omega j given x take the summation over all j not equal to i because wherever j is not equal to i lambda i j is 1 and whenever j is equal to i lambda i j is equal to 0.
5.srt	00:19:22.180 --> 00:19:38.780	So, I have to take this summation over all j where j is not equal to i for all of them lambda i j is 1 and this is nothing but 1 minus p of omega i.
5.srt	00:19:39.070 --> 00:19:39.880	given X.
5.srt	00:19:42.220 --> 00:19:56.310	Now, see that what we wanted is in Bayes minimum risk classification, I want to take that particular action alpha i for which r of alpha i X alpha i given X is minimum.
5.srt	00:19:58.070 --> 00:20:08.340	In Bayes minimum risk classification, we wanted to classify X to that particular class for which p of omega i given X is maximum.
5.srt	00:20:12.590 --> 00:20:20.640	Now, if you look at this expression, you can see that R of alpha i given x is equal to 1 minus p of omega i given x.
5.srt	00:20:21.480 --> 00:20:41.470	Obviously, you can find out you can check that R of alpha i given x will be maximum or R of alpha i given x will be minimum when p of omega i x is maximum because R of alpha i given x is nothing but 1 minus p of omega i given x.
5.srt	00:20:43.050 --> 00:20:48.550	So, however, r of alpha i x is minimum, p of omega i given x is maximum.
5.srt	00:20:49.790 --> 00:21:11.820	So, in this particular case when my loss function is 1 0 loss function or 0 1 loss function that is for every correct decision I assume that I incur a loss or I do not incur any loss that is the loss function value is 0 for every incorrect decision I incur unity loss.
5.srt	00:21:14.450 --> 00:21:21.539	So, under that condition my base minimum risk classifier and base minimum error classifier both of them are same.
5.srt	00:21:23.860 --> 00:21:34.210	But in general for taking wrong decisions for different types of wrong decisions my loss function will not be same right.
5.srt	00:21:34.309 --> 00:21:36.700	So, we will discuss about thatmore later.
5.srt	00:21:36.950 --> 00:21:40.140	Now, let us considercase oftwo classes.
5.srt	00:21:45.720 --> 00:22:16.940	So, we are discussing about the risk function and we have defined that if you take an action say alpha i where the true state of nature is say omega j, then for an given input vector x the risk involved is given by r of alpha i given x which is nothing but lambda alpha i given omega j.
5.srt	00:22:17.600 --> 00:22:27.530	into p of omega j given x and you take the sum of this over all j.
5.srt	00:22:28.680 --> 00:22:36.570	So, that is the total risk for taking an action alpha i given an input feature vector x.
5.srt	00:22:48.220 --> 00:23:00.820	So, if I have say k number of such actions where alpha i, i varying from 1 to So, for each of this i, I have to compute what is the risk function and I have to take that particular action for which the risk involved is minimum.
5.srt	00:23:01.430 --> 00:23:05.270	So, that is what Bayes minimum risk classifier says.
5.srt	00:23:20.540 --> 00:23:27.250	So, now let us take a two class problem where I assume that I have two actions given as alpha 1 and alpha 2 and I have 2 states of nature or 2 classes given by omega 1 and omega 2.
5.srt	00:23:29.080 --> 00:23:40.140	So, let us compute try to find out that what is the risk involved if I take an action alpha i or what is the risk involved if I take an action alpha 2.
5.srt	00:23:40.410 --> 00:23:44.530	So, alpha 1 and alpha 2 I want to compute the 2 risk functions.
5.srt	00:23:45.210 --> 00:23:52.100	And the loss function that we have defined lambda alpha i given omega j.
5.srt	00:23:52.530 --> 00:23:57.100	For simplicity, I will write this in the form of lambda ij.
5.srt	00:23:58.000 --> 00:24:12.170	So, the risk or the loss function for taking an action alpha i, if the true state of nature is omega j which is which is lambda alpha i given omega j, I represent this as lambda ij.
5.srt	00:24:22.780 --> 00:24:24.400	So, given this now I will have two risk functions involved, one is for taking action alpha i, the other one is for taking action alpha j.
5.srt	00:24:25.110 --> 00:24:52.880	So, I have to compute r of alpha 1 given omega 1 and I also have to compute r of alpha 2 givensorry r of alpha 1 given x and I also have to compute r of alpha 2 given x.
5.srt	00:24:54.050 --> 00:25:13.580	So, this r of alpha 1 given x is nothing but lambda 1 1 p of omega 1 given x plus lambda 1 2 p of omega 2 given x.
5.srt	00:25:14.450 --> 00:25:20.880	So, here you find that lambda 1 1 is nothing but lambda alpha 1 given omega 1.
5.srt	00:25:23.470 --> 00:25:26.520	Similarly, lambda 1 2 2 is nothing but lambda alpha 1 given omega 2.
5.srt	00:25:27.820 --> 00:25:46.570	And in the same form I can write all of r of alpha 2 given x as lambda 2 1 p of omega 1 given x plus lambda 2 2 p of omega 2 given x.
5.srt	00:25:47.910 --> 00:25:55.870	So, given these two risk values my decision will be in favor of action alpha 1.
5.srt	00:25:56.180 --> 00:26:10.960	or deciding that input x belongs to class omega 1 is when I find that r of alpha 1 given x is less than r of alpha 2 given x.
5.srt	00:26:11.630 --> 00:26:20.450	That is the risk involved in taking action alpha 1 is less than the risk involved in taking taking action alpha 2.
5.srt	00:26:21.780 --> 00:26:28.160	So, if I put this bringing or using the risk values from here.
5.srt	00:26:28.630 --> 00:27:00.040	I have to have lambda 1 1 p omega 1 given x plus lambda 1 2 p omega 2 given x this has to be less than lambda 2 1 p of omega 1 given x plus lambda 2 2 p of omega 2 given x .
5.srt	00:27:03.150 --> 00:27:32.330	Or I can rewrite this as lambda 2 1 minus lambda 1 1 p of omega 1 given x has to be greater than lambda 1 2 minus lambda 2 2 p of omega 2 given x right .
5.srt	00:27:33.280 --> 00:27:50.630	So, this is the condition that has to be satisfied that is lambda 1 2 minus lambda 2 1 minus lambda 1 1 into p of omega 1 given x has to be greater than lambda 1 2 minus lambda 2 2 p of omega 2 given x.
5.srt	00:27:51.680 --> 00:28:02.870	So, let me just rewrite this in the form as it may or refresh this .
5.srt	00:28:05.000 --> 00:28:35.040	So, my condition was that lambda 1 1 p of omega 1 given x plus lambda 1 2 p of omega 2 given x that has to be less than p lambda 2 1.
5.srt	00:28:35.850 --> 00:28:46.750	p of omega 1 given x plus lambda 2 2 p of omega 2 given x.
5.srt	00:29:08.000 --> 00:29:17.500	So, which we have rewritten in the form lambda 2 1 minus lambda 1 1 p of omega 1 given x has to be greater than lambda 1 2 minus lambda 2 2 into p of omega 2 given x.
5.srt	00:29:17.890 --> 00:29:27.330	So, this is the condition that has to be satisfied for taking a decision in favor of class omega 1 or for taking action alpha 1.
5.srt	00:29:39.840 --> 00:29:58.520	So, I can also rewrite this in the form p of omega 1 given x 2 upon p of omega 2 given x to be greater than lambda 1 2 minus lambda 2 2 upon lambda 2 1 minus lambda 1 1.
5.srt	00:29:59.610 --> 00:30:09.810	And you remember that lambda 1 2 is the loss function for taking an action alpha 1.
5.srt	00:30:10.190 --> 00:30:25.740	when the actual true of nature is omega 2 and lambda 2 2 is the loss function involved when you are taking action alpha 2 when the true class of nature is omega 2.
5.srt	00:30:26.080 --> 00:30:30.110	So, naturally lambda 2 2 has to be less than lambda 1 2.
5.srt	00:30:30.800 --> 00:30:35.660	Similarly, lambda 1 1 will also be less than lambda 2 1.
5.srt	00:30:40.460 --> 00:30:43.620	So, both these quantities both in the numerator and denominator on the right hand side both these quantities are positive.
5.srt	00:30:45.390 --> 00:30:54.260	And again you remember from the Bayes rule that p omega 1 given x which is the a posteriori probability.
5.srt	00:30:54.990 --> 00:31:10.150	I can write this as p of omega 1 given x as p of x given omega 1 which is the class conditional probability of x.
5.srt	00:31:10.600 --> 00:31:13.890	into the a priori probability p of omega 1.
5.srt	00:31:15.230 --> 00:31:27.420	Similarly, p of omega 2 given x can also be written as p of x given omega 2 into p of omega 2.
5.srt	00:31:41.890 --> 00:32:08.430	So, using this now this expression can be written as p of x given omega 1 upon p of X given omega 2 has to be greater than lambda 1 2 minus lambda 2 2 upon lambda 2 1 minus lambda 1 1 into p of omega 2 upon p of omega 1.
5.srt	00:32:11.430 --> 00:32:15.860	So, now considering this p of X given omega 1. .
5.srt	00:32:16.700 --> 00:32:23.820	to be a function of omega 1, p of x given omega 1 gives me the likelihood value.
5.srt	00:32:25.240 --> 00:32:33.990	And accordingly p of x given omega 1 upon p of x given omega 2 that gives me the likelihood ratio.
5.srt	00:32:35.170 --> 00:32:47.170	So, this expression that in order to take an action in favor of class omega 1 which is p of x given omega 1 upon p of x given omega 2.
5.srt	00:32:47.490 --> 00:32:59.150	has to be greater than lambda 1 2 minus lambda 2 2 upon lambda 2 1 minus lambda 1 1 into p of omega 2 given omega 1.
5.srt	00:33:00.170 --> 00:33:09.940	This condition has to be true for taking an action in favor of class omega 1 and that is what comes from the Bayes minimum risk classification rule.
5.srt	00:33:11.210 --> 00:33:18.460	So, going by that you find that on the right hand side of this expression of this inequality.
5.srt	00:33:18.970 --> 00:33:29.250	that is lambda 1 2 minus lambda 2 2 upon lambda 2 1 minus lambda 1 1 into p of omega 2 upon p of omega 1 this is independent of X.
5.srt	00:33:30.580 --> 00:33:41.190	So, a favorable decision in favor of class omega 1 can be that if the likelihood ratio is greater than certain threshold where the threshold is given by this.
5.srt	00:33:42.060 --> 00:33:48.620	The thresholds are in terms of the loss functions and the appraisal probabilities.
5.srt	00:33:49.460 --> 00:33:58.930	So, we can say that if the likelihood ratio is above than this threshold, then we take an action in favor of class omega 1.
5.srt	00:34:00.620 --> 00:34:02.340	So, we will continue this discussion further.
5.srt	00:34:04.200 --> 00:34:15.300	So, in today's lecture what we have discussed about we have recapitulated our previous lectures content that is feature representation of a given signal.
5.srt	00:34:16.150 --> 00:34:18.960	Then we have talked about the Bayes theory.
5.srt	00:34:20.030 --> 00:34:35.930	classification and the Bayes minimum error classifier, Bayes minimum risk classifier and we have also tried to establish that what is the relation between Bayes minimum error classification and Bayes minimum risk classification.
5.srt	00:34:36.720 --> 00:34:37.040	Thank you.
1.srt	00:00:00.610 --> 00:00:27.929	Hello, welcome to the NPTEL certification course on Deep Learning .
1.srt	00:00:32.410 --> 00:00:46.689	So, in today we are going to introduce the content of this course and we are going to talk about that what all we will be covering in this lecture series on deep learning.
1.srt	00:00:48.600 --> 00:01:02.120	So, the topics that I will cover is obviously, the first one is an introduction to deep learning, then we will talk about that when we learn something how do we learn.
1.srt	00:01:02.660 --> 00:01:07.770	When we are going for deep learning, what is the difference between machine learning and deep learning?
1.srt	00:01:09.020 --> 00:01:13.590	Then coming to deep learning again, we will talk about two different models of deep learning.
1.srt	00:01:14.260 --> 00:01:19.439	One of them is the discriminative model and the other one is the generative model.
1.srt	00:01:21.520 --> 00:01:31.439	Then we will see that what are the challenges of deep learning applications, when we want to have any application of the deep learning techniques, what are the challenges that we face.
1.srt	00:01:32.809 --> 00:01:35.939	how we try to mitigate those challenges.
1.srt	00:01:37.079 --> 00:01:46.659	And then we will briefly talk about that what is the power of deep learning techniques or what we can do using deep learning methods.
1.srt	00:01:48.439 --> 00:01:54.669	So, first let us try to see that what is learning or then we will come to what is machine learning.
1.srt	00:01:57.899 --> 00:02:03.089	So, to talk about what is learning I will show you these two pictures or .
1.srt	00:02:03.629 --> 00:02:09.599	you take any picture for thatmatter or even a word say father.
1.srt	00:02:11.459 --> 00:02:17.089	So, coming to these two pictures I will simply ask you can you recognize these two pictures?
1.srt	00:02:18.599 --> 00:02:20.169	The answer will be obviously yes.
1.srt	00:02:21.089 --> 00:02:35.029	All of you hopefully will say that the picture on the left is a cave painting in Aujanta caves and picture on the right is the picture of parliament building in New Delhi.
1.srt	00:02:35.840 --> 00:02:52.159	So, we have been able to recognize these two pictures or we will be able to recognize thousands of such pictures which are shown to us or we will be able to understand thousands of words which we will hear or thousands of sentences we will hear.
1.srt	00:02:54.069 --> 00:03:05.099	But the question is we have been able to understand we or we have been able to recognize these two pictures that is fine, but the question is how do you recognize it.
1.srt	00:03:06.419 --> 00:03:19.929	So, you find that when we look at any of these two pictures, obviously how do I recognize that the picture on the left is a Ojantha is a painting from Ojantha caves.
1.srt	00:03:20.849 --> 00:03:28.669	The reason is either my parents, my friends they have shown me that these are the paintings from Ojantha cave.
1.srt	00:03:29.789 --> 00:03:39.870	If not maybe I have visited Ojantha cave and there I have seen this painting or maybe I have seen this paintings in textbooks in history books.
1.srt	00:03:40.399 --> 00:03:40.679	right.
1.srt	00:03:40.729 --> 00:03:45.849	In most of the history books such paintings images of such paintings are abundant.
1.srt	00:03:46.899 --> 00:03:59.059	So, I have while seeing those pictures I have unknowingly unintentionally tried to capture certain properties or certain descriptors from this picture.
1.srt	00:04:00.579 --> 00:04:06.269	And using those properties or those pictures I have built a model which is embedded in my pen.
1.srt	00:04:07.529 --> 00:04:11.669	So, next time whenever this painting is shown to me.
1.srt	00:04:12.250 --> 00:04:22.899	I try to find out similar descriptors or similar features and try to and I try to match those features with the model that I have been that is embedded in my brain.
1.srt	00:04:23.439 --> 00:04:30.930	That means, this picture is associated with an a priori knowledge that I have right.
1.srt	00:04:32.039 --> 00:04:37.659	So, using that a priori knowledge I try to recognize or I can recognize this picture very easily.
1.srt	00:04:39.069 --> 00:04:41.579	But suppose the picture on the right.
1.srt	00:04:42.129 --> 00:04:43.699	that has never been shown to me.
1.srt	00:04:44.490 --> 00:04:50.500	I have never seen parliament building or I have never seen an image of parliament building, nobody has shown me, nobody has told me.
1.srt	00:04:51.709 --> 00:05:05.339	So, if this picture on the right is shown to me, I will probably say ok this is some building because I know the buildings look like this, but I will not be able to say that this is parliament building because that association I do not have.
1.srt	00:05:05.339 --> 00:05:14.579	So, how do you recognize or how do you get the description or the features of any event or any object or any picture, we will try to see.
1.srt	00:05:14.849 --> 00:05:16.939	and profit from experience.
1.srt	00:05:17.779 --> 00:05:28.439	So, you find that this definition is very very crisp definition and these three words comprehend, understand and profit from experience.
1.srt	00:05:29.039 --> 00:05:34.990	These three lies at the heart of what is machine learning or what is deep learning.
1.srt	00:05:36.550 --> 00:05:44.419	Or in other words we can also say that the intelligence is the capability to acquire and apply knowledge.
1.srt	00:05:46.490 --> 00:06:00.170	experiencing various events every day each and every day, we are watching new objects every day and through that we are acquiring knowledge.
1.srt	00:06:01.170 --> 00:06:10.089	And then what we are trying to do is we are applying the knowledge that we have acquired through experience and that is what is intelligence.
1.srt	00:06:19.849 --> 00:06:39.879	So, coming back it is almost 2300 years ago or even more than The great philosopher Plato during the who was there during the period 427 to 347 BC, he brought the concept that the abstract ideas are known to us a priori through a mystic connection with the world.
1.srt	00:06:50.589 --> 00:06:51.219	So, you note what Plato said that it is a mystic connection while with the world.
1.srt	00:06:52.549 --> 00:06:54.899	So, the abstract ideas are known to us after.
1.srt	00:06:55.949 --> 00:07:07.829	And of course, this makes sense because otherwise how is it possible that a newly born baby can easily recognize his or her mother right.
1.srt	00:07:08.370 --> 00:07:11.539	So, definitely it is something mystic connection with the world.
1.srt	00:07:13.229 --> 00:07:19.389	And Plato concluded that ability to think is found in a priori knowledge of the concepts.
1.srt	00:07:21.120 --> 00:07:21.419	Right.
1.srt	00:07:21.589 --> 00:07:24.279	So, everything is as per Plato everything is a priori.
1.srt	00:07:26.250 --> 00:07:30.129	So, does it mean that we do not learn anything new?
1.srt	00:07:31.479 --> 00:07:39.750	So, that was something which was missing in what Plato said more than 2300 years ago.
1.srt	00:07:41.620 --> 00:07:50.769	But soon after it was actually Plato's pupil Plato's student who brought in the concept of learning.
1.srt	00:07:56.319 --> 00:08:06.159	He pointed out Aristotle pointed out that, in Plato's concept a very important aspect was missing that is ability to learn or adapt to changing world.
1.srt	00:08:07.620 --> 00:08:19.929	So, all of you know that every day as we experience new and new events, as we see new and new things, we are learning continuously.
1.srt	00:08:20.399 --> 00:08:26.370	So, learning is a never ending process, every day we are learning something new.
1.srt	00:08:27.040 --> 00:08:38.259	So, that is what has been introduced by Platothat is what has been introduced by Aristotle who was Plato's student.
1.srt	00:08:40.240 --> 00:08:54.830	So, coming back again to the machine learning or when we try to recognize something why when we learn some object or some animal or some word how do we learn it let us come to this.
1.srt	00:08:58.250 --> 00:09:06.870	So, either we see an object or an image of an object or maybe we listen to some words to some sentences every day.
1.srt	00:09:08.930 --> 00:09:28.450	So, when you talk about say machine learning or deep learning a very very important application of this deep learning or machine learning is being able to understand or recognize objects that we see or the images that we see or being able to understand.
1.srt	00:09:29.170 --> 00:09:32.120	or comprehend the sentences that we hear.
1.srt	00:09:33.680 --> 00:09:40.870	See when I am someone says go to school, I do not I know that what does the sentence mean go to school.
1.srt	00:09:41.720 --> 00:09:43.879	So, that means, we understand it ok.
1.srt	00:09:44.720 --> 00:10:00.009	So, coming to the machine when the machine is to learn and the machine is to deliver then obviously, these sentences or these images are to be converted into a form which the machine will understand.
1.srt	00:10:01.860 --> 00:10:22.060	So, come to a picture which is shown on the left, apparently it is a picture of a cat all these pictures are actually represented by two dimensional arrays of numerical values and mostly those are integer values.
1.srt	00:10:32.330 --> 00:10:37.139	So, those of you who know about the digital images you know that we talk about pixels, we talk about megapixels 18 megapixel, 40 megapixel, 50 50 megapixel and so on which are actually the power of the camera that we have.
1.srt	00:10:38.269 --> 00:10:47.070	So, these pixels are nothing, but an element in a two dimensional array or an element in a matrix.
1.srt	00:10:47.840 --> 00:10:56.360	So, any image is represented as a two two dimensional matrix which is as shown over here.
1.srt	00:10:57.159 --> 00:11:02.190	So, this is a two dimensional matrix which is part of the image image which is shown on the left.
1.srt	00:11:03.560 --> 00:11:11.680	And, every element in this matrix is normally an integer value and you know that these integer values are 8 bit integer values.
1.srt	00:11:11.990 --> 00:11:18.840	That means, every element in the image every element in this matrix can assume a value from 0 to 255.
1.srt	00:11:20.910 --> 00:11:26.040	And, that is true for a black and white image or a gray level image which does not have any color information.
1.srt	00:11:27.100 --> 00:11:34.360	But, if I have a color image the color image is represented in two planes the red plane green plane and blue plane.
1.srt	00:11:34.720 --> 00:11:45.250	And, each of these planes can be considered as a grayscale image and every pixel in such grayscale images are again 8 bit quantized.
1.srt	00:11:46.230 --> 00:12:00.550	That means, coming to a color image every pixel in a color image will have three components the red component, blue component and green component and each of these components can take values from 0 to 255.
1.srt	00:12:00.880 --> 00:12:06.220	That means, every pixel in a color image is represented by 24 bits.
1.srt	00:12:06.850 --> 00:12:09.200	8 bit per color component.
1.srt	00:12:10.490 --> 00:12:14.690	So, that is how an image is represented in a computer.
1.srt	00:12:16.030 --> 00:12:25.380	Similarly, when it comes to word recognition or voice recognition or speech recognition, then the speech signals are to be represented digitally.
1.srt	00:12:26.560 --> 00:12:38.690	So, what is shown on the right hand side is what you get from the output of a microphone, you know that microphone converts an acoustic signal which is a voice signal or any other sound.
1.srt	00:12:39.050 --> 00:12:43.530	input into an electrical form and then into an electrical waveform.
1.srt	00:12:44.660 --> 00:13:00.460	So, this is the snapshot of an waveform which is output of a microphone and this you get when you utter a pair of words say news items, then the microphone output will be something like this.
1.srt	00:13:01.680 --> 00:13:11.820	And now if we sample these outputs and digitize each of the samples what we get is a time series a sequence of samples in time.
1.srt	00:13:12.870 --> 00:13:21.730	So, this is how a voice signal or a speech signal or a sound signal can be represented in a computer.
1.srt	00:13:23.100 --> 00:13:38.110	So, once I have these representations, next is how do we process these informations so that this processed information can be used by a computer for understanding or for recognizing.
1.srt	00:13:38.960 --> 00:13:43.010	So, for that what we need are the descriptors or the feature vectors.
1.srt	00:13:44.320 --> 00:13:52.610	So, here I am showing you two different pictures, one is the picture of a horse, the other one is the picture of a zebra.
1.srt	00:13:54.470 --> 00:14:03.740	Now, given those two pictures you find that both of them has got two types of properties, one is the shape property, other one is the region property.
1.srt	00:14:04.940 --> 00:14:06.040	So, what is the shape property?
1.srt	00:14:06.570 --> 00:14:08.220	Let us come to the next picture.
1.srt	00:14:09.440 --> 00:14:13.550	If I simply take the boundary of a horse.
1.srt	00:14:13.810 --> 00:14:18.730	or the boundary of a zebra what we get is shape of these two animals.
1.srt	00:14:20.160 --> 00:14:24.000	And here you find that the shapes of these two animals are almost similar.
1.srt	00:14:24.790 --> 00:14:34.110	So, by looking at the shape only possibly I will not be able to say which one is horse or which one is zebra right.
1.srt	00:14:34.540 --> 00:14:45.140	But maybe that using this shape information I will be able to say that ok this is either a horse or a zebra it is not a bird ok.
1.srt	00:14:45.980 --> 00:15:00.690	So, this is a kind of information that I will be possiblybe generated, I will be able to generate given the shape information that this might be a horse or a zebra, but definitely this is not a bird.
1.srt	00:15:01.860 --> 00:15:13.690	But to distinguish between horse and zebra what I need is the additional information that is what is the property of the region bounded within this boundary.
1.srt	00:15:16.670 --> 00:15:32.180	So, if you look at On the left where I have a horse or on the right where I have a zebra, in case of a horse the color of the bounded region and the texture of the bounded region is totally different from the color and texture of the bounded region corresponding to a zebra.
1.srt	00:15:32.900 --> 00:15:39.440	So, in case of a zebra I have black and white stripes which usually I do not have in case of a horse.
1.srt	00:15:47.290 --> 00:16:08.910	So, if I want to distinguish between a horse and a zebra or given an image if one I have to recognize that which is the image of a horse or which is the image of a zebra, then possibly I will make use of this information both the shape information as well as the region information or the region properties which will help me to identify that which figure is the figure of a horse or which figure is the figure of a zebra.
1.srt	00:16:10.340 --> 00:16:19.700	So, we need both these kind of informations the shape information and the boundary information there are different shape informations possible.
1.srt	00:16:20.220 --> 00:16:27.180	So, given a shape I will have multiple informations because I may have to distinguish one shape from other.
1.srt	00:16:27.770 --> 00:16:33.110	So, I have to distinguish a rectangle from a circle.
1.srt	00:16:33.840 --> 00:16:38.550	So, the shape information of a rectangle and the shape information of a circle will not be same they will be different.
1.srt	00:16:39.240 --> 00:16:49.310	And this discrimination can be done using multiple number of properties it may not be possible that I will have a single property this has to be done using multiple number of properties.
1.srt	00:16:50.270 --> 00:16:52.430	Similarly, when I will go for color.
1.srt	00:16:54.370 --> 00:16:57.930	Again, from the color I can extract multiple number of properties.
1.srt	00:16:58.980 --> 00:17:04.000	Similarly, when I go for texture for texture I can extract multiple number of properties.
1.srt	00:17:04.950 --> 00:17:13.270	And each of these properties if I can represent in the form of numerical values, then you concatenate all these properties together right.
1.srt	00:17:13.650 --> 00:17:24.130	Say from shape if I extract 5 properties, then the shape information can be represented by of by a vector having 5 elements.
1.srt	00:17:25.150 --> 00:17:37.720	Similarly, color from the color if I extract 10 properties or 10 descriptors describing a color all those 10 descriptors putting together gives me a vector having 10 number of elements.
1.srt	00:17:38.549 --> 00:17:41.930	Similarly, for texture again I can have 10 number of elements.
1.srt	00:17:42.350 --> 00:17:46.870	So, if I concatenate all of them together I get say total 25 elements.
1.srt	00:17:54.630 --> 00:18:01.420	So, that means, a bounded shape a bounded region is described by 25 features or by feature vector having 25 elements.
1.srt	00:18:02.110 --> 00:18:11.340	Now, using these feature vectors I go and go for identification or classification of the objects or classification of the bounded region.
1.srt	00:18:25.009 --> 00:18:27.250	Whether the bounded region is corresponds to a horse or it corresponds to a zebra or it corresponds to a bird, if it is a bird what kind of bird and all these detailed classification can be made once I compute these descriptors or features.
1.srt	00:18:28.460 --> 00:18:37.330	So, the first level of understanding or learning is to find out the features.
1.srt	00:18:39.960 --> 00:18:51.350	So, once I have these features then let us talk about what is machine learning and when I talk about the machine learning then I will come to deep learning.
1.srt	00:18:52.480 --> 00:18:55.650	So, for that let me try to find out.
1.srt	00:18:56.039 --> 00:18:59.930	Let me see that what is machine learning right.
1.srt	00:19:00.289 --> 00:19:05.410	So, what you have obtained so far given an object or given an image.
1.srt	00:19:05.950 --> 00:19:23.730	So, given an image or an object the image is converted into a set of vectorsinto a set of features where the features collected together is forming a feature vector f .
1.srt	00:19:23.730 --> 00:19:32.600	So, you find that if I have say 25 such features or I have a feature vector having 25 elements .
1.srt	00:19:33.470 --> 00:19:43.880	Then, this image is represented by a vector or by a point in a 25 dimensional feature space.
1.srt	00:19:45.500 --> 00:19:52.830	Now, for simplicity let me assume that this f is actually a 2 dimensional feature vector for simplicity.
1.srt	00:20:06.190 --> 00:20:14.019	Obviously, a shape cannot be represented by or any image cannot be represented by 2 dimensional feature vector accurately, but for simplicity I am doing So, if I have this two dimensional feature vector, let me put this feature vector feature components as component f 1 and component f 2.
1.srt	00:20:14.930 --> 00:20:17.210	So, f 1 f 2 gives you a feature vector.
1.srt	00:20:18.820 --> 00:20:29.759	Now if I have images of hordes, they will form a point distribution somewhere over here, say in my two dimensional space.
1.srt	00:20:30.630 --> 00:20:35.000	Similarly, if I have images of zebras, they are very similar right.
1.srt	00:20:35.370 --> 00:20:40.480	So, they can have a set of point cloud somewhere over here.
1.srt	00:20:42.480 --> 00:20:55.900	But if I have images of say apples and I compute the same similar feature vector similar features f 1 and f 2 for apples, they may form a set of points somewhere over here.
1.srt	00:20:57.059 --> 00:20:58.160	Now, why this distribution?
1.srt	00:20:59.059 --> 00:21:05.870	The distribution is because every apple is not identical, every horse is not identical.
1.srt	00:21:06.280 --> 00:21:07.810	every zebra is not identical.
1.srt	00:21:08.350 --> 00:21:15.660	So, for all those different pictures when I compute f 1 and f 2 they will not always give me unique values, but there will be a variation.
1.srt	00:21:16.610 --> 00:21:19.990	And because of this I get distribution of these feature vectors.
1.srt	00:21:21.300 --> 00:21:25.000	Now, what is the advantage of having such a kind of distribution?
1.srt	00:21:26.440 --> 00:21:31.980	The advantage isadvantage of having such a kind of feature vectors or descriptors.
1.srt	00:21:32.720 --> 00:21:37.560	The advantage is the moment I have a feature vector that means, my image is now represented.
1.srt	00:21:37.720 --> 00:21:39.340	by point in the feature space.
1.srt	00:21:40.610 --> 00:21:51.090	And given two points in the feature space, if I find that the distance between the two points is very large, I can immediately say that these two images are not similar they are different.
1.srt	00:21:52.090 --> 00:22:01.070	But given two points like this where the distance is very small, I can immediately say that these two images or these two objects are similar.
1.srt	00:22:01.070 --> 00:22:06.170	So, that is what you get the advantage that you get when I represent these as feature vectors.
1.srt	00:22:07.960 --> 00:22:09.010	Now, given an image.
1.srt	00:22:09.780 --> 00:22:17.770	I can have different types of picture vectors I said as I said the shape, color, texture and many other features.
1.srt	00:22:19.300 --> 00:22:22.220	Given an image I can directly compute a vector from that.
1.srt	00:22:22.920 --> 00:22:32.590	So, an image is typically of size m by n which has got m number of rows and n number of columns.
1.srt	00:22:33.700 --> 00:22:37.980	One way of vectorization is you take every column from this image.
1.srt	00:22:39.970 --> 00:22:50.960	So, I get 1 column having n number of elements, then I take the second column having again n number of m number of elements and concatenate with this.
1.srt	00:22:52.160 --> 00:23:05.230	So, first here I have the first column that is first m number of elements, here I have the second column second m number of elements and so on and that we continue and concatenate with this the last column.
1.srt	00:23:06.180 --> 00:23:12.350	So, you find that this entire image of size m by n is now converted.
1.srt	00:23:12.690 --> 00:23:19.900	2 and 1 dimensional vector, where this vector has m into n number of elements.
1.srt	00:23:20.779 --> 00:23:23.960	So, this whole image is now represented by a single vector.
1.srt	00:23:26.950 --> 00:23:34.829	Now, coming to what is the difference between our conventional machine learning and the deep learning.
1.srt	00:23:36.160 --> 00:23:45.970	In case of conventional machine learning techniques, what used to be that you decide that what are the features or what are the descriptors that are that are to be extracted from the input signal.
1.srt	00:23:47.000 --> 00:23:51.519	whether shape features, color features, texture features and what are those features.
1.srt	00:23:52.430 --> 00:23:58.829	So, accordingly you have a pre-processing technique and this pre-processing technique gives you the feature vectors.
1.srt	00:23:58.829 --> 00:24:04.339	And these feature vectors are inputted to your machine learning algorithms.
1.srt	00:24:04.339 --> 00:24:12.619	And for that we can have different types of machine learning algorithms, statisticalmachine like Bayes rules, Bayes classification rules.
1.srt	00:24:19.799 --> 00:24:25.710	I can have linear or non-linear classifier I can have support vector machines, we will talk about each of these in our later part later lectures.
1.srt	00:24:26.710 --> 00:24:32.250	So, I can have different types of classifiers, even I can have neural networks as classifiers.
1.srt	00:24:32.909 --> 00:24:38.849	So, this feature vectors are inputted to those classification algorithms or machine learning algorithms.
1.srt	00:24:39.879 --> 00:24:49.759	And for training the machine learning algorithm or for training the classifier, what you do is you feed a large number of feature vectors.
1.srt	00:24:50.190 --> 00:24:58.480	taken from known objects that means, the feature vectors I know that from from which object or from which class that feature vector has been computed.
1.srt	00:24:59.440 --> 00:25:09.180	And using this knowledge you try to train your classifiers whether it is neural network, it is base classifier, it is a support vector machine or whatever it is.
1.srt	00:25:09.930 --> 00:25:13.069	And this is something which is very similar to what we do.
1.srt	00:25:21.449 --> 00:25:27.409	Coming to our previous the first example when you are shown the image cave painting, Ajanta cave painting it was also told that it was Ajanta cave painting.
1.srt	00:25:27.819 --> 00:25:30.849	So, I knew what that object is or what that image is.
1.srt	00:25:31.159 --> 00:25:39.549	So, in the same manner you train your machine learning algorithms, but the feature vectors are pre computed by some pre processingmodules.
1.srt	00:25:39.549 --> 00:25:53.769	In deep learning what we do is no I will not have a pre processing module, I will directly input the raw signal to our machine learning algorithm.
1.srt	00:25:54.259 --> 00:26:02.799	So, the machine learning algorithm will not only learn the classes, it will also learn which feature to look for.
1.srt	00:26:04.609 --> 00:26:11.209	And usually these all the machine learning deep learning algorithms that we will be talking about they are all neural networks.
1.srt	00:26:11.379 --> 00:26:18.899	So, effectively what you are doing is you are adding additional layers in your neural network to learn the features as well.
1.srt	00:26:19.519 --> 00:26:24.969	So, typically that is the difference between your traditional machine learning and the deep learning algorithms.
1.srt	00:26:26.819 --> 00:26:33.019	Now, there are two types of deep learning algorithms, one is discriminative learning, one is generative learning.
1.srt	00:26:33.619 --> 00:26:43.079	In case of discriminative learning what you try to do is, once you are shown a set of images or set of objects, you try to discriminate among those objects.
1.srt	00:26:43.250 --> 00:26:50.679	That means, given the image of a dog, I try to say that it is a dog, it is not a cat right.
1.srt	00:26:55.889 --> 00:27:22.649	So, basically as I said that every image or every object If, I represent as a point distribution given by p x in case of discriminative learning or discriminating model given this distribution x p x and given the set of classes say y I try to find out what is the posterior a posteriori probability p of y given x that is given an input what is the probability that it belongs to certain class that is what is discriminative model.
1.srt	00:27:24.429 --> 00:27:25.750	In case of generative model.
1.srt	00:27:26.399 --> 00:27:35.509	So, it ismotivated bywhat was told by Richard Feynman that what I cannot create I do not understand.
1.srt	00:27:36.679 --> 00:27:48.219	That is it is not only that you will be able to classify or discriminate, it you should also be able to recreate what you learn and that is what is your generative model.
1.srt	00:27:49.809 --> 00:27:50.759	So, how do you do this?
1.srt	00:27:50.789 --> 00:27:57.019	You collect a large amount of data in the same domain and then train a model to generate data like it.
1.srt	00:27:57.990 --> 00:28:01.449	We will also talk about this in our future lectures.
1.srt	00:28:03.279 --> 00:28:06.709	Then what are the challenges in deep learning or the challenges in machine learning?
1.srt	00:28:07.569 --> 00:28:15.419	When you look at an object, you can look at object from various angles and from various angles or various viewing angles, it will appear to be different.
1.srt	00:28:16.179 --> 00:28:25.679	So, same object can have different views and from those different views we have to identify the object or we have to classify the objects that is one of the challenge.
1.srt	00:28:30.679 --> 00:28:35.619	They can may be available in different poses There may be illumination variation, there may be inter class variation.
1.srt	00:28:35.619 --> 00:28:47.509	Say for example, here who will say that this is a chair though all these are chair classes.
1.srt	00:28:48.159 --> 00:29:01.719	So, I can also have intra class variation that is another challenge in this deep learning algorithms, but because our deep learning algorithm has to work even in presence of intra class variation.
1.srt	00:29:03.549 --> 00:29:13.440	There may be distortions and occlusions, may be part of the object is visible, the majority of the object is not visible, it might be present in a distorted fashion and so on.
1.srt	00:29:14.109 --> 00:29:17.000	So, those are all challenges of the deep learning algorithm.
1.srt	00:29:18.349 --> 00:29:29.279	And coming to the power of deep learningtechniques what we can achieve is we can even able to synthesize high resolution images and this is what is done through generativemodel.
1.srt	00:29:35.959 --> 00:29:41.399	From a low resolution image, we can get a we can create super resolution image.
1.srt	00:29:41.399 --> 00:29:47.759	Given any sketch of image any sketch of an object I can generate I can synthesize a photograph of that object.
1.srt	00:29:48.659 --> 00:29:52.139	Given a semanticsegmented output I can have a real looking image.
1.srt	00:29:52.969 --> 00:29:59.719	So, all these are possible using the recent modern deep learning techniques.
1.srt	00:29:59.719 --> 00:30:05.949	Similarly, we can alsocompose videos with different tiles.
1.srt	00:30:08.409 --> 00:30:09.729	different styles.
1.srt	00:30:10.839 --> 00:30:24.189	So, all these are possible using modern deep learning techniques and that are multiple applications like in medical image processing, in object recognition, in speech recognition and so on.
1.srt	00:30:25.439 --> 00:30:34.889	So, we will talk about all these different aspects of these deep learning techniques insubsequent lectures of this course.
1.srt	00:30:35.379 --> 00:30:43.959	I hope you will be able to learn the content of these deep learnings and will be able to apply it in real life problems.
1.srt	00:30:44.219 --> 00:30:44.529	Thank you.
2.srt	00:00:00.610 --> 00:00:28.800	Hello, welcome to the NPTEL online certification course on deep learning .
2.srt	00:00:33.469 --> 00:00:44.700	In today's lecture, we will try to find out how do we capture the information or the descriptions of from the signals that we capture from the real world.
2.srt	00:00:47.030 --> 00:00:56.750	In our previous introductory lecture, we had given we have shown you the images of a horse and a zebra.
2.srt	00:00:58.379 --> 00:01:07.959	And then we have told that to differentiate between these two images that is to identify that which is the horse and which is the zebra.
2.srt	00:01:08.939 --> 00:01:09.180	zebra.
2.srt	00:01:09.180 --> 00:01:31.909	We can extract two types of descriptors, one is the shape descriptor that is the shape of the horse and the shape of the zebra and the second one is the region descriptor which means that what is the content of or what is the color intensity and texture of the body of the horse and the body of the zebra.
2.srt	00:01:33.099 --> 00:01:39.349	So, if you look at the shape of these two animals the horse and the zebra.
2.srt	00:01:39.880 --> 00:01:44.040	zebra, you find that the shape boundary is more or less same.
2.srt	00:01:44.820 --> 00:02:00.030	That means, this shape information of the boundary information does not give you the sufficient description or sufficient information by which you can differentiate between a horse and a zebra.
2.srt	00:02:01.150 --> 00:02:13.790	But when you look at the entire figure that is along with the shape information, when we also consider the information of the color, the information of intensity.
2.srt	00:02:13.990 --> 00:02:21.069	the information of texture, then only I can differentiate or I can say that which is the horse and which is the zebra.
2.srt	00:02:22.310 --> 00:02:33.430	So, that makes two things very clear that for images or for objects that we see in the real world, we can have two types of information.
2.srt	00:02:33.670 --> 00:02:46.060	One is the shape information or the boundary information and the other kind of information is the region information which gives you what is the intensity or what is the color or what is the texture.
2.srt	00:02:47.229 --> 00:03:03.299	And, when we combine both these informations that is the shape information, the color information, the intensity information and the texture information all of them together can identify a particular object or a particular animal.
2.srt	00:03:04.479 --> 00:03:17.049	So, in today's lecture what we are going to talk about that how we can obtain the descriptors or features from the signals that we obtain from the real world.
2.srt	00:03:18.419 --> 00:03:25.859	These signals can be visual signals as in the form of images or what we can see through our eyes.
2.srt	00:03:26.599 --> 00:03:43.809	These signals can also be audio signals that we can hear and signals like the speech signals or voice signals using which I can differentiate among different speakers, I can also understand what is being spoken.
2.srt	00:03:44.619 --> 00:03:47.759	The applications can be speaker identification.
2.srt	00:03:48.569 --> 00:03:51.969	speech to text conversion and many such applications.
2.srt	00:03:53.019 --> 00:04:05.969	So, firstly I will talk about the visual signals or how do I extract the different types of features or different types of descriptors from a visual signal.
2.srt	00:04:05.969 --> 00:04:17.930	And these descriptors will can be of two types as we have already said that the descriptors can be obtained from the boundary which tells you what is the boundary property.
2.srt	00:04:18.689 --> 00:04:30.870	It can also be obtained from the region which tells you what is the region property that includes the intensity, that includes the color and that includes the texture properties.
2.srt	00:04:31.910 --> 00:04:40.589	So, firstly let us see that how we can obtain the different types of boundary features or how we can extract the boundary properties.
2.srt	00:04:41.629 --> 00:04:51.230	So, for that I will take a very simple shape .
2.srt	00:04:51.230 --> 00:04:52.740	So, I take a boundary shape .
2.srt	00:04:53.099 --> 00:05:17.629	something of this form, let me change the size of the pen .
2.srt	00:05:24.579 --> 00:05:29.139	So suppose I have a shape of this form which is a closed boundary.
2.srt	00:05:30.729 --> 00:05:41.800	Now, find that though this closed boundary I have shown it as a continuous curve, but you remember that we are talking about the discrete signals or digital signals.
2.srt	00:05:42.560 --> 00:05:55.349	So, this curve is not really a closed curve or a continuous curve rather this curve is consists of a set of discrete points.
2.srt	00:05:55.439 --> 00:05:56.629	So, something like this.
2.srt	00:05:57.319 --> 00:06:01.189	I have a set of points on this discrete curve.
2.srt	00:06:03.149 --> 00:06:11.560	So, one of the ways in which such an arbitrary boundary can be represented is in the form of a polygon.
2.srt	00:06:13.009 --> 00:06:27.269	The way we can represent an arbitrary shaped boundary in the form of a polygon is that we can recursively subdivide that arbitrary shape into a number of segments.
2.srt	00:06:28.550 --> 00:06:41.300	So, the way we can do this is suppose I take two points on this boundary which are at maximum distance.
2.srt	00:06:42.420 --> 00:06:52.830	So, the first division will be that I draw a straight line passing to these points on the boundary which are maximum at maximum distance.
2.srt	00:06:54.019 --> 00:06:58.980	So, once I do that this particular chord or this particular straight line.
2.srt	00:06:59.379 --> 00:07:03.550	sub divides this boundary into two sub boundaries.
2.srt	00:07:04.120 --> 00:07:06.280	One sub boundary is in the upper part.
2.srt	00:07:06.540 --> 00:07:16.580	So, let me call it sub boundary A and the other one is on the lower part let me call it as sub boundary B .
2.srt	00:07:16.620 --> 00:07:27.400	So, at the next level we can again subdivide both these sub boundaries and for that we have to use a criteria.
2.srt	00:07:31.189 --> 00:07:37.839	The criteria can be that I compute the perpendicular distance of different points on these boundary segments from this straight line.
2.srt	00:07:38.579 --> 00:07:45.399	So, I can find out given a point over here, I can try to compute what is the perpendicular distance of this point on this boundary.
2.srt	00:07:46.220 --> 00:07:52.879	I can also compute what is the perpendicular distance of this pointon the boundary from this straight line.
2.srt	00:07:54.220 --> 00:08:01.459	And, I find out a point on this boundary which is at maximum distance from this line segment.
2.srt	00:08:02.339 --> 00:08:08.410	So, I can identify that maybe this is a point on the boundary which is at maximum distance.
2.srt	00:08:10.500 --> 00:08:18.170	So, once I identify this point then this point subdivides this uppersub boundary into two parts.
2.srt	00:08:18.170 --> 00:08:26.480	So, one part is starting from this point to this point, the other part is starting from this point to this point.
2.srt	00:08:27.220 --> 00:08:32.539	So, let me name these points the initial points let me name this as P and Q.
2.srt	00:08:33.750 --> 00:08:44.519	this point is S. So, the next subdivision after doing the next subdivision the vertices of the polygon that I get is something like this.
2.srt	00:08:45.769 --> 00:09:06.910	Similarly coming to the lower part of the boundary maybe this is a point which is at maximum distance from the straight line P Q and in that case this point let me call it point R. So, this point R subdivides this lower part of the boundary segment P Q into two more segments.
2.srt	00:09:07.519 --> 00:09:10.059	1 is P R the other one is R Q.
2.srt	00:09:10.980 --> 00:09:15.240	So, the next level of polygonal representation is by this.
2.srt	00:09:17.679 --> 00:09:32.440	So, you find that up to this I have got a polygon P S Q R. So, this is the polygonal representation at this level of this arbitrary shaped boundary that we had.
2.srt	00:09:33.950 --> 00:09:36.090	So, this process can be repeated recursively.
2.srt	00:09:37.669 --> 00:09:38.940	This may be another.
2.srt	00:09:39.559 --> 00:09:41.959	of this arbitrary shaped boundary.
2.srt	00:09:43.399 --> 00:09:57.129	So, once I get such a polygonal representation from this polygon I can try to extract different types of boundary features simply from the properties of the polygon.
2.srt	00:09:58.129 --> 00:10:12.579	So, this is one way of polygonization of an arbitrary boundary and once I have such polygonal approximation representation from this polygonal representation I can obtain different types of descriptors or.
2.srt	00:10:12.839 --> 00:10:19.559	I can also obtain different types of descriptors from this boundary segments, right.
2.srt	00:10:19.769 --> 00:10:24.569	So, here you find that I have different boundary segments, starting from this vertex to this vertex.
2.srt	00:10:24.569 --> 00:10:34.139	This is one boundary segment from this vertex to this vertex I have another boundary segment from this vertex to this vertex I have another boundary segment.
2.srt	00:10:34.479 --> 00:10:40.259	So, I can have different techniques to find out what is the shape of these different boundary segments.
2.srt	00:10:46.679 --> 00:10:51.479	So, the properties of the polygons as well as the properties of these boundary segments can give me important information about the shape of the boundary.
2.srt	00:10:52.269 --> 00:10:57.709	So, this is one kind of descriptor or one kind of features that we can obtain.
2.srt	00:10:57.709 --> 00:11:04.749	The next kind of features that we can obtain is what is known as signature.
2.srt	00:11:06.139 --> 00:11:22.389	So, to see what is a signature let me take a very simple shape which is a square.
2.srt	00:11:29.139 --> 00:11:33.269	So, I take a square something like this.
2.srt	00:11:37.339 --> 00:11:38.139	What is signature?
2.srt	00:11:38.969 --> 00:11:52.409	Signature is the plot of the distance of different boundary points from the centroid of this shape taken in various directions or in various orientations.
2.srt	00:11:53.899 --> 00:12:02.969	So, as I have to compute or I have to find out the distance of different boundary points from the centroid of the shape in different orientations.
2.srt	00:12:03.249 --> 00:12:05.149	So, I have to have a reference line.
2.srt	00:12:05.829 --> 00:12:09.639	So, let me assume that my reference line is this.
2.srt	00:12:12.079 --> 00:12:15.709	So, this is the centroid and my reference line is this one.
2.srt	00:12:17.389 --> 00:12:23.159	What I do is I compute the distance of the boundary point from the centroid.
2.srt	00:12:25.429 --> 00:12:36.459	which is oriented at an angle theta from the reference line and suppose this distance I call as d theta .
2.srt	00:12:36.459 --> 00:12:53.189	So, what I plot is the distance d theta against theta as theta varies from 0 to .
2.srt	00:12:53.849 --> 00:13:07.439	360 degree ok. And in this case you find that when theta is 0 as my reference line over is over here the distance will be one of the minimas.
2.srt	00:13:08.249 --> 00:13:22.019	So, I start from here and when theta is 45 degree as I have taken a square when theta is 45 degree that means, I am computing the distance of this vertex of the square from the centroid this distance will be maximum.
2.srt	00:13:23.029 --> 00:13:23.999	So, I will have.
2.srt	00:13:24.249 --> 00:13:37.289	a d theta versus theta plot which will be something like this and it will go on up to 360 degree.
2.srt	00:13:38.179 --> 00:13:52.999	So, I will have a minima at 0, I will have a maxima at 45 degrees, I will have another minima at 90 degree, I will have a maxima at 135 degrees and so on.
2.srt	00:13:56.659 --> 00:14:05.919	So, such of d theta versus theta gives you important information about the nature of the boundary or the shape of the boundary.
2.srt	00:14:06.719 --> 00:14:19.019	So, this is a kind of plot which I am getting for a square figure if the figure instead of being square it is something else then naturally naturally the nature of the plot will also be different.
2.srt	00:14:19.669 --> 00:14:26.619	So, the shape of the plot or the nature of the plot also gives me important information about the shape of the boundary.
2.srt	00:14:27.079 --> 00:14:32.579	So, by processing this signature I can also obtain boundary descriptors.
2.srt	00:14:32.879 --> 00:14:38.009	So, this is another way of obtaining the boundary descriptors.
2.srt	00:14:39.559 --> 00:14:44.019	The next type of features that we can obtain is what is known as Fourier descriptor.
2.srt	00:14:46.079 --> 00:14:52.699	So, to obtain the Fourier descriptor I hope all of you know what is a Fourier transformation or Fourier coefficients.
2.srt	00:14:57.529 --> 00:15:04.189	So, to obtain Fourier descriptor I represent the boundary points the points on the boundary as a sequence of say complex numbers.
2.srt	00:15:04.799 --> 00:15:05.649	Let us see how we do it.
2.srt	00:15:07.089 --> 00:15:21.579	So, I assume a two-dimensional space and suppose I have a closed boundary something like this.
2.srt	00:15:32.529 --> 00:15:37.360	As I said before that this boundary consists of a number of discrete points .
2.srt	00:15:37.389 --> 00:15:57.289	So, I take any points say kth point on this boundary segment and this kth point I call it say S k which have two components one is in the x dimension direction and other one is in the y direction.
2.srt	00:16:04.289 --> 00:16:07.509	So, this k will have two components which is x k and I represent this as say complex number.
2.srt	00:16:07.859 --> 00:16:20.750	So, j times y k. So, when I consider all these different points on this boundary, what I get is a sequence of such complex numbers.
2.srt	00:16:20.789 --> 00:16:24.819	So, you remember that all these points are to be represented as a sequence.
2.srt	00:16:36.049 --> 00:17:02.529	So, I get a sequence of complex numbers which is given by this x k is equal to x k plus x k plus times y k where k may vary from say 0 to capital N minus 1 where I have total number of points on this boundary which is capital N. So, once I have this what I can do is this sequence of numbers can be represented by their Fourier coefficients.
2.srt	00:17:05.049 --> 00:17:08.559	So, for that what I have to do is I have to take the Fourier transformation of this sequence of numbers.
2.srt	00:17:09.259 --> 00:17:25.329	So, I had sequence of numbers S k given by X k plus j times Y k, k varying from 0 to capital N minus 1.
2.srt	00:17:27.220 --> 00:17:35.940	And what I do is I take the Fourier transformation and you know the Fourier transformation is given by A u is equal to S k.
2.srt	00:17:36.839 --> 00:17:43.349	e to the power minus j 2 pi u k by n right.
2.srt	00:17:44.180 --> 00:17:54.150	Take the sum of this over k is equal to 0 to capital N minus 1.
2.srt	00:17:56.339 --> 00:18:04.049	And this I will get coefficients I will get for all values of u varying from 0 to capital N minus 1.
2.srt	00:18:08.309 --> 00:18:16.259	So, as I have capital N number of points in my sequence, I will also have capital N number of coefficients.
2.srt	00:18:17.400 --> 00:18:24.650	And the magnitudes of these coefficients represent or give me useful information of the shape of the boundary.
2.srt	00:18:39.850 --> 00:18:41.259	Now, you can also find out that instead of considering all the N number of coefficients, if I consider say lesser number of coefficients, kind of effect I can have.
2.srt	00:18:41.830 --> 00:19:05.540	Suppose I want to consider p number of coefficients that means, I want a u where u varies from 0 to capital P minus 1 where p is less than capital N. Then what kind of effect this truncation of the coefficients you will have.
2.srt	00:19:06.250 --> 00:19:15.910	So, to see the to see this truncation of the effect of the truncation of the coefficients, I can take the inverse Fourier transformation to reconstruct.
2.srt	00:19:16.779 --> 00:19:21.259	the boundary with which I have started for which I have taken the forward transformation.
2.srt	00:19:22.890 --> 00:19:31.619	So, if you do that you find that if we had started with say a square shape something like this.
2.srt	00:19:34.750 --> 00:19:47.450	Suppose this square shape had capital N number of boundary points and from this capital N number of boundary points we have also obtained capital N number of Fourier coefficients.
2.srt	00:19:47.589 --> 00:19:48.619	Then what I have done is.
2.srt	00:19:49.190 --> 00:19:56.600	this capital N number of Fourier coefficients out of this I have considered say first p number of coefficients.
2.srt	00:19:58.940 --> 00:20:16.019	And if you know the Fourier transformation, you know that the low order coefficients Fourier coefficients gives you some information about the trend of the signal, whereas high order Fourier coefficients gives you the detailed information of the signal.
2.srt	00:20:21.800 --> 00:20:31.310	So, it may so happen that if I consider say p equal to 2 that is I consider only first two Fourier coefficients a u where u is equal to 0 and 1 .
2.srt	00:20:31.310 --> 00:20:41.730	So, only with these coefficients I want to reconstruct or find out the inverse Fourier transformation for reconstruction of the boundary .
2.srt	00:20:41.730 --> 00:20:51.920	So, for that my inverse Fourier transformation expression will be S k is equal to a u e to the power g .
2.srt	00:20:52.140 --> 00:21:19.680	2 pi u k upon capital N sum of this over u is equal to 0 to capital P minus 1 and k will vary from 0 to capital N minus 1 .
2.srt	00:21:22.260 --> 00:21:30.670	So, what we are doing is since I had capital N number of points on the boundary, I am reconstructing capital N number of points through this inverse Fourier transformation.
2.srt	00:21:31.070 --> 00:21:52.500	But while doing so, the number of Fourier coefficients that I am considering is not N number of Fourier coefficients, rather p number of Fourier coefficients where p is lesser than n. So, given this if I consider p equal to 2 that is if I consider only the Fourier coefficients A u 0.
2.srt	00:21:52.800 --> 00:22:17.250	and u 1 for reconstruction or in the inverse Fourier transformation, then maybe the kind of shape that I will reconstruct will be something like this, which will be a circular shape.
2.srt	00:22:19.000 --> 00:22:23.250	Because as I said that low order coefficients gives you only trend of the signal.
2.srt	00:22:24.170 --> 00:22:27.170	So, this But, the high order coefficients gives you the details of the signal.
2.srt	00:22:28.100 --> 00:22:34.170	So, in a square shape the details means the presence of all these corners of the vertices.
2.srt	00:22:34.830 --> 00:22:41.590	So, as I have truncated all the high order coefficients this detailed information in the reconstructed signal is lost.
2.srt	00:22:42.690 --> 00:22:53.460	If I increase the value of p say from 2 if I go to 10 where I assume say p n is equal to something like.
2.srt	00:22:53.740 --> 00:22:55.539	say128.
2.srt	00:22:57.410 --> 00:23:05.119	So, against 128 if I take only 10 coefficients I will get slightly better reconstruction.
2.srt	00:23:07.769 --> 00:23:14.000	So, which is like this it is not a perfect square neither a perfectcircle.
2.srt	00:23:14.740 --> 00:23:19.549	So, I get some detailed information present the reconstructed signal.
2.srt	00:23:20.599 --> 00:23:28.549	Only when I consider all these 128 coefficients in the reconstruction or p varies u varies from 0 to 0 to 0.
2.srt	00:23:29.110 --> 00:23:38.620	127 in this inverse Fourier transformation expression, then only I will get back my original shape which is a square.
2.srt	00:23:40.720 --> 00:23:53.049	So, all these Fourier coefficients can also give you some information ofor important information of the boundary of a bound shape of the boundary.
2.srt	00:24:00.740 --> 00:24:11.520	So, over here I have obtained the different types of descriptors that I can get firstly going for a polygonal representation.
2.srt	00:24:12.200 --> 00:24:30.740	When I go for polygonal representation then from the polygon itself I can compute some descriptors or when I go for polygonal representrepresentation then you find that the different vertices of the polygon that I get those vertices break the original boundary into a number of some boundaries.
2.srt	00:24:31.350 --> 00:24:36.610	So, I can also obtain some shape information of all those sub boundaries.
2.srt	00:24:37.740 --> 00:24:49.360	Then I can have what we have talked about is the signature and the nature of the signature or the shape of the signature gives you inform a important information of the boundary.
2.srt	00:24:50.310 --> 00:24:56.740	Then we have also talked about the Fourier descriptor which also gives you the important information of the shape of the boundary.
2.srt	00:25:02.070 --> 00:25:05.620	Now, let me go for some further analysis of the shape which is through statistical moments.
2.srt	00:25:07.040 --> 00:25:25.830	So, what we have said is that say for example, I had an arbitrary shape something of this form and I had a polygonal representation through a polygonal representation a segment of the shape which is this ok.
2.srt	00:25:26.040 --> 00:25:33.100	So, one is I have this edge of the polygon, I also have this segment of the boundary.
2.srt	00:25:33.930 --> 00:25:42.540	So, I can compute the shape of this boundary, I can have different information about the shape of the boundary through statistical moments.
2.srt	00:25:43.560 --> 00:25:44.520	So, how I can do it?
2.srt	00:25:45.300 --> 00:25:58.640	If I just put this shape like this, so I have a shape of this form right, this is a sub or segment of the arbitrary shape.
2.srt	00:26:05.230 --> 00:26:10.230	What I can do is this straight line I rotate So, that I rotate it by an angle theta in the clockwise direction.
2.srt	00:26:10.530 --> 00:26:17.930	So, that this straight line chord or which is the edge one of the edges of the polygon that becomes horizontal.
2.srt	00:26:18.690 --> 00:26:25.300	So, if I do that I will have a boundary something like this.
2.srt	00:26:25.420 --> 00:26:26.770	So, this is a boundary segment.
2.srt	00:26:28.280 --> 00:26:32.680	Using this I can represent it in the form of a function.
2.srt	00:26:39.860 --> 00:27:02.790	So, I can put this as r. So, and this function can be represented as g r. So, what I am doing is I am representing this boundary or the boundary segment as a function g r. Obviously, this will not be a continuous function because as I said before that I actually have a set of discrete points on this boundary segment .
2.srt	00:27:12.660 --> 00:27:13.960	So, if I have if I represent this variable r by set of discrete variables say r i, this boundary is represented by a function g r i.
2.srt	00:27:15.720 --> 00:27:27.770	Now, if I normalize this boundary, normalize it by the area under this segment in that case this g r i is nothing, but a histogram.
2.srt	00:27:28.840 --> 00:27:42.510	So, what I can say is that after normalization this g r i tells me what is the frequency of occurrence of this discrete variable r i in this case.
2.srt	00:27:42.870 --> 00:27:44.950	in this particular scenario.
2.srt	00:27:44.950 --> 00:27:47.810	So, it is a frequency of occurrence.
2.srt	00:27:48.770 --> 00:27:56.190	So, once I have this frequency of occurrence, then I can compute different types of statistical moments.
2.srt	00:27:57.720 --> 00:28:13.800	So, a statistical moment of order k is given by this r i is a minus mu to the power k times pi r i.
2.srt	00:28:15.040 --> 00:28:24.400	where P r i is the frequency of occurrence or probability of occurrence of i take the summation of this over all i.
2.srt	00:28:26.090 --> 00:28:45.640	So, this is a statistical moment of order k. So, I can put it as mu k sorry I will not put it as mu k. So, this one what I will do is instead of mu k.
2.srt	00:28:45.950 --> 00:28:56.120	as I have used mu to represent the mean let me call it say sigma k .
2.srt	00:28:56.120 --> 00:29:04.350	So, sigma k is the statistical moment of order k given this particular distribution.
2.srt	00:29:04.350 --> 00:29:10.190	And you find that for different values of k I can get different types of shape information.
2.srt	00:29:10.190 --> 00:29:17.400	Obviously, in this case mu being the mean mu is nothing, but r i times p r i .
2.srt	00:29:18.040 --> 00:29:20.240	take the sum of this over all i.
2.srt	00:29:22.270 --> 00:29:26.960	So, here you find that if I take the value of k is equal to 2 right.
2.srt	00:29:27.170 --> 00:29:28.870	So, what I get is the variance.
2.srt	00:29:30.510 --> 00:29:35.390	If I take value of k to be equal to 3, I get third order moment.
2.srt	00:29:36.530 --> 00:29:46.070	Second order moment ispopularly known as the variance that tells you what is the spread of this distribution.
2.srt	00:29:47.830 --> 00:30:00.280	If The second order moment is very high that means, the distribution will be of this form, it will be spread higher if the value of sigma square is small my distribution will be something like this.
2.srt	00:30:02.140 --> 00:30:07.650	The third order moment tells you about the skewness or the symmetry of the distribution about its mean.
2.srt	00:30:08.490 --> 00:30:17.590	Similarly, all moments of different orders captures some information of the shape of this distribution or in this particular case.
2.srt	00:30:18.010 --> 00:30:28.270	it captures the shape of this sub segment of this particular boundary .
2.srt	00:30:30.600 --> 00:30:47.090	So, till now what we have covered is the different types of boundary information that we can obtain from a given shape .
2.srt	00:30:47.090 --> 00:30:49.190	So, with this I conclude .
2.srt	00:30:49.460 --> 00:30:50.660	this part of the lecture.
2.srt	00:30:51.780 --> 00:31:04.470	In the next lecture, I will talk about how we can obtain the different region descriptors or the region information including intensity, color and texture.
2.srt	00:31:05.200 --> 00:31:05.520	Thank you.
3.srt	00:00:00.610 --> 00:00:28.030	Hello, welcome to the NPTEL online certification course.
3.srt	00:00:31.460 --> 00:00:32.460	on deep learning.
3.srt	00:00:34.219 --> 00:00:53.750	In the previous lecture, we have discussed about the ways in which we can obtain the boundary descriptor or boundary features of any given shape, which tells you what is the shape of the boundary or capture some information of the shape of the boundary.
3.srt	00:00:55.150 --> 00:01:01.560	So, in the previous class, I showed you these two figures one of the horse and one of the zebra.
3.srt	00:01:02.469 --> 00:01:09.790	And, we have said that though the shape of those two animals horse and the zebra are similar.
3.srt	00:01:10.609 --> 00:01:18.650	So, these shape information is not really sufficient to distinguish between a horse and a zebra.
3.srt	00:01:19.939 --> 00:01:31.659	So, to distinguish between these two animals horse and zebra, we need the description of the shape which is obtained from the boundary of the figures.
3.srt	00:01:32.129 --> 00:01:41.340	In addition, we also need information of what is the color, what is the texture and what is the intensity.
3.srt	00:01:42.390 --> 00:01:50.699	So, these are the descriptors or the features which are known as region descriptors or region features.
3.srt	00:01:51.729 --> 00:02:01.079	So, in the previous class, we have talked about the boundary features, how we can obtain the boundary descriptors or boundary features from any arbitrary shape.
3.srt	00:02:02.340 --> 00:02:03.390	In today's lecture.
3.srt	00:02:03.859 --> 00:02:07.040	I am going to discuss about the region features.
3.srt	00:02:07.750 --> 00:02:16.689	So, how the intensity, the texture and the color that description can be obtained what are the techniques for that.
3.srt	00:02:34.000 --> 00:02:36.170	In addition as we said in the previous class that machine learning or deep learning not necessarily is concerned about only the visual signals, it is also concerned or applicable for understanding the audio signals.
3.srt	00:02:37.110 --> 00:02:58.689	So, for that I also need to understand how we can extract the discriminating features of the discriminating descriptors from the audio signals using which I can different I can have different applications like speech car identification, speech to text conversion and all that.
3.srt	00:03:05.620 --> 00:03:06.650	So, firstly I will talk about the region descriptors, how we can obtain region descriptors.
3.srt	00:03:07.650 --> 00:03:16.360	So, as we said before that when we talk about region descriptors, I am concerned about extraction of three types of information.
3.srt	00:03:17.330 --> 00:03:28.259	One of the information that I want to obtain from the figure is what is the intensity or the intensity profile.
3.srt	00:03:28.900 --> 00:03:34.509	So, this is one of the information of the region that I want to capture or I want to obtain.
3.srt	00:03:40.610 --> 00:03:41.500	The second kind of information that I will also be interested in is what is the texture.
3.srt	00:03:44.780 --> 00:03:53.150	So, texture information is also important to distinguish between two different figures or among different figures.
3.srt	00:03:54.110 --> 00:04:04.080	Similarly, the third kind of information that will be interested to obtain is what is the color of the particular object or the particular region.
3.srt	00:04:05.220 --> 00:04:11.090	So, in region descriptor extraction, we are mainly concerned about these three quantities.
3.srt	00:04:11.460 --> 00:04:14.160	the intensity, the color and the texture.
3.srt	00:04:14.890 --> 00:04:22.810	So, we will talk about what are the different ways in which we can obtain these three different types of informations.
3.srt	00:04:23.800 --> 00:04:26.379	So, I will go to them one by one.
3.srt	00:04:29.069 --> 00:04:31.000	So, how do I obtain the intensity?
3.srt	00:04:31.670 --> 00:04:42.310	You find that over here I have shown a picture and on the right hand side what I have is what is the histogram or intensity histogram.
3.srt	00:04:43.310 --> 00:04:47.750	So, before going into that let me define what is meant by intensity histogram.
3.srt	00:04:49.900 --> 00:05:04.530	We told earlier that if I have a black and white image or a grayscale image like this, then at every point or every pixel in the image, the intensity is quantized by 8 bit binary number.
3.srt	00:05:05.010 --> 00:05:12.490	So, because it is 8 bit number, so I can have an intensity at any pixel varying from 0 to 255.
3.srt	00:05:13.640 --> 00:05:25.330	So, the minimum intensity level or very dark pixel is having an intensity value 0 and a white pixel or having an intensity which is maximum the intensity value is 255.
3.srt	00:05:26.420 --> 00:05:32.000	So, what I say the way a histogram is defined is like this.
3.srt	00:06:13.689 --> 00:06:24.730	If I have take an intensity value say i then histogram h i tells me that how many times this intensity i appears within the given image or in other words h i tells me the number n i that is how many pixels within the image have intensity value h i if i normalize this histogram that means if i put it as h i is equal to n i by capital N, where capital N is the total number of pixels in the given image and n i is the number of pixels having intensity value i.
3.srt	00:06:25.819 --> 00:06:40.870	So, this actually tells you that what is the frequency of occurrence of intensity level i within the given image or this is nothing but what is the probability of a pixel having an intensity value i.
3.srt	00:06:41.680 --> 00:06:43.550	So, when I normalize the histogram.
3.srt	00:06:43.600 --> 00:06:50.390	histogram, the normalized histogram also gives me the intensity probability distribution.
3.srt	00:06:51.710 --> 00:07:03.210	So here you find that in this particular image, the intensity values, most of the pixels are having intensity values which are on the lower side.
3.srt	00:07:03.720 --> 00:07:14.640	So on this side I have intensity 0, on this side I have intensity 255 that is the maximum intensity value and in between the intensity values changes accordingly.
3.srt	00:07:15.199 --> 00:07:15.939	as per this scale.
3.srt	00:07:16.930 --> 00:07:33.319	So, this histogram says that most of the pixels as over here the h i value for i within a small region over here is quite high compared to the frequency over here where the intensity is high, here the intensity is low.
3.srt	00:07:34.090 --> 00:07:46.439	So, for lower intensity the h i is high that indicates that most of the pixels within this image have intensity value which are very low that is.
3.srt	00:07:46.920 --> 00:07:54.430	the image is very dark and that is quite obvious by looking at the nature of this image.
3.srt	00:07:54.500 --> 00:08:18.060	Now, as against this if I take the next image here, here you find that the histogram, the intensity values over here may be something around 70 or so, it is in between 50 and 100, the probability of occurrence.
3.srt	00:08:18.489 --> 00:08:24.309	or the frequency of occurrence of intensity values around 70 is very high compared to other two.
3.srt	00:08:25.449 --> 00:08:33.490	This is as against the previous one, where the intensity values were maximum maximum probability at intensity values near about 0.
3.srt	00:08:34.899 --> 00:08:37.309	And you see that what is the effect of that?
3.srt	00:08:38.519 --> 00:08:42.589	This image appears to be brighter than the previous image that we have shown.
3.srt	00:08:43.969 --> 00:08:50.459	So that clearly says that this histogram gives you very important information.
3.srt	00:08:50.860 --> 00:08:57.929	about the intensity distribution within the given image or within a given region.
3.srt	00:08:59.049 --> 00:09:16.600	So, as we have extracted the shape information or the shape descriptors in our previous class, in this class we are going to describe discuss about the region property extraction and this intensity distribution is one of the important region properties.
3.srt	00:09:22.000 --> 00:09:26.569	And it is clearly shown that this intensity distribution is captured is in is captured within what is known as intensity histogram.
3.srt	00:09:27.579 --> 00:09:38.509	So, based on the nature or shape of the intensity histogram, we can estimate the different descriptors, we can find out different intensity descriptors.
3.srt	00:09:39.500 --> 00:09:48.659	So, a very important approach for intensity distribution extraction is using the histogram shape.
3.srt	00:09:53.049 --> 00:10:02.559	So, similarly over here if I have a color image as we said earlier that for color images we have three different planes right.
3.srt	00:10:03.370 --> 00:10:08.599	One of the plane is a red plane, the other one is green plane and the third one is blue plane.
3.srt	00:10:09.679 --> 00:10:16.620	So, here in this particular image you find that the color image which is given over here.
3.srt	00:10:17.519 --> 00:10:22.109	If I take the histogram of the red plane the histogram shape is something like this.
3.srt	00:10:24.059 --> 00:10:33.099	So, this tells you that how strong or what is the distribution of the strength of the red color component within this image.
3.srt	00:10:35.169 --> 00:10:37.659	This is the histogram of the green component.
3.srt	00:10:37.819 --> 00:10:44.509	So, this tells that what is the distribution of the strength of the green component within this color image.
3.srt	00:10:45.089 --> 00:10:54.369	Similarly, the third one gives you the information of the distribution of a blue component or strength of the blue component within the given image.
3.srt	00:10:55.399 --> 00:11:13.699	So, as we have seen in the previous example with the black and white image or the grayscale image that the histogram shape of the histogram gives you important information about the intensity distribution within the given image.
3.srt	00:11:13.939 --> 00:11:24.379	Similarly, these three colored histograms gives you important information about the color distribution, the nature of the color of the given image.
3.srt	00:11:25.469 --> 00:11:37.769	And, by analyzing these histograms I can update important information, important descriptors of the intensity distribution and important descriptors of the color distribution.
3.srt	00:11:38.869 --> 00:11:40.379	So, how we can do it?
3.srt	00:12:04.709 --> 00:12:31.709	So, the way I will do it is I assume that the histogram So, my intensity is intensity level I put it as r i and the histogram is given by h of r i and this histogram is having different types of shape depending upon the intensity distribution if it is the histogram taken from an intensity image or color distribution where I will have three such histograms.
3.srt	00:12:31.899 --> 00:12:33.949	for each of the color planes.
3.srt	00:12:35.069 --> 00:12:47.499	Now, once I have this histogram and if the histogram is normalized that means, it gives you the frequency of occurrence of an intensity value r i which is indicated by h r i.
3.srt	00:12:48.639 --> 00:12:55.869	So, in that case this shape information can also be captured through different statistical moments that we have said earlier.
3.srt	00:12:56.699 --> 00:13:04.829	So, to capture that different statistical moments firstly what I have compute up to compute is what is mu that is the mean of the intensity values.
3.srt	00:13:05.189 --> 00:13:19.109	which is nothing but r i times h of r i where h r i is the frequency of occurrence of the intensity value r i take the summation of this over all i.
3.srt	00:13:19.659 --> 00:13:24.249	So, that gives you what is the mean intensity value.
3.srt	00:13:24.249 --> 00:13:35.769	And once I have this mean intensity value then I can compute the statistical moment of order k which I write as sigma k which is given by r i.
3.srt	00:13:36.279 --> 00:13:45.579	minus mu to the power k times h of r i take the summation of this over all i.
3.srt	00:13:47.619 --> 00:14:07.249	So, this is my statistical moment of order k and as we said earlier this statistical moment of order k gives you different shape information, information about the shape of the histogram or how the intensity varies, what is the variation of intensity or what is the variation of different color components within the given image.
3.srt	00:14:08.439 --> 00:14:18.179	And, we said earlier that if k is equal to 2 this is nothing but what is variance, the variance tells you what is the spread of the histogram, whether it is a wide or a narrow histogram.
3.srt	00:14:18.959 --> 00:14:28.539	If k equal to 3, it tells you the skewness of the histogram that means whether the histogram is symmetric about the mean or it is asymmetric about the mean.
3.srt	00:14:28.769 --> 00:14:35.519	If it is asymmetric how the asymmetricity is which is captured by the third order moment.
3.srt	00:14:35.879 --> 00:14:42.389	Similarly fourth order, fifth order, all higher order moments gives you some information about the shape of the histogram.
3.srt	00:14:43.639 --> 00:14:55.359	And, the shape of the histogram if it is histogram of an intensity image or black and white image tells you useful information about the nature of intensity distribution.
3.srt	00:14:56.329 --> 00:15:04.979	And, if it is for color image obviously, for color image I have to compute this histogram for all the three components the red component, green component and blue component.
3.srt	00:15:05.629 --> 00:15:15.939	And, all of them tells you useful information about how the green component varies within the image, how the red component varies in within the image or how the blue component varies in the image.
3.srt	00:15:16.959 --> 00:15:20.509	So, I can have different color information from that.
3.srt	00:15:22.259 --> 00:15:37.019	So, this in histograms or moments from the shape of the histogram tells you useful information about the intensity of the region, it tells you useful information about the color within the region.
3.srt	00:15:38.519 --> 00:15:46.889	The next type of region descriptors that we are going to talk about is the texture descriptors.
3.srt	00:15:47.759 --> 00:15:52.919	This is also a region descriptor along with intensity and color.
3.srt	00:15:54.769 --> 00:15:56.889	So, what is a texture descriptor?
3.srt	00:15:57.729 --> 00:15:58.889	Let us look at this figure.
3.srt	00:16:00.209 --> 00:16:17.029	The image which is shown on the left, this is a texture image though we do not have a solid definition, a convincing definition of a texture, but it tells you the way the intensity varies within the given image and it follows certain pattern and it may not always be possible to.
3.srt	00:16:17.979 --> 00:16:21.419	represent this pattern through a formal definition.
3.srt	00:16:22.669 --> 00:16:39.009	However, earlier we have said that an image is nothing but a two dimensional array of integer values, where normally in an image and intensity is represented by an 8 bit binary number.
3.srt	00:16:39.349 --> 00:16:42.289	So, an intensity value varies from 0 to 255.
3.srt	00:16:43.209 --> 00:16:48.829	So, given that if I take a small rectangular or square area within this texture image.
3.srt	00:16:50.039 --> 00:16:57.499	This is nothing but a two dimensional array or a matrix of integer numbers which is as shown over here.
3.srt	00:16:59.059 --> 00:17:07.729	So, given this and texture image is also nothing but a matrix of two dimensional matrix of such integer numbers.
3.srt	00:17:08.449 --> 00:17:20.949	So, given this matrix I have to compute or I have to extract the texture features where the texture is nothing but variation of intensity values at a regular or semi regular manner.
3.srt	00:17:22.439 --> 00:17:23.259	So, how we can do it?
3.srt	00:17:24.329 --> 00:17:33.259	So, one of the ways in which this texture information can be obtained in the pixel domain is by using something known as a co-occurrence matrix.
3.srt	00:17:33.259 --> 00:17:37.939	So, let us see that what this co-occurrence matrix means.
3.srt	00:17:37.939 --> 00:17:48.339	Co-occurrence matrix says that given two intensity values say i and j, i is one intensity value, j is another intensity value.
3.srt	00:17:54.980 --> 00:17:57.049	So, it says that how these two intensity values co-occur within the given image.
3.srt	00:17:58.219 --> 00:18:11.149	So, when I say co-occur that is two intensity values i and j, the pixels having intensity values i and j also has to follow certain geometric or locationalconstant.
3.srt	00:18:11.149 --> 00:18:24.000	So, I put this location information in the form of a vector say p or in the form of a parameter p, where this p will consist of two components.
3.srt	00:18:25.299 --> 00:18:28.149	one is L and the other one is theta.
3.srt	00:18:30.549 --> 00:18:53.359	So, by this what I want to say is if I have 2 pixels say A having an intensity value say I and another pixel say B having an intensity value J, then the pixels A and B will be separated following this positional parameter.
3.srt	00:18:54.659 --> 00:18:57.639	That means the distance between the pixel A and B will be L.
3.srt	00:18:58.429 --> 00:19:05.139	And, the orientation of the line joining these 2 pixels a and b will be theta with say horizontal axis.
3.srt	00:19:07.059 --> 00:19:27.709	So, given this and an image of this form which obviously, I have shown by a very small square matrix having intensity values in this case intensity values from minimum intensity value is 0 maximum intensity value is 15.
3.srt	00:19:27.799 --> 00:19:27.829	15.
3.srt	00:19:28.299 --> 00:19:31.709	That means it is basically a 4 bit quantization.
3.srt	00:19:32.359 --> 00:19:35.389	So, intensity values of every pixel varies from 0 to 15.
3.srt	00:19:37.029 --> 00:19:42.849	I am not considering up to 255 because there my co-occurrence matrix size will be very high.
3.srt	00:19:42.849 --> 00:19:50.909	And I want to find out the co-occurrence matrix or for a particular L theta pair.
3.srt	00:19:50.999 --> 00:19:57.989	And for this case, let me assume that value of L is equal to 1 and value of theta is equal to 45 degree.
3.srt	00:19:59.919 --> 00:20:09.149	ok. And I also put say I intensity I is equal to say 4 and intensity j is equal to 8.
3.srt	00:20:11.179 --> 00:20:28.489	So, given this what I want to compute is this co-occurrence matrix I will put it as a matrix A, I want to compute the element value A i j.
3.srt	00:20:30.639 --> 00:20:37.509	where i may vary from 0 to 15 as I have said that the minimum intensity value in this image is 0 the maximum intensity value is 15.
3.srt	00:20:37.819 --> 00:20:40.339	Similarly, j is also varying from 0 to 15.
3.srt	00:20:40.339 --> 00:20:49.639	So, effectively I have a co-occurs matrix A of dimension 1516 by 16 varying from 0 to 15 for each of i and j.
3.srt	00:21:00.889 --> 00:21:18.169	So, as I said earlier that I assume value of i to be is equal to 4 and value of j to b is equal to 8 and this follows a positional constant p, where p is given by L theta pair having L is equal to 1 and theta is equal to 45 degree.
3.srt	00:21:19.629 --> 00:21:32.019	So, basically what I want to compute is I want to compute the number of occurrences of 2 pixels, the first pixel having intensity value 4.
3.srt	00:21:32.649 --> 00:21:39.909	what are the values at these two locations, how many such occurrences I have within this given image.
3.srt	00:21:39.909 --> 00:21:47.059	So, if you scan this image you will find that this is one such occurrence ok.
3.srt	00:21:48.679 --> 00:21:55.049	If you look at this is another such occurrence, do I have any more?
3.srt	00:21:57.659 --> 00:22:02.859	This is one such occurrence I think that is all.
3.srt	00:22:04.009 --> 00:22:15.889	So, you find there are 3 occurrences of pair 4, 8 intensity pair 4, 8 following this positional constant p within the given image.
3.srt	00:22:16.249 --> 00:22:21.099	So, the content at location 4, 8 will be equal to 3.
3.srt	00:22:22.139 --> 00:22:32.959	So, my co-occurrence matrix is a matrix A having 16 elements starting from 0 to 15 horizontally.
3.srt	00:22:35.929 --> 00:23:00.419	0 to 15 vertically and at location 4, 8 the value is 3 indicating that this pair of intensity values 4, 8 following this positional constant p occurs 3 times in this given image and that I compute for all values of i and j.
3.srt	00:23:07.479 --> 00:23:22.719	So, effectively what it gives me is the number of occurrences different pairs of intensity values, how many times they occur within the given image for a given p. So, if I vary p, obviously I will have different number of such co-occurrence matrices.
3.srt	00:23:22.719 --> 00:23:30.369	Now, if I normalize this co-occurrence matrix, then what I basically get is a joint distribution, right.
3.srt	00:23:30.369 --> 00:23:41.069	That is the, what is the frequency of occurrence of ijth pair of intensity values following this positional constant p.
3.srt	00:23:42.829 --> 00:23:43.989	occurring in the given events.
3.srt	00:23:44.029 --> 00:23:50.239	So, it is the frequency of occurrence which is nothing but the probability distribution of the pair of intensity values.
3.srt	00:23:51.509 --> 00:24:02.229	So, once I have this probability distribution then I can compute different types of features from such a matrix.
3.srt	00:24:03.329 --> 00:24:11.919	One of the feature is what is the maximally occurring pair of intensity values.
3.srt	00:24:14.789 --> 00:24:15.249	So, that is what is the maximum probability.
3.srt	00:24:17.369 --> 00:24:22.049	So, this C i j represents the normalized matrix A i j.
3.srt	00:24:23.359 --> 00:24:29.049	So, one of the property that I can extract is what is the maximally occurring pair of intensity values i j.
3.srt	00:24:30.599 --> 00:24:45.169	The other one that I can compute is what is known as element difference moment of order k which is given by i minus j to the power k C i j take the summation over all values of i and j.
3.srt	00:24:46.909 --> 00:24:48.279	What is the significance of this?
3.srt	00:24:49.789 --> 00:25:14.879	The element difference moment you find that if the larger values of C i j are concentrated around the diagonal, around the main diagonal of the co-occurrence matrix or normalized co-occurrence matrix C i j, then the value of element difference moment will be very low.
3.srt	00:25:15.999 --> 00:25:25.289	because, of this factor i minus j to the power k. Similarly, I can have the opposite one which is inverse element difference moment.
3.srt	00:25:25.689 --> 00:25:34.809	So, which is c i j upon a i minus j to the power k. So, this will have an effect which is just opposite to the element difference moment.
3.srt	00:25:35.209 --> 00:25:39.809	So, when element difference moment is large, inverse element difference moment will be low.
3.srt	00:25:40.949 --> 00:25:43.569	I can also have a measure of uniformity.
3.srt	00:25:46.989 --> 00:25:57.659	So, you find that the sum of c i j square will be maximum if all the elements of this co-occurrence matrix c i j they are equal that tells me what is the uniformity.
3.srt	00:25:57.689 --> 00:26:02.249	Similarly, it also tells me that what is the entropy right.
3.srt	00:26:03.499 --> 00:26:09.929	So, this entropy will be maximum if the contents c i j are maximally random.
3.srt	00:26:09.929 --> 00:26:17.159	So, all these different types of features or the properties that can be computed from the co-occurrence matrix .
3.srt	00:26:18.249 --> 00:26:19.869	that we have just computed.
3.srt	00:26:22.139 --> 00:26:27.689	So, this is what you obtain from the raw image, the raw texture image itself.
3.srt	00:26:29.079 --> 00:26:39.839	We can also obtain the features in the frequency domain.
3.srt	00:26:41.049 --> 00:26:44.369	These are the features that we can have in the pixel domain in the raw image.
3.srt	00:26:45.409 --> 00:26:56.319	So, if I want to compute features in the frequency domain, there are different transformations that can be applied on the given texture image to transform into frequency domain and I can compute.
3.srt	00:26:57.159 --> 00:26:59.349	the different types of descriptors in the frequency domain.
3.srt	00:27:30.029 --> 00:27:31.019	So, for texture images the number of transformations, the different transformations which have been very very popular to extract texture features are one is weblet transformation and the other one is Gabor transformation.
3.srt	00:27:40.239 --> 00:27:51.399	So, what you do in case of Weibullet transformation is this breaks the original signal into different frequency sub bands.
3.srt	00:27:52.639 --> 00:28:02.069	And then you compute the energies in the different sub bands and put those energies of different sub bands as different features.
3.srt	00:28:05.459 --> 00:28:18.109	In case of Gabor transformation, this is very interesting Gabor transformation is nothing but a filter which is cosine modulated Gaussian envelope and that can be oriented in various directions.
3.srt	00:28:19.229 --> 00:28:23.439	So, here as it is as it is cosine modulatedGaussian.
3.srt	00:28:24.119 --> 00:28:28.779	So, I have two parameters over there.
3.srt	00:28:29.419 --> 00:28:33.449	One is what is the variance of the Gaussian that tells you about the scale.
3.srt	00:28:34.509 --> 00:28:39.809	And, because it is cosine modulated, what is the cosine, what is the frequency of that cosine signal?
3.srt	00:28:41.709 --> 00:28:46.039	And, the other parameter that I get, because it can be oriented, what is the orientation angle?
3.srt	00:28:46.369 --> 00:28:52.629	So, I can have three different parameters for Gabor filters, frequency, scale and orientation.
3.srt	00:28:53.649 --> 00:28:58.199	And, I can have different filter coefficients by varying these three outputs.
3.srt	00:28:58.619 --> 00:29:02.609	So, I can generate an array of filtered signal outputs.
3.srt	00:29:02.869 --> 00:29:09.169	And, for each of these outputs, I can compute the energy and put the energies in the form of a feature vector.
3.srt	00:29:10.239 --> 00:29:13.649	So, that is what can be done in the transformation domain as well.
3.srt	00:29:13.849 --> 00:29:25.329	So, I can have components in the frequent in the spatial domain, I can also have features extracted in the transformation domain or in the frequency domain.
3.srt	00:29:25.329 --> 00:29:31.769	So, all these what I have done is for the visual signals like images or what we can see.
3.srt	00:29:33.339 --> 00:29:40.069	But as we have seen said before that the frequency extraction or feature extraction.
3.srt	00:29:41.209 --> 00:29:46.409	is not only required for the visual information, it is also for the audio information.
3.srt	00:29:47.279 --> 00:29:58.719	So, in case of an audio, an audio signal whatever I am speaking, audio signal is generated by capturing this information by a microphone.
3.srt	00:29:59.029 --> 00:30:10.469	And if you check with a CRO, what is the output of the microphone that is nothing but a signal of this form, something like this.
3.srt	00:30:10.529 --> 00:30:12.399	This is the output of the microphone.
3.srt	00:30:14.399 --> 00:30:20.519	So, for audio signal feature extraction what is done is this output is passed through a digitizer.
3.srt	00:30:20.839 --> 00:30:40.579	So, through a digitizer I get a sequence of samples and from the sequence of samples I can compute different types of features right and all those features can be used as descriptors to be used for speech recognition for speech recognition for speech to text conversion and all that.
3.srt	00:30:41.169 --> 00:30:44.859	So, even an audio signal can be represented in the form of a vector.
3.srt	00:30:47.169 --> 00:31:00.129	So, the different types of vector representation that we can have is one of them is a well known linear predictive coding or LPC coefficients.
3.srt	00:31:00.909 --> 00:31:13.999	The other kind of feature vectors which has become very popular and very powerful is what is known as MFCC or male frequency capstrum coefficients.
3.srt	00:31:14.859 --> 00:31:16.759	So, this shows what are the steps.
3.srt	00:31:17.009 --> 00:31:19.109	for computation of MFCC.
3.srt	00:31:19.919 --> 00:31:33.369	First is you take the Fourier transformation of the signal samples that you have or speech samples that you have, then you convert these frequency coefficients the Fourier coefficients into male frequency coefficients.
3.srt	00:31:34.499 --> 00:31:43.919	This is required because our auditory system is not that sensitive to high frequency components, but it is very sensitive to low frequency components, right.
3.srt	00:31:44.309 --> 00:31:46.469	So, that is what is known as this.
3.srt	00:31:48.209 --> 00:31:54.809	conversion to male frequencies, then after that you take the logarithm of male frequency coefficients.
3.srt	00:31:55.329 --> 00:31:56.329	Why do you need logarithm?
3.srt	00:31:56.609 --> 00:32:08.169	Because again our auditory system is not that sensitive to loud signals, but it is very sensitive to the signals which are not so loud.
3.srt	00:32:08.389 --> 00:32:12.029	So, you get a logarithm you have to perform a logarithmic transformation.
3.srt	00:32:13.519 --> 00:32:17.169	And the output of this log operation.
3.srt	00:32:17.549 --> 00:32:24.929	you take the discrete Fourier transformation of that and the discrete Fourier transformation coefficients are nothing but your MFCC coefficients.
3.srt	00:32:25.409 --> 00:32:34.609	And using this MFCC coefficients, I can discriminate among different speakers, I can identify the different spoken words, okay.
3.srt	00:32:35.369 --> 00:32:41.719	So, all these that have talked about is regarding or traditional machine learning approaches.
3.srt	00:32:42.339 --> 00:32:43.199	So, what is that?
3.srt	00:32:44.109 --> 00:32:51.869	In traditional machine learning approach, the system is like this.
3.srt	00:33:24.889 --> 00:33:41.659	I have input raw signal which passes through a feature extracted block and these features are fed to the machine learning algorithms, where this machine learning algorithm has some parameter set of parameters theta.
3.srt	00:33:43.099 --> 00:33:50.129	And using this machine learning algorithm you take decision on this input signal what it is.
3.srt	00:33:51.389 --> 00:33:56.969	But when you talk about today's deep learning algorithm, this feature extraction block is absent.
3.srt	00:33:58.459 --> 00:34:24.419	So, what you have is I have this machine learning algorithm again with some set of parameters theta and raw signal is fed directly to this machine and output of the machine is the decision that you take from this signal.
3.srt	00:34:27.619 --> 00:34:34.559	So, even for deep learning, you can see that I also need to represent the input signal as vector or set of vectors.
3.srt	00:34:35.619 --> 00:34:39.289	So, how do I represent that that input signal as a set of vectors?
3.srt	00:34:57.339 --> 00:35:02.649	So, for that let me assume again from the visual domain that I have an image and I take a small segment of the image or 2 by 3 image and this image may be the pixel intensities may be 10, 15, 12, 9, 8, 10, 11, 10 again 3, 12, 6 something like this.
3.srt	00:35:03.869 --> 00:35:08.499	So, I need to convert this image itself into a form of vector.
3.srt	00:35:09.319 --> 00:35:10.109	How we can do it?
3.srt	00:35:11.079 --> 00:35:16.949	Take each column of this image and concatenate all the columns together to form a single vector.
3.srt	00:35:17.909 --> 00:35:21.979	So, what you are doing is from a matrix I am converting this to a vector.
3.srt	00:35:27.899 --> 00:35:38.929	So, in this case my vector will be 10, 9, 3, 4, 5, 6, that is the first column, then I take the next column it will be 15, 8, 12, then I take the third column again it will be 12, 10, 6.
3.srt	00:35:40.349 --> 00:35:49.589	So, you find that from this 3 by 3 matrix I have made a one dimensional vector having 9 different components.
3.srt	00:35:50.419 --> 00:35:57.919	And this vector is fed to the machine learning algorithm whether it is during training of the machine.
3.srt	00:35:58.309 --> 00:36:00.829	or during the testing testing phase.
3.srt	00:36:01.689 --> 00:36:20.829	And that is what you do in case of deep learning algorithms, where we expect in case of machine learning, traditional machine learning, the features are to be decided by the user or the human being accordingly I have to have feature extraction algorithms and then the machine learning comes into picture.
3.srt	00:36:22.079 --> 00:36:30.999	In case of deep learning, we expect that no, we will not tell what features to analyze for taking a particular decision.
3.srt	00:36:31.569 --> 00:36:34.339	But, let the machine learn the features also.
3.srt	00:36:35.389 --> 00:36:47.149	So, during training phase what we say is you feed the input raw signal in the form of vector to the machine and tell the machine what this signal is and based on this.
3.srt	00:36:47.149 --> 00:37:02.919	So, that is basically you are trying to supervise the machine to learn the features from the signal and not only the features it also learns to take the decision or to learns to describe those signals or those features.
3.srt	00:37:03.669 --> 00:37:14.589	So, starting from feature extraction to decision making this end to end application is done by machine and that is what is done in deep learning.
3.srt	00:37:17.059 --> 00:37:27.469	So, you see that in today's lecture we have talked about the different types of features both from the visual signal domain as well as from audio signal domain.
3.srt	00:37:29.419 --> 00:37:31.939	How to extract those different feature vectors?
3.srt	00:37:33.609 --> 00:37:43.129	In case of traditional machine learning, in case of deep learning given a raw signal in the form of a raw image or this is also applicable in case of audio signals.
3.srt	00:37:43.129 --> 00:37:52.059	So, I have given audio signal inputs in the form of sequence of samples, I can form vectors out of it following window operation.
3.srt	00:37:53.849 --> 00:37:59.099	So, given a raw signal how we can obtain or how we can vectorize that raw signal.
3.srt	00:38:01.089 --> 00:38:03.669	So, next class onwards.
3.srt	00:38:04.099 --> 00:38:11.739	we will not discuss about the descriptor or how do you obtain a descriptor of a given signal.
3.srt	00:38:12.239 --> 00:38:17.629	I will assume that given any signal it is represented as a vector.
3.srt	00:38:17.949 --> 00:38:28.339	So, the input to my machine will be a vector and everything that we do whether it is learning or testing decision making everything has to be done on that vector.
3.srt	00:38:30.019 --> 00:38:30.339	Thank you.
