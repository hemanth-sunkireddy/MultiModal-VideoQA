{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f1c1376",
   "metadata": {},
   "source": [
    "## Qwen 0.6B Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056097c4",
   "metadata": {},
   "source": [
    "### Install SUMMARISER MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc777f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-extractive-summarizer in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.10.1)\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from bert-extractive-summarizer) (4.55.0)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from bert-extractive-summarizer) (1.7.1)\n",
      "Requirement already satisfied: spacy in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from bert-extractive-summarizer) (3.8.7)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn->bert-extractive-summarizer) (2.3.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn->bert-extractive-summarizer) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn->bert-extractive-summarizer) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn->bert-extractive-summarizer) (3.6.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from spacy->bert-extractive-summarizer) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from spacy->bert-extractive-summarizer) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from spacy->bert-extractive-summarizer) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from spacy->bert-extractive-summarizer) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from spacy->bert-extractive-summarizer) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from spacy->bert-extractive-summarizer) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from spacy->bert-extractive-summarizer) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from spacy->bert-extractive-summarizer) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from spacy->bert-extractive-summarizer) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from spacy->bert-extractive-summarizer) (0.17.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from spacy->bert-extractive-summarizer) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from spacy->bert-extractive-summarizer) (2.32.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from spacy->bert-extractive-summarizer) (2.11.7)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from spacy->bert-extractive-summarizer) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from spacy->bert-extractive-summarizer) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/hemanth/Library/Python/3.13/lib/python/site-packages (from spacy->bert-extractive-summarizer) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from spacy->bert-extractive-summarizer) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langcodes<4.0.0,>=3.2.0->spacy->bert-extractive-summarizer) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->bert-extractive-summarizer) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->bert-extractive-summarizer) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->bert-extractive-summarizer) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->bert-extractive-summarizer) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2025.8.3)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from thinc<8.4.0,>=8.3.4->spacy->bert-extractive-summarizer) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from thinc<8.4.0,>=8.3.4->spacy->bert-extractive-summarizer) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (14.1.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from weasel<0.5.0,>=0.1.0->spacy->bert-extractive-summarizer) (0.22.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from weasel<0.5.0,>=0.1.0->spacy->bert-extractive-summarizer) (7.3.1)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->bert-extractive-summarizer) (1.17.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->bert-extractive-summarizer) (1.3.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/hemanth/Library/Python/3.13/lib/python/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jinja2->spacy->bert-extractive-summarizer) (3.0.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers->bert-extractive-summarizer) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers->bert-extractive-summarizer) (0.34.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers->bert-extractive-summarizer) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers->bert-extractive-summarizer) (2025.7.34)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers->bert-extractive-summarizer) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers->bert-extractive-summarizer) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers->bert-extractive-summarizer) (2025.7.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers->bert-extractive-summarizer) (1.1.7)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install bert-extractive-summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d657e91d",
   "metadata": {},
   "source": [
    "Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bfbf162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import ffmpeg\n",
    "import os\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "# Paths\n",
    "VIDEO_DIR = \"Data/Videos\"             # Folder containing input video files\n",
    "AUDIO_DIR = \"Data/Audios\"             # Folder to store extracted audio files\n",
    "CHUNK_DIR = \"Data/Audio-Chunks\"       # Folder to save audio chunks after VAD\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "os.makedirs(AUDIO_DIR, exist_ok=True)\n",
    "os.makedirs(CHUNK_DIR, exist_ok=True)\n",
    "\n",
    "# Audio processing\n",
    "TARGET_SAMPLE_RATE = 16000  # or 32000 Hz depending on your use case\n",
    "\n",
    "# VAD settings\n",
    "MIN_CHUNK_DURATION_SEC = 30  # Minimum duration for an audio chunk\n",
    "USE_ONNX_MODEL = False      # Set True to use ONNX version of Silero VAD\n",
    "\n",
    "from silero_vad import (\n",
    "    load_silero_vad, read_audio, get_speech_timestamps, \n",
    "    save_audio, VADIterator\n",
    ")\n",
    "\n",
    "# faiss_index = faiss.read_index(\"Data/sentence_embeddings.index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a321f47e",
   "metadata": {},
   "source": [
    "### Model for Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "554479d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"Qwen/Qwen3-Embedding-0.6B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af288996",
   "metadata": {},
   "source": [
    "### Summarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2e89e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from summarizer import Summarizer\n",
    "\n",
    "# Initialize summarizer\n",
    "summarizer = Summarizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41c6490",
   "metadata": {},
   "source": [
    "## Video to Audio Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d21fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all .mp4 files in the input folder\n",
    "for filename in os.listdir(VIDEO_DIR):\n",
    "    if filename.endswith(\".mp4\"):\n",
    "        input_path = os.path.join(VIDEO_DIR, filename)\n",
    "        output_path = os.path.join(AUDIO_DIR, filename.replace(\".mp4\", \".wav\"))\n",
    "\n",
    "        print(f\"Processing: {input_path} -> {output_path}\")\n",
    "        \n",
    "        # Extract audio\n",
    "        input_video = ffmpeg.input(input_path)\n",
    "        output_audio = ffmpeg.output(input_video.audio, output_path, ac=1, ar=TARGET_SAMPLE_RATE)\n",
    "        ffmpeg.run(output_audio, overwrite_output=True)\n",
    "        \n",
    "        # Probe the generated audio file for details\n",
    "        audio_info = ffmpeg.probe(output_path, v=\"error\", select_streams=\"a\", show_entries=\"stream=codec_name,codec_type,sample_rate,channels,bit_rate,duration\")\n",
    "        \n",
    "        codec_name = audio_info['streams'][0]['codec_name']\n",
    "        sample_rate = int(audio_info['streams'][0]['sample_rate'])\n",
    "        channels = int(audio_info['streams'][0]['channels'])\n",
    "        bit_rate = audio_info['streams'][0].get('bit_rate', 'N/A')\n",
    "        duration_sec = float(audio_info['streams'][0]['duration'])\n",
    "        duration_ms = duration_sec * 1000\n",
    "        \n",
    "        print(f\"Audio extracted: {output_path}\")\n",
    "        # print(f\"Codec: {codec_name}, Sample Rate: {sample_rate} Hz, Channels: {channels}, Bit Rate: {bit_rate}, Duration: {duration_ms} ms\\n\")\n",
    "\n",
    "print(\"Video to Audio converted successfully!.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5d8a67",
   "metadata": {},
   "source": [
    "Voice Activity Detection Algorithm on Audio Files - Converting into Smaller Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184e3aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Silero VAD model\n",
    "model = load_silero_vad(onnx=USE_ONNX_MODEL)\n",
    "\n",
    "def process_audio_file(audio_path, output_chunk_dir):\n",
    "    \"\"\"Process an audio file, split it into chunks, and save them.\"\"\"\n",
    "    wav = read_audio(audio_path, sampling_rate=TARGET_SAMPLE_RATE)\n",
    "    speech_timestamps = get_speech_timestamps(\n",
    "        wav, model, sampling_rate=TARGET_SAMPLE_RATE, return_seconds=True\n",
    "    )\n",
    "    \n",
    "    # Format timestamps to 4 decimal places\n",
    "    for segment in speech_timestamps:\n",
    "        segment['start'] = float(f\"{segment['start']:.4f}\")\n",
    "        segment['end'] = float(f\"{segment['end']:.4f}\")\n",
    "    \n",
    "    vad_iterator = VADIterator(model, sampling_rate=TARGET_SAMPLE_RATE)\n",
    "    chunks = []\n",
    "    current_chunk_start = 0\n",
    "    \n",
    "    for segment in speech_timestamps:\n",
    "        start, end = segment['start'], segment['end']\n",
    "        if (end - current_chunk_start) >= MIN_CHUNK_DURATION_SEC:\n",
    "            chunk_wav = wav[int(current_chunk_start * TARGET_SAMPLE_RATE):int(end * TARGET_SAMPLE_RATE)]\n",
    "            chunk_path = os.path.join(output_chunk_dir, f\"{len(chunks) + 1}.wav\")\n",
    "            save_audio(chunk_path, chunk_wav, sampling_rate=TARGET_SAMPLE_RATE)\n",
    "            chunks.append((current_chunk_start, end, chunk_wav))\n",
    "            current_chunk_start = end\n",
    "    \n",
    "    # Save the last chunk if necessary\n",
    "    if current_chunk_start < speech_timestamps[-1]['end']:\n",
    "        chunk_wav = wav[int(current_chunk_start * TARGET_SAMPLE_RATE):]\n",
    "        chunk_path = os.path.join(output_chunk_dir, f\"{len(chunks) + 1}.wav\")\n",
    "        save_audio(chunk_path, chunk_wav, sampling_rate=TARGET_SAMPLE_RATE)\n",
    "        chunks.append((current_chunk_start, speech_timestamps[-1]['end'], chunk_wav))\n",
    "    \n",
    "    vad_iterator.reset_states()\n",
    "    print(f\"Processed {audio_path}, saved chunks in {output_chunk_dir}\")\n",
    "\n",
    "def process_all_audio_files():\n",
    "    \"\"\"Process all .wav files in the main audio folder and save their chunks.\"\"\"\n",
    "    if not os.path.exists(AUDIO_DIR):\n",
    "        print(f\"Audio folder '{AUDIO_DIR}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    for file_name in sorted(os.listdir(AUDIO_DIR)):\n",
    "        if file_name.endswith(\".wav\"):\n",
    "            audio_path = os.path.join(AUDIO_DIR, file_name)\n",
    "            audio_id = os.path.splitext(file_name)[0]  # Extract the number without extension\n",
    "            output_chunk_dir = os.path.join(CHUNK_DIR, audio_id)\n",
    "            process_audio_file(audio_path, output_chunk_dir)\n",
    "\n",
    "# Process VAD on Audio Files.\n",
    "process_all_audio_files()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e7588d",
   "metadata": {},
   "source": [
    "## SRT to Sentences generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eba7e8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing SRT files: 100%|██████████| 31/31 [00:00<00:00, 715.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata saved as 'Data/srt-embedding-metadata.tsv'\n",
      "Sentences saved as 'Data/sentences.txt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to extract combined sentences with timestamps from .srt file\n",
    "def extract_sentences_from_srt(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    sentences = []\n",
    "    timestamps = []\n",
    "    current_sentence = \"\"\n",
    "    current_timestamp = \"\"\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        # Check for timestamp lines\n",
    "        timestamp_match = re.match(r'(\\d{2}:\\d{2}:\\d{2}[.,]\\d{3}) --> (\\d{2}:\\d{2}:\\d{2}[.,]\\d{3})', line)\n",
    "        if timestamp_match:\n",
    "            current_timestamp = timestamp_match.group(1).replace(',', '.') + ' --> ' + timestamp_match.group(2).replace(',', '.')\n",
    "            continue\n",
    "\n",
    "        # Skip empty lines and cue identifiers\n",
    "        if not line or line.isdigit():\n",
    "            continue\n",
    "\n",
    "        # Add line to current sentence\n",
    "        current_sentence += \" \" + line if current_sentence else line\n",
    "\n",
    "        # If sentence ends, save it\n",
    "        if re.search(r'[.!?]$', line):\n",
    "            sentences.append(current_sentence.strip())\n",
    "            timestamps.append(current_timestamp)\n",
    "            current_sentence = \"\"\n",
    "            current_timestamp = \"\"\n",
    "\n",
    "    return sentences, timestamps\n",
    "\n",
    "# Directory containing SRT files\n",
    "srt_directory = 'Data/SRT-Files'\n",
    "\n",
    "# Initialize lists for all sentences, timestamps, and filenames\n",
    "all_sentences = []\n",
    "all_timestamps = []\n",
    "all_filenames = []\n",
    "\n",
    "# Process all SRT files with tqdm\n",
    "srt_files = [f for f in os.listdir(srt_directory) if f.endswith('.srt')]\n",
    "for file_name in tqdm(srt_files, desc=\"Processing SRT files\"):\n",
    "    file_path = os.path.join(srt_directory, file_name)\n",
    "    sentences, timestamps = extract_sentences_from_srt(file_path)\n",
    "    all_sentences.extend(sentences)\n",
    "    all_timestamps.extend(timestamps)\n",
    "    all_filenames.extend([file_name] * len(sentences))  # associate each sentence with its file\n",
    "\n",
    "# print(\"Encoding sentences into embeddings...\")\n",
    "# Uncomment for all miniLM and all mpnet.\n",
    "# sentence_embeddings = np.array(\n",
    "#     model.encode(all_sentences) \n",
    "# ).astype('float32')\n",
    "\n",
    "# sentence_embeddings = model.encode(all_sentences)\n",
    "\n",
    "# Create FAISS index (use Inner Product for cosine similarity)\n",
    "# embedding_dimension = sentence_embeddings.shape[1]\n",
    "# faiss_index = faiss.IndexFlatIP(embedding_dimension)\n",
    "# faiss_index.add(sentence_embeddings)\n",
    "\n",
    "# Save FAISS index\n",
    "# faiss.write_index(faiss_index, \"Data/sentence_embeddings.index\")\n",
    "\n",
    "# Save metadata to file\n",
    "metadata_file = 'Data/srt-embedding-metadata.tsv'\n",
    "with open(metadata_file, 'w', encoding='utf-8') as file:\n",
    "    file.write(\"filename\\ttimestamp\\tsentence\\n\")\n",
    "    for fname, timestamp, sentence in zip(all_filenames, all_timestamps, all_sentences):\n",
    "        clean_sentence = sentence.replace('\\t', ' ').replace('\\n', ' ')\n",
    "        file.write(f\"{fname}\\t{timestamp}\\t{clean_sentence}\\n\")\n",
    "\n",
    "# Save sentences to a text file\n",
    "sentences_file = 'Data/sentences.txt'\n",
    "with open(sentences_file, 'w', encoding='utf-8') as file:\n",
    "    for sentence in all_sentences:\n",
    "        file.write(sentence.strip().replace('\\n', ' ') + '\\n')\n",
    "\n",
    "# Summary\n",
    "# print(f\"\\nEmbeddings created for {len(all_sentences)} sentences from {len(srt_files)} SRT files.\")\n",
    "# print(\"FAISS index saved as 'Data/sentence_embeddings.index'\")\n",
    "print(f\"Metadata saved as '{metadata_file}'\")\n",
    "print(f\"Sentences saved as '{sentences_file}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f406234c",
   "metadata": {},
   "source": [
    "## Finding Related Sentences to a Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565b77c4",
   "metadata": {},
   "source": [
    "### Grouping Sentences N-gram technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbdc7e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped Sentence to Metadata First element: Hello, welcome to the NPTEL online certification course on deep learning. Now, we are discussing about the discriminant function and the decision boundary among different classes. So, in the previous class we have considered two simple cases where the covariance matrices of the different classes they are same and in one of the case we have assumed that the covariance matrix is of the form sigma square i where sigma is the variance of all the components of the vectors. -> ('8.srt', '00:00:00.160 -> 00:01:04.390')\n"
     ]
    }
   ],
   "source": [
    "metadata_list = []\n",
    "with open(\"Data/srt-embedding-metadata.tsv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        filename, timestamp, sentence = row\n",
    "        metadata_list.append((filename, timestamp, sentence))\n",
    "\n",
    "grouped_sentences = []\n",
    "grouped_sent_to_metadata = {}\n",
    "group_size = 3\n",
    "\n",
    "def extract_start_end(ts):\n",
    "    start, end = ts.split(\"-->\")\n",
    "    return start.strip(), end.strip()\n",
    "\n",
    "for i in range(len(metadata_list) - group_size + 1):\n",
    "    group = metadata_list[i:i+group_size]\n",
    "    grouped_text = \" \".join(sent for _, _, sent in group)\n",
    "    filename = group[0][0]\n",
    "    first_start, _ = extract_start_end(group[0][1])\n",
    "    _, last_end = extract_start_end(group[-1][1])\n",
    "    timestamp_range = f\"{first_start} -> {last_end}\"\n",
    "    grouped_sentences.append(grouped_text)\n",
    "    grouped_sent_to_metadata[grouped_text] = (filename, timestamp_range)\n",
    "\n",
    "with open(\"Data/grouped_sentences.pkl\", \"wb\") as f:\n",
    "    pickle.dump(grouped_sentences, f)\n",
    "\n",
    "with open(\"Data/grouped_sent_to_metadata.pkl\", \"wb\") as f:\n",
    "    pickle.dump(grouped_sent_to_metadata, f)\n",
    "\n",
    "first_key = next(iter(grouped_sent_to_metadata))\n",
    "print(\"Grouped Sentence to Metadata First element:\", first_key, \"->\", grouped_sent_to_metadata[first_key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41c6e162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding grouped sentences into embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding batches: 100%|██████████| 319/319 [23:39<00:00,  4.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAISS index created and saved!\n"
     ]
    }
   ],
   "source": [
    "# Load grouped sentences\n",
    "with open(\"Data/grouped_sentences.pkl\", \"rb\") as f:\n",
    "    grouped_sentences = pickle.load(f)\n",
    "\n",
    "# Load precomputed metadata mapping\n",
    "with open(\"Data/grouped_sent_to_metadata.pkl\", \"rb\") as f:\n",
    "    grouped_sent_to_metadata = pickle.load(f)\n",
    "print(\"Encoding grouped sentences into embeddings...\")\n",
    "\n",
    "batch_size = 16  # you can adjust this based on memory\n",
    "all_embeddings = []\n",
    "\n",
    "for i in tqdm(range(0, len(grouped_sentences), batch_size), desc=\"Encoding batches\"):\n",
    "    batch = grouped_sentences[i:i+batch_size]\n",
    "    batch_emb = model.encode(batch)  # encode the batch\n",
    "    all_embeddings.append(batch_emb)\n",
    "\n",
    "# Combine all batches into one array and convert to float32\n",
    "grouped_embeddings = np.vstack(all_embeddings).astype('float32')\n",
    "\n",
    "# Create FAISS index (Inner Product for cosine similarity)\n",
    "embedding_dim = grouped_embeddings.shape[1]\n",
    "faiss_index = faiss.IndexFlatIP(embedding_dim)\n",
    "faiss_index.add(grouped_embeddings)\n",
    "\n",
    "# Save FAISS index\n",
    "faiss.write_index(faiss_index, \"Data/grouped-sentences-embeddings.idx\")\n",
    "\n",
    "print(\"✅ FAISS index created and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53dd7e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS available: True\n",
      "MPS enabled: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())\n",
    "print(\"MPS enabled:\", torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947e47fe",
   "metadata": {},
   "source": [
    "### QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c19be7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Explain Linear Regression?\n",
      "\n",
      "Top Related Sentences with Metadata:\n",
      "- [2.srt | 00:01:19.590 -> 00:01:30.569] So what is a linear regression? It is one of the simplest kind of supervised learning model. And it predicts a real value number which is regression.\n",
      "\n",
      "- [2.srt | 00:00:06.419 -> 00:00:26.550] In this video, we're going to talk about linear regression. So we'll begin by the definition of linear regression, and we'll talk about how this model can optimize to get the best estimate value. And then we're going to talk about important quantities for linear regression, such as a fitness performance metric, things like that.\n",
      "\n",
      "- [2.srt | 00:00:05.429 -> 00:00:17.170] Hi everyone. In this video, we're going to talk about linear regression. So we'll begin by the definition of linear regression, and we'll talk about how this model can optimize to get the best estimate value.\n",
      "\n",
      "- [2.srt | 00:04:20.089 -> 00:04:40.349] And this is called linear combination. So this type of model, whether we have many variables or one variable, that shows some linear relationship of the variable to the target and this type of model is called the linear regression. Let's take an example.\n",
      "\n",
      "- [2.srt | 00:00:09.619 -> 00:00:30.570] So we'll begin by the definition of linear regression, and we'll talk about how this model can optimize to get the best estimate value. And then we're going to talk about important quantities for linear regression, such as a fitness performance metric, things like that. And we'll talk about how statistically significant these estimate values are.\n",
      "\n",
      "- [2.srt | 00:04:13.289 -> 00:04:34.989] this becomes my linear model. And this is called linear combination. So this type of model, whether we have many variables or one variable, that shows some linear relationship of the variable to the target and this type of model is called the linear regression.\n",
      "\n",
      "- [2.srt | 00:04:22.079 -> 00:04:42.909] So this type of model, whether we have many variables or one variable, that shows some linear relationship of the variable to the target and this type of model is called the linear regression. Let's take an example. This data is coming from Kaggle website.\n",
      "\n",
      "- [2.srt | 00:01:50.079 -> 00:02:06.859] And importantly, linear regression model assumes a linear relationship between the features and the target variable. Well, what does that mean? It means the feature, let's say we have only one feature for now, has a linear relationship to the target variable.\n",
      "\n",
      "- [2.srt | 00:01:40.769 -> 00:01:58.969] That means the user doesn't need to figure out some design parameters in advance or during the training. And importantly, linear regression model assumes a linear relationship between the features and the target variable. Well, what does that mean?\n",
      "\n",
      "- [2.srt | 00:01:07.469 -> 00:01:24.949] And our goal is to tweak this parameter by optimization so that the model makes a prediction that's close to the target as much as possible. So what is a linear regression? It is one of the simplest kind of supervised learning model.\n",
      "\n",
      "\n",
      "Ordered & Merged Top Related Sentences (duplicates removed):\n",
      "\n",
      "Group 1\n",
      "Text: Hi everyone. In this video, we're going to talk about linear regression. So we'll begin by the definition of linear regression, and we'll talk about how this model can optimize to get the best estimate value. And then we're going to talk about important quantities for linear regression, such as a fitness performance metric, things like that. And we'll talk about how statistically significant these estimate values are.\n",
      "Metadata: ('2.srt', '00:00:05.429 -> 00:00:30.570')\n",
      "\n",
      "Group 2\n",
      "Text: And our goal is to tweak this parameter by optimization so that the model makes a prediction that's close to the target as much as possible. So what is a linear regression? It is one of the simplest kind of supervised learning model. And it predicts a real value number which is regression.\n",
      "Metadata: ('2.srt', '00:01:07.469 -> 00:01:30.569')\n",
      "\n",
      "Group 3\n",
      "Text: That means the user doesn't need to figure out some design parameters in advance or during the training. And importantly, linear regression model assumes a linear relationship between the features and the target variable. Well, what does that mean. Well, what does that mean? It means the feature, let's say we have only one feature for now, has a linear relationship to the target variable.\n",
      "Metadata: ('2.srt', '00:01:40.769 -> 00:02:06.859')\n",
      "\n",
      "Group 4\n",
      "Text: this becomes my linear model. And this is called linear combination. So this type of model, whether we have many variables or one variable, that shows some linear relationship of the variable to the target and this type of model is called the linear regression. Let's take an example. This data is coming from Kaggle website.\n",
      "Metadata: ('2.srt', '00:04:13.289 -> 00:04:42.909')\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import torch\n",
    "import pickle\n",
    "import faiss\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "model.to(device)\n",
    "\n",
    "faiss_index = faiss.read_index(\"Data/grouped-sentences-embeddings.idx\")\n",
    "\n",
    "with open(\"Data/grouped_sentences.pkl\", \"rb\") as f:\n",
    "    grouped_sentences = pickle.load(f)\n",
    "\n",
    "with open(\"Data/grouped_sent_to_metadata.pkl\", \"rb\") as f:\n",
    "    grouped_sent_to_metadata = pickle.load(f)\n",
    "\n",
    "student_question = input(\"Enter your question: \")\n",
    "question_embedding = model.encode(student_question, prompt_name=\"query\")\n",
    "if question_embedding.ndim == 1:\n",
    "    question_embedding = np.expand_dims(question_embedding, axis=0)\n",
    "\n",
    "distances, indices = faiss_index.search(question_embedding, 10)\n",
    "\n",
    "related_results = []\n",
    "for idx in indices[0]:\n",
    "    grouped_sent = grouped_sentences[idx]\n",
    "    filename, timestamp_range = grouped_sent_to_metadata.get(\n",
    "        grouped_sent, (\"Unknown\", \"Unknown\")\n",
    "    )\n",
    "    related_results.append((filename, timestamp_range, grouped_sent))\n",
    "\n",
    "print(\"Question:\", student_question)\n",
    "print(\"\\nTop Related Sentences with Metadata:\")\n",
    "for filename, timestamp, sent in related_results:\n",
    "    print(f\"- [{filename} | {timestamp}] {sent}\\n\")\n",
    "\n",
    "# Group results by file\n",
    "grouped_by_file = {}\n",
    "for filename, timestamp, sent in related_results:\n",
    "    if filename not in grouped_by_file:\n",
    "        grouped_by_file[filename] = []\n",
    "    grouped_by_file[filename].append((timestamp, sent))\n",
    "\n",
    "# Helper to parse timestamps\n",
    "def parse_ts(ts):\n",
    "    start, end = ts.split(\"->\")\n",
    "    fmt = \"%H:%M:%S.%f\"\n",
    "    return datetime.strptime(start.strip(), fmt), datetime.strptime(end.strip(), fmt)\n",
    "\n",
    "# Helper to clean and normalize sentences\n",
    "def clean_sentences(sentences):\n",
    "    cleaned = []\n",
    "    seen = set()\n",
    "    for s in sentences:\n",
    "        s = s.strip()\n",
    "        while s and s[-1] in \".!?\":\n",
    "            s = s[:-1].strip()\n",
    "        if s and s not in seen:\n",
    "            cleaned.append(s)\n",
    "            seen.add(s)\n",
    "    return cleaned\n",
    "\n",
    "def extract_file_number(fname):\n",
    "    # Extract numeric part from \"1.srt\", \"2.srt\" etc.\n",
    "    match = re.search(r\"(\\d+)\", fname)\n",
    "    return int(match.group(1)) if match else float('inf')\n",
    "\n",
    "# Order by start timestamp\n",
    "related_results_sorted = sorted(\n",
    "    related_results,\n",
    "    key=lambda x: (extract_file_number(x[0]), parse_ts(x[1])[0])\n",
    ")\n",
    "\n",
    "# Merge sentences and remove duplicates\n",
    "merged_results = []\n",
    "for filename, ts_range, text in related_results_sorted:\n",
    "    sentences = clean_sentences(text.split('. '))\n",
    "\n",
    "    if not merged_results:\n",
    "        merged_results.append([filename, ts_range, '. '.join(sentences) + '.'])\n",
    "        continue\n",
    "\n",
    "    prev = merged_results[-1]\n",
    "    prev_start, prev_end = parse_ts(prev[1])\n",
    "    curr_start, curr_end = parse_ts(ts_range)\n",
    "\n",
    "    if filename == prev[0] and curr_start <= prev_end:\n",
    "        new_start = prev_start.strftime(\"%H:%M:%S.%f\")[:-3]\n",
    "        new_end = max(prev_end, curr_end).strftime(\"%H:%M:%S.%f\")[:-3]\n",
    "        prev[1] = f\"{new_start} -> {new_end}\"\n",
    "\n",
    "        prev_sentences = clean_sentences(prev[2].split('. '))\n",
    "        combined_sentences = prev_sentences + sentences\n",
    "        prev[2] = '. '.join(clean_sentences(combined_sentences)) + '.'\n",
    "    else:\n",
    "        merged_results.append([filename, ts_range, '. '.join(sentences) + '.'])\n",
    "\n",
    "print(\"\\nOrdered & Merged Top Related Sentences (duplicates removed):\")\n",
    "for i, (fname, ts, sent) in enumerate(merged_results, 1):\n",
    "    print(f\"\\nGroup {i}\")\n",
    "    print(\"Text:\", sent)\n",
    "    print(\"Metadata:\", (fname, ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46f9b6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2.srt', '00:00:05.429 -> 00:00:30.570', \"Hi everyone. In this video, we're going to talk about linear regression. So we'll begin by the definition of linear regression, and we'll talk about how this model can optimize to get the best estimate value. And then we're going to talk about important quantities for linear regression, such as a fitness performance metric, things like that. And we'll talk about how statistically significant these estimate values are.\", 0.0), ('2.srt', '00:01:07.469 -> 00:01:30.569', \"And our goal is to tweak this parameter by optimization so that the model makes a prediction that's close to the target as much as possible. So what is a linear regression? It is one of the simplest kind of supervised learning model. And it predicts a real value number which is regression.\", 0.0), ('2.srt', '00:01:40.769 -> 00:02:06.859', \"That means the user doesn't need to figure out some design parameters in advance or during the training. And importantly, linear regression model assumes a linear relationship between the features and the target variable. Well, what does that mean. Well, what does that mean? It means the feature, let's say we have only one feature for now, has a linear relationship to the target variable.\", 0.0), ('2.srt', '00:04:13.289 -> 00:04:42.909', \"this becomes my linear model. And this is called linear combination. So this type of model, whether we have many variables or one variable, that shows some linear relationship of the variable to the target and this type of model is called the linear regression. Let's take an example. This data is coming from Kaggle website.\", 0.0)]\n"
     ]
    }
   ],
   "source": [
    "segment_list = []\n",
    "\n",
    "for filename, ts_range, text in merged_results:\n",
    "    # distance placeholder\n",
    "    distance = 0.0\n",
    "    segment_list.append((filename, ts_range, text, distance))\n",
    "\n",
    "# Now segment_list is ready to use\n",
    "print(segment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07dff472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video Data/answer.mp4.\n",
      "MoviePy - Writing audio in answerTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:  21%|██        | 485/2293 [00:00<00:02, 866.40it/s, now=None]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "chunk:  43%|████▎     | 995/2293 [00:01<00:01, 726.15it/s, now=None]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "chunk:  71%|███████   | 1626/2293 [00:02<00:00, 710.59it/s, now=None]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video Data/answer.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready Data/answer.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip, concatenate_videoclips, ColorClip\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "def format_srt_timestamp(seconds):\n",
    "    td = datetime.timedelta(seconds=seconds)\n",
    "    total_seconds = int(td.total_seconds())\n",
    "    milliseconds = int((td.total_seconds() - total_seconds) * 1000)\n",
    "    hours, remainder = divmod(total_seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return f\"{hours:02}:{minutes:02}:{int(seconds):02},{milliseconds:03}\"\n",
    "\n",
    "def create_continuous_srt(clips_info, output_filename=\"Data/stitched_output.srt\", transition_sec=0.01):\n",
    "    srt_lines = []\n",
    "    current_time = 0.0\n",
    "\n",
    "    for idx, (duration, sentence, start, video_file) in enumerate(clips_info, start=1):\n",
    "        start_time = format_srt_timestamp(current_time)\n",
    "        end_time = format_srt_timestamp(current_time + duration)\n",
    "        srt_lines.append(f\"{idx}\\n{start_time} --> {end_time}\\n{sentence}\\n\")\n",
    "        current_time += duration + transition_sec  # Account for pause\n",
    "    with open(output_filename, \"w\") as f:\n",
    "        f.write(\"\\n\".join(srt_lines))\n",
    "\n",
    "def parse_timestamp(timestamp_str):\n",
    "    start, end = timestamp_str.split(\" -> \")\n",
    "    return start.strip(), end.strip()\n",
    "\n",
    "def stitch_video_from_segments(segment_list, srt_filename=\"Data/stitched_output.srt\", pause_duration=0.01):\n",
    "    clips = []\n",
    "    clips_info = []\n",
    "    sources = set()\n",
    "\n",
    "    for idx, (filename, timestamp, sentence, distance) in enumerate(segment_list):\n",
    "        lecture_no = os.path.splitext(filename)[0]\n",
    "        video_file = \"Data/Videos/\" + lecture_no + \".mp4\"\n",
    "        start, end = parse_timestamp(timestamp)\n",
    "        sources.add(\"Lecture - \" + lecture_no)\n",
    "\n",
    "        try:\n",
    "            clip = VideoFileClip(video_file).subclip(start, end)\n",
    "\n",
    "            # Resize black screen to match clip size\n",
    "            if idx > 0:\n",
    "                black_clip = ColorClip(size=clip.size, color=(0, 0, 0), duration=pause_duration)\n",
    "                black_clip = black_clip.set_fps(clip.fps)\n",
    "                clips.append(black_clip)\n",
    "\n",
    "            clips.append(clip)\n",
    "            clips_info.append((clip.duration, sentence, start, video_file))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing segment ({filename}, {timestamp}): {e}\")\n",
    "\n",
    "    if not clips:\n",
    "        print(\"No valid clips found.\")\n",
    "        return\n",
    "\n",
    "    final_clip = concatenate_videoclips(clips, method=\"chain\")\n",
    "\n",
    "    final_clip.write_videofile(\n",
    "        \"Data/answer.mp4\",\n",
    "        codec=\"libx264\",\n",
    "        preset=\"ultrafast\",\n",
    "        threads=4,\n",
    "        audio_codec=\"aac\"\n",
    "    )\n",
    "\n",
    "    create_continuous_srt(clips_info, output_filename=srt_filename, transition_sec=pause_duration)\n",
    "\n",
    "stitch_video_from_segments(segment_list, srt_filename=\"Data/stitched_output.srt\", pause_duration=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d4614df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi everyone. In this video, we're going to talk about multilinear regression. So last time we talked about multilinear regression with the higher order terms of a single variable, and this time we're going to talk about multilinear regression model when there are multiple variables.\n",
      "('2.srt', '00:00:06.169 --> 00:00:06.910', '00:00:05.429 --> 00:00:06.209')\n"
     ]
    }
   ],
   "source": [
    "key = list(grouped_sent_to_metadata.keys())[0]\n",
    "print(key)\n",
    "print(grouped_sent_to_metadata[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53200b5",
   "metadata": {},
   "source": [
    "### Summarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24187d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUJAL IS NOT HERE\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Combine all top-K grouped sentences into one text\n",
    "all_text = \" \".join([sent for _, _, sent in related_results])\n",
    "print(all_text)\n",
    "\n",
    "print(\"SUJAL IS NOT HERE\")\n",
    "# Summarize across groups (num_sentences controls how many groups to pick)\n",
    "summary_text = summarizer(all_text, num_sentences=4)  # pick top 4 important groups\n",
    "print(\"SUJAL CODE IS WORKING\")\n",
    "# Map summary back to original grouped sentences to get metadata\n",
    "important_groups = []\n",
    "for filename, timestamp, grouped_sent in related_results:\n",
    "    # Check if this grouped sentence appears in the summary\n",
    "    if grouped_sent in summary_text:\n",
    "        important_groups.append((filename, timestamp, grouped_sent))\n",
    "\n",
    "# Print important groups with metadata\n",
    "print(\"\\nMost Important Groups with Metadata:\")\n",
    "for filename, timestamp, grouped_sent in important_groups:\n",
    "    print(f\"- [{filename} | {timestamp}] {grouped_sent}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
